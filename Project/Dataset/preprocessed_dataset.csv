Judul,Penulis,Link,Abstrak,Preprocessed_Judul,Preprocessed_Abstrak
Sistem Deteksi Android Malware Menggunakan Metode Gated Reccurent Unit (GRU) Deep Learning.,"Abidin, Zainal",http://repository.its.ac.id/99166/,"Malware merupakan perangkat lunak jahat yang dirancang dengan tujuan untuk merusak sistem device-device ( smartphone, computer, dan perangkat-perangkat lain ) korban. Penggunaan sistem operasi Android menempati urutan pertama dalam pangsa pasar. Android merupakan sistem operasi yang menggunakan kernel linux, linux merupakan sistem operasi yang open source. Sehingga dengan kondisi tersebut menyebabkan dengan lebih mudah dan lebih menguntungkan bagi pembuat malware untuk menargetkan operasi sistem yang opensource, dan pada android tidak adanya batasan pemasangan aplikasi dari sumber mana pun yang memungkinkan. Oleh karena itu diperlukan pendeteksi yang dapat mengikuti perkembangan serta menyadarkan pengguna kepeduliannya terhadap kemaanan informasi. Pada tugas akhir ini akan menggunakan dataset Android malware yang teridiri fitur permission, dataset tersebut meru pakan dataset opensource terdiri dari 2 kelas sampel ( malware dan benign) dengan total 11,975 sample (6,000 malware and 5,975 benign) dalam bentuk format file csv. Arsitektur model deep learning yang digunakan adalah arsitektur GRU .Pada penilitian tugas akhir ini akan membandingkan kinerja yang dihasilkan dari tiga optimizer yaitu adamax, radam, dan SGD. Kinerja yangdibandingkan meliputi precision , recall , f1-measure dan specitivity.==================================================================================================================================Malware is malicious software designed with the intent to damage the systems of devices such as smartphones, computers, and other equipment. Android operating systems hold the highest market share, making them a prevalent target for malware creators. As an open-source system using a Linux kernel, Android’s accessibility potentially provides more opportunities for malware developers to exploit. Moreover, Android allows applications to be installed from any source, adding to the vulnerability. Therefore, it is crucial to have detection systems that can evolve with the malware landscape and alert users to potential threats to their information security.In this research, we utilize an open-source Android malware dataset, which consist of permissions features. The dataset consists of two sample classes (malware and benign) with a total of 11,975 samples (6,000 malware and 5,975 benign), represented in a CSV file format. We employ a deep learning model architecture known as the Gated Recurrent Unit (GRU) .This research aims to compare the performance of three optimizers—adamax, radam, and Stochastic Gradient Descent (SGD)—in terms of precision, recall, F1-measure, and specificity. This com- parison aims to determine which optimizer produces the most efficient and accurate malware detection results for Android systems.",sistem deteksi android malware metode gated reccurent unit gru deep learning,malware perangkat lunak jahat rancang tuju rusak sistem devicedevice smartphone computer perangkatperangkat korban guna sistem operasi android tempat urut pangsa pasar android sistem operasi kernel linux linux sistem operasi open source kondisi sebab mudah untung buat malware target operasi sistem opensource android batas pasang aplikasi sumber deteksi ikut kembang sadar guna peduli kemaanan informasi tugas dataset android malware teridiri fitur permission dataset meru pakan dataset opensource 2 kelas sampel malware benign total 11975 sample 6000 malware and 5975 benign bentuk format file csv arsitektur model deep learning arsitektur gru penilitian tugas banding kerja hasil optimizer adamax radam sgd kerja yangdibandingkan liput precision recall f1measure specitivitymalware is malicious software designed with the intent to damage the systems of devices such as smartphones computers and other equipment android operating systems hold the highest market share making them a prevalent target for malware creators as an opensource system using a linux kernel android  s accessibility potentially provides more opportunities for malware developers to exploit moreover android allows applications to be installed from any source adding to the vulnerability therefore it is crucial to have detection systems that can evolve with the malware landscape and alert users to potential threats to their information securityin this research we utilize an opensource android malware dataset which consist of permissions features the dataset consists of two sample classes malware and benign with a total of 11975 samples 6000 malware and 5975 benign represented in a csv file format we employ a deep learning model architecture known as the gated recurrent unit gru this research aims to compare the performance of three optimizers adamax radam and stochastic gradient descent sgd in terms of precision recall f1measure and specificity this com parison aims to determine which optimizer produces the most efficient and accurate malware detection results for android systems
Klasifikasi Penyakit Berdasarkan Foto Rontgen Thorax Menggunakan Metode Support Vector Machine.,"Abiyyi, Muhammad Zuhdi Afi",http://repository.its.ac.id/98468/,"Pada tahun 2019 seluruh dunia terdampak pandemi Covid-19, Covid-19 disebabkan oleh SARS-Cov-2 yang merupakan virus jenis baru dari coronavirus atau kelompok virus yang menginfeksi sistem pernafasan. Virus ini akan memberikan dampak yang berbeda-beda pada setiap orang, mulai dari infeksi tanpa gejala, penyakit ringan seperti flu, hingga penyakit kritis seperti pneumonia, atau bahkan kematian. Keragaman ini menyebabkan para dokter khususnya spesialis paru memerlukan tindakan foto rontgen sebagai penunjang dalam proses penegakan diagnosis. Dan peningkatan jumlah pasien tidak sebanding dengan jumlah tenaga kerja yang memiliki kemampuan dalam menginterpretasikan foto rontgen, karena hanya dokter spesialis radiologi yang memiliki kemampuan tersebut, bahkan dokter spesialis paru pun belum tentu bisa menginterpretasikan foto rontgen. Penelitian Tugas Akhir ini dilakukan dengan metode principle component analysis sebagai salah satu cara dalam melakukan reduksi dimensi terhadap data yang diperoleh. Selain itu, penelitian ini juga menggunakan metode support vector machine sebagai salah satu cara dalam melakukan pengklasifikasian jenis-jenis penyakit berdasarkan foto rontgent. Model SVM terbaik yang didapatkan dari percobaan pada tugas akhir adalah model SVM dengan proporsi data 80% data training, 20% data testing, dan ukuran gambar 200x200. Model tersebut mampu menghasilkan akurasi sebesar 83.65%. Hasil dari penelitian ini diharapkan dapat membantu para tenaga medis maupun pasien dalam mengetahui atau mendiagnosis hasil foto rontgennya sedini mungkin dengan hasil yang tepat dan akurat.=================================================================================================================================In 2019 the whole world was affected by the Covid-19 pandemic, Covid-19 was caused by SARS-Cov-2 which is a new type of coronavirus or a group of viruses that infect the respiratory system. This virus will have a different impact on each person, ranging from asymptomatic infections, minor illnesses such as the flu, to critical illnesses such as pneumonia, or even death. This diversity causes doctors, especially pulmonary specialists, to require X-rays as a support in the process of making a diagnosis. And the increase in the number of patients is not proportional to the number of workers who have the ability to interpret X-rays, because only radiology specialists have this ability, even lung specialists may not necessarily be able to interpret X-rays. This Final Project research was conducted using the principle component analysis method as a way of reducing the dimensions of the data obtained. In addition, this study also used the support vector machine method as a way of classifying the types of diseases based on X-rays. The best SVM model obtained from the experiments in the final assignment is the SVM model with the proportion of data 80% training data, 20% testing data, and 200x200 image size. This model is capable of producing an accuracy of 83.65%. The results of this study are expected to assist medical personnel and patients in knowing or diagnosing X-ray results as early as possible with precise and accurate results.",klasifikasi sakit dasar foto rontgen thorax metode support vector machine,2019 dunia dampak pandemi covid19 covid19 sebab sarscov2 virus jenis coronavirus kelompok virus infeksi sistem nafas virus dampak berbedabeda orang infeksi gejala sakit ringan flu sakit kritis pneumonia mati ragam sebab dokter spesialis paru tindak foto rontgen tunjang proses tega diagnosis tingkat pasien banding tenaga kerja milik mampu interpretasi foto rontgen dokter spesialis radiologi milik mampu dokter spesialis paru interpretasi foto rontgen teliti tugas metode principle component analysis salah reduksi dimensi data oleh teliti metode support vector machine salah klasifikasi jenisjenis sakit dasar foto rontgent model svm baik dapat coba tugas model svm proporsi data 80 data training 20 data testing ukur gambar 200x200 model hasil akurasi 8365 hasil teliti harap bantu tenaga medis pasien diagnosis hasil foto rontgen din hasil akuratin 2019 the whole world was affected by the covid19 pandemic covid19 was caused by sarscov2 which is a new type of coronavirus or a group of viruses that infect the respiratory system this virus will have a different impact on each person ranging from asymptomatic infections minor illnesses such as the flu to critical illnesses such as pneumonia or even death this diversity causes doctors especially pulmonary specialists to require xrays as a support in the process of making a diagnosis and the increase in the number of patients is not proportional to the number of workers who have the ability to interpret xrays because only radiology specialists have this ability even lung specialists may not necessarily be able to interpret xrays this final project research was conducted using the principle component analysis method as a way of reducing the dimensions of the data obtained in addition this study also used the support vector machine method as a way of classifying the types of diseases based on xrays the best svm model obtained from the experiments in the final assignment is the svm model with the proportion of data 80 training data 20 testing data and 200x200 image size this model is capable of producing an accuracy of 8365 the results of this study are expected to assist medical personnel and patients in knowing or diagnosing xray results as early as possible with precise and accurate results
Analisis Sentimen Berdasar Aspek Review Kuliner dan Restoran Menggunakan Latent Dirichlet Allocation dan Support Vector Machine Untuk Meningkatkan Profitabilitas Bisnis Kuliner dan Restoran di Surabaya.,"Ajipangestu, Drajad Bima",http://repository.its.ac.id/84978/,"Makanan merupakan hal yang selalu dekat dengan kita, seiring dengan berkembangnya jumlah penduduk, bisnis kuliner dan restoran terus berkembang. Di kala Pandemi Covid-19, walaupun banyak orang yang tidak bepergian, tetapi sesekali pasti ingin membeli makanan favorit mereka di luar rumah baik itu beli langsung di tempat maupun online. Dengan semakin bertumbuhnya wisata kuliner dan restoran di Indonesia, persaingan antar pelaku bisnis tersebut semakin tinggi. Maka dari itu pada penelitian ini dilakukan analisa sentiment review pelanggan yang mereka tulis di media sosial untuk mendapatkan aspek kuliner dan restoran yang paling berpengaruh dan memiliki sentimen positif tinggi dari pelanggan di Surabaya. Penelitian ini melakukan analisis sentimen review kuliner dan restoran di Surabaya dan bertujuan untuk mendapatkan strategi peningkatkan profitabilitas restoran yang ada di Surabaya. Setiap tweet mengenai kuliner dan restoran akan dikumpulkan sebagai data dan dikategorikan menjadi empat aspek yang kami tentukan yaitu: Price, Taste, Place dan Service. Dalam penelitian ini, data Twitter akan diambil menggunakan Twitter API dan disimpan dalam format JSON. Selanjutnya, akan dilakukan preprocessing. Kemudian dilakukan kategorisasi aspek dengan menggabungkan metode Latent Dirichlet Allocation (LDA) dan semantic similarity untuk meng-kategorisasikan dokumen kedalam 4 aspek kuliner (Price, Taste, Place dan Service). Kemudian dalam menghitung Semantic Similatiry, term list akan diperluas dengan menggunakan metode Term Frequency-Inverse Cluster Frequency (TF-ICF). Setelah itu masuk ke tahap klasifikasi dengan Word Embedding untuk mengekstrak ekstraksi fitur menggunakan metode Global Vector for Word Representation (GloVe). Klasifikasi yang digunakan pada penelitian ini adalah dengan menggunakan Support Vectorc Machine (SVM) dengan 3 modifikasi parameter dari metode SVM yaitu C-SVC, SVC Linear, SVCnu dengan berbagai perubahan kernel untuk mendapatkan hasil terbaik. Analisa sentimen dalam penelitian ini akan membandingkan antara klasifikasi sentimen dengan menggunakan 3 metode perubahan SVM dan Klasifikasi tambahan menggunakan SentiCircle. Performa skenario terbaik untuk analisa sentimen akan diaplikasikan. Performa dari setiap metode dievaluasi menggunakan precision, recall dan F1-Measure. Hasil dari uji coba menunjukkan bahwa performa kategorisasi aspek tertinggi dilakukan dengan melakukan penggabungan metode Latent Dirichlet Allocation (LDA) untuk mencari hidden topic, digabungkan dengan Term Frequency-Inverse Cluster Frequency (TF-ICF) 100% untuk peluasan term dan Semantic Similarity untuk kategorisasi aspek yang mendapatkan hasil performa hingga mencapai 91% dan performa Word Embedding untuk representasi angka vector dengan GloVe dan SVM nuSVC dengan kernel RBF dan perubahan parameter nu 0.1 untuk klasifikasi sentimen mendapatkan performa mencapai 88%. Sehingga, peneliti melakukan penggabungan metode LDA+TF-ICF 100% + Semantic Similarity untuk melakukan kategorisasi aspek dan menggunakan GloVe+SVM NuSVC 0.1 untuk melakukan klasifikasi sentimen pada setiap review. Kemudian, pada evaluasi akhir yang dilakukan, peneliti mendapatkan bahwa aspek service pada kuliner dan restoran memiliki review dengan sentiment negative tinggi yang mencapai 10,869% dibanding dengan sentiment review pada aspect lainnya (price: 4.348, taste: 6.522, place: 4.521) sehingga pemilik bisnis kuliner perlu melakukan perbaikan-perbaikan untuk lebih memperhatikan pelayanan pelanggan dengan tujuan untuk mengurangi jumlah review negative pada aspect service tersebut. Hasil juga menunjukkan bahwa perubahan sentiment (pada positive atau negative sentiment) dipengaruhi oleh aspect yang dimiliki oleh setiap review. Analisa sentimen dari review terhadap aspek kuliner dan restoran dilakukan untuk membantu manajer bisnis atau pemilik usaha kuliner melakukan perbaikan layanan dalam tujuan untuk peningkatan profitabilitas restoran di Surabaya.====================================================================================================Food is something that is always close to us, along with the growing population, the culinary and restaurant business continues to grow. During the Covid-19 Pandemic, although many people don't travel, sometimes they definitely want to buy their favorite food outside the home, whether it's buying directly on the spot or online. With the growing growth of culinary tourism and restaurants in Indonesia, the competition between these business actors is getting higher. Therefore, in this study, an analysis of the customer review sentiments they wrote on social media was carried out to get the most influential culinary and restaurant aspects and have high positive sentiment from customers in Surabaya. This study analyzes the sentiment analysis of culinary and restaurant reviews in Surabaya and aims to obtain a strategy to increase the profitability of restaurants in Surabaya. Every tweet about culinary and restaurant will be collected as data and categorized into four aspects that we determine, namely: Price, Taste, Place and Service.In this study, Twitter data will be retrieved using the Twitter API and stored in JSON format. Next, preprocessing will be carried out. Then the aspect categorization is carried out by combining the Latent Dirichlet Allocation (LDA) and semantic similarity methods to categorize the document into 4 culinary aspects (Price, Taste, Place and Service). Then in calculating Semantic Similatiry, the term list will be expanded using the Term Frequency-Inverse Cluster Frequency (TF-ICF) method. After that, enter the classification stage with Word Embedding to extract feature extraction using the Global Vector for Word Representation (GloVe) method. The classification used in this study is to use the Support Vectorc Machine (SVM) with 3 modifications to the parameters of the SVM method, namely C-SVC, SVC Linear, SVCnu with various kernel changes to get the best results. Sentiment analysis in this study will compare sentiment classification using 3 methods of changing SVM and additional classification using SentiCircle. The best scenario performance for sentiment analysis will be applied.The performance of each method was evaluated using precision, recall and F1-Measure. The results of the trial show that the highest aspect categorization performance is carried out by combining the Latent Dirichlet Allocation (LDA) method to find hidden topics, combined with Term Frequency-Inverse Cluster Frequency (TF-ICF) 100% for term extension and Semantic Similarity for aspect categorization. which got performance results up to 91% and Word Embedding performance for vector number representation with GloVe and SVM nuSVC with RBF kernel and parameter changes to nu 0.1 for sentiment classification got performance reaching 88%. Thus, the researchers combined the LDA+TF-ICF 100% + Semantic Similarity method to categorize aspects and used GloVe+SVM NuSVC 0.1 to classify sentiments for each review. Then, in the final evaluation carried out, the researcher found that the service aspect in culinary and restaurant has a review with a high negative sentiment that reaches 10.869% compared to sentiment reviews on other aspects (price: 4,348, taste: 6,522, place: 4,521) so that business owners culinary needs to make improvements to pay more attention to customer service with the aim of reducing the number of negative reviews on this service aspect. The results also show that changes in sentiment (on positive or negative sentiment) are influenced by the aspect of each review. Sentiment analysis from reviews of culinary and restaurant aspects is carried out to help business managers or culinary business owners make service improvements in order to increase the profitability of restaurants in Surabaya.",analisis sentimen dasar aspek review kuliner restoran latent dirichlet allocation support vector machine tingkat profitabilitas bisnis kuliner restoran surabaya,makan iring kembang duduk bisnis kuliner restoran kembang pandemi covid19 orang pergi beli makan favorit rumah beli langsung online tumbuh wisata kuliner restoran indonesia saing laku bisnis teliti analisa sentiment review langgan tulis media sosial aspek kuliner restoran pengaruh milik sentimen positif langgan surabaya teliti analisis sentimen review kuliner restoran surabaya tuju strategi tingkat profitabilitas restoran surabaya tweet kuliner restoran kumpul data kategori aspek tentu price taste place service teliti data twitter ambil twitter api simpan format json preprocessing kategorisasi aspek gabung metode latent dirichlet allocation lda semantic similarity kategorisasi dokumen dalam 4 aspek kuliner price taste place service hitung semantic similatiry term list luas metode term frequencyinverse cluster frequency tficf masuk tahap klasifikasi word embedding ekstrak ekstraksi fitur metode global vector for word representation glove klasifikasi teliti support vectorc machine svm 3 modifikasi parameter metode svm csvc svc linear svcnu ubah kernel hasil baik analisa sentimen teliti banding klasifikasi sentimen 3 metode ubah svm klasifikasi tambah senticircle performa skenario baik analisa sentimen aplikasi performa metode evaluasi precision recall f1measure hasil uji coba performa kategorisasi aspek tinggi gabung metode latent dirichlet allocation lda cari hidden topic gabung term frequencyinverse cluster frequency tficf 100 luas term semantic similarity kategorisasi aspek hasil performa capai 91 performa word embedding representasi angka vector glove svm nusvc kernel rbf ubah parameter nu 01 klasifikasi sentimen performa capai 88 teliti gabung metode ldatficf 100 semantic similarity kategorisasi aspek glovesvm nusvc 01 klasifikasi sentimen review evaluasi teliti aspek service kuliner restoran milik review sentiment negative capai 10869 banding sentiment review aspect price 4348 taste 6522 place 4521 milik bisnis kuliner perbaikanperbaikan perhati layan langgan tuju kurang review negative aspect service hasil ubah sentiment positive negative sentiment pengaruh aspect milik review analisa sentimen review aspek kuliner restoran bantu manajer bisnis milik usaha kuliner baik layan tuju tingkat profitabilitas restoran surabayafood is something that is always close to us along with the growing population the culinary and restaurant business continues to grow during the covid19 pandemic although many people dont travel sometimes they definitely want to buy their favorite food outside the home whether its buying directly on the spot or online with the growing growth of culinary tourism and restaurants in indonesia the competition between these business actors is getting higher therefore in this study an analysis of the customer review sentiments they wrote on social media was carried out to get the most influential culinary and restaurant aspects and have high positive sentiment from customers in surabaya this study analyzes the sentiment analysis of culinary and restaurant reviews in surabaya and aims to obtain a strategy to increase the profitability of restaurants in surabaya every tweet about culinary and restaurant will be collected as data and categorized into four aspects that we determine namely price taste place and servicein this study twitter data will be retrieved using the twitter api and stored in json format next preprocessing will be carried out then the aspect categorization is carried out by combining the latent dirichlet allocation lda and semantic similarity methods to categorize the document into 4 culinary aspects price taste place and service then in calculating semantic similatiry the term list will be expanded using the term frequencyinverse cluster frequency tficf method after that enter the classification stage with word embedding to extract feature extraction using the global vector for word representation glove method the classification used in this study is to use the support vectorc machine svm with 3 modifications to the parameters of the svm method namely csvc svc linear svcnu with various kernel changes to get the best results sentiment analysis in this study will compare sentiment classification using 3 methods of changing svm and additional classification using senticircle the best scenario performance for sentiment analysis will be appliedthe performance of each method was evaluated using precision recall and f1measure the results of the trial show that the highest aspect categorization performance is carried out by combining the latent dirichlet allocation lda method to find hidden topics combined with term frequencyinverse cluster frequency tficf 100 for term extension and semantic similarity for aspect categorization which got performance results up to 91 and word embedding performance for vector number representation with glove and svm nusvc with rbf kernel and parameter changes to nu 01 for sentiment classification got performance reaching 88 thus the researchers combined the ldatficf 100 semantic similarity method to categorize aspects and used glovesvm nusvc 01 to classify sentiments for each review then in the final evaluation carried out the researcher found that the service aspect in culinary and restaurant has a review with a high negative sentiment that reaches 10869 compared to sentiment reviews on other aspects price 4348 taste 6522 place 4521 so that business owners culinary needs to make improvements to pay more attention to customer service with the aim of reducing the number of negative reviews on this service aspect the results also show that changes in sentiment on positive or negative sentiment are influenced by the aspect of each review sentiment analysis from reviews of culinary and restaurant aspects is carried out to help business managers or culinary business owners make service improvements in order to increase the profitability of restaurants in surabaya
"PENGENALAN WAJAH MENGGUNAKAN METODE DEEP NEURAL NETWORKS DENGAN PERPADUAN METODE DISCRETE WAVELET TRANSFORM, STATIONARY WAVELET TRANSFORM, DAN DISCRETE COSINE TRANSFORM.","Akbar, Afrizal Laksita",http://repository.its.ac.id/78130/,"Metode pengenalan identitas dilakukan dengan menggunakan wajah, sidik jari, telapak tangan, retina mata, atau suara yang umum dikenal dengan metode biometric. Wajah adalah organ tubuh manusia yang paling sering dijadikan indikasi pengenalan seseorang. Dalam pengembangan sistem pengenalan wajah terdapat beberapa isu yang harus diperhatikan, karena dalam proses pengenalan wajah terdapat beberapa faktor yang mempengaruhi, yaitu faktor pencahayaan, ekspresi wajah dan perubahan atribut wajah antara lain dagu, kumis, dan aksesoris yang digunakan misalnya kacamata atau syal. Pada penelitian ini, diusulkan penggabungan metode Discrete Wavelet Transform dan Stationary Wavelet Transform untuk meningkatkan kualitas citra khususnya pada gambar berukuran kecil. Sedangkan metode Histogram Equalization dapat memperbaiki citra pada kondisi citra dengan kelebihan atau kekurangan intensitas cahaya. Metode Discrete Cosine Transform digunakan untuk mengubah citra wajah ke dalam bentuk citra frekuensi untuk ekstraksi fitur pada metode klasifikasi Deep Neural Networks. Pengujian dilakukan dengan 10 fold Cross Validation. Hasil penelitian menunjukkan bahwa penggabungan 4 metode yang diusulkan diperoleh tingkat akurasi yang paling baik sebesar 92.73% dibandingkan dengan metode Histogram Equalization 80.73%, Discrete Wavelet Transform 85.85%, Stationary Wavelet Transform 64.27%, Discrete Cosine Transform 89.50%, penggabunggan Discrete Wavelet Transform dan Stationary Wavelet Transform 86.89%, penggabunggan Histogram Equalization, Discrete Wavelet Transform, dan Stationary Wavelet Transform 69.77%, dan Stationary Wavelet Transform, Discrete Wavelet Transform, dan Histogram Equalization 77.39%.================================================================Personal identification can be done by using face, fingerprint, palm prints, eye’s retina, or voice recognition which commonly called as biometric methods. The face recognition is the most popular and widely used among those biometric methods. However, there are some issues in the implementation of this method. They are lighting factor, facial expression and attributes (chin, mustache, or wearing some accessories). In this study, we propose a combination method of Discrete Wavelet Transform and Stationary Wavelet Transform that able to improve the image quality, especially in the small-sized image. Moreover, we also use Histogram Equalization in order to correct noises such as over or under exposure, Discrete Cosine Transform in order to transform the image into frequency domain, and Deep Neural Networks in order to perform the feature extraction and classify the image. A 10-fold cross-validation method was used in this study. As the result, the proposed method showed the highest accuracy up to 92.73% compared to Histogram Equalization up to 80.73%, Discrete Wavelet Transform up to 85.85%, Stationary Wavelet Transform up to 64.27%, Discrete Cosine Transform up to 89.50%, the combination of Histogram Equalization, Discrete Wavelet Transform, and Stationary Wavelet Transform up to 69.77%, and the combination of Stationary Wavelet Transform, Discrete Wavelet Transform, and Histogram Equalization up to 77.39%.",kenal wajah metode deep neural networks padu metode discrete wavelet transform stationary wavelet transform discrete cosine transform,metode kenal identitas wajah sidik jari telapak tangan retina mata suara kenal metode biometric wajah organ tubuh manusia jadi indikasi kenal kembang sistem kenal wajah isu perhati proses kenal wajah faktor pengaruh faktor cahaya ekspresi wajah ubah atribut wajah dagu kumis aksesoris kacamata syal teliti usul gabung metode discrete wavelet transform stationary wavelet transform tingkat kualitas citra gambar ukur metode histogram equalization baik citra kondisi citra lebih kurang intensitas cahaya metode discrete cosine transform ubah citra wajah bentuk citra frekuensi ekstraksi fitur metode klasifikasi deep neural networks uji 10 fold cross validation hasil teliti gabung 4 metode usul oleh tingkat akurasi 9273 banding metode histogram equalization 8073 discrete wavelet transform 8585 stationary wavelet transform 6427 discrete cosine transform 8950 penggabunggan discrete wavelet transform stationary wavelet transform 8689 penggabunggan histogram equalization discrete wavelet transform stationary wavelet transform 6977 stationary wavelet transform discrete wavelet transform histogram equalization 7739personal identification can be done by using face fingerprint palm prints eye  s retina or voice recognition which commonly called as biometric methods the face recognition is the most popular and widely used among those biometric methods however there are some issues in the implementation of this method they are lighting factor facial expression and attributes chin mustache or wearing some accessories in this study we propose a combination method of discrete wavelet transform and stationary wavelet transform that able to improve the image quality especially in the smallsized image moreover we also use histogram equalization in order to correct noises such as over or under exposure discrete cosine transform in order to transform the image into frequency domain and deep neural networks in order to perform the feature extraction and classify the image a 10fold crossvalidation method was used in this study as the result the proposed method showed the highest accuracy up to 9273 compared to histogram equalization up to 8073 discrete wavelet transform up to 8585 stationary wavelet transform up to 6427 discrete cosine transform up to 8950 the combination of histogram equalization discrete wavelet transform and stationary wavelet transform up to 6977 and the combination of stationary wavelet transform discrete wavelet transform and histogram equalization up to 7739
Evaluasi Pemeliharaan Extruder Machine Dalam Rangka Meningkatkan Efektivitas Waktu Pemeliharaan Dengan Menggunakan Metode Markov Chain.,"Akbar, Ilham",http://repository.its.ac.id/95744/,"PT. WTR merupakan perusahaan yang bergerak dalam bidang manufaktur, produk pipa Polyvinyl Chloride (PVC). Pada proses produksi terdapat mesin yang selalu digunakan yaitu Extruder Machine. Mesin tersebut sangat penting dalam memproduksi pipa PVC sehingga diperlukan suatu metode supaya terhindar dari seringnya terjadi kerusakan. Pemeliharaan meliputi pemeliharaan preventif kegiatan pemeliharaan dalam mencegah kerusakan dan pemeliharaan korektif kegiatan pemeliharaan yang dilakukan setelah mesin rusak. Kegiatan pemeliharaan tersebut dapat mengefektivitaskan waktu pemeliharan. Dengan adanya permasalahan tersebut, maka akan dilakukan perencanaan pemeliharaan mesin pada Extruder Machine. Metode yang digunakan adalah Markov Chain, merupakan teknik matematika yang biasa digunakan untuk melakukan pembuatan model (modelling) bermacam-macam sistem dan proses bisnis. Markov Chain dapat digunakan untuk mengefektivitaskan waktu pemeliharaan dalam suatu perusahaan apalagi untuk perusahaan yang sering terjadi kerusakan pada mesin produksinya. Hasil yang didapatkan alternatif waktu pemeliharaan yang efektif sebesar 184 jam dalam 4 tahun dengan perencanaan pemeliharaan preventive dilakukan setiap 203 hari (6 bulan 17 hari) yang terdapat pada pemeliharaan usulan III menggunakan metode Markov chain.==============================================================================================================================PT WTR is a company engaged in manufacturing, Polyvinyl Chloride (PVC) pipe products. In the production process there is a machine that is always used, namely the Extruder Machine. The machine is very important in producing PVC pipes so that a method is needed to avoid frequent damage. Maintenance includes preventive maintenance of maintenance activities in preventing damage and corrective maintenance of maintenance activities carried out after the machine is damaged. These maintenance activities can streamline maintenance time. With these problems, the machine maintenance planning will be carried out on the Extruder Machine. The method used is Markov Chain, which is a mathematical technique commonly used for modeling various systems and business processes. Markov Chain can be used to streamline maintenance time in a company especially for companies that often occur damage to their production machines. The results obtained alternative effective maintenance time of 184 hours in 4 years with preventive maintenance planning carried out every 203 days (6 months 17 days) contained in the maintenance of proposal III using the Markov Chain method.",evaluasi pelihara extruder machine rangka tingkat efektivitas pelihara metode markov chain,pt wtr usaha gerak bidang manufaktur produk pipa polyvinyl chloride pvc proses produksi mesin extruder machine mesin produksi pipa pvc metode hindar rusa pelihara liput pelihara preventif giat pelihara cegah rusa pelihara korektif giat pelihara mesin rusak giat pelihara efektivitas pemeliharan masalah rencana pelihara mesin extruder machine metode markov chain teknik matematika buat model modelling bermacammacam sistem proses bisnis markov chain efektivitas pelihara usaha usaha rusa mesin produksi hasil dapat alternatif pelihara efektif 184 jam 4 rencana pelihara preventive 203 6 17 pelihara usul iii metode markov chainpt wtr is a company engaged in manufacturing polyvinyl chloride pvc pipe products in the production process there is a machine that is always used namely the extruder machine the machine is very important in producing pvc pipes so that a method is needed to avoid frequent damage maintenance includes preventive maintenance of maintenance activities in preventing damage and corrective maintenance of maintenance activities carried out after the machine is damaged these maintenance activities can streamline maintenance time with these problems the machine maintenance planning will be carried out on the extruder machine the method used is markov chain which is a mathematical technique commonly used for modeling various systems and business processes markov chain can be used to streamline maintenance time in a company especially for companies that often occur damage to their production machines the results obtained alternative effective maintenance time of 184 hours in 4 years with preventive maintenance planning carried out every 203 days 6 months 17 days contained in the maintenance of proposal iii using the markov chain method
Prediksi Data Time Series Multivariat Menggunakan Echo State Network Double Loop Reservoir Dan Harmony Search Optimization.,"Al Haromainy, Muhammad Muharrom",http://repository.its.ac.id/82972/,"Prediksi data deret waktu multivariat banyak diterapkan di berbagai bidang. Beberapa metode digunakan untuk penelitian prediksi data deret waktu, seperti metode Artificial Neural Network (ANN) dan Recurrent Neural Network (RNN). RNN menghasilkan nilai akurasi lebih baik dibandingkan ANN, karena dapat menyimpan memori (feedback loop) dengan melakukan perulangan dalam arsitekturnya kemudian menggunakannya untuk prediksi sehingga tidak membuang informasi dari masa lalu. Namun, salah satu kelemahan utama RNN adalah kesulitan dalam mengadaptasi bobot. Metode pengembangan dari RNN adalah Echo State Network (ESN) model prediksi deret waktu nonlinear multivariat yang kuat dan adaptif. Terlepas dari keunggulan yang disebutkan, pengaturan parameter ESN, seperti inisialisasi parameter reservoir harus dilakukan beberapa kali percobaan hingga mendapatkan hasil yang sesuai. Kemudian, struktur reservoir yang acak menyebabkan ESN membutuhkan waktu yang lama untuk menghasilkan reservoir.Maka dari itu, penelitian ini mengusulkan Echo State Network dengan Double Loop Reservoir untuk proses prediksi data deret waktu multivariat dan dioptimasi menggunakan Harmony Search (HS), sehingga diharapkan dapat meningkatkan performa hasil prediksi. Metode evaluasi menggunakan Root Mean Square Error (MSE) dan Mean Absolute Percent Error (MAPE). Hasil prediksi menggunakan metode ESN-DLR lebih baik dari pada metode RNN dan ESN dengan nilai kesalahan 0.0001 dan 0.0082 untuk dataset 1, 5.88e-6 dan 0.0049 untuk dataset 2. Penentuan nilai parameter metode ESN yang sangat berpengaruh terhadap hasil prediksi, dibantu dengan optimasi metode HS sehingga mendapatkan nilai kesalahan lebih baik sebesar 3.36e-5 dan 0.0048 untuk dataset 1, pada dataset 2 memeroleh nilai kesalahan 1.46e-6 dan 0.0007.=====================================================================================================Multivariate time series data prediction is widely applied in various fields.Several methods are used to research time series data predictions, such as theArtificial Neural Network (ANN) and Recurrent Neural Network (RNN) methods.RNN produces better accuracy than ANN, because it can save memory (feedbackloop) by looping in its architecture then using it for predictions so as not to throwinformation from the past. One of the main drawbacks of the RNN, however, is thedifficulty in adapting weights. The development method of the RNN is the EchoState Network (ESN), a multivariate and adaptive nonlinear time series predictionmodel. Apart from the stated advantages, setting ESN parameters, such as reservoirparameter initialization, must be carried out several times to get the right results.Then, the random reservoir structure causes the ESN to take a long time to generatea reservoir.Therefore, this study proposes Echo State Network with Double LoopReservoir for the process of predicting multivariate time series data and is optimizedusing Harmony Search (HS), so that it is expected to improve the performance ofthe prediction results. The evaluation method uses the Root Mean Square Error(MSE) and Mean Absolute Percent Error (MAPE). The prediction results using theESN-DLR method are better than the RNN and ESN methods with an error valueof 0.0001 and 0.0082 for dataset 1, 5.88e-6 and 0.0049 for dataset 2. Determinationof parameter values for the ESN method which greatly affects the prediction results,is assisted by optimization HS method so that it gets better error values of 3.36e-5and 0.0048 for dataset 1, for dataset 2 it gets error values 1.46e-6 and 0.0007.",prediksi data time series multivariat echo state network double loop reservoir harmony search optimization,prediksi data deret multivariat terap bidang metode teliti prediksi data deret metode artificial neural network ann recurrent neural network rnn rnn hasil nilai akurasi banding ann simpan memori feedback loop ulang arsitektur guna prediksi buang informasi salah lemah utama rnn sulit adaptasi bobot metode kembang rnn echo state network esn model prediksi deret nonlinear multivariat kuat adaptif lepas unggul atur parameter esn inisial parameter reservoir kali coba hasil sesuai struktur reservoir acak sebab esn butuh hasil reservoirmaka teliti usul echo state network double loop reservoir proses prediksi data deret multivariat dioptimasi harmony search hs harap tingkat performa hasil prediksi metode evaluasi root mean square error mse mean absolute percent error mape hasil prediksi metode esndlr metode rnn esn nilai salah 00001 00082 dataset 1 588e6 00049 dataset 2 tentu nilai parameter metode esn pengaruh hasil prediksi bantu optimasi metode hs nilai salah 336e5 00048 dataset 1 dataset 2 oleh nilai salah 146e6 00007multivariate time series data prediction is widely applied in various fieldsseveral methods are used to research time series data predictions such as theartificial neural network ann and recurrent neural network rnn methodsrnn produces better accuracy than ann because it can save memory feedbackloop by looping in its architecture then using it for predictions so as not to throwinformation from the past one of the main drawbacks of the rnn however is thedifficulty in adapting weights the development method of the rnn is the echostate network esn a multivariate and adaptive nonlinear time series predictionmodel apart from the stated advantages setting esn parameters such as reservoirparameter initialization must be carried out several times to get the right resultsthen the random reservoir structure causes the esn to take a long time to generatea reservoirtherefore this study proposes echo state network with double loopreservoir for the process of predicting multivariate time series data and is optimizedusing harmony search hs so that it is expected to improve the performance ofthe prediction results the evaluation method uses the root mean square errormse and mean absolute percent error mape the prediction results using theesndlr method are better than the rnn and esn methods with an error valueof 00001 and 00082 for dataset 1 588e6 and 00049 for dataset 2 determinationof parameter values for the esn method which greatly affects the prediction resultsis assisted by optimization hs method so that it gets better error values of 336e5and 00048 for dataset 1 for dataset 2 it gets error values 146e6 and 00007
Sistem Prediksi Status Stunting dan Severe Stunting Menggunakan Multinomial Logistic Regression pada Anak di Indonesia.,"Aletha, Deanda Bevani",http://repository.its.ac.id/88791/,"Stunting merupakan salah satu kondisi kesehatan malnutrisi yang disebabkan oleh kurangnya gizi kronis balita pada 1.000 Hari Pertama Kehidupan (HPK). Stunting dapat menyebabkan seorang anak menjadi lebih pendek dan penurunan kemampuan akademik dari anak-anak lainnya, serta dapat memiliki keterlambatan dalam berpikir. Stunting dapat terjadi di seluruh penjuru dunia, namun negara berkembang dan negara terbelakang memiliki tingkat stunting diatas batas wajar. Di Indonesia sendiri, angka prevalansi stunting pada tahun 2019 mencapai 27,67%. Walaupun angka ini merupakan penurunan 10 persen dari angka prevalansi stunting pada 2017 dengan angka 37%, namun Indonesia termasuk negara yang memiliki masalah kesehatan berdasarkan dari ketetapan WHO yang menyatakan bahwa batasan masalah gizi tidak lebih dari 20%.  Stunting jika diabaikan dapat berdampak pada Sumber Daya Manusia (SDM) di Indonesia, dimana dapat berdampak buruk pada saing bangsa, akan meningkatkan kerugian ekonomi, serta berpengaruh pada Produk Domestik Bruto (PDB). Pengkajian dan penelitian telah dilakukan untuk mengetahui dan memahami lebih dalam mengenai penyebab serta dampak dari stunting di Indonesia. Namun, masih sedikit penelitian yang membahas model prediksi status stunting dan severe stunting pada anak-anak Indonesia menggunakan data Indonesian Family Life Survey (IFLS) dengan metode Multinomial Logistic Regression.Hasil dari tugas akhir ini adalah suatu sistem prediksi yang dapat mendeteksi status stunting pada anak yang dibagi menjadi tiga kategori, yaitu normal, stunting dan severe stunting menggunakan Multinomial Logistic Regression. Tugas akhir ini akan menggunakan data sekunder pada IFLS 4 tahun 2007 dan IFLS 5 tahun 2014. Label stunting dibuat dengan mengacu pada Standar Antropometri Anak oleh Kementerian Kesehatan Indonesia yan dihitung dengan menggunakan tinggi badan anak, jenis kelamin anak, dan usia anak. Variabel independent pada penelitian ini antara lain jenis kelamin, umur, tinggi badan anak, tinggi badan ibu, usia ibu saat melahirkan, berat badan lahir, tingkat pendidikan terakhir ibu, area tempat tinggal dan sanitasi lingkungan Variabel ini akan dianalisa menggunakan metode Kruskal-Wallis untuk variabel kategori dan T-test untuk variabel numerik. Metode Multinomial Logistic Regression yang digunakan pada tugas akhir ini akan dicoba dengan 3 skenario dan 3 rasio pembagian data latih dan data uji. Parameter terbaik dari skenario-skenario yang diuji coba akan dijadikan acuan dalam membangun model sistem prediksi status stunting.Variabel yang memiliki korelasi secara signifikan dengan perubahan status stunting anak antara lain tinggi badan balita, berat badan balita, tinggi badan ibu, pendidikan ibu terakhir, area tempat tinggal, dan sanitasi lingkungan,. Dari skenario yang dilakukan, model prediksi yang memiliki hasil akurasi tertinggi adalah penggunaan variabel signifikan dengan rasio pembagian data 90:10 dan solver newton-cg dengan nilai akurasi 62%.================================================================================================Stunting is one of the health conditions of malnutrition caused by chronic undernutrition of toddlers in the First 1,000 Days of Life (HPK). Stunting could cause a child to be a lot shorter and decreases their ability academically. Stunting could happen all around the globe, but developing countries have a stunting rate above the average limit. In Indonesia, the stunting prevalence rate on 2019 reached 27.67%. Although this figure is a 10% decrease from the stunting prevalence rate in 2017 which is 37%, Indonesia has health problems based on the WHO decision which states that the limit for nutritional problems could not be higher than 20%. When ignored, stunting could affect human resources in Indonesia, which could negatively impact on nation's competitiveness, economy, and gross domestic product (PDB). Studies and researches have been conducted to find out and understand more deeply about the causes and impacts of stunting in Indonesia. However, there are still few studies that discuss models for predicting stunting status and severe stunting in Indonesian children using Indonesian Family Life Survey (IFLS) data with the Multinomial Logistic Regression method.The result of this final project is a prediction system that can detect stunting status in children which is divided into three categories, namely normal, stunting and severe stunting using Multinomial Logistic Regression. This final project will use data on IFLS 4 in 2007 and IFLS 5 in 2014 from RAND Corporation. The stunting status label was made by referring to Antropometry Standards of the Ministry of Health Republic of Indonesia which was calculated with child’s height, age and gender. Independent variables include data on child’s gender, child’s age, child’s height, child’s weight, mother’s height, mother’s age of birth, child’s birth weight, mother’s latest education level, area of residence, and environmental sanitation. These variables will be analyzed using Kruskal-Wallis test for categorical variables and T-test for numerical variables. The Multinomial Logistic Regression method used in this final project will be tested with 3 scenarios and 3 ratios of training and test data distribution. The best parameters from the tested scenarios will be used as a reference in building a stunting status prediction system model.Variables that have a significant correlation with changes in child stunting status include toddler's height, toddler's weight, mother's height, last mother's education, area of residence, and environmental sanitation. From the scenarios carried out, the prediction model that has the highest accuracy results is the use of significant variables with a data sharing ratio of 90:10 and the newton-cg solver with an accuracy value of 62%.",sistem prediksi status stunting severe stunting multinomial logistic regression anak indonesia,stunting salah kondisi sehat malnutrisi sebab kurang gizi kronis balita 1000 hidup hpk stunting sebab anak pendek turun mampu akademik anakanak milik lambat pikir stunting penjuru dunia negara kembang negara belakang milik tingkat stunting atas batas wajar indonesia angka prevalansi stunting 2019 capai 2767 angka turun 10 persen angka prevalansi stunting 2017 angka 37 indonesia negara milik sehat dasar tetap who batas gizi 20 stunting abai dampak sumber daya manusia sdm indonesia mana dampak buruk saing bangsa tingkat rugi ekonomi pengaruh produk domestik bruto pdb kaji teliti paham sebab dampak stunting indonesia teliti bahas model prediksi status stunting severe stunting anakanak indonesia data indonesian family life survey ifls metode multinomial logistic regressionhasil tugas sistem prediksi deteksi status stunting anak bagi kategori normal stunting severe stunting multinomial logistic regression tugas data sekunder ifls 4 2007 ifls 5 2014 label stunting acu standar antropometri anak menteri sehat indonesia yan hitung badan anak jenis kelamin anak usia anak variabel independent teliti jenis kelamin umur badan anak badan usia lahir berat badan lahir tingkat didik area tinggal sanitasi lingkung variabel dianalisa metode kruskalwallis variabel kategori ttest variabel numerik metode multinomial logistic regression tugas coba 3 skenario 3 rasio bagi data latih data uji parameter baik skenarioskenario uji coba jadi acu bangun model sistem prediksi status stuntingvariabel milik korelasi signifikan ubah status stunting anak badan balita berat badan balita badan didik area tinggal sanitasi lingkung skenario model prediksi milik hasil akurasi tinggi guna variabel signifikan rasio bagi data 9010 solver newtoncg nilai akurasi 62stunting is one of the health conditions of malnutrition caused by chronic undernutrition of toddlers in the first 1000 days of life hpk stunting could cause a child to be a lot shorter and decreases their ability academically stunting could happen all around the globe but developing countries have a stunting rate above the average limit in indonesia the stunting prevalence rate on 2019 reached 2767 although this figure is a 10 decrease from the stunting prevalence rate in 2017 which is 37 indonesia has health problems based on the who decision which states that the limit for nutritional problems could not be higher than 20 when ignored stunting could affect human resources in indonesia which could negatively impact on nations competitiveness economy and gross domestic product pdb studies and researches have been conducted to find out and understand more deeply about the causes and impacts of stunting in indonesia however there are still few studies that discuss models for predicting stunting status and severe stunting in indonesian children using indonesian family life survey ifls data with the multinomial logistic regression methodthe result of this final project is a prediction system that can detect stunting status in children which is divided into three categories namely normal stunting and severe stunting using multinomial logistic regression this final project will use data on ifls 4 in 2007 and ifls 5 in 2014 from rand corporation the stunting status label was made by referring to antropometry standards of the ministry of health republic of indonesia which was calculated with child  s height age and gender independent variables include data on child  s gender child  s age child  s height child  s weight mother  s height mother  s age of birth child  s birth weight mother  s latest education level area of residence and environmental sanitation these variables will be analyzed using kruskalwallis test for categorical variables and ttest for numerical variables the multinomial logistic regression method used in this final project will be tested with 3 scenarios and 3 ratios of training and test data distribution the best parameters from the tested scenarios will be used as a reference in building a stunting status prediction system modelvariables that have a significant correlation with changes in child stunting status include toddlers height toddlers weight mothers height last mothers education area of residence and environmental sanitation from the scenarios carried out the prediction model that has the highest accuracy results is the use of significant variables with a data sharing ratio of 9010 and the newtoncg solver with an accuracy value of 62
Klasifikasi Bahasa Isyarat Indonesia Penyandang Tunawicara Convolutional Neural Network-2D Time-Distributed.,"Amri Rahman, Afrizal",http://repository.its.ac.id/93868/,"Bahasa merupakan sebuah media untuk berkomunikas dengan sesamai antar manusia. Namun dalam bahasa ada yang dilakukan dengan verbal dan nonverbal, dan para penyandang tunawicara merupakan salah satunya untuk berkomunikasi secara non-verbal. Teknologi motion capture merupakan teknologi yang dikembangkan dengan pesat hingga digunakan dalam bisnis industri. Dan tantangan terbaru pada teknologi tersebut adalah mampu mengimplementasikannya ke dalam bahasa isyarat Indonesia khusus penyandang tuna wicara. Hal tersebut bertujuan agar para penyandang tuna-wicara tidak memilikikesusahan untuk berkomunikasi dengan masyarakat umum. Dengan adanya penelitian ini bisa bermanfaat bagi peneliti sebelumnya untuk dikembangkan lagi dan menjadi inovasi dalam menyelesaikan sebuah permasalah.================================================================================================Language is a medium for communicating with fellow human beings. However, in language there are things that are done verbally and non-verbally, and people with disabilities are one of them to communicate non-verbally. Motion capture technology is a technology that is being developed rapidly to be used in industrial businesses. And the latest challenge in this technology is being able to implement it into Indonesian sign language specifically for the speech impaired. This is intended so that people with speech impairments do not have difficulty communicating with the general public. With this research, it can be useful for previous researchers to be developed again and become an innovation in solving a problem.",klasifikasi bahasa isyarat indonesia sandang tunawicara convolutional neural network2d timedistributed,bahasa media berkomunikas sama manusia bahasa verbal nonverbal sandang tunawicara salah satu komunikasi nonverbal teknologi motion capture teknologi kembang pesat bisnis industri tantang baru teknologi implementasi bahasa isyarat indonesia khusus sandang tuna wicara tuju sandang tunawicara memilikikesusahan komunikasi masyarakat teliti manfaat teliti kembang inovasi selesai permasalahlanguage is a medium for communicating with fellow human beings however in language there are things that are done verbally and nonverbally and people with disabilities are one of them to communicate nonverbally motion capture technology is a technology that is being developed rapidly to be used in industrial businesses and the latest challenge in this technology is being able to implement it into indonesian sign language specifically for the speech impaired this is intended so that people with speech impairments do not have difficulty communicating with the general public with this research it can be useful for previous researchers to be developed again and become an innovation in solving a problem
Kontrol Pergerakan Kursi Roda Berbasis Head Gesture Menggunakan CNN.,"Ananto, Batrisyia Zahrani",http://repository.its.ac.id/108772/,"Kuadriplegia atau tetraplegia merupakan kelumpuhan yang terjadi pada keempat anggota gerak tubuh. Karena limitasi yang mereka miliki, maka mereka memerlukan kursi roda. Mengendalikan pergerakan kursi roda bisa menjadi tantangan, terutama bagi pengguna dengan keterbatasan fisik signifikan. Diperlukan pengembangan sistem kontrol kursi roda yang dapat digunakan penderita tetraplegia. Salah satu pendekatan yang dapat dilakukan untuk mengontrol kursi roda adalah dengan melakukan ekstraksi fitur wajah dan pendeteksian head gesture dengan menggunakan mediapipe. Kemudian data head gesture yang telah diklasifikasikan akan dikirimkan oleh NUC ke sistem kontrol kursi roda. Sistem kontrol tersebutlah yang akan mengatur arah gerak kursi roda. Dengan menggunakan metodologi yang digunakan, dapat ditarik beberapa kesimpulan dari pengujian yang telah dilakukan. Model yang akan digunakan memiliki arsitektur CNN 7 layer dengan Convolutional 2D 64, 256 dan diakhiri dengan Dense 512. Jarak model yang paling tinggi akurasinya adalah 50 sentimeter. Intensitas cahaya yang paling tinggi akurasinya adalah 110 lux. Kecepatan FPS laptop penulis lebih tinggi daripada NUC yang digunakan. Rata-rata waktu delay renspons motor adalah 0,3025423729 detik dan inference time nya adalah 0,07220 detik. Rata-rata kestabilan gerak motor kursi roda untuk pendeteksian selama 2 detik adalah 8,9364 detik.==================================================================================================================================Quadriplegia or tetraplegia is paralysis that occurs in all four limbs. Because of their limitations, they need a wheelchair. Controlling the movement of a wheelchair can be a challenge, especially for users with significant physical limitations. It is necessary to develop a wheelchair control system that can be used by tetraplegic sufferers. One approach that can be taken to control a wheelchair is to extract facial features and detect head gesture using mediapipe. Then the classified head gesture data will be sent by the NUC to the wheelchair control system. This control system will regulate the direction of movement of the wheelchair. By using the methodology used, several conclusions can be drawn from the tests that have been carried out. The model that will be used has a 7 layer CNN architecture with Convolutional 2D 64, 256 and ending with Dense 512. The model distance with the highest accuracy is 50 centimeters. The light intensity with the highest accuracy is 110 lux. The FPS speed of the writer's laptop is higher than the NUC used. The average motor response time delay is 0.3025423729 seconds and the inference time is 0.07220 seconds. The average stability of the wheelchair motor for detection for 2 seconds is 8,9364 seconds.",kontrol gera kursi roda bas head gesture cnn,kuadriplegia tetraplegia lumpuh empat anggota gerak tubuh limitasi milik kursi roda kendali gera kursi roda tantang guna batas fisik signifikan kembang sistem kontrol kursi roda derita tetraplegia salah dekat kontrol kursi roda ekstraksi fitur wajah deteksi head gesture mediapipe data head gesture klasifikasi kirim nuc sistem kontrol kursi roda sistem kontrol atur arah gerak kursi roda metodologi tarik simpul uji model milik arsitektur cnn 7 layer convolutional 2d 64 256 dense 512 jarak model akurasi 50 sentimeter intensitas cahaya akurasi 110 lux cepat fps laptop tulis nuc ratarata delay renspons motor 03025423729 detik inference time nya 007220 detik ratarata stabil gerak motor kursi roda deteksi 2 detik 89364 detikquadriplegia or tetraplegia is paralysis that occurs in all four limbs because of their limitations they need a wheelchair controlling the movement of a wheelchair can be a challenge especially for users with significant physical limitations it is necessary to develop a wheelchair control system that can be used by tetraplegic sufferers one approach that can be taken to control a wheelchair is to extract facial features and detect head gesture using mediapipe then the classified head gesture data will be sent by the nuc to the wheelchair control system this control system will regulate the direction of movement of the wheelchair by using the methodology used several conclusions can be drawn from the tests that have been carried out the model that will be used has a 7 layer cnn architecture with convolutional 2d 64 256 and ending with dense 512 the model distance with the highest accuracy is 50 centimeters the light intensity with the highest accuracy is 110 lux the fps speed of the writers laptop is higher than the nuc used the average motor response time delay is 03025423729 seconds and the inference time is 007220 seconds the average stability of the wheelchair motor for detection for 2 seconds is 89364 seconds
Multimodal Fusion dengan Pendekatan Deep Learning pada Sistem Pendeteksi Risiko Komplikasi Continuous Ambulatory Peritoneal Dialysis (CAPD).,"Andhina, Jayanti Totti",http://repository.its.ac.id/110204/,"Continuous Ambulatory Peritoneal Dialysis (CAPD) merupakan alternatif terapi dialisis peritoneal yang dapat dimanfaatkan secara optimal karena pasien dapat melakukannya sendiri di rumah dan tidak memerlukan sarana transportasi menuju pusat hemodialisis. Di sisi lain, CAPD juga memiliki kekurangan berupa risiko infeksi yang tinggi akibat kegagalan membran peritoneum yang disebabkan oleh kelalaian pasien dan pengoperasian yang tidak sesuai standar. Kelainan warna pada cairan effluent dialysate dan kondisi klinis pasien dapat menjadi indikator awal untuk mendeteksi adanya risiko komplikasi pada pasien CAPD. Sebelumnya, telah terdapat penelitian yang memanfaatkan deep learning image classification untuk mendeteksi risiko komplikasi CAPD menggunakan citra effluent dialysate. Pada penelitian ini, ditambahkan faktor kondisi klinis pasien yang didapatkan dari aplikasi SahabatCAPD dan berbentuk data tabular. Kedua indikator (gambar dan tabular) kemudian digabungkan sehingga menghasilkan model deep learning dan machine learning baru yang dapat mendeteksi risiko komplikasi pada pasien CAPD. Metode deep learning dengan transfer learning fine tuning digunakan untuk menghasilkan model baru untuk task klasifikasi citra effluent dialysate dari beberapa model pre-trained: YOLOv8, MobileNetV3, ConvNeXTV2, dan MobileViTv2. Selanjutnya, model deep learning terbaik digunakan untuk ekstraksi fitur dari setiap gambar. Hasil ekstraksi fitur berupa single feature vector dengan dimensi 512 dan 2 yang didapatkan dari fully connected layer akan digabungkan dengan data klinis pasien, seperti jenis cairan, volume masuk, volume ultrafiltrasi, dan dwell time. Penggabungan data pada penelitian ini menggunakan pendekatan multimodal early fusion. Data-data yang telah diseleksi dalam bentuk tabular selanjutnya akan dijadikan input pada model machine learning: logistic regression, k-nearest neighbors (KNN), support vector machine, decision tree, random forest, dan AdaBoost. Hasil penelitian menunjukkan bahwa model deep learning terbaik dicapai oleh MobileNetV3 dengan recall 86% dan F1-score 92% dengan praproses augmentasi. Sedangkan untuk model machine learning terbaik dicapai oleh random forest dan AdaBoost 95% dan F1-score sebesar 98% pada skenario penggunaan 2 fitur ekstraksi gambar dan 4 fitur data tabular tanpa oversampling. Dari hasil tersebut, kedua model diharapkan dapat membantu dalam hal deteksi risiko komplikasi CAPD pada SahabatCAPD sehingga pasien dan tenaga medis dapat menentukan tindakan lebih dini apabila ditemukan risiko komplikasi yang serius.====================================================================================================================================Continuous Ambulatory Peritoneal Dialysis (CAPD) is an alternative peritoneal dialysis therapy that can be optimally utilized because patients can perform it themselves at home, eliminating the need for transportation to a hemodialysis center. However, CAPD also has the drawback of a high risk of infection due to peritoneal membrane failure caused by patient negligence and improper operation. Discoloration of the effluent dialysate and the patient's clinical condition can be early indicators for detecting the risk of complications in CAPD patients. Previously, there have been studies utilizing deep learning image classification to detect CAPD complication risks using effluent dialysate images. In this study, the patient's clinical condition factors obtained from the SahabatCAPD application in tabular data form are added. Both indicators (images and tabular data) are then combined to produce a new deep learning and machine learning model that can detect complication risks in CAPD patients. The deep learning method with transfer learning fine-tuning is used to create a new model for the effluent dialysate image classification task from several pre-trained models: YOLOv8, MobileNetV3, ConvNeXTV2, and MobileViTv2. The best deep learning model is then used to extract features from each image. The feature extraction results in a single feature vector with dimensions 512 and 2 obtained from the fully connected layer will be combined with the patient's clinical data, such as fluid type, input volume, ultrafiltration volume, and dwell time. Data combination in this study uses the multimodal early fusion approach. The selected tabular data will then be used as input to machine learning models: logistic regression, k-nearest neighbors (KNN), support vector machine, decision tree, random forest, and AdaBoost. The study results show that the best deep learning model is achieved by MobileNetV3 with a recall of 86% and an F1-score of 92% with augmentation preprocessing. Meanwhile, the best machine learning models are achieved by random forest and AdaBoost with 95% recall and an F1-score of 98% in the scenario using 2 image extraction features and 4 tabular data features without oversampling. From these results, both models are expected to assist in detecting CAPD complication risks in SahabatCAPD so that patients and medical personnel can take early action if serious complication risks are found.",multimodal fusion dekat deep learning sistem deteksi risiko komplikasi continuous ambulatory peritoneal dialysis capd,continuous ambulatory peritoneal dialysis capd alternatif terapi dialisis peritoneal manfaat optimal pasien laku rumah sarana transportasi pusat hemodialisis sisi capd milik kurang risiko infeksi akibat gagal membran peritoneum sebab lalai pasien operasi sesuai standar lain warna cair effluent dialysate kondisi klinis pasien indikator deteksi risiko komplikasi pasien capd teliti manfaat deep learning image classification deteksi risiko komplikasi capd citra effluent dialysate teliti faktor kondisi klinis pasien dapat aplikasi sahabatcapd bentuk data tabular indikator gambar tabular gabung hasil model deep learning machine learning deteksi risiko komplikasi pasien capd metode deep learning transfer learning fine tuning hasil model task klasifikasi citra effluent dialysate model pretrained yolov8 mobilenetv3 convnextv2 mobilevitv2 model deep learning baik ekstraksi fitur gambar hasil ekstraksi fitur single feature vector dimensi 512 2 dapat fully connected layer gabung data klinis pasien jenis cair volume masuk volume ultrafiltrasi dwell time gabung data teliti dekat multimodal early fusion datadata seleksi bentuk tabular jadi input model machine learning logistic regression knearest neighbors knn support vector machine decision tree random forest adaboost hasil teliti model deep learning baik capai mobilenetv3 recall 86 f1score 92 praproses augmentasi model machine learning baik capai random forest adaboost 95 f1score 98 skenario guna 2 fitur ekstraksi gambar 4 fitur data tabular oversampling hasil model harap bantu deteksi risiko komplikasi capd sahabatcapd pasien tenaga medis tentu tindak temu risiko komplikasi seriuscontinuous ambulatory peritoneal dialysis capd is an alternative peritoneal dialysis therapy that can be optimally utilized because patients can perform it themselves at home eliminating the need for transportation to a hemodialysis center however capd also has the drawback of a high risk of infection due to peritoneal membrane failure caused by patient negligence and improper operation discoloration of the effluent dialysate and the patients clinical condition can be early indicators for detecting the risk of complications in capd patients previously there have been studies utilizing deep learning image classification to detect capd complication risks using effluent dialysate images in this study the patients clinical condition factors obtained from the sahabatcapd application in tabular data form are added both indicators images and tabular data are then combined to produce a new deep learning and machine learning model that can detect complication risks in capd patients the deep learning method with transfer learning finetuning is used to create a new model for the effluent dialysate image classification task from several pretrained models yolov8 mobilenetv3 convnextv2 and mobilevitv2 the best deep learning model is then used to extract features from each image the feature extraction results in a single feature vector with dimensions 512 and 2 obtained from the fully connected layer will be combined with the patients clinical data such as fluid type input volume ultrafiltration volume and dwell time data combination in this study uses the multimodal early fusion approach the selected tabular data will then be used as input to machine learning models logistic regression knearest neighbors knn support vector machine decision tree random forest and adaboost the study results show that the best deep learning model is achieved by mobilenetv3 with a recall of 86 and an f1score of 92 with augmentation preprocessing meanwhile the best machine learning models are achieved by random forest and adaboost with 95 recall and an f1score of 98 in the scenario using 2 image extraction features and 4 tabular data features without oversampling from these results both models are expected to assist in detecting capd complication risks in sahabatcapd so that patients and medical personnel can take early action if serious complication risks are found
Klasifikasi Jenis Bentuk Tubuh Berdasarkan Data Antropometri dengan Metode Deep Learning.,"Anfasya, Yusuf",http://repository.its.ac.id/106705/,"Bentuk tubuh manusia memiliki variasi yang kompleks serta dapat mempengaruhi kesehatan serta penampilan seseorang. Dalam identifikasi dan klasifikasi jenis bentuk tubuh secara akurat dapat memberikan wawasan penting dalam bidang kesehatan, kebugaran, dan fesyen. Metode konvensional dalam melakukan klasifikasi bentuk tubuh yaitu dengan menggunakan 3D scanner, depth camera, dan foto tubuh memiliki sebuah kekurangan dikarenakan dalam melakukan pengenalan masih membutuhkan perangkat keras. Selain menggunakan metode konvensional, terdapat pendekatan dengan memanfaatkan metode deep learning pada data antropometri dan gambar tubuh. Penelitian ini dilakukan untuk mengatasi kelemahan dari beberapa penelitian sebelumnya dalam melakukan klasifikasi bentuk tubuh. Penelitian ini menggunakan data antropometri yang mencakup tinggi badan, berat badan, lebar dada, lebar pinggang, dan lebar pinggul. Data ini diperoleh dari internet dan merupakan antropometri dari artis-artis internasional. Sebagai langkah awal, data tersebut dibersihkan dan dianalisis menggunakan metode Exploratory Data Analysis. Setelah itu, data dibagi menjadi dua bagian, yaitu data latih dan data uji, untuk membantu dalam pembentukan model. Model dieksplorasi dengan menggunakan metode Sequential Attention berbasis Deep Learning. Variasi K-Fold Validation digunakan untuk menggeneralisasi model dan melakukan evaluasi kinerja setiap model. Hasil optimasi model TabNet menunjukkan kinerja yang lebih baik dibandingkan dengan model MLP, SVM, dan Random Forest. Selisih tertinggi dengan SVM dengan perbedaan akurasi 4,9% dan selisih terendah dengan perbedaan akurasi 3,1% . Hasil kinerja menunjukkan bahwa metode yang digunakan dalam penelitian ini efektif dalam meningkatkan akurasi prediksi.=============================================================================================================================The shape of the human body has complex variations and can affect a person`s health and appearance. Accurately identifying and classifying body shape types can provide important insights into the fields of health, fitness, and fashion. The conventional method of classifying body shape, namely using a 3D scanner, depth camera and body photos, has a drawback because recognition still requires hardware. Apart from using conventional methods, there are approaches that use deep learning methods on anthropometric data and body images. This research was conducted to overcome the weaknesses of several previous studies in classifying body shape. This study used anthropometric data that included height, weight, chest width, waist width, and hip width. This data is obtained from the internet and is anthropometry from international artists. As a first step, the data is cleaned and analyzed using the Exploratory Data Analysis method. After that, the data is divided into two parts, namely the training data and the test data, to assist in the formation of the model. The model was explored using Deep Learning-based Sequential Attention methods. A variation of K-Fold Validation is used to generalize models and evaluate the performance of each model. The optimization results of the TabNet model show better performance compared to MLP, SVM, and Random Forest models. The highest difference with SVM with an accuracy difference of 4.9% and the lowest difference with an accuracy difference of 3.1%. The performance results showed that the method used in this study was effective in improving the accuracy of predictions.",klasifikasi jenis bentuk tubuh dasar data antropometri metode deep learning,bentuk tubuh manusia milik variasi kompleks pengaruh sehat tampil identifikasi klasifikasi jenis bentuk tubuh akurat wawas bidang sehat bugar fesyen metode konvensional klasifikasi bentuk tubuh 3d scanner depth camera foto tubuh milik kurang kenal butuh perangkat keras metode konvensional dekat manfaat metode deep learning data antropometri gambar tubuh teliti atas lemah teliti klasifikasi bentuk tubuh teliti data antropometri cakup badan berat badan lebar dada lebar pinggang lebar pinggul data oleh internet antropometri artisartis internasional langkah data bersih analis metode exploratory data analysis data bagi data latih data uji bantu bentuk model model eksplorasi metode sequential attention bas deep learning variasi kfold validation generalisasi model evaluasi kerja model hasil optimasi model tabnet kerja banding model mlp svm random forest selisih tinggi svm beda akurasi 49 selisih rendah beda akurasi 31 hasil kerja metode teliti efektif tingkat akurasi prediksithe shape of the human body has complex variations and can affect a persons health and appearance accurately identifying and classifying body shape types can provide important insights into the fields of health fitness and fashion the conventional method of classifying body shape namely using a 3d scanner depth camera and body photos has a drawback because recognition still requires hardware apart from using conventional methods there are approaches that use deep learning methods on anthropometric data and body images this research was conducted to overcome the weaknesses of several previous studies in classifying body shape this study used anthropometric data that included height weight chest width waist width and hip width this data is obtained from the internet and is anthropometry from international artists as a first step the data is cleaned and analyzed using the exploratory data analysis method after that the data is divided into two parts namely the training data and the test data to assist in the formation of the model the model was explored using deep learningbased sequential attention methods a variation of kfold validation is used to generalize models and evaluate the performance of each model the optimization results of the tabnet model show better performance compared to mlp svm and random forest models the highest difference with svm with an accuracy difference of 49 and the lowest difference with an accuracy difference of 31 the performance results showed that the method used in this study was effective in improving the accuracy of predictions
Deteksi Multiview Kanker Payudara Dari Citra Mamografi Menggunakan Multiview Convolutional Neural Network.,"Anggraini, Sisilia",http://repository.its.ac.id/103425/,"Deteksi dini kanker payudara melalui citra mammografi sangat penting untuk meningkatkan tingkat kesembuhan dan mengurangi angka kematian. Penelitian sebelumnya telah mengembangkan deteksi kanker payudara dari citra tampilan Craniocaudal (CC) atau Mediolateral Oblique (MLO), namun masih dilakukan secara terpisah. Oleh karena itu, penelitian ini bertujuan untuk mengembangkan sistem deteksi kanker payudara berbasis komputer  menggunakan citra mammografi dari tampilan CC dan MLO secara bersamaan. Dengan mengintegrasikan informasi dari kedua tampilan, diharapkan dapat meningkatkan akurasi deteksi. Metode deteksi yang digunakan adalah Multiview Convolutional Neural Network (MVCNN) yang dirancang khusus untuk menerima tampilan CC dan MLO. Sistem yang dikembangkan untuk mengenali pola dan fitur dari kedua tampilan sehingga dapat memberikan informasi berupa hasil deteksi normal atau abnormal. Untuk meningkatkan efektivitas sistem deteksi, dilakukan prapemrosesan citra yang meliputi tahap background removal, image enhancement, dan pectoral muscle removal. Pengujian sistem deteksi dilakukan dengan membandingkan pembelajaran pada tiga jenis dataset yang telah dibentuk. Hasil penelitian menunjukkan bahwa pembelajaran pada dataset kedua, tanpa menggunakan pectoral muscle removal menghasilkan hasil yang optimal yaitu akurasi deteksi sebesar 98,63%, presisi sebesar 97,29%, sensitivitas 100%, dan spesifisitas 97,29%. Dengan menggabungkan metode MVCNN dengan dataset yang efektif, sistem deteksi yang dikembangkan dapat membantu meningkatkan efisiensi dan akurasi dalam proses diagnosis kanker payudara. Sehingga berpotensi untuk meningkatkan kesembuhan dan mengurangi angka kematian akibat kanker payudara melalui deteksi dini yang lebih efektif.===============================================================================================================================Early detection of breast cancer through mammography images is crucial to improve survival rates and reduce mortality. Previous studies have developed breast cancer detection from Craniocaudal (CC) or Mediolateral Oblique (MLO) view images, but they have been performed separately. Therefore, this study aims to develop a computer-based breast cancer detection system using mammography images from both CC and MLO views simultaneously. By integrating information from both views, it is expected to improve detection accuracy. The detection method used is the Multiview Convolutional Neural Network (MVCNN) specifically designed to handle CC and MLO views. The developed system recognizes patterns and features from both views to provide information regarding normal or abnormal detection outcomes. To enhance the effectiveness of the detection system, image pre-processing is conducted, including background removal, image enhancement, and pectoral muscle removal stages. The detection system is tested by comparing the learning performance on three types of formed datasets. The research results show that learning on the second dataset, without using pectoral muscle removal, yields optimal outcomes with a detection accuracy of 98.63%, precision of 97.29%, sensitivity of 100%, and specificity of 97.29%. By combining the MVCNN method with an effective dataset, the developed detection system can help improve efficiency and accuracy in breast cancer diagnosis processes. Thus, it has the potential to enhance survival rates and reduce breast cancer-related mortality through more effective early detection.",deteksi multiview kanker payudara citra mamografi multiview convolutional neural network,deteksi kanker payudara citra mammografi tingkat tingkat sembuh kurang angka mati teliti kembang deteksi kanker payudara citra tampil craniocaudal cc mediolateral oblique mlo pisah teliti tuju kembang sistem deteksi kanker payudara bas komputer citra mammografi tampil cc mlo sama integrasi informasi tampil harap tingkat akurasi deteksi metode deteksi multiview convolutional neural network mvcnn rancang khusus terima tampil cc mlo sistem kembang nali pola fitur tampil informasi hasil deteksi normal abnormal tingkat efektivitas sistem deteksi prapemrosesan citra liput tahap background removal image enhancement pectoral muscle removal uji sistem deteksi banding ajar jenis dataset bentuk hasil teliti ajar dataset pectoral muscle removal hasil hasil optimal akurasi deteksi 9863 presisi 9729 sensitivitas 100 spesifisitas 9729 gabung metode mvcnn dataset efektif sistem deteksi kembang bantu tingkat efisiensi akurasi proses diagnosis kanker payudara potensi tingkat sembuh kurang angka mati akibat kanker payudara deteksi efektifearly detection of breast cancer through mammography images is crucial to improve survival rates and reduce mortality previous studies have developed breast cancer detection from craniocaudal cc or mediolateral oblique mlo view images but they have been performed separately therefore this study aims to develop a computerbased breast cancer detection system using mammography images from both cc and mlo views simultaneously by integrating information from both views it is expected to improve detection accuracy the detection method used is the multiview convolutional neural network mvcnn specifically designed to handle cc and mlo views the developed system recognizes patterns and features from both views to provide information regarding normal or abnormal detection outcomes to enhance the effectiveness of the detection system image preprocessing is conducted including background removal image enhancement and pectoral muscle removal stages the detection system is tested by comparing the learning performance on three types of formed datasets the research results show that learning on the second dataset without using pectoral muscle removal yields optimal outcomes with a detection accuracy of 9863 precision of 9729 sensitivity of 100 and specificity of 9729 by combining the mvcnn method with an effective dataset the developed detection system can help improve efficiency and accuracy in breast cancer diagnosis processes thus it has the potential to enhance survival rates and reduce breast cancerrelated mortality through more effective early detection
Analisa Komparatif Pada Prediksi Konsumsi Bahan Bakar Dengan Metode Machine Learning.,"Antoridi, Hizbi Muhamadsyah",http://repository.its.ac.id/102800/,"There were issues with fuel on the older ships, such as a lack of fuel when sailing due to the manual nature of the estimation calculations. One of the causes of problems is also the lack of computers. Consequently, this study was conducted to develop a solution to this problem;  fuel consumption estimation will be performed using machine learning. Machine learning is a subset of Artificial Intelligence that uses regression to make predictions. Using twelve variables, including ship speed (knot), engine RPM, engine torque (kNm), engine power (kW), charge air pressure (bar), charge air temperature (°C), calorific heat value (kj/kg), SFOC (g/kWh), period of seawave (s), ambient air pressure (Pa), temperature (°C), humidity (%) and the fuel oil consumption (l/h), it should be possible to accurately estimate fuel consumption. This study's  research yielded classification and estimation that are rated as excellent. Polynomial Regression is the most accurate regression method, with a 99.99% accuracy rate and RMSE value of 0.13867 and MAE value of 0.108, when compared to other regression methods.=================================================================================================================================Ada beberapa masalah terkait bahan bakar pada kapal yang lebih tua, seperti kekurangan bahan bakar saat berlayar karena perhitungan estimasi yang masih manual. Salah satu penyebab masalah juga kurangnya komputer. Oleh karena itu, penelitian ini dilakukan untuk mengembangkan solusi atas masalah tersebut; Estimasi konsumsi bahan bakar akan dilakukan dengan menggunakan machine learning. Pembelajaran mesin adalah bagian dari Kecerdasan Buatan yang menggunakan regresi untuk membuat prediksi. Dengan menggunakan dua belas variabel, kecepatan kapal (knot), RPM mesin, torsi mesin (kNm), daya mesin (kW), tekanan udara muatan (bar), suhu udara muatan (°C), calorific heat value (kj/kg), SFO (g/kWh), periode gelombang laut (s), tekanan udara ambien (Pa), suhu (°C), kelembaban (%), seharusnya dapat memperkirakan konsumsi bahan bakar secara akurat. Penelitian studi ini menghasilkan klasifikasi dan estimasi yang dinilai sangat baik. Regresi Polinomial merupakan metode regresi yang paling akurat, dengan tingkat akurasi 99,99% dan nilai RMSE sebesar 0,13867 serta nilai MAE sebesar 0,108, jika dibandingkan dengan metode regresi lainnya.",analisa komparatif prediksi konsumsi bahan bakar metode machine learning,there were issues with fuel on the older ships such as a lack of fuel when sailing due to the manual nature of the estimation calculations one of the causes of problems is also the lack of computers consequently this study was conducted to develop a solution to this problem fuel consumption estimation will be performed using machine learning machine learning is a subset of artificial intelligence that uses regression to make predictions using twelve variables including ship speed knot engine rpm engine torque knm engine power kw charge air pressure bar charge air temperature c calorific heat value kjkg sfoc gkwh period of seawave s ambient air pressure pa temperature c humidity and the fuel oil consumption lh it should be possible to accurately estimate fuel consumption this studys research yielded classification and estimation that are rated as excellent polynomial regression is the most accurate regression method with a 9999 accuracy rate and rmse value of 013867 and mae value of 0108 when compared to other regression methodsada kait bahan bakar kapal tua kurang bahan bakar layar hitung estimasi manual salah sebab kurang komputer teliti kembang solusi estimasi konsumsi bahan bakar machine learning ajar mesin cerdas buat regresi prediksi belas variabel cepat kapal knot rpm mesin torsi mesin knm daya mesin kw tekan udara muat bar suhu udara muat c calorific heat value kjkg sfo gkwh periode gelombang laut s tekan udara ambien pa suhu c kelembaban konsumsi bahan bakar akurat teliti studi hasil klasifikasi estimasi nilai regresi polinomial metode regresi akurat tingkat akurasi 9999 nilai rmse 013867 nilai mae 0108 banding metode regresi
Design and Dynamic Analysis of Inertia Wheel Pendulum with LQR Controller and Kalman Filter.,"Aqila, Marsha Haya",http://repository.its.ac.id/102817/,"Industri otomotif merupakan salah satu sektor yang berkembang pesat, contohnya yaitu kendaraan. Salah satu tantangan kritis pada kendaraan yaitu menjaga stabilitas pada saat pergerakaan secara tiba-tiba dan adanya perubahan kondisi jalan. Prinsip yang bisa dilakukan, yaitu dengan menggunakan inertia wheel pendulum. Secara prinsip, Inertia Wheel Pendulum menggunakan sistem kontrol untuk menggerakkan inertia wheel ke posisi tegak. Penelitian ini terdiri dari desain dan analisis dinamik Inertia Wheel Pendulum dengan kontroler LQR dan Kalman Filter. Pada penelitian ini digunakan tiga jenis model inertia wheel dengan momen inersia yang berbeda. Sistem kontrol didesain dengan menurunkan persamaan gerak sistem Inertia wheel Pendulum dengan persamaan lagrange, kemudian hasil penurunan persamaan gerak digunakan untuk mendesain sistem kendali. Hasil penelitian menunjukkan bahwa momen inersia memiliki dampak signifikan pada sistem inertia wheel pendulum. Inertia wheel dengan momen inersia yang lebih kecil dapat menstabilkan pendulum lebih cepat, sementara momen inersia yang lebih besar menghasilkan kecepatan sudut yang lebih tinggi dan stabilisasi yang lebih lambat.  Sistem Inertia Wheel Pendulum menggunakan pengendali LQR ketika dibandingkan dengan menggunakan filter Kalman mencapai stabilisasi dalam kurun waktu lambat, tegangan masukan yang lebih tinggi, yang menyebabkan peningkatan kecepatan sudut pendulum, namun memiliki kecepatan sudut motor BLDC yang lebih lambat. Filter Kalman menawarkan stabilisasi yang lebih cepat dan efisien dengan tegangan masukan yang lebih rendah dan respons yang lebih halus melalui estimasi variabel dan pengurangan noise, sehingga menjadi pilihan sistem pengendalian yang terbaik untuk sistem inertia wheel pendulum.=================================================================================================================================The automotive industries are one of the sectors that are growing massively, one example of an automotive industry product is a vehicle. Ensuring vehicle stability during abrupt movements and changing road conditions is a critical challenge. One principle employed to maintain stability is using an inertia wheel pendulum. In principle, an inertia wheel pendulum uses a control system to drive the inertia wheel pendulum to the upward position This research uses an Inertia Wheel Pendulum system with three types of inertia wheel models with different moments of inertia. The control system is designed by deriving the equation of motion of the Inertia Wheel Pendulum System with the Lagrange equation. Then the results of deriving the equations of motion are used to design the control system. The result shows that the moment of inertia value significantly affects the inertia wheel pendulum system. Smaller values lead to faster stabilization, while larger values result in higher angular velocities and slower stabilization. The Inertia wheel pendulum system with LQR controller is stabilized in longer duration with small value of the angular velocity of BLDC motor and requires higher input voltage, leading to increased angular velocity of the pendulum. Meanwhile, the Kalman filter offers faster and more efficient stabilization with smaller input voltage and smoother response through variable estimation and noise reduction, making it the suitable control system for the inertia wheel pendulum.",design and dynamic analysis of inertia wheel pendulum with lqr controller and kalman filter,industri otomotif salah sektor kembang pesat contoh kendara salah tantang kritis kendara jaga stabilitas pergerakaan tibatiba ubah kondisi jalan prinsip inertia wheel pendulum prinsip inertia wheel pendulum sistem kontrol gerak inertia wheel posisi tegak teliti desain analisis dinamik inertia wheel pendulum kontroler lqr kalman filter teliti jenis model inertia wheel momen inersia beda sistem kontrol desain turun sama gerak sistem inertia wheel pendulum sama lagrange hasil turun sama gerak desain sistem kendali hasil teliti momen inersia milik dampak signifikan sistem inertia wheel pendulum inertia wheel momen inersia stabil pendulum cepat momen inersia hasil cepat sudut stabilisasi lambat sistem inertia wheel pendulum kendali lqr banding filter kalman capai stabilisasi kurun lambat tegang masuk sebab tingkat cepat sudut pendulum milik cepat sudut motor bldc lambat filter kalman tawar stabilisasi cepat efisien tegang masuk rendah respons halus estimasi variabel kurang noise pilih sistem kendali baik sistem inertia wheel pendulumthe automotive industries are one of the sectors that are growing massively one example of an automotive industry product is a vehicle ensuring vehicle stability during abrupt movements and changing road conditions is a critical challenge one principle employed to maintain stability is using an inertia wheel pendulum in principle an inertia wheel pendulum uses a control system to drive the inertia wheel pendulum to the upward position this research uses an inertia wheel pendulum system with three types of inertia wheel models with different moments of inertia the control system is designed by deriving the equation of motion of the inertia wheel pendulum system with the lagrange equation then the results of deriving the equations of motion are used to design the control system the result shows that the moment of inertia value significantly affects the inertia wheel pendulum system smaller values lead to faster stabilization while larger values result in higher angular velocities and slower stabilization the inertia wheel pendulum system with lqr controller is stabilized in longer duration with small value of the angular velocity of bldc motor and requires higher input voltage leading to increased angular velocity of the pendulum meanwhile the kalman filter offers faster and more efficient stabilization with smaller input voltage and smoother response through variable estimation and noise reduction making it the suitable control system for the inertia wheel pendulum
Pembuatan Model Bahasa Medik Berbahasa Indonesia Dengan Menggunakan Teknik Masked Language Model Pada BERT.,"Arasyi, Firqa Aqila Noor",http://repository.its.ac.id/88310/,"Pembuatan Language Model (LM) untuk domain yang lebih spesifik belum banyak dilakukan terutama dalam teks berbahasa Indonesia. Disisi lain jenis teks dalam Bahasa Indonesia juga sangat beragam seperti teks berita, politik, sains, finansial, ekonomi, kedokteran, dan berbagai jenis teks lainnya. Namun banyaknya jenis teks tersebut belum terdapat model bahasa yang spesifk untuk mengatasi permasalahan terkait domain tersebut. Oleh karena itu, penelitian ini bertujuan untuk melakukan pembuatan Language Model (LM) untuk domain spesifik yaitu kedokteran. Model yang digunakan adalah model BERT. Data yang digunakan dalam penelitian ini adalah data yang diambil dari kumpulan jurnal di bidang kedokteran berbahasa Indonesia. Pada tahap evaluasi penelitian ini menggunakan dataset terjemahan dan hanya akan diuji untuk permasalahan klasifikasi teks. Penelitian ini menghasilkan sebuah model yang kami namai sebagai MedBERT. Penelitian ini juga berhasil menunjukan bahwa language model yang telah dilatih dalam teks latih didomain yang lebih spesifik memiliki performa yang lebih baik daripada model yang dilatih dalam teks latih yang lebih general. Uji performa dari model MedBERT yang kami hasilkan memiliki performa yang kompetitif jika dibandingkan dengan language model berbahasa Indonesia lainnya yang lebih general seperti IndoBERT dan IndoLEM. Model MedBERT yang dihasilkan juga memiliki performa yang jauh lebih baik jika dibandingkan dengan model bahasa multilingual seperti mBERT dan XLM-RoBERTa dengan selisih akurasi sekitar 2% - 10% lebih baik daripada kedua model tersebut. Hasil evaluasi nilai akurasi tertinggi yang didapatkan oleh model MedBERT adalah 42 persen.================================================================================================Creating Language Model (LM) for more specific domains has not been done much, especially in Indonesian texts. On the other hand, the types of texts in Indonesian are also very diverse, such as news texts, politics, science, finance, economics, medicine, and various other types of texts. However, there are many types of texts that do not have a specific language model to solve problems related to this domain. Therefore, this study aims to make a Language Model (LM) for a specific domain, namely medicine. The model used is the BERT model. The data used in this study is data taken from a collection of journals in the field of medicine in Indonesian language. At the evaluation stage, this research uses a translation dataset and will only be tested for text classification problems. This research resulted in a model which we named as MedBERT. This study also succeeded in showing that language models that have been trained in training texts in more specific domains have better performance than models trained in more general training texts. The performance test of our MedBERT model has a competitive performance when compared to other more general Indonesian language models such as IndoBERT and IndoLEM. The resulting MedBERT model also has a much better performance when compared to multilingual language models such as mBERT and XLM-RoBERTa with an accuracy difference of about 2% - 10% better than the two models. The evaluation result of the highest accuracy value obtained by the MedBERT model is 42 percent.",buat model bahasa medik bahasa indonesia teknik masked language model bert,buat language model lm domain spesifik teks bahasa indonesia sisi jenis teks bahasa indonesia agam teks berita politik sains finansial ekonomi dokter jenis teks banyak jenis teks model bahasa spesifk atas masalah kait domain teliti tuju buat language model lm domain spesifik dokter model model bert data teliti data ambil kumpul jurnal bidang dokter bahasa indonesia tahap evaluasi teliti dataset terjemah uji masalah klasifikasi teks teliti hasil model nama medbert teliti hasil tunjuk language model latih teks latih domain spesifik milik performa model latih teks latih general uji performa model medbert hasil milik performa kompetitif banding language model bahasa indonesia general indobert indolem model medbert hasil milik performa banding model bahasa multilingual mbert xlmroberta selisih akurasi 2 10 model hasil evaluasi nilai akurasi tinggi dapat model medbert 42 persencreating language model lm for more specific domains has not been done much especially in indonesian texts on the other hand the types of texts in indonesian are also very diverse such as news texts politics science finance economics medicine and various other types of texts however there are many types of texts that do not have a specific language model to solve problems related to this domain therefore this study aims to make a language model lm for a specific domain namely medicine the model used is the bert model the data used in this study is data taken from a collection of journals in the field of medicine in indonesian language at the evaluation stage this research uses a translation dataset and will only be tested for text classification problems this research resulted in a model which we named as medbert this study also succeeded in showing that language models that have been trained in training texts in more specific domains have better performance than models trained in more general training texts the performance test of our medbert model has a competitive performance when compared to other more general indonesian language models such as indobert and indolem the resulting medbert model also has a much better performance when compared to multilingual language models such as mbert and xlmroberta with an accuracy difference of about 2 10 better than the two models the evaluation result of the highest accuracy value obtained by the medbert model is 42 percent
Prediksi Nilai Warna Larutan (ICUMSA) dan Besar Jenis Butir (BJB) untuk Menentukan Kualitas Gula Berdasarkan Metode Support Vector Machine (Studi Kasus: PT Pabrik Gula Rajawali I Surabaya).,"Ariani, Ria Widiya",http://repository.its.ac.id/49577/,"Gula merupakan salah satu komoditas yang sering kita temuidalam kehidupan sehari-hari. Gula biasa dimanfaatkan untukmenambah cita rasa manis pada makanan atau minuman.Penggunaan gula tidak hanya oleh rumah tangga namun jugabanyak digunakan di bidang industri, khususnya industri dibidang makanan dan minuman. Mengingat penggunaan gulabaik di rumah tangga atau industri, tidak heran jika jumlahkonsumsi gula di Indonesia juga besar. Sebagai bahan untukmembuat produk makanan atau minuman yang akandikonsumsi oleh masyarakat, gula yang dipergunakan tentunyaperlu memenuhi standar kualitas atau mutu tertentu agar layakuntuk dikonsumsi. Untuk itu, pemerintah melalui BadanStandardisasi Nasional telah mengatur standar mengenaikualitas gula.PT. PG Rajawali I Surabaya merupakan salah satu pabrik yangmemproduksi gula. Untuk dapat melakukan pengujian kualitasgula, perusahaan memerlukan pihak ketiga yang berlokasidiluar Surabaya. Hal ini menyebabkan perusahaan mengalamikesulitan untuk melakukan pengujian kualitas gula yaitu berupapermasalahan biaya yang mahal dan waktu yang dibutuhkanuntuk pengujian lama.Untuk mengatasi permasalahan tersebut, perusahaan dapatmelakukan prediksi kualitas gula mereka sendiri. Karena dapatxidilakukan sendiri, waktu yang dibutuhkan bisa menjadi lebihsingkat sehingga bisa segera dilakukan evaluasi jika hasilproduksi kualitasnya rendah. Melalui penelitian tugas akhir ini,metode Support Vector Machine (SVM) digunakan untukmemprediksi kualitas gula yang dihasilkan di PT. PG RajawaliI Surabaya. SVM merupakan salah satu metode yang dapatdigunakan untuk melakukan prediksi dengan mencari nilaihyperplane dari data-data yang ada. Nilai prediksi dapatdioptimumkan dengan mengatur parameter-parameter yangmempengaruhi prediksi. Model terbaik untuk data trainingditentukan berdasarkan nilai root mean square error (RMSE)dan absolute error dari hasil prediksi. Namun model terbaikuntuk testing ditentukan berdasarkan nilai MAPE yangdihasilkan.Pada penelitian ini, terdapat tiga jenis kualitas gula yangdihasilkan yaitu GKP 1, GKP 2, dan gula yang tidak termasukkedalam GKP 1 atau GKP 2 (undefined). Untuk menentukankualitas gula tersebut, proses produksi sangat berpengaruh.Dimana pada masing-masing proses produksi terdapatbeberapa parameter yang perlu dipenuhi agar gula tersebutbisa menghasilkan kualitas yang sesuai standar.Model terbaik untuk data testing warna larutan (ICUMSA)yang memberikan MAPE terbaik adalah menggunakan kernelRadial, C=18.65, gamma=0.045 dengan MAPE 31% yangtermasuk kategori cukup baik. Model terbaik untuk data testingBJB menghasilkan MAPE sebesar 8% termasuk kategori sangatbaik. Untuk kernel Dot nilai C=1 dan kernel Radial C=0.675serta gamma=8.65. Sedangkan hasil akurasi klasifikasikualitas gula terbaik adalah sebesar 73.33% denganmenggunakan kernel Dot.",prediksi nilai warna larut icumsa jenis butir bjb tentu kualitas gula dasar metode support vector machine studi pt pabrik gula rajawali i surabaya,gula salah komoditas temuidalam hidup seharihari gula manfaat untukmenambah cita manis makan minumanpenggunaan gula rumah tangga jugabanyak bidang industri industri bidang makan minum guna gulabaik rumah tangga industri heran jumlahkonsumsi gula indonesia bahan untukmembuat produk makan minum akandikonsumsi masyarakat gula tentunyaperlu penuh standar kualitas mutu layakuntuk konsumsi perintah badanstandardisasi nasional atur standar mengenaikualitas gulapt pg rajawali i surabaya salah pabrik yangmemproduksi gula uji kualitasgula usaha tiga berlokasidiluar surabaya sebab usaha mengalamikesulitan uji kualitas gula berupapermasalahan biaya mahal dibutuhkanuntuk uji lamauntuk atas masalah usaha dapatmelakukan prediksi kualitas gula dapatxidilakukan butuh lebihsingkat evaluasi hasilproduksi kualitas rendah teliti tugas inimetode support vector machine svm untukmemprediksi kualitas gula hasil pt pg rajawali surabaya svm salah metode dapatdigunakan prediksi cari nilaihyperplane datadata nilai prediksi dapatdioptimumkan atur parameterparameter yangmempengaruhi prediksi model baik data trainingditentukan dasar nilai root mean square error rmsedan absolute error hasil prediksi model terbaikuntuk testing tentu dasar nilai mape yangdihasilkanpada teliti jenis kualitas gula yangdihasilkan gkp 1 gkp 2 gula termasukkedalam gkp 1 gkp 2 undefined menentukankualitas gula proses produksi berpengaruhdimana masingmasing proses produksi terdapatbeberapa parameter penuh gula tersebutbisa hasil kualitas sesuai standarmodel baik data testing warna larut icumsayang mape baik kernelradial c1865 gamma0045 mape 31 yangtermasuk kategori model baik data testingbjb hasil mape 8 kategori sangatbaik kernel dot nilai c1 kernel radial c0675serta gamma865 hasil akurasi klasifikasikualitas gula baik 7333 denganmenggunakan kernel dot
Rancang Bangun Sistem Monitoring Kualitas Udara Berdasarkan Indeks Standar Pencemaran Udara Berbasis IoT dan Machine Learning.,"Armandito, Axellino Anggoro",http://repository.its.ac.id/106154/,"Polusi udara telah menjadi masalah lingkungan yang mendesak di seluruh dunia karena memiliki dampak signifikan terhadap kesehatan manusia. Menurut Indeks Standar Pencemaran Udara (ISPU), terdapat 7 parameter partikulat dan gas, seperti PM10, PM2.5, karbon monoksida (CO), nitrogen dioksida (NO2), sulfur dioksida (SO2), ozon (O3), dan hidrokarbon (HC). Untuk mengatasi permasalahan ini penulis mengajukan sistem pemantauan kualitas udara yang dapat diakses secara real time yang mampu mendeteksi 6 parameter gas, yaitu PM1, PM10, PM2.5, CO, NO2, dan O3. Sistem ini juga dilengkapi dengan model kecerdasan buatan algoritma eXtreme Gradient Boosting (XGBoost) untuk memprediksi 6 polutan gas di dalam ruangan selama 1 jam kedepan. Arsitektur sistem mengintegrasikan mikrokontroler yang terhubung dengan sensor untuk mengukur dan mengirimkan data ke MQTT Broker, memungkinkan web server untuk mengolah data sesuai pedoman ISPU. Model algoritma XGBoost menunjukkan performa dengan akurasi yang lebih baik dibandingkan Random Forest dan SVM menggunakan default parameter dengan hasil CO memiliki MAE sebesar 3,5166, RMSE 4,4629, dan MAPE 1,2259%. NO2 menunjukkan MAE 0,0491, RMSE 0,0541, dan MAPE 0,3865%, O3 memiliki MAE 1,5457, RMSE 1,8233, dan MAPE 2,3848%, PM1 memiliki MAE 1,1789, RMSE 1,3505, MAPE 2,9976%, PM2.5 memiliki MAE 1,6855, RMSE 1,9016, MAPE 3,4948%, dan PM10 memiliki MAE 1,5301, RMSE 1,7601, dan MAPE 2,7949%.=================================================================================================================================Air pollution has become an urgent environmental issue worldwide due to its significant impact on human health. According to the Air Pollution Standard Index (ISPU), there are 7 particulate and gas parameters, such as PM10, PM2.5, Carbon Monoxide (CO), Nitrogen Dioxide (NO2), Sulfur Dioxide (SO2), Ozone (O3), and Hydrocarbon (HC). To address this issue, the authors propose a real-time accessible air quality monitoring system capable of detecting 6 gas parameters, namely PM1, PM10, PM2.5, CO, NO2, and O3. This system is also equipped with an Artificial Intelligence model using the eXtreme Gradient Boosting (XGBoost) algorithm to predict 6 indoor gas pollutants for the next hour. The system architecture integrates a microcontroller connected to sensors for measuring and transmitting data to the MQTT Broker, enabling the web server to process data according to the ISPU guidelines. Using default parameters, the XGBoost algorithm model demonstrates better performance accuracy than Random Forest and SVM, with CO yielding an MAE of 3.5166, RMSE of 4.4629, and MAPE of 1.2259%. NO2 exhibits an MAE of 0.0491, RMSE of 0.0541, and MAPE of 0.3865%, O3 shows an MAE of 1.5457, RMSE of 1.8233, and MAPE of 2.3848%, PM1 has an MAE of 1.1789, RMSE of 1.3505, MAPE of 2.9976%, PM2.5 has an MAE of 1.6855, RMSE of 1.9016, MAPE of 3.4948%, and PM10 has an MAE of 1.5301, RMSE of 1.7601, and MAPE of 2.7949%.",rancang bangun sistem monitoring kualitas udara dasar indeks standar cemar udara bas iot machine learning,polusi udara lingkung desak dunia milik dampak signifikan sehat manusia indeks standar cemar udara ispu 7 parameter partikulat gas pm10 pm25 karbon monoksida co nitrogen dioksida no2 sulfur dioksida so2 ozon o3 hidrokarbon hc atas masalah tulis aju sistem pantau kualitas udara akses real time deteksi 6 parameter gas pm1 pm10 pm25 co no2 o3 sistem lengkap model cerdas buat algoritma extreme gradient boosting xgboost prediksi 6 polutan gas ruang 1 jam depan arsitektur sistem integrasi mikrokontroler hubung sensor ukur kirim data mqtt broker web server olah data sesuai pedoman ispu model algoritma xgboost performa akurasi banding random forest svm default parameter hasil co milik mae 35166 rmse 44629 mape 12259 no2 mae 00491 rmse 00541 mape 03865 o3 milik mae 15457 rmse 18233 mape 23848 pm1 milik mae 11789 rmse 13505 mape 29976 pm25 milik mae 16855 rmse 19016 mape 34948 pm10 milik mae 15301 rmse 17601 mape 27949air pollution has become an urgent environmental issue worldwide due to its significant impact on human health according to the air pollution standard index ispu there are 7 particulate and gas parameters such as pm10 pm25 carbon monoxide co nitrogen dioxide no2 sulfur dioxide so2 ozone o3 and hydrocarbon hc to address this issue the authors propose a realtime accessible air quality monitoring system capable of detecting 6 gas parameters namely pm1 pm10 pm25 co no2 and o3 this system is also equipped with an artificial intelligence model using the extreme gradient boosting xgboost algorithm to predict 6 indoor gas pollutants for the next hour the system architecture integrates a microcontroller connected to sensors for measuring and transmitting data to the mqtt broker enabling the web server to process data according to the ispu guidelines using default parameters the xgboost algorithm model demonstrates better performance accuracy than random forest and svm with co yielding an mae of 35166 rmse of 44629 and mape of 12259 no2 exhibits an mae of 00491 rmse of 00541 and mape of 03865 o3 shows an mae of 15457 rmse of 18233 and mape of 23848 pm1 has an mae of 11789 rmse of 13505 mape of 29976 pm25 has an mae of 16855 rmse of 19016 mape of 34948 and pm10 has an mae of 15301 rmse of 17601 and mape of 27949
Analisis Klasifikasi Sentimen Tentang Penggunaan Aplikasi Mypertamina Untuk Pembelian Bbm Menggunakan Support Vector Machine Pada Media Sosial Twitter.,"As'ad, Muhammad Abiyyu",http://repository.its.ac.id/101725/,"Kelangkaan bahan bakar minyak dapat menjadi salah satu ancaman bagi negara, dikarenakan bahan bakar minyak merupakan salah satu kebutuhan yang diperlukan oleh mayoritas penduduk Indonesia. Kelangkaan bahan bakar minyak yang sudah mulai terjadi membuat perusahaan Pertamina mengeluarkan kebijakan untuk membatasi dan mengontrol pembelian jenis bahan bakar solar dan pertalite. Wujud Pertamina dalam merealisasikan kebijakan ini yaitu dengan menggunakan aplikasi buatan mereka yang bernama MyPertamina. Aplikasi ini bertujuan untuk mempermudah masyarakat saat bertransaksi serta mengontrol pembelian bahan bakar minyak yang sudah dilakukan. Adanya aplikasi MyPertamina membuat banyak argumen di masyarakat, khususnya masyarakat yang daerahnya menjadi uji coba dari kebijakan baru ini. Argumen yang terbentuk di masyarakat sangatlah beragam meliputi argumen positif dan negatif. oleh karena itu, diperlukan kajian pada aplikasi ini dengan cara menganalisis sentimen masyarakat pengguna Twitter tentang aplikasi MyPertamina. Untuk analisis yang dilakukan akan menggunakan algoritma Support Vector Machine dengan membandingkan kernel linear dan radial basis function (RBF) agar mendapatkan metode terbaik dalam pengklasifikasian sentimen. Setelah dilakukannya analisa didapatkan bahwa pengkategorian teks setelah dilakukannya pra-proses terbagi menjadi 60% sentimen negatif dan 40% sentimen positif dan pengklasifikasian algoritma Support Vector Machine menggunakan kernel RBF mendapatkan hasil akurasi sebesar 87,77% sedangkan penggunaan kernel linear mendapatkan hasil akurasi sebesar 88,03%, yang dapat disimpulkan bahwa penggunaan kernel linear dan RBF untuk klasifikasi sentimen data tweet terkait aplikasi MyPertamina adalah baik tetapi lebih cenderung lebih baik menggunkan kernel linear.=================================================================================================================================The scarcity of fuel oil can be a threat to the country, because fuel oil is one of the needs needed by the majority of Indonesia's population. The scarcity of fuel oil that has started to occur has forced the Pertamina company to issue a policy to limit and control the purchase of diesel and pertalite fuel types. Pertamina's form in realizing this policy is by using an application made by them called MyPertamina. This application aims to make it easier for people when making transactions and controlling purchases of fuel oil that have been made. The existence of the MyPertamina application makes a lot of arguments in society, especially people whose areas are being tested for this new policy. Arguments formed in the community are very diverse including positive and negative arguments. Therefore it is necessary to study this application by analyzing the sentiments of Twitter users about the MyPertamina application. The analysis will use the Support Vector Machine algorithm by comparing the linear and radial basis function (RBF) kernels to get the best method for classifying sentiment. After doing the analysis, it was found that the text categorization after pre-processing was divided into 60% negative sentiment and 40% positive sentiment and the classification of the Support Vector Machine algorithm using the RBF kernel obtains an accuracy of 87.77% while the use of a linear kernel obtains an accuracy of 88.03%, which can be concluded that the use of a linear kernel and RBF for classification sentiment tweet data related to the MyPertamina application is good but it tends to be better to use a linear kernel.",analisis klasifikasi sentimen guna aplikasi mypertamina beli bbm support vector machine media sosial twitter,langka bahan bakar minyak salah ancam negara bahan bakar minyak salah butuh mayoritas duduk indonesia langka bahan bakar minyak usaha pertamina keluar bijak batas kontrol beli jenis bahan bakar solar pertalite wujud pertamina realisasi bijak aplikasi buat nama mypertamina aplikasi tuju mudah masyarakat transaksi kontrol beli bahan bakar minyak aplikasi mypertamina argumen masyarakat masyarakat daerah uji coba bijak argumen bentuk masyarakat agam liput argumen positif negatif kaji aplikasi analis sentimen masyarakat guna twitter aplikasi mypertamina analisis algoritma support vector machine banding kernel linear radial basis function rbf metode baik klasifikasi sentimen laku analisa dapat kategori teks laku praproses bagi 60 sentimen negatif 40 sentimen positif klasifikasi algoritma support vector machine kernel rbf hasil akurasi 8777 guna kernel linear hasil akurasi 8803 simpul guna kernel linear rbf klasifikasi sentimen data tweet kait aplikasi mypertamina cenderung gun kernel linearthe scarcity of fuel oil can be a threat to the country because fuel oil is one of the needs needed by the majority of indonesias population the scarcity of fuel oil that has started to occur has forced the pertamina company to issue a policy to limit and control the purchase of diesel and pertalite fuel types pertaminas form in realizing this policy is by using an application made by them called mypertamina this application aims to make it easier for people when making transactions and controlling purchases of fuel oil that have been made the existence of the mypertamina application makes a lot of arguments in society especially people whose areas are being tested for this new policy arguments formed in the community are very diverse including positive and negative arguments therefore it is necessary to study this application by analyzing the sentiments of twitter users about the mypertamina application the analysis will use the support vector machine algorithm by comparing the linear and radial basis function rbf kernels to get the best method for classifying sentiment after doing the analysis it was found that the text categorization after preprocessing was divided into 60 negative sentiment and 40 positive sentiment and the classification of the support vector machine algorithm using the rbf kernel obtains an accuracy of 8777 while the use of a linear kernel obtains an accuracy of 8803 which can be concluded that the use of a linear kernel and rbf for classification sentiment tweet data related to the mypertamina application is good but it tends to be better to use a linear kernel
Incremental Learning Pada Klasifikasi Penyakit Kulit Pada Citra Wajah.,"Asayanda, Fikra Agha Rabbani",http://repository.its.ac.id/110741/,"Pada penelitian ini telah dilakukan pengembangan metode Incremental Learning untuk klasifikasi penyakit kulit pada citra wajah, Incremental Learning merupakan sebuah metode yang dapat menyesuaikan dengan data baru secara berkelanjutan tanpa melupakan informasi sebelumnya. dataset yang digunakan adalah penyakit kulit jerawat dan ham10000 dataset yang merupakan penyakit kulit untuk dilakukan klasfikasi pada model awal. Terdapat 1052 sampel untuk delapan class yang dilakukan untuk pelatihan data dengan akurasi testing sebesar 87% dan ditambahakan 800 data baru pada proses Incremental Learning menghasilkan akurasi sebesar 90% pada model yang diperbaharui.========================================================================================================In this research, the Incremental Learning method has been developed for the classification of skin diseases on facial images. Incremental Learning is a method that can continuously adapt to new data without forgetting previous information. The datasets used include acne skin disease and the HAM10000 dataset, which are used for classification in the initial model. There were 1052 samples for eight classes used for training, resulting in a testing accuracy of 87%. Additionally, 800 new data points were added during the Incremental Learning process, achieving an accuracy of 90% in the updated model.",incremental learning klasifikasi sakit kulit citra wajah,teliti kembang metode incremental learning klasifikasi sakit kulit citra wajah incremental learning metode sesuai data lanjut lupa informasi dataset sakit kulit jerawat ham10000 dataset sakit kulit klasfikasi model 1052 sampel delapan class latih data akurasi testing 87 ditambahakan 800 data proses incremental learning hasil akurasi 90 model diperbaharuiin this research the incremental learning method has been developed for the classification of skin diseases on facial images incremental learning is a method that can continuously adapt to new data without forgetting previous information the datasets used include acne skin disease and the ham10000 dataset which are used for classification in the initial model there were 1052 samples for eight classes used for training resulting in a testing accuracy of 87 additionally 800 new data points were added during the incremental learning process achieving an accuracy of 90 in the updated model
Peramalan Harga Emas Indonesia Menggunakan SETAR Dan SETAR-TREE.,"Ashilla, Aurell Faza",http://repository.its.ac.id/103432/,"Emas digunakan sebagai standar keuangan di banyak negara dan juga sebagai alat tukar yang relatif abadi dan diterima di seluruh negara. Emas dipilih sebagai instrumen investasi karena sifatnya yang likuid atau mudah dikonversi menjadi uang tunai sebagai alat tukar pembayaran yang sah. Selain itu, kelebihan dari investasi emas adalah risiko yang rendah, sebagai hedging tool, dan harga yang tidak dipengaruhi oleh kebijakan suku bunga. Meskipun resiko investasi nya rendah, tidak semua investor emas dapat mencetak laba dari harga emas tersebut. Jika dilihat dari pergerakan harganya yang cenderung fluktuatif dan memiliki volatilitas tinggi, harga emas dapat mengandung komponen non-linier. Untuk dapat mengakomodasi pola nonlinier pada harga emas, diperlukan pemodelan nonlinier untuk meramalkan harga emas di masa depan. Metode yang dilakukan pada penelitian ini yaitu SETAR dan SETAR-Tree untuk meramalkan harga emas Indonesia. Berdasarkan hasil simulasi, model SETAR dan SETAR-Tree memiliki performa yang sama baik untuk jumlah data kecil maupun besar. Berdasarkan hasil analisis yang dilakukan, pada pemodelan pada in sample dan out sample, SETAR(2,1,1) dan SETAR-Tree memiliki performa yang hampir sama karena jika dibandingkan melalui nilai AIC, model SETAR-Tree memiliki nilai AIC yang lebih kecil. Sedangkan jika dibandingkan melalui nilai RMSE dan MAPE, model SETAR(2,1,1) memiliki nilai RMSE dan MAPE yang lebih kecil. Pada penelitian ini juga dilakukan simulasi pada data bangkitan yang mengikuti SETAR(2,2,2) dengan jumlah data yang berbeda yaitu 200 dan 2000 data. Model SETAR(2,1,1) meramalkan harga emas Indonesia akan menurun nilainya sedangkan dari hasil peramalan yang diperoleh model SETAR-Tree, harga emas Indonesia cenderung fluktuatif pergerakannya selama 14 hari dari 17 April hingga 4 Mei 2023.===============================================================================================================================Gold is used as a financial standard in many countries and also as a relatively enduring and accepted medium of exchange across countries. Gold was chosen as an investment instrument because it is liquid or easily converted into cash as a legal medium of exchange. In addition, the advantages of investing in gold are low risk, as a hedging tool, and prices that are not affected by interest rate policies. Even though the investment risk is low, not all gold investors can make a profit from the gold price. When viewed from the price movements that tend to fluctuate and have high volatility, the price of gold can contain a non-linear component. In order to accommodate nonlinear patterns in gold prices, nonlinear modeling is needed to predict gold prices in the future. The method used in this research is SETAR and SETAR-Tree to predict the price of Indonesian gold. Based on the simulation results, the SETAR and SETAR-Tree model has the same performance both for data with a small amount of data and a large amount of data. Based on the results of the analysis carried out, in the in sample and out sample modeling, SETAR(2,1,1) and SETAR-Tree have almost the same performance because when compared through AIC values, the SETAR-Tree model has a smaller AIC value. Meanwhile, when compared through RMSE and MAsPE values, the SETAR(2,1,1) model has smaller RMSE and MAPE values. In this study, a simulation was also carried out on the generated data following SETAR(2,2,2) with a different amount of data, namely 200 and 2000 data. The SETAR model (2,1,1) predicts that Indonesia's gold price will decrease in value, while from the forecasting results obtained by the SETAR-Tree model, Indonesia's gold price tends to fluctuate for 14 days from 17 April to 4 May 2023.",amal harga emas indonesia tar setartree,emas standar uang negara alat tukar relatif abadi terima negara emas pilih instrumen investasi sifat likuid mudah konversi uang tunai alat tukar bayar sah lebih investasi emas risiko rendah hedging tool harga pengaruh bijak suku bunga resiko investasi nya rendah investor emas cetak laba harga emas gera harga cenderung fluktuatif milik volatilitas harga emas kandung komponen nonlinier akomodasi pola nonlinier harga emas model nonlinier ramal harga emas metode teliti tar setartree ramal harga emas indonesia dasar hasil simulasi model tar setartree milik performa data dasar hasil analisis model in sample out sample setar211 setartree milik performa banding nilai aic model setartree milik nilai aic banding nilai rmse mape model setar211 milik nilai rmse mape teliti simulasi data bangkit ikut setar222 data beda 200 2000 data model setar211 ramal harga emas indonesia turun nilai hasil amal oleh model setartree harga emas indonesia cenderung fluktuatif gera 14 17 april 4 mei 2023gold is used as a financial standard in many countries and also as a relatively enduring and accepted medium of exchange across countries gold was chosen as an investment instrument because it is liquid or easily converted into cash as a legal medium of exchange in addition the advantages of investing in gold are low risk as a hedging tool and prices that are not affected by interest rate policies even though the investment risk is low not all gold investors can make a profit from the gold price when viewed from the price movements that tend to fluctuate and have high volatility the price of gold can contain a nonlinear component in order to accommodate nonlinear patterns in gold prices nonlinear modeling is needed to predict gold prices in the future the method used in this research is tar and setartree to predict the price of indonesian gold based on the simulation results the tar and setartree model has the same performance both for data with a small amount of data and a large amount of data based on the results of the analysis carried out in the in sample and out sample modeling setar211 and setartree have almost the same performance because when compared through aic values the setartree model has a smaller aic value meanwhile when compared through rmse and maspe values the setar211 model has smaller rmse and mape values in this study a simulation was also carried out on the generated data following setar222 with a different amount of data namely 200 and 2000 data the tar model 211 predicts that indonesias gold price will decrease in value while from the forecasting results obtained by the setartree model indonesias gold price tends to fluctuate for 14 days from 17 april to 4 may 2023
Seleksi Fitur Pada Sinyal Photoplethysmograph Untuk Permodelan Regresi Menggunakan Machine Learning.,"Atoil Haq, Faris",http://repository.its.ac.id/101622/,"Photoplethysmograph (PPG) merupakan metode non-invasif dengan cara membaca morfologi dari bentuk gelombang yang mirip dengan bentuk gelombang tekanan darah arteri. PPG merupakan metode untuk mengukur jumlah cahaya yang diserap atau dipantulkan oleh pembuluh darah. Beberapa penelitian telah menggunakan sinyal PPG sebagai subyek penelitian, salah satunya untuk mendiagnosis penyakit melalui fingertip pulse wave. PPG lebih responsif terhadap perubahan volume darah. Hal ini dikarenakan jumlah penyerapan atau refleksi optik bergantung pada jumlah darah yang melalui jalur optik tersebut.Penelitian ini mengusulkan pendekatan baru untuk mengoptimalisasi fitur data regresi yang dihasilkan oleh sinyal PPG. Perangkat fingertip pulse wave digunakan untuk mengambil sampel sinyal PPG pada subyek jari manusia untuk didapatkan sinyal PPG tersebut. Sampel sinyal yang telah diperoleh kemudian diterapkan pada metode machine learning untuk dihasilkan fitur yang terdapat pada sinyal PPG. Metode machine learning yang digunakan antara lain Support Vector Regression, Decision Tree, dan XGBoost dengan pemilihan hyperparameter digunakan sebagai model machine learning untuk menerapkan model dari hasil pemrosesan ekstraksi dan seleksi fitur terhadap fitur data regresi dari sinyal PPG tersebut. Beberapa algoritma feature selection yang digunakan yaitu antara lain: Forward Feature Selection Algorithm, Sequential Input Selection dan Genetic Algorithm.Pengujian pada beberapa metode algoritma seleksi fitur yang diusulkan, diperoleh performa yang cukup baik. Hasil pengujian tersebut didapatkan nilai error berdasarkan data prediksi yang didapatkan. Nilai error tersebut didapatkan menggunakan MAPE. Nilai MAPE yang diperoleh sudah mengalami penurunan nilai error, yaitu diangka 18%. Hal ini disebabkan penggunaan dari fitur yang saling berkorelasi dan juga kombinasi dari beberapa model machine learning seperti XGBoost, Decision Tree, dan Support Vector Regression melalui beberapa pengujian metode sehingga didapatkan hasil fitur yang tepat melalui algoritma seleksi fitur.",seleksi fitur sinyal photoplethysmograph model regresi machine learning,photoplethysmograph ppg metode noninvasif baca morfologi bentuk gelombang bentuk gelombang tekan darah arteri ppg metode ukur cahaya serap pantul buluh darah teliti sinyal ppg subyek teliti salah satu diagnosis sakit fingertip pulse wave ppg responsif ubah volume darah serap refleksi optik gantung darah jalur optik tersebutpenelitian usul dekat optimalisasi fitur data regresi hasil sinyal ppg perangkat fingertip pulse wave ambil sampel sinyal ppg subyek jari manusia dapat sinyal ppg sampel sinyal oleh terap metode machine learning hasil fitur sinyal ppg metode machine learning support vector regression decision tree xgboost pilih hyperparameter model machine learning terap model hasil pemrosesan ekstraksi seleksi fitur fitur data regresi sinyal ppg algoritma feature selection forward feature selection algorithm sequential input selection genetic algorithmpengujian metode algoritma seleksi fitur usul oleh performa hasil uji dapat nilai error dasar data prediksi dapat nilai error dapat mape nilai mape oleh alami turun nilai error angka 18 sebab guna fitur korelasi kombinasi model machine learning xgboost decision tree support vector regression uji metode dapat hasil fitur algoritma seleksi fitur
Sistem Analisis Sentimen Berbasis Aspek pada Media Sosial X terhadap Electric Vehicle (EV) di Indonesia menggunakan INDOBERT dan Machine Learning.,"Audyna, Adinda Putri",http://repository.its.ac.id/108609/,"Kementerian Perindustrian menunjukkan bahwa Indonesia sedang mengalami transisi menuju industri ramah lingkungan melalui penggunaan Electric Vehicle (EV) yang didukung oleh Peraturan Presiden Nomor 55 Tahun 2019. EV menjadi salah satu topik yang cukup ramai dibicarakan di Indonesia, khususnya pada media sosial X. Oleh karena itu, penelitian yang menggunakan data dari media sosial X ini bertujuan memanfaatkan teknologi Natural Language Processing (NLP) dengan fokus analisis sentimen berdasarkan beberapa aspek EV (baterai, biaya, infrastruktur, kenyamanan, dan performa) menggunakan metode IndoBERT. Menurut penelitian terdahulu, IndoBERT dinilai lebih efektif dibandingkan dengan metode Machine Learning lainnya. Penggunaan NLP dan IndoBERT diharapkan dapat membuka pandangan masyarakat Indonesia terhadap EV, dengan hasil analisis yang dibandingkan dengan beberapa metode Machine Learning dan Deep Learning. Performa model dievaluasi menggunakan confusion matrix yang mana dari matrix tersebut dapat diketahui nilai accuracy, precision, recall, dan F1 score. Implementasi analisis sentimen berdasarkan beberapa aspek EV akan diaplikasikan dalam bentuk website dashboard sehingga pengguna dapat lebih mudah memperoleh wawasan dan visualisasi data terkait sentimen EV di Indonesia. Dengan demikian, penelitian ini tidak hanya berkontribusi terhadap pemahaman masyarakat dan industri terhadap EV, tetapi juga membuka potensi pengembangan lebih lanjut dalam penerapan teknologi Machine Learning dan Deep Learning untuk analisis sentimen berbasis aspek. Dari hasil penelitian, penggunaan NLP dan IndoBERT menunjukkan performa terbaik dibandingkan metode lainnya, dengan akurasi sentimen mencapai 0,82 dan akurasi aspek mencapai 0,85. Penelitian ini membuat sebuah website dashboard untuk menganalisis sentimen berdasarkan beberapa aspek EV di Indonesia, dan menunjukkan bahwa sentimen negatif dominan dari tahun 2021 hingga 2024. Aspek biaya mendapatkan sentimen positif terbanyak setiap tahunnya, sementara aspek infrastruktur mendapat sentimen negatif terbanyak dari tahun 2021 hingga 2023. Namun aspek baterai mendominasi sentimen negatif pada tahun 2024.=================================================================================================================================The Ministry of Industry has indicated that Indonesia is transitioning towards an environmentally friendly industry through the use of Electric Vehicle (EV), supported by Presidential Regulation No. 55 of 2019. EV have become a widely discussed topic in Indonesia, particularly on the social media platform X. Consequently, this research utilizes data from X to leverage Natural Language Processing (NLP) technology, focusing on sentiment analysis based on various aspects of EV (battery, cost, infrastructure, comfort, and performance) using the IndoBERT method. Previous studies have found IndoBERT to be more effective compared to other Machine Learning methods. The use of NLP and IndoBERT aims to broaden the Indonesian public's perspective on EVs, with analysis results compared to several Machine Learning and Deep Learning methods. The model's performance is evaluated using a confusion matrix, from which accuracy, precision, recall, and F1 score values are derived. The implementation of sentiment analysis based on various aspects of EV will be applied in the form of a website dashboard, allowing users to easily gain insights and visualize data related to EV sentiment in Indonesia. This research not only contributes to the public and industry's understanding of EV but also opens up further development potential in the application of Machine Learning and Deep Learning technologies for aspect-based sentiment analysis. The research results indicate that the use of NLP and IndoBERT shows the best performance compared to other methods, with sentiment accuracy reaching 0,82 and aspect accuracy reaching 0,85. This research created a website dashboard to analyze sentiment based on various aspects of EV in Indonesia, revealing that negative sentiment was dominant from 2021 to 2024. The cost aspect received the most positive sentiment each year, while the infrastructure aspect received the most negative sentiment from 2021 to 2023. However, the battery aspect dominated negative sentiment in 2024.",sistem analisis sentimen bas aspek media sosial x electric vehicle ev indonesia indobert machine learning,menteri industri indonesia alami transisi industri ramah lingkung guna electric vehicle ev dukung atur presiden nomor 55 2019 ev salah topik ramai bicara indonesia media sosial x teliti data media sosial x tuju manfaat teknologi natural language processing nlp fokus analisis sentimen dasar aspek ev baterai biaya infrastruktur nyaman performa metode indobert teliti indobert nilai efektif banding metode machine learning guna nlp indobert harap buka pandang masyarakat indonesia ev hasil analisis banding metode machine learning deep learning performa model evaluasi confusion matrix matrix nilai accuracy precision recall f1 score implementasi analisis sentimen dasar aspek ev aplikasi bentuk website dashboard guna mudah oleh wawas visualisasi data kait sentimen ev indonesia teliti kontribusi paham masyarakat industri ev buka potensi kembang terap teknologi machine learning deep learning analisis sentimen bas aspek hasil teliti guna nlp indobert performa baik banding metode akurasi sentimen capai 082 akurasi aspek capai 085 teliti website dashboard analis sentimen dasar aspek ev indonesia sentimen negatif dominan 2021 2024 aspek biaya sentimen positif tahun aspek infrastruktur sentimen negatif 2021 2023 aspek baterai dominasi sentimen negatif 2024the ministry of industry has indicated that indonesia is transitioning towards an environmentally friendly industry through the use of electric vehicle ev supported by presidential regulation no 55 of 2019 ev have become a widely discussed topic in indonesia particularly on the social media platform x consequently this research utilizes data from x to leverage natural language processing nlp technology focusing on sentiment analysis based on various aspects of ev battery cost infrastructure comfort and performance using the indobert method previous studies have found indobert to be more effective compared to other machine learning methods the use of nlp and indobert aims to broaden the indonesian publics perspective on evs with analysis results compared to several machine learning and deep learning methods the models performance is evaluated using a confusion matrix from which accuracy precision recall and f1 score values are derived the implementation of sentiment analysis based on various aspects of ev will be applied in the form of a website dashboard allowing users to easily gain insights and visualize data related to ev sentiment in indonesia this research not only contributes to the public and industrys understanding of ev but also opens up further development potential in the application of machine learning and deep learning technologies for aspectbased sentiment analysis the research results indicate that the use of nlp and indobert shows the best performance compared to other methods with sentiment accuracy reaching 082 and aspect accuracy reaching 085 this research created a website dashboard to analyze sentiment based on various aspects of ev in indonesia revealing that negative sentiment was dominant from 2021 to 2024 the cost aspect received the most positive sentiment each year while the infrastructure aspect received the most negative sentiment from 2021 to 2023 however the battery aspect dominated negative sentiment in 2024
Integrasi MPC Dengan Sistem Deteksi Lajur dan Kendaraan Untuk Mengikuti Lajur dan Penjagaan Jarak Aman Berkendara Pada Mobil Otonom.,"Aufar, Muhammad Ayub Purnama",http://repository.its.ac.id/106131/,"Penelitian ini mengeksplorasi integrasi deteksi lajur dan kendaraan dalam mobil otonom menggunakan Model Predictive Control (MPC) dengan sensor ultrasonic, lidar, radar, dan kamera. Fokusnya pada konsep driving scene understanding, terutama deteksi jarak terhadap objek, yang kritis untuk pengambilan keputusan aman. MPC, sebagai kontroler efektif, memanfaatkan pergerakan lateral dan longitudinal untuk menjaga kendaraan pada jalur yang ditentukan. Tujuannya adalah menciptakan mobil otonom responsif dan dapat diandalkan. Pengujian mencakup variasi kondisi lingkungan, dan sistem deteksi lajur terbukti efektif, tetapi menghadapi tantangan saat sudut lajur tak terdeteksi. Deteksi kendaraan cukup akurat, tetapi dipengaruhi oleh kecerahan lingkungan virtual dan akurasi model ACF yang terbatas. MPC mampu merespons hasil deteksi, meskipun hasil pengujian menunjukkan perbedaan dengan penelitian sebelumnya, dengan peningkatan error pada RMSE posisi X dan peningkatan kinerja pada RMSE posisi Y. Dengan demikian, penelitian ini menyajikan solusi terintegrasi untuk meningkatkan kemampuan kendaraan otonom dalam memahami dan merespons lingkungan sekitar.=================================================================================================================================This research explores the integration of lane and vehicle detection in autonomous vehicles using Model Predictive Control (MPC) with ultrasonic, lidar, radar, and camera sensors. The focus is on the concept of driving scene understanding, particularly object distance detection, crucial for safe decision-making. MPC, as an effective controller, utilizes lateral and longitudinal movements to keep the vehicle on the designated path. The goal is to create a responsive and reliable autonomous vehicle. Testing involves various environmental conditions, and the lane detection system proves effective but faces challenges when lane angles are undetected. Vehicle detection is fairly accurate, yet influenced by the brightness of the virtual environment and limited accuracy of the ACF model. MPC can respond to detection results, although test outcomes differ from previous studies, showing increased error in X-axis position RMSE and improved performance in Y-axis position RMSE. Thus, this research presents an integrated solution to enhance the capabilities of autonomous vehicles in understanding and responding to their surrounding environment.",integrasi mpc sistem deteksi lajur kendara ikut lajur jaga jarak aman kendara mobil otonom,teliti eksplorasi integrasi deteksi lajur kendara mobil otonom model predictive control mpc sensor ultrasonic lidar radar kamera fokus konsep driving scene understanding deteksi jarak objek kritis ambil putus aman mpc kontroler efektif manfaat gera lateral longitudinal jaga kendara jalur tentu tuju cipta mobil otonom responsif andal uji cakup variasi kondisi lingkung sistem deteksi lajur bukti efektif hadap tantang sudut lajur deteksi deteksi kendara akurat pengaruh cerah lingkung virtual akurasi model acf batas mpc respons hasil deteksi hasil uji beda teliti tingkat error rmse posisi x tingkat kerja rmse posisi y teliti saji solusi integrasi tingkat mampu kendara otonom paham respons lingkung sekitarthis research explores the integration of lane and vehicle detection in autonomous vehicles using model predictive control mpc with ultrasonic lidar radar and camera sensors the focus is on the concept of driving scene understanding particularly object distance detection crucial for safe decisionmaking mpc as an effective controller utilizes lateral and longitudinal movements to keep the vehicle on the designated path the goal is to create a responsive and reliable autonomous vehicle testing involves various environmental conditions and the lane detection system proves effective but faces challenges when lane angles are undetected vehicle detection is fairly accurate yet influenced by the brightness of the virtual environment and limited accuracy of the acf model mpc can respond to detection results although test outcomes differ from previous studies showing increased error in xaxis position rmse and improved performance in yaxis position rmse thus this research presents an integrated solution to enhance the capabilities of autonomous vehicles in understanding and responding to their surrounding environment
Implementasi Machine Learning untuk Prediksi Imbal Hasil Obligasi Indonesia.,"Azizah, Leyli Lathifatul",http://repository.its.ac.id/103356/,"Imbal hasil obligasi yang diperoleh investor mengalami perubahan dari waktu ke waktu. Perubahan imbal hasil tersebut berpengaruh pada tingkat harga pasar obligasi itu sendiri. Oleh karena itu, investor dan pemerintah harus selalu memperhatikan fluktuasi harga imbal hasil obligasi tersebut. Studi penelitian terkait prediksi imbal hasil obligasi telah menggunakan model machine learning dengan tingkat akurasi yang baik. Akan tetapi, masih belum diterapkan untuk prediksi imbal hasil obligasi Indonesia. Untuk permasalahan prediksi imbal hasil obligasi Indonesia, penelitian ini menggunakan model machine learning berupa Support Vector Regression (SVR), Multilayer Perceptron (MLP), dan Transformer. Tujuan dari penelitian ini adalah untuk mendapatkan nilai prediksi yang paling akurat dari ketiga model machine learning tersebut. Dataset yang digunakan untuk uji nilai akurasi diperoleh dari data imbal hasil obligasi Indonesia untuk tenor 10 tahun dalam kurun waktu 2017-2022. Untuk prediksi short term seminggu kedepan dan long term selama 5 tahun kedepan, didapatkan hasil terbaik menggunakan metode MLP dengan tingkat akurasi short term untuk MAE sebesar 0.07796, MAPE sebesar 0.01171, dan RMSE sebesar 0.10947 dan tingkat akurasi long term untuk MAE sebesar 0.55166, MAPE sebesar 0.07716, dan RMSE sebesar 0.66122.=================================================================================================================================Bond yields obtained by investors have changed from time to time. Changes in yields affect the market price level of the bonds themselves. Therefore, investors and the government must always pay attention to fluctuations in the price of these bond yields. Research studies related to the prediction of bond yields have used machine learning models with a good level of accuracy. However, it has not yet been applied to predictions of Indonesian bond yields. For the problem of predicting Indonesian bond yields, this study uses machine learning models in the form of Support Vector Regression (SVR), Multilayer Perceptron (MLP), and Transformers. The purpose of this research is to get the most accurate predictive value of the three machine learning models. The dataset used to test the accuracy value was obtained from data on Indonesian bond yields for a tenor of 10 years in the period 2017-2022. For short term predictions for the next week and long term for the next 5 years, the best results are obtained using the MLP method with an accuracy level for short term for MAE 0.07796, MAPE 0.01171, and RMSE 0.10947. In addition, an accuracy level of long term for MAE 0.55166, MAPE 0.07716, and RMSE 0.66122.",implementasi machine learning prediksi imbal hasil obligasi indonesia,imbal hasil obligasi oleh investor alami ubah ubah imbal hasil pengaruh tingkat harga pasar obligasi investor perintah perhati fluktuasi harga imbal hasil obligasi studi teliti kait prediksi imbal hasil obligasi model machine learning tingkat akurasi terap prediksi imbal hasil obligasi indonesia masalah prediksi imbal hasil obligasi indonesia teliti model machine learning support vector regression svr multilayer perceptron mlp transformer tuju teliti nilai prediksi akurat tiga model machine learning dataset uji nilai akurasi oleh data imbal hasil obligasi indonesia tenor 10 kurun 20172022 prediksi short term minggu depan long term 5 depan dapat hasil baik metode mlp tingkat akurasi short term mae 007796 mape 001171 rmse 010947 tingkat akurasi long term mae 055166 mape 007716 rmse 066122bond yields obtained by investors have changed from time to time changes in yields affect the market price level of the bonds themselves therefore investors and the government must always pay attention to fluctuations in the price of these bond yields research studies related to the prediction of bond yields have used machine learning models with a good level of accuracy however it has not yet been applied to predictions of indonesian bond yields for the problem of predicting indonesian bond yields this study uses machine learning models in the form of support vector regression svr multilayer perceptron mlp and transformers the purpose of this research is to get the most accurate predictive value of the three machine learning models the dataset used to test the accuracy value was obtained from data on indonesian bond yields for a tenor of 10 years in the period 20172022 for short term predictions for the next week and long term for the next 5 years the best results are obtained using the mlp method with an accuracy level for short term for mae 007796 mape 001171 and rmse 010947 in addition an accuracy level of long term for mae 055166 mape 007716 and rmse 066122
Perancangan Sistem Klasifikasi Kesegaran Ikan Osphronemus Gouramy Menggunakan Imaging System Dengan Sumber Cahaya UV Dan Algoritma Deep Neural Network.,"Azizah, Nafil Nur",http://repository.its.ac.id/100248/,"Daging ikan merupakan salah satu sumber makanan yang banyak dikonsumsi manusia karena kaya akan manfaat tinggi protein, rendah lemak, dan terdapat beberapa vitamin dan mineral. Kesegaran ikan  merupakan salah satu hal utama pada konsumen. Total Volatile Base Nitrogen (TVBN) suatu parameter yang dapat mengindikasikan kesegaran ikan. Perubahan warna berdampak langsung pada kesegaran ikan menurut SNI 2729:2013 menunjukkan tata cara pemeriksaan kesegaran secara konvensional. Imaging system dengan sinar UV telah diimplementasikan untuk menguantifikasi kesegaran ikan melalui warna permukaan sisik ikan. Ruang warna yang digunakan berupa RGB, HSV, LAB dengan empat momen warna yaitu mean, standar deviasi, skewness, kurtosis. Klasifikasi kesegaran ikan pada imaging system dengan sumber cahaya UV dan parameter kesegaran TVBN algoritma  dengan Deep Neural Network.  Hasil dari sistem klasifikasi kesegaran ikan memiliki akurasi keseluruhan sebesar 99.62%, sensitivitas rata-rata pada kelas sebesar 99.67%, presisi rata-rata pada kelas sebesar 99.33%.========================================================================================================================Fish meat is a food source that is widely consumed by humans because it is rich in the benefits of high protein, low fat, and contains several vitamins and minerals. Fish freshness is one of the main concerns of consumers. Total Volatile Base Nitrogen (TVBN) is a parameter that can indicate the freshness of fish. Changes in color and texture have a direct impact on the freshness of fish according to SNI 2729: 2013 shows the procedure for conventional freshness inspection. Imaging system equipped with UV light has been implemented to predict fish freshness by the surface color. The color space used is RGB, HSV, LAB with four color moments namely mean, standard deviation, skewness, kurtosis. Fish freshness classification on imaging system combines UV light source and TVBN freshness parameter algorithm with Deep Neural Network. The results of the fish freshness classification system have an overall accuracy of 99.62%, an average sensitivity in class of 99.67%, an average precision in class of 99.33%.",ancang sistem klasifikasi segar ikan osphronemus gouramy imaging system sumber cahaya uv algoritma deep neural network,daging ikan salah sumber makan konsumsi manusia kaya manfaat protein rendah lemak vitamin mineral segar ikan salah utama konsumen total volatile base nitrogen tvbn parameter indikasi segar ikan ubah warna dampak langsung segar ikan sni 27292013 tata periksa segar konvensional imaging system sinar uv implementasi kuantifikasi segar ikan warna muka sisik ikan ruang warna rgb hsv lab momen warna mean standar deviasi skewness kurtosis klasifikasi segar ikan imaging system sumber cahaya uv parameter segar tvbn algoritma deep neural network hasil sistem klasifikasi segar ikan milik akurasi 9962 sensitivitas ratarata kelas 9967 presisi ratarata kelas 9933fish meat is a food source that is widely consumed by humans because it is rich in the benefits of high protein low fat and contains several vitamins and minerals fish freshness is one of the main concerns of consumers total volatile base nitrogen tvbn is a parameter that can indicate the freshness of fish changes in color and texture have a direct impact on the freshness of fish according to sni 2729 2013 shows the procedure for conventional freshness inspection imaging system equipped with uv light has been implemented to predict fish freshness by the surface color the color space used is rgb hsv lab with four color moments namely mean standard deviation skewness kurtosis fish freshness classification on imaging system combines uv light source and tvbn freshness parameter algorithm with deep neural network the results of the fish freshness classification system have an overall accuracy of 9962 an average sensitivity in class of 9967 an average precision in class of 9933
Simulasi Pengaruh Jumlah Kasur Dan Aliran Aerosol Dari Mesin Sanitasi Terhadap Sirkulasi Udara Di Dalam Ruang Rawat Inap Pasien Covid-19.,"Azmi, Nararyya Zufar El",http://repository.its.ac.id/86602/,"Virus Corona (Covid-19) menjadi perhatian khusus karena penyebarannya yang cepat ke seluruh dunia dan menyebabkan okupansi rumah sakit menjadi sangat tinggi. Sehingga perlu dilakukan pemodelan pada ruang isolasi pasien Covid-19 untuk menginvestugasi aliran udara serta keefekitfan aerosol sanitizer yang menggunakan AC untuk melindungi para tenaga medis dan meminimalisir persebaran virus Covid-19. Dengan menggunakan Solidworks, dilakukan pemodelan pada masing-masing ruang isolasi pasien (9144 mm x 6096 mm x 3658 mm) berupa Pintu (1234 mm x 1066 mm), exhaust vent (1800 mm x 300 mm), AC vent (1000 mm x 1000 mm). Kasur (1219 mm x 1828 mm x 2134 mm) dimodelkan dan divariasikan pada 6 ruangan, dimana Ruang 1-3 masing-masing berisi 2 kasur, 3 kasur, dan 6 kasur tanpa mesin sanitasi. Sedangkan Ruang 4-6 masing-masing berisi 2 kasur, 3 kasur, dan 6 kasur dengan mesin sanitasi (1524 mm x 1328 mm x 1219 mm). Kemudian untuk simulasi Ansys, Meshing secara tetrahedral dan hexahedral dilakukan serta kondisi batas dimasukkan. Untuk kondisi inlet AC, temperaturnya seragam sebesar 24 oC dengan kecepatan sebesar 3,91 m/s. Sedangkan kondisi mesin inlet sanitasi, temperaturnya seragam di 30 oC dengan kecepatan inlet sebesar 1,5 m/s. Setelah dilakukan simulasi pada Ansys, didapatkan bahwa ruangan dengan varian 6 kasur dengan mesin sanitasi, memiliki nilai turbulen energi kinetik terbesar, dengan nilai 2,19 m2/s2 .Turbulensi energi kinetik yang tinggi di ruang isolasi membuat persebaran campuran udara sanitasi dan AC menjadi rata ke segala penjuru ruangan, sehingga semakin tinggi nilainya maka akan semakin bagus.================================================================================================Coronavirus disease (Covid-19) became an attention because the virus spread rapidly all over the world. Hospital occupancy became high due to high case each day. Hence, modeling and simulation in the Covid-19 isolation room needed to investigate the airflow inside the room and the effectivity of aerosol from sanitizing machine with Air Conditioner to protect doctor, nurse, and minimizing the virus spread. Solidworks was used for room design, the patient room (9144 mm x 6096 mm x 3658) is modelled with Door (1234 mm x 1066 mm), exhaust vent (1800 mm x 300 mm), AC vent (1000 mm x 1000 mm) in each room. Beds (1219 mm x 1828 mm x 2134 mm) were the variations and modelled at 6 rooms in total. Room 1-3 contained 2, 3, and 6 beds respectively without sanitizing machine. Room 4-6 contained 2, 3, and 6 beds with sanitizing machine (1524 mm x 1328 mm x 1219 mm). Tetrahedral and hexahedral meshing were needed and after that inserting inlet condition as the boundary condition. Boundary condition of AC: Uniform temperature at 24 oC, velocity 3.91 m/s. Inlet condition for sanitizing machine: Uniform temperature at 30 oC, velocity 1.5 m/s. It was known that the room with configuration of 6 beds with sanitizing machine has the biggest turbulence kinetic energy, with the value of 2.19 m2/s2. When the turbulency value was high, the flow of mixing air from AC and aerosol spread to all of the room, so the isolation room is fully sanitized so the room free of virus and flatten the curve.",simulasi pengaruh kasur alir aerosol mesin sanitasi sirkulasi udara ruang rawat inap pasien covid19,virus corona covid19 perhati khusus sebar cepat dunia sebab okupansi rumah sakit model ruang isolasi pasien covid19 menginvestugasi alir udara keefekitfan aerosol sanitizer ac lindung tenaga medis meminimalisir sebar virus covid19 solidworks model masingmasing ruang isolasi pasien 9144 mm x 6096 mm x 3658 mm pintu 1234 mm x 1066 mm exhaust vent 1800 mm x 300 mm ac vent 1000 mm x 1000 mm kasur 1219 mm x 1828 mm x 2134 mm model variasi 6 ruang mana ruang 13 masingmasing isi 2 kasur 3 kasur 6 kasur mesin sanitasi ruang 46 masingmasing isi 2 kasur 3 kasur 6 kasur mesin sanitasi 1524 mm x 1328 mm x 1219 mm simulasi ansys meshing tetrahedral hexahedral kondisi batas masuk kondisi inlet ac temperatur seragam 24 oc cepat 391 ms kondisi mesin inlet sanitasi temperatur seragam 30 oc cepat inlet 15 ms simulasi ansys dapat ruang varian 6 kasur mesin sanitasi milik nilai turbulen energi kinetik besar nilai 219 m2s2 turbulensi energi kinetik ruang isolasi sebar campur udara sanitasi ac penjuru ruang nilai baguscoronavirus disease covid19 became an attention because the virus spread rapidly all over the world hospital occupancy became high due to high case each day hence modeling and simulation in the covid19 isolation room needed to investigate the airflow inside the room and the effectivity of aerosol from sanitizing machine with air conditioner to protect doctor nurse and minimizing the virus spread solidworks was used for room design the patient room 9144 mm x 6096 mm x 3658 is modelled with door 1234 mm x 1066 mm exhaust vent 1800 mm x 300 mm ac vent 1000 mm x 1000 mm in each room beds 1219 mm x 1828 mm x 2134 mm were the variations and modelled at 6 rooms in total room 13 contained 2 3 and 6 beds respectively without sanitizing machine room 46 contained 2 3 and 6 beds with sanitizing machine 1524 mm x 1328 mm x 1219 mm tetrahedral and hexahedral meshing were needed and after that inserting inlet condition as the boundary condition boundary condition of ac uniform temperature at 24 oc velocity 391 ms inlet condition for sanitizing machine uniform temperature at 30 oc velocity 15 ms it was known that the room with configuration of 6 beds with sanitizing machine has the biggest turbulence kinetic energy with the value of 219 m2s2 when the turbulency value was high the flow of mixing air from ac and aerosol spread to all of the room so the isolation room is fully sanitized so the room free of virus and flatten the curve
Identifikasi Tokoh dan Penokohan pada Teks Cerita Berbahasa Bali Menggunakan Pendekatan Berbasis Aturan dan Supervised Machine Learning.,"Bimantara, I Made Satria",http://repository.its.ac.id/111416/,"Tokoh pada teks cerita merupakan entitas yang dapat menerima dan melakukan aksi. Tokoh merupakan komponen utama sebelum pengembangan elemen pada teks cerita lainnya dapat dibuat, seperti plot, alur, latar, dan penokohan. Pengarang dapat menggambarkan tokoh ke dalam peran tertentu, misalnya protagonis atau antagonis. Proses mendeteksi kemunculan tokoh pada suatu segmen teks disebut sebagai identifikasi tokoh. Mayoritas penelitian identifikasi tokoh hanya berfokus pada karya sastra barat umumnya berbahasa Inggris karena ditunjang dengan kakas bantu yang melimpah (high resource language). Padahal, terdapat banyak karya sastra yang tidak dibuat dengan bahasa Inggris, seperti teks cerita berbahasa Bali (Satua Bali), sebagai salah satu low resource language. Identifikasi tokoh dan penokohan pada Satua Bali berbasis komputasi secara otomatis belum dilakukan karena masih terdapat tantangan. Pertama, tokoh pada teks dapat muncul dengan beragam bentuk selain person proper noun, misalnya frasa nomina dan frasa pronomina. Kedua, tokoh pada teks cerita fiksi tidak hanya terdiri dari entitas manusia saja, melainkan entitas lainnya juga dapat menjadi tokoh, misalnya non-human animate entities, inanimate object, makhluk fantasi, dan entitas tokoh yang spesifik. Ketiga, pengarang inkonsisten dalam menyebut nama suatu tokoh dengan menggunakan berbagai alias (misalnya Mr. Sherlock Holmes, Sherlock, Mr. Holmes), sehingga tugas pengelompokkan nama alias (alias clustering) diperlukan. Oleh karena itu, identifikasi tokoh dengan menggunakan NER berbasis aturan yang hanya mengidentifikasi entitas PERSON saja sebagai tokoh tidak cukup. Keempat, narasi yang rumit dan penokohan yang kompleks seringkali ditampilkan pada Satua Bali, sehingga memperumit penokohan suatu tokoh. Kelima, minimnya kakas bantu dan belum ada model state-of-the-art untuk tugas identifikasi dan klasifikasi penokohan pada teks Satua Bali.Penelitian ini mengembangkan kerangka kerja untuk proses identifikasi tokoh dan penokohan pada Satua Bali berbasis komputasi. Terdapat dua modul utama yang dikembangkan, yaitu: 1) modul identifikasi tokoh dan pengelompokkan nama alias; serta 2) modul klasifikasi penokohan tokoh. Penelitian ini menganotasi sebanyak 120 teks Satua Bali bernama “Balinese Story Texts Dataset” sebagai ground truth dalam pengembangan kerangka kerja dengan melibatkan validasi dari ahli. NER hybrid bernama SatuaNER berbasis Binary Particle Swarm Optimization – Conditional Random Fields (BPSO-CRF) diusulkan untuk bisa mengenali lima kategori nama entitas tokoh (CHAR NE). Setiap frasa yang dilabeli sebagai CHAR NE oleh SatuaNER selanjutnya diidentifikasi sebagai tokoh. Algoritma berbasis aturan digunakan untuk mengelompokkan setiap nama alias yang merujuk pada entitas tokoh yang sama ke dalam suatu kelompok tokoh dengan menggunakan lima metode pairwise distance string similarity, yaitu: Ratcliff-Obershelp Algorithm, Jaccard similarity, Sorensen-dice similarity, Jaro-distance similarity, dan Jaro-winkler. Klasifikasi penokohan dari setiap kelompok tokoh ke dalam protagonis atau antagonis dilakukan menggunakan konteks kalimat yang merujuk atau merepresentasikan semua nama alias pada kelompok tokoh tersebut. Fitur lexicon dan word vector kemudian diekstraksi dari konteks kalimat tersebut. Enam model supervised machine learning (ML), yaitu k-Nearest Neighbor (KNN), Decision Tree (DT), Support Vectori Machine (SVM), Random Forest (RF), Gaussian Naïve Bayes (GNB), dan Multilayer Perceptron (MLP) dievaluasi sebagai model benchmark untuk mengklasifikasikan penokohan kelompok tokoh ke dalam protagonis atau antagonis. Performa model-model pada kedua modul dievaluasi dengan recall, precision, dan F1-score.Performa model yang diusulkan dibandingkan dengan model baseline. Performa F1-score dari SatuaNER ketika dievaluasi dengan 10-fold cross-validation dan data uji masing-masing sebesar 95,4% dan 95,53%. Evaluasi pada data uji menunjukkan peningkatan performa SatuaNER sebesar 7,42% dan 6,01% terhadap Hidden Markov Model (HMM). Performa pretrained SatuaNER juga lebih baik apabila dibandingkan dengan NER berbasis aturan dalam mengidentifikasi tokoh pada level kalimat. Pretrained SatuaNER menghasilkan performa rata-rata F1-score sebesar 95,08% dan 96,04%, sedangkan NER berbasis aturan hanya 63,79% ketika dievaluasi dengan 10-fold cross-validation. Terdapat peningkatan performa sebesar 27,63%. Model alias clustering yang diterapkan terhadap hasil identifikasi tokoh pada SatuaNER dengan sorensen-dice similarity dan jaro-distance similarity memberikan performa rata-rata F1-score sebesar 70,69% dan 71,72%. Terjadi peningkatan performa rata-rata F1-score tertinggi dari model alias clustering yang diusulkan terhadap baseline sebesar 26,91% dan 27,77% ketika dievaluasi pada 120 teks cerita. Evaluasi performa dari enam model supervised ML untuk klasifikasi penokohan menunjukkan bahwa peningkatan performa rata-rata F1-score tertinggi dihasilkan model SVM dari yang awalnya (baseline) sebesar 52,92% menjadi 68,45% dengan menggunakan fitur FastText word embedding dan menerapkan tahapan coreference resolution terhadap konteks kalimat kelompok tokoh. Performa F1-score dari model supervised ML untuk klasifikasi penokohan lebih unggul apabila dibandingkan dengan performa F1-score dari model pengklasifikasi berbasis aturan sederhana yang menggunakan leksikon berbahasa Bali yang menghasilkan 51,48%.===========================================================Characters in story texts are entities that can receive and carry out actions. Characters are the main component before the development of other elements in the story text can be made, such as plot, flow, setting, and characterization. Authors can portray characters in certain roles, for example, protagonist or antagonist. The process of detecting the appearance of characters in a text segment is called character identification. Most of character identification research only focuses on western literary works, generally in English, because they are supported by abundant tools (high-resource languages). In fact, there are many literary works that are not written in English, such as story texts in Balinese (Satua Bali), which is one of the low-resource languages. Automatic computing-based identification of characters and characterizations in Satua Bali has not been carried out because there are still challenges. First, characters in the text can appear in various forms other than person-proper nouns, for example, noun phrases and pronoun phrases. Second, characters in fictional story texts do not only consist of human entities, but other entities can also become characters, for example, non-human animate entities, inanimate objects, fantasy creatures, and specific character entities. Third, the author is inconsistent in naming a character using various aliases (for example, Mr. Sherlock Holmes, Sherlock, Mr. Holmes), so the task of grouping aliases (aka clustering) is necessary. Therefore, character identification using rule-based NER, which only identifies the PERSON entity as a character, is not sufficient. Fourth, complicated narratives and complex characterizations are often presented in Satua Bali, thus complicating the characterization of a character. Fifth, there is a lack of tools, and there is no state-of-the-art model for the task of identifying and classifying characterizations in the Satua Bali text.This research develops a computing-based framework for the process of character identification and characterization in Satua Bali. There are two main modules being developed, namely: 1) the character identification and alias clustering module; and 2) the character characterization classification module. This research annotated 120 Satua Bali texts called the ""Balinese Story Texts Dataset"" as ground truth in developing a framework involving validation from experts. A hybrid NER called SatuaNER based on Binary Particle Swarm Optimization with Conditional Random Fields (BPSO-CRF) is proposed to be able to recognize five categories of character entity names (CHAR NE). Each phrase labeled as CHAR NE by SatuaNER is further identified as a character. A rule-based algorithm is proposed to group each alias that refers to the same character entity into a group of characters using five pairwise distance string similarity methods, namely: Ratcliff-Obershelp Algorithm, Jaccard similarity, Sorensen-dice similarity, Jaro-distance similarity, and Jaro-Winkler. Characterization classification of each character groups into protagonists or antagonists is carried out using the context of sentences that refer to or represent all aliases in that character group. Lexicon and word vector features are then extracted from the context of the sentence. Six supervised machine learning (ML) models, namely k-Nearest Neighbor (KNN), Decision Tree (DT), Support Vector Machine (SVM), Random Forest (RF), Gaussian Naïve Bayes (GNB), and Multilayer Perceptron (MLP), were evaluated as benchmark models for classifying characterizations of character groups into protagonists or antagonists. The performance of the models in both modules is evaluated using recall, precision, and F1-score.The performance of the proposed model is compared with the baseline model. The F1-score performance of SatuaNER when evaluated with 10-fold cross-validation and test data was 95.4% and 95.53%, respectively. Evaluation of test data shows an increase in SatuaNER performance of 7.42% and 6.01% against the Hidden Markov Model (HMM). SatuaNER's pretrained performance is also better when compared to rule-based NER in identifying characters at the sentence level. Pretrained SatuaNER produces average F1-score performance of 95.08% and 96.04%, while rule-based NER is only 63.79% when evaluated with 10-fold cross-validation. There is a performance increase of 27.63%. The alias clustering model applied to the results of character identification in SatuaNER with sorensen-dice similarity and jaro-distance similarity gives an average F1-score performance of 70.69% and 71.72%. There was an increase in the highest average F1-score performance of the proposed alias clustering model against the baseline of 26.91% and 27.77% when evaluated on 120 story texts. Performance evaluation of six supervised ML models for characterization classification shows that the highest average F1-score performance increase was produced by the SVM model from the initial (baseline) of 52.92% to 68.45% by using the FastText word embedding feature and applying the coreference stage resolution of the context of the character group's sentences. The F1-score performance of the supervised ML model for characterization classification is superior when compared to the F1-score performance of a simple rule-based classifier model that uses the Balinese lexicon which produces 51.48%.",identifikasi tokoh tokoh teks cerita bahasa bal dekat bas atur supervised machine learning,tokoh teks cerita entitas terima aksi tokoh komponen utama kembang elemen teks cerita plot alur latar tokoh arang gambar tokoh peran protagonis antagonis proses deteksi muncul tokoh segmen teks identifikasi tokoh mayoritas teliti identifikasi tokoh fokus karya sastra barat bahasa inggris tunjang kakas bantu limpah high resource language karya sastra bahasa inggris teks cerita bahasa bal satua bal salah low resource language identifikasi tokoh tokoh satua bal bas komputasi otomatis tantang tokoh teks muncul agam bentuk person proper noun frasa nomina frasa pronomina tokoh teks cerita fiksi entitas manusia entitas tokoh nonhuman animate entities inanimate object makhluk fantasi entitas tokoh spesifik tiga arang inkonsisten sebut nama tokoh alias mr sherlock holmes sherlock mr holmes tugas kelompok nama alias alias clustering identifikasi tokoh ner bas atur identifikasi entitas person tokoh empat narasi rumit tokoh kompleks seringkali tampil satua bal rumit tokoh tokoh minim kakas bantu model stateoftheart tugas identifikasi klasifikasi tokoh teks satua balipenelitian kembang kerangka kerja proses identifikasi tokoh tokoh satua bal bas komputasi modul utama kembang 1 modul identifikasi tokoh kelompok nama alias 2 modul klasifikasi tokoh tokoh teliti anotasi 120 teks satua bal nama  balinese story texts dataset  ground truth kembang kerangka kerja libat validasi ahli ner hybrid nama satuaner bas binary particle swarm optimization  conditional random fields bpsocrf usul nali kategori nama entitas tokoh char ne frasa label char ne satuaner identifikasi tokoh algoritma bas atur kelompok nama alias rujuk entitas tokoh kelompok tokoh metode pairwise distance string similarity ratcliffobershelp algorithm jaccard similarity sorensendice similarity jarodistance similarity jarowinkler klasifikasi tokoh kelompok tokoh protagonis antagonis konteks kalimat rujuk representasi nama alias kelompok tokoh fitur lexicon word vector ekstraksi konteks kalimat enam model supervised machine learning ml knearest neighbor knn decision tree dt support vectori machine svm random forest rf gaussian na ve bayes gnb multilayer perceptron mlp evaluasi model benchmark klasifikasi tokoh kelompok tokoh protagonis antagonis performa modelmodel modul evaluasi recall precision f1scoreperforma model usul banding model baseline performa f1score satuaner evaluasi 10fold crossvalidation data uji masingmasing 954 9553 evaluasi data uji tingkat performa satuaner 742 601 hidden markov model hmm performa pretrained satuaner banding ner bas atur identifikasi tokoh level kalimat pretrained satuaner hasil performa ratarata f1score 9508 9604 ner bas atur 6379 evaluasi 10fold crossvalidation tingkat performa 2763 model alias clustering terap hasil identifikasi tokoh satuaner sorensendice similarity jarodistance similarity performa ratarata f1score 7069 7172 tingkat performa ratarata f1score tinggi model alias clustering usul baseline 2691 2777 evaluasi 120 teks cerita evaluasi performa enam model supervised ml klasifikasi tokoh tingkat performa ratarata f1score tinggi hasil model svm baseline 5292 6845 fitur fasttext word embedding terap tahap coreference resolution konteks kalimat kelompok tokoh performa f1score model supervised ml klasifikasi tokoh unggul banding performa f1score model klasifikasi bas atur sederhana leksikon bahasa bal hasil 5148characters in story texts are entities that can receive and carry out actions characters are the main component before the development of other elements in the story text can be made such as plot flow setting and characterization authors can portray characters in certain roles for example protagonist or antagonist the process of detecting the appearance of characters in a text segment is called character identification most of character identification research only focuses on western literary works generally in english because they are supported by abundant tools highresource languages in fact there are many literary works that are not written in english such as story texts in balinese satua bal which is one of the lowresource languages automatic computingbased identification of characters and characterizations in satua bal has not been carried out because there are still challenges first characters in the text can appear in various forms other than personproper nouns for example noun phrases and pronoun phrases second characters in fictional story texts do not only consist of human entities but other entities can also become characters for example nonhuman animate entities inanimate objects fantasy creatures and specific character entities third the author is inconsistent in naming a character using various aliases for example mr sherlock holmes sherlock mr holmes so the task of grouping aliases aka clustering is necessary therefore character identification using rulebased ner which only identifies the person entity as a character is not sufficient fourth complicated narratives and complex characterizations are often presented in satua bal thus complicating the characterization of a character fifth there is a lack of tools and there is no stateoftheart model for the task of identifying and classifying characterizations in the satua bal textthis research develops a computingbased framework for the process of character identification and characterization in satua bal there are two main modules being developed namely 1 the character identification and alias clustering module and 2 the character characterization classification module this research annotated 120 satua bal texts called the balinese story texts dataset as ground truth in developing a framework involving validation from experts a hybrid ner called satuaner based on binary particle swarm optimization with conditional random fields bpsocrf is proposed to be able to recognize five categories of character entity names char ne each phrase labeled as char ne by satuaner is further identified as a character a rulebased algorithm is proposed to group each alias that refers to the same character entity into a group of characters using five pairwise distance string similarity methods namely ratcliffobershelp algorithm jaccard similarity sorensendice similarity jarodistance similarity and jarowinkler characterization classification of each character groups into protagonists or antagonists is carried out using the context of sentences that refer to or represent all aliases in that character group lexicon and word vector features are then extracted from the context of the sentence six supervised machine learning ml models namely knearest neighbor knn decision tree dt support vector machine svm random forest rf gaussian na ve bayes gnb and multilayer perceptron mlp were evaluated as benchmark models for classifying characterizations of character groups into protagonists or antagonists the performance of the models in both modules is evaluated using recall precision and f1scorethe performance of the proposed model is compared with the baseline model the f1score performance of satuaner when evaluated with 10fold crossvalidation and test data was 954 and 9553 respectively evaluation of test data shows an increase in satuaner performance of 742 and 601 against the hidden markov model hmm satuaners pretrained performance is also better when compared to rulebased ner in identifying characters at the sentence level pretrained satuaner produces average f1score performance of 9508 and 9604 while rulebased ner is only 6379 when evaluated with 10fold crossvalidation there is a performance increase of 2763 the alias clustering model applied to the results of character identification in satuaner with sorensendice similarity and jarodistance similarity gives an average f1score performance of 7069 and 7172 there was an increase in the highest average f1score performance of the proposed alias clustering model against the baseline of 2691 and 2777 when evaluated on 120 story texts performance evaluation of six supervised ml models for characterization classification shows that the highest average f1score performance increase was produced by the svm model from the initial baseline of 5292 to 6845 by using the fasttext word embedding feature and applying the coreference stage resolution of the context of the character groups sentences the f1score performance of the supervised ml model for characterization classification is superior when compared to the f1score performance of a simple rulebased classifier model that uses the balinese lexicon which produces 5148
Simulator Gitar Berbasis Realtime Recording.,"Brilyan, Ragil Bintang",http://repository.its.ac.id/91100/,"Musik merupakan sebuah seni gabungan antara beberapa komposisi alat musik. Diantaranya adalah vokal, piano, gitar, bass, drum, dan sebagainya. Untuk memainkan sebuah alat musik juga dibutuhkan sebuah teknik hingga formula, supaya dalam permainan musik menjadi lebih harmoni. Teknik dan formula dalam permainan alat musik meliputi tempo, ritme, cara memainkan alat musik, hingga akord. Namun bagi orang yang baru belajar memainkan alat musik tentulah sulit untuk mengetahui rumus akord yang akan dimainkan. Belum lagi saat suara akord yang dimainkan berbeda dengan suara akord yang ditujukan. Hal tersebut dapat mengubah sebuah lagu yang dimainkan terdengar menjadi fals atau menyimpang dari lagu sesungguhnya. Sering kali dalam pembelajaran permainan alat musik beberapa media tidak menjelaskan atau memaparkan bagaimana bentuk akord yang dimainkan dan apakah akord yang dimainkan sudah tepat. Salah satu cara untuk menentukan ketepatan suara akord dalam permainan musik secara otodidak, dapat dilakukan menggunakan bantuan Machine Learning. Metode ini merekam suara akord gitar yang dimainkan dan mengklasifikasikan akord gitar sesuai dengan suara aslinya. Namun akord yang dapat diklasifikasikan masih terbatas pada akord dasar, karena ditujukan untuk pembelajaran paling dasar. Dan untuk tampilan rumus akord yang dimainkan akan lebih interaktif apabila menggunakan desain game.====================================================================================================Music is an art that combines several compositions of musical instruments. Among them are vocals, piano, guitar, bass, drums, and so on. To play a musical instrument also requires a technique to a formula, so that the music game becomes more harmonious. Techniques and formulas in playing musical instruments include tempo, rhythm, how to play a musical instrument, to chords. But for people who are just learning to play a musical instrument, it is certainly difficult to know the formula for the chords to be played. Not to mention when the sound of the chord being played is different from the sound of the intended chord. This can change a song being played sound fake or deviate from the actual song. Often in learning to play musical instruments, some media do not explain or explain how the chords are played and whether the chords are played correctly. One way to determine the accuracy of the chord sound in a self-taught music game, can be done using the help of Machine Learning. This method records the sound of guitar chords being played and classifies guitar chords according to their original sound. However chords that can be classified are still limited to basic chords, because they are intended for the most basic learning. And for the display of the chord formula that is played it will be more interactive when using game design.",simulator gitar bas realtime recording,musik seni gabung komposisi alat musik vokal piano gitar bass drum main alat musik butuh teknik formula main musik harmoni teknik formula main alat musik liput tempo ritme main alat musik akord orang ajar main alat musik sulit rumus akord main suara akord main beda suara akord ubah lagu main dengar fals simpang lagu sungguh kali ajar main alat musik media papar bentuk akord main akord main salah tentu tepat suara akord main musik otodidak bantu machine learning metode rekam suara akord gitar main klasifikasi akord gitar sesuai suara asli akord klasifikasi batas akord dasar ajar dasar tampil rumus akord main interaktif desain gamemusic is an art that combines several compositions of musical instruments among them are vocals piano guitar bass drums and so on to play a musical instrument also requires a technique to a formula so that the music game becomes more harmonious techniques and formulas in playing musical instruments include tempo rhythm how to play a musical instrument to chords but for people who are just learning to play a musical instrument it is certainly difficult to know the formula for the chords to be played not to mention when the sound of the chord being played is different from the sound of the intended chord this can change a song being played sound fake or deviate from the actual song often in learning to play musical instruments some media do not explain or explain how the chords are played and whether the chords are played correctly one way to determine the accuracy of the chord sound in a selftaught music game can be done using the help of machine learning this method records the sound of guitar chords being played and classifies guitar chords according to their original sound however chords that can be classified are still limited to basic chords because they are intended for the most basic learning and for the display of the chord formula that is played it will be more interactive when using game design
Klasifikasi Ictal dan Interictal Berdasarkan Rekaman EEG pada Pasien Epilepsi di Rumah Sakit Universitas Airlangga Menggunakan Smooth Support Vector Machine.,"Cahyaningrum, Fibia Sentauri",http://repository.its.ac.id/61622/,"Epilepsi merupakan salah satu gangguan neurologi yang ditandai dengan serangan kejang berulang. Peningkatan risiko serangan epilepsi dapat digambarkan dengan menggunakan EEG (electroencephalogram), yaitu rekaman aktivitas listrik sepanjang kulit kepala yang dihasilkan oleh penembakan neuron dalam otak selama periode tertentu. Klinis dengan kejang (ictal) dan klinis tanpa kejang (interictal) berdasarkan rekaman EEG perlu diklasifikasikan untuk mempermudah tenaga medis dalam memberikan treatment kepada pasien epilepsi. Namun, hasil analisa rekaman EEG secara visual antar tenaga medis dapat menghasilkan diagnosa yang berbeda akibat dari subjektivitas dan pengalaman tenaga medis yang berbeda, sehingga diperlukan metode klasifikasi yang cepat dan tepat. Metode pre-processing data rekaman EEG yang digunakan adalah Discrete Wavelet Transform untuk mendekomposisikan sinyal sehingga didapatkan gelombang theta, alpha, dan beta. Gelombang tersebut diekstraksi ke dalam fitur energy, deviasi standar, maksimum, minimum, dan entropy. Selanjutnya, pada tahap klasifikasi ictal dan interictal berdasarkan rekaman EEG menggunakan SVM dan SSVM didapatkan AUC masing-masing sebesar 97.83% dan 100%, sehingga metode SSVM lebih baik dibandingkan metode SVM.================================================================================================Epilepsy is a neurological disorder characterized by recurrent seizures. The increased risk of epileptic seizures can be described using EEG (electroencephalogram), which is a record of electrical activity along the scalp produced by the firing of neurons in the brain over a period of time. Clinically with seizures (ictal) and clinical without seizures (interictal) based on EEG recordings need to be classified to facilitate medical personnel in providing treatment to epilepsy patients. However, the results of analyzing EEG recordings visually between medical personnel can produce different diagnoses as a result of subjectivity and experience of different medical personnel, so a fast and precise classification method is needed. The pre-processing method of EEG recording data used is Discrete Wavelet Transform to decompose signals so that theta, alpha, and beta waves are obtained. The wave is extracted into the energy feature, standard deviation, maximum, minimum and entropy. Furthermore, at the ictal and interictal classification stages based on EEG recordings using SVM and SSVM, the AUC was 97.83% and 100% respectively, so the SSVM method was better than the SVM.",klasifikasi ictal interictal dasar rekam eeg pasien epilepsi rumah sakit universitas airlangga smooth support vector machine,epilepsi salah ganggu neurologi tanda serang kejang ulang tingkat risiko serang epilepsi gambar eeg electroencephalogram rekam aktivitas listrik kulit kepala hasil tembak neuron otak periode klinis kejang ictal klinis kejang interictal dasar rekam eeg klasifikasi mudah tenaga medis treatment pasien epilepsi hasil analisa rekam eeg visual tenaga medis hasil diagnosa beda akibat subjektivitas alam tenaga medis beda metode klasifikasi cepat metode preprocessing data rekam eeg discrete wavelet transform dekomposisi sinyal dapat gelombang theta alpha beta gelombang ekstraksi fitur energy deviasi standar maksimum minimum entropy tahap klasifikasi ictal interictal dasar rekam eeg svm ssvm dapat auc masingmasing 9783 100 metode ssvm banding metode svmepilepsy is a neurological disorder characterized by recurrent seizures the increased risk of epileptic seizures can be described using eeg electroencephalogram which is a record of electrical activity along the scalp produced by the firing of neurons in the brain over a period of time clinically with seizures ictal and clinical without seizures interictal based on eeg recordings need to be classified to facilitate medical personnel in providing treatment to epilepsy patients however the results of analyzing eeg recordings visually between medical personnel can produce different diagnoses as a result of subjectivity and experience of different medical personnel so a fast and precise classification method is needed the preprocessing method of eeg recording data used is discrete wavelet transform to decompose signals so that theta alpha and beta waves are obtained the wave is extracted into the energy feature standard deviation maximum minimum and entropy furthermore at the ictal and interictal classification stages based on eeg recordings using svm and ssvm the auc was 9783 and 100 respectively so the ssvm method was better than the svm
Surge Speed and Yaw Angle Control System Design On Unmanned Surface Vehicle (USV) Using PID-Fuzzy-Genetic Algorithm.,"Cendikiarani, Mutiara Tawakkal",http://repository.its.ac.id/105997/,"In this era of increasing technological and communication advances, human work is increasingly helped by the presence of technology, one of which is the advancement of Unmanned Surface Vehicle (USV). This research focuses on the design and implementation of control systems for Unmanned Surface Vehicles (USVs), which specifically address surge speed and yaw angle. One of the types of thrusters used in USVs is the Azimuth Thruster which indicates that the USV does not use steering leaves. The controller development carried out in this study is optimizing the PID-Fuzzy controller from previous research. The optimization method used is a genetic algorithm. Fuzzy used to adjust gain  K_p,τ_i,τ_d  whose design uses two inputs, namely error and delta error and output in the form of gain in the form of K_p,τ_i,τ_d . The genetic algorithm works to optimize the membership function of PID-Fuzzy where the results of the optimization will show the smallest error values in the control of the surge speed and yaw angle. FIS (Fuzzy Inference System) of the best generation then carried out closed loop trials on both control systems. The simulation results presented show that this method succeeded in reducing cross-track error (XTE) at the yaw angle to 62022 compared to PID and PID-Fuzzy controllers of 62199 and 62192 respectively. The number of error areas at surge speeds also decreased in the PID-Fuzzy-Genetic Algorithm controller by as much. As shown, the intended method has the lowest error and can reduce until 7.1577% and reducing %Overshoot and speed up rise time. The best generation generated by genetic algorithms is able to make USVs cross the track quite well compared to other controllers.===================================================================================================================================Di zaman kemajuan teknologi dan komunikasi yang terus meningkat ini, pekerjaan manusia semakin terbantu dengan hadirnya teknologi salah satunya berupa kemajuan Unmanned Surface Vehicle (USV). Penelitian ini berfokus pada desain dan implementasi sistem kontrol untuk Unmanned Surface Vehicles (USV), yang secara khusus menangani kecepatan surge dan sudut yaw. Tipe pendorong yang digunakan pada USV salah satunya adalah Azimuth Thruster yang menandakan USV tersebut tidak menggunakan daun kemudi. Pengembangan kontroler yang dilakukan pada penelitian ini adalah mengoptimisasi kontroler PID-Fuzzy dari penelitian sebelumnya. Metode pengoptimisasian yang digunakan adalah algoritma genetika. Fuzzy yang digunakan mengatur gain K_p,τ_i,τ_d  . yang perancangannya menggunakan dua input yaitu error dan delta error dan output berupa gain berupa K_p,τ_i,τ_d . Algoritma genetika berkerja untuk mengoptimisasi membership function dari PID-Fuzzy dimana hasil dari optimisasi akan menunjukkan nilai error terkecil pada kontrol kecepatan surge dan sudut yaw. FIS (Fuzzy Inference System) dari generasi terbaik kemudian dilakukan uji coba closed loop pada kedua system kontrol. Hasil simulasi yang disajikan menunjukkan bahwa metode ini berhasil mereduksi cross-track error (XTE) pada sudut yaw menjadi sebesar 62022 dibandingkan dengan kontroler PID dan PID-Fuzzy yang masing-masing sebesar 62199 dan 62192. Jumlah area eror pada kecepatan surge juga mengalami penurunan pada kontroler yang dimaksud sebanyak 7.1577% . Seperti yang ditunjukkan, metode yang dimaksudkan memiliki kesalahan terendah dan dapat mengurangi %Overshoot dan mempercepat rise time. Generasi terbaik yang dihasilkan algoritma genetika mampu membuat USV melintasi lintasan dengan cukup baik dibandingkan pengontrol lainnya.",surge speed and yaw angle control system design on unmanned surface vehicle usv using pidfuzzygenetic algorithm,in this era of increasing technological and communication advances human work is increasingly helped by the presence of technology one of which is the advancement of unmanned surface vehicle usv this research focuses on the design and implementation of control systems for unmanned surface vehicles usvs which specifically address surge speed and yaw angle one of the types of thrusters used in usvs is the azimuth thruster which indicates that the usv does not use steering leaves the controller development carried out in this study is optimizing the pidfuzzy controller from previous research the optimization method used is a genetic algorithm fuzzy used to adjust gain kp i d whose design uses two inputs namely error and delta error and output in the form of gain in the form of kp i d the genetic algorithm works to optimize the membership function of pidfuzzy where the results of the optimization will show the smallest error values in the control of the surge speed and yaw angle fis fuzzy inference system of the best generation then carried out closed loop trials on both control systems the simulation results presented show that this method succeeded in reducing crosstrack error xte at the yaw angle to 62022 compared to pid and pidfuzzy controllers of 62199 and 62192 respectively the number of error areas at surge speeds also decreased in the pidfuzzygenetic algorithm controller by as much as shown the intended method has the lowest error and can reduce until 71577 and reducing overshoot and speed up rise time the best generation generated by genetic algorithms is able to make usvs cross the track quite well compared to other controllersdi zaman maju teknologi komunikasi tingkat kerja manusia bantu hadir teknologi salah satu maju unmanned surface vehicle usv teliti fokus desain implementasi sistem kontrol unmanned surface vehicles usv khusus tangan cepat surge sudut yaw tipe dorong usv salah satu azimuth thruster tanda usv daun kemudi kembang kontroler teliti mengoptimisasi kontroler pidfuzzy teliti metode pengoptimisasian algoritma genetika fuzzy atur gain kp i d ancang input error delta error output gain kp i d algoritma genetika kerja mengoptimisasi membership function pidfuzzy mana hasil optimisasi nilai error kecil kontrol cepat surge sudut yaw fis fuzzy inference system generasi baik uji coba closed loop system kontrol hasil simulasi saji metode hasil reduksi crosstrack error xte sudut yaw 62022 banding kontroler pid pidfuzzy masingmasing 62199 62192 area eror cepat surge alami turun kontroler 71577 metode milik salah rendah kurang overshoot cepat rise time generasi baik hasil algoritma genetika usv lintas lintas banding kontrol
Analisis Sentimen Tentang Berita Terkait Risiko Industri di Indonesia Pada Masa Pandemi COVID-19 Menggunakan Metode Hybrid GRU-SVM.,"Chofiyya, Violeta Nur",http://repository.its.ac.id/91260/,"Dengan diberlakukan kebijakan Pembatasan Sosial Berskala Besar (PSBB) oleh Pemerintah Indonesia, banyak sektor mengalami keterpurukan seperti halnya pada sektor Industri. Salah satu upaya untuk membangkitkan kondisi terpuruk sektor industri adalah dengan mengetahui beberapa risiko industri selama masa pandemi COVID19. Dengan memanfaatkan media sosial, Tugas Akhir ini bertujuan untuk menganalisis sentimen pendapat masyarakat terkait risiko industri selama masa pandemi COVID19. Analisis sentimen pada penelitian ini dilakukan dengan menggunakan metode hybrid antara Gated Recurrent Unit (GRU) dan Support Vector Machine (SVM) yang disingkat menjadi Hybrid GRUSVM. Secara singkat, metode GRU digunakan untuk membangkitkan fitur semantik teks data dari media sosial. Selanjutnya, SVM mengklasifikasikan fitur semantik tersebut menjadi positif, netral atau negatif. Metode Hybrid GRUSVM diimplementasikan pada data Twitter dan berita online terkait risiko industri selama pandemi COVID19 di Indonesia, dan dibandingkan dengan metode dasar yaitu GRU dan SVM. Hasil eksperimen diperoleh bahwa SVM mampu mengalahkan baik metode GRU dan Hybrid GRUSVM.====================================================================================================As a largescale social restriction enacted by government, many sectors was have experienced a slump as in the industrial sector. One of the efforts to revive the slumping condition of the industrial sector is to know some industrial risks during the COVID19 pandemic. By utilizing social media, this Final Project aims to analyze public opinion sentiment regarding industrial risks during the COVID19 pandemic. Sentiment analysis in this study was conducted using a hybrid method between the Gated Recurrent Unit (GRU) and the Support Vector Machine (SVM) which is abbreviated as Hybrid GRUSVM. Briefly, the GRU method is used to generate semantic features of data text from social media. Furthermore, SVM classifies these semantic features into positive, neutral or negative. The Hybrid GRUSVM method is implemented on Twitter data and online news related to industrial risks during the COVID19 pandemic in Indonesia, and compared to the basic methods, namely GRU and SVM. The experimental results show that SVM is able to beat both the GRU and Hybrid GRUSVM methods.",analisis sentimen berita kait risiko industri indonesia pandemi covid19 metode hybrid grusvm,laku bijak batas sosial skala psbb perintah indonesia sektor alami puruk hal sektor industri salah upaya bangkit kondisi puruk sektor industri risiko industri pandemi covid19 manfaat media sosial tugas tuju analis sentimen dapat masyarakat kait risiko industri pandemi covid19 analisis sentimen teliti metode hybrid gated recurrent unit gru support vector machine svm singkat hybrid grusvm singkat metode gru bangkit fitur semantik teks data media sosial svm klasifikasi fitur semantik positif netral negatif metode hybrid grusvm implementasi data twitter berita online kait risiko industri pandemi covid19 indonesia banding metode dasar gru svm hasil eksperimen oleh svm kalah metode gru hybrid grusvmas a largescale social restriction enacted by government many sectors was have experienced a slump as in the industrial sector one of the efforts to revive the slumping condition of the industrial sector is to know some industrial risks during the covid19 pandemic by utilizing social media this final project aims to analyze public opinion sentiment regarding industrial risks during the covid19 pandemic sentiment analysis in this study was conducted using a hybrid method between the gated recurrent unit gru and the support vector machine svm which is abbreviated as hybrid grusvm briefly the gru method is used to generate semantic features of data text from social media furthermore svm classifies these semantic features into positive neutral or negative the hybrid grusvm method is implemented on twitter data and online news related to industrial risks during the covid19 pandemic in indonesia and compared to the basic methods namely gru and svm the experimental results show that svm is able to beat both the gru and hybrid grusvm methods
Kontrol Pergerakan Kursi Roda Berbasis Eye Gesture Menggunakan CNN.,"Collin, Evandrew Reynald",http://repository.its.ac.id/108688/,"Penelitian ini menghadirkan pendekatan baru untuk meningkatkan mobilitas bagi pasien ALS dengan mengembangkan sistem kontrol pergerakan kursi roda menggunakan CNN (Convolutional Neural Network), yang berfokus pada pengenalan pose mata, dan diimplementasikan pada platform Intel NUC. Studi ini didorong oleh tantangan yang dihadapi oleh pasien ALS, yang meskipun kehilangan mobilitas fisik, tetap dapat menggerakkan mata. Sistem yang diusulkan bertujuan untuk memberikan kemandirian yang lebih besar dan peningkatan kualitas hidup bagi individu tersebut. Metodologi penelitian ini terdiri dari beberapa komponen kunci: pengambilan dan pengolahan gambar mata, ekstraksi fitur yang relevan, estimasi dan klasifikasi posisi mata, serta eksekusi sistem kontrol pada Next Unit of Computing (NUC). Dengan memanfaatkan MediaPipe untuk pengenalan pose secara real-time dan kemampuan komputasi Intel NUC, studi ini menghasilkan peningkatan yang signifikan dalam otonomi pengguna kursi roda dengan gangguan mobilitas. Model klasifikasi yang digunakan menunjukkan kinerja yang sangat baik berdasarkan hasil evaluasi confusion matrix, dengan nilai accuracy, precision, recall, dan f-1 score sebesar 99%. Performa model pada jarak 30 dan 50 cm, model memiliki akurasi tertinggi yaitu 100%. Model memiliki kinerja yang cukup baik di berbagai tingkat pencahayaan, dengan akurasi tertinggi 100% pada pencahayaan 131 Lux. Model juga menunjukkan hasil deteksi yang cukup baik pada subjek yang berbeda-beda. Sistem menunjukkan kinerja FPS yang cukup baik pada NUC. Waktu respons motor rata-rata untuk perintah ""Kanan,"" ""Kiri,"" dan ""Mundur"" di bawah 0,25 detik, sedangkan untuk perintah ""Maju"" dan ""Stop"" sekitar 0,43 detik. Motor kursi roda menunjukkan waktu output yang konsisten di setiap kelas perintah, dengan standar deviasi terendah pada perintah ""Maju"" (0,117), menunjukkan keandalan sistem dalam memberikan respons yang stabil dan konsisten. Penelitian ini tidak hanya berkontribusi pada bidang teknologi bantu, tetapi juga berpotensi menjadi model untuk inovasi masa depan dalam solusi mobilitas bagi individu dengan berbagai disabilitas fisik.=================================================================================================================================This research presents a novel approach to improving mobility for ALS patients by developing a wheelchair movement control system using CNN (Convolutional Neural Network), focusing on eye pose recognition, and implementing it on the Intel NUC platform. This study is motivated by the challenges faced by ALS patients, who, despite losing physical mobility, can still move their eyes. The proposed system aims to provide greater independence and improved quality of life for these individuals. The research methodology comprises several key components: eye image capture and processing, relevant feature extraction, eye position estimation and classification, and control system execution on the Next Unit of Computing (NUC). Utilizing MediaPipe for real-time pose recognition and the computational capabilities of Intel NUC, this study significantly enhances the autonomy of wheelchair users with mobility impairments. The classification model used demonstrates excellent performance based on the evaluation of the confusion matrix, with accuracy, precision, recall, and F-1 score values of 99%. It achieves the highest accuracy of 100% at distances of 30 and 50 cm. It performs well under various lighting conditions, with the highest accuracy of 100% at 131 Lux. It also shows good detection results across different subjects. The system shows decent FPS performance on the NUC. The average motor response time for ""Right,"" ""Left,"" and ""Backward"" commands is below 0.25 seconds, while for ""Forward"" and ""Stop"" commands it is around 0.43 seconds. The wheelchair motor demonstrates consistent output time across all command classes, with the lowest standard deviation on the ""Forward"" command (0.117), indicating the system's reliability in providing stable and consistent responses. This research not only contributes to the field of assistive technology but also has the potential to serve as a model for future innovations in mobility solutions for individuals with various physical disabilities.",kontrol gera kursi roda bas eye gesture cnn,teliti hadir dekat tingkat mobilitas pasien als kembang sistem kontrol gera kursi roda cnn convolutional neural network fokus kenal pose mata implementasi platform intel nuc studi dorong tantang hadap pasien als hilang mobilitas fisik gerak mata sistem usul tuju mandiri tingkat kualitas hidup individu metodologi teliti komponen kunci ambil olah gambar mata ekstraksi fitur relevan estimasi klasifikasi posisi mata eksekusi sistem kontrol next unit of computing nuc manfaat mediapipe kenal pose realtime mampu komputasi intel nuc studi hasil tingkat signifikan otonomi guna kursi roda ganggu mobilitas model klasifikasi kerja dasar hasil evaluasi confusion matrix nilai accuracy precision recall f1 score 99 performa model jarak 30 50 cm model milik akurasi tinggi 100 model milik kerja tingkat cahaya akurasi tinggi 100 cahaya 131 lux model hasil deteksi subjek berbedabeda sistem kerja fps nuc respons motor ratarata perintah kanan kiri mundur 025 detik perintah maju stop 043 detik motor kursi roda output konsisten kelas perintah standar deviasi rendah perintah maju 0117 andal sistem respons stabil konsisten teliti kontribusi bidang teknologi bantu potensi model inovasi solusi mobilitas individu disabilitas fisikthis research presents a novel approach to improving mobility for als patients by developing a wheelchair movement control system using cnn convolutional neural network focusing on eye pose recognition and implementing it on the intel nuc platform this study is motivated by the challenges faced by als patients who despite losing physical mobility can still move their eyes the proposed system aims to provide greater independence and improved quality of life for these individuals the research methodology comprises several key components eye image capture and processing relevant feature extraction eye position estimation and classification and control system execution on the next unit of computing nuc utilizing mediapipe for realtime pose recognition and the computational capabilities of intel nuc this study significantly enhances the autonomy of wheelchair users with mobility impairments the classification model used demonstrates excellent performance based on the evaluation of the confusion matrix with accuracy precision recall and f1 score values of 99 it achieves the highest accuracy of 100 at distances of 30 and 50 cm it performs well under various lighting conditions with the highest accuracy of 100 at 131 lux it also shows good detection results across different subjects the system shows decent fps performance on the nuc the average motor response time for right left and backward commands is below 025 seconds while for forward and stop commands it is around 043 seconds the wheelchair motor demonstrates consistent output time across all command classes with the lowest standard deviation on the forward command 0117 indicating the systems reliability in providing stable and consistent responses this research not only contributes to the field of assistive technology but also has the potential to serve as a model for future innovations in mobility solutions for individuals with various physical disabilities
Prediksi Infesi Saluran Pernafasan Akut (ISPA) Pada Anak Dibawah Lima Tahun Menggunakan Stacking Support Vector Machine (SVN).,"Damayanti, Reynata Tri",http://repository.its.ac.id/96341/,"Kesehatan anak pada usia awal kehidupan sangat rentan terhadap penyakit. Terdapat penyakit yang mengancam kematian pada anak yaitu Infeksi Saluran Pernafasan Akut (ISPA). ISPA merupakan infeksi akut pada saluran pernafasan bagian atas. Infeksi ini menyerang komponen saluran pernafasan bagian atas seperti hidung, sinus, faring, dan laring. Menurut World Health Organization (WHO), kematian anak akibat penyakit ini cukup tinggi. ISPA menyebabkan kematian hampir 20% kematian anak balita di seluruh dunia. Terdapat berbagai faktor yang mengakibatkan anak sakit, salah satunya berkaitan dengan masalah gizi anak. Oleh karena itu, penelitian ini akan membuat model prediksi berdasarkan data kebutuhan gizi anak untuk mencegah anak mengidap ISPA.  Penelitian ini mengembangkan model untuk memprediksi penyakit ISPA pada anak dibawah umur lima tahun menggunakan pendekatan machine learning. Metode yang digunakan yaitu Support Vector Machine (SVM) dan stacking SVM. Sementara data yang digunakan berasal dari Clinical, Anthropometric & Bio-Chemical (CAB). Data yang tersedia pada dataset CAB antara lain berkaitan dengan data antropometri seperti berat badan dan tinggi badan; data klinis seperti tekanan darah, hasil tes gula darah; data biokimia seperti tingkat Hb; dan konsumsi saat anak dibawah umur 3 tahun seperti waktu konsumsi ASI, waktu awal konsumsi air, susu hewan, makanan pendamping semisolid dan solid, serta sayuran.  Hasil dari percobaan menggunakan SVM saja menghasilkan akurasi terbaik sebesar 67%. Model SVM ini menggunakan parameter kernel Poly, Cost = 10, dan gamma = 0.1. Sementara pada model stacking SVM menghasilkan akurasi yang sama yaitu 67% dengan model sebagai berikut: model SVM dengan kernel linear, C=100, gamma=1; SVM dengan kernel poly; dan SVM dengan kernel poly, C=10, gamma=0.1=====================================================================================================================================Children's health at an early age of life is very vulnerable to disease. There is a disease that threatens death in children, namely Acute Respiratory Infection (ARI). ISPA is an acute infection of the upper respiratory tract. This infection attacks the components of the upper respiratory tract such as the nose, sinuses, pharynx and larynx. According to the World Health Organization (WHO), child mortality due to this disease is quite high. ISPA causes the death of nearly 20% of under-five deaths worldwide. There are various factors that cause children to get sick, one of which is related to child nutrition problems. Therefore, this study will create a predictive model based on data on children's nutritional needs to prevent children from contracting ARI. This research develops a model to predict ARI in children under the age of five using a machine learning approach. The method used is Support Vector Machine (SVM) and SVM stacking. While the data used comes from Clinical, Anthropometric & Bio-Chemical (CAB). The data available in the CAB dataset relates to anthropometric data such as body weight and height; clinical data such as blood pressure, blood sugar test results; biochemical data such as Hb level; and consumption when children are under 3 years old such as when consuming breast milk, when starting to consume water, animal milk, semisolid and solid complementary foods, and vegetables. The results of the experiment using SVM alone produce the best accuracy of 67%. This SVM model uses kernel parameters Poly, Cost = 10, and gamma = 0.1. While the SVM stacking model produces the same accuracy of 67% with the following models: SVM model with a linear kernel, C=100, gamma=1; SVM with poly kernels; and SVM with poly kernel, C=10, gamma=0.1",prediksi infesi salur nafas akut ispa anak bawah stacking support vector machine svn,sehat anak usia hidup rentan sakit sakit ancam mati anak infeksi salur nafas akut ispa ispa infeksi akut salur nafas infeksi serang komponen salur nafas hidung sinus faring laring world health organization who mati anak akibat sakit ispa sebab mati 20 mati anak balita dunia faktor akibat anak sakit salah satu kait gizi anak teliti model prediksi dasar data butuh gizi anak cegah anak idap ispa teliti kembang model prediksi sakit ispa anak bawah umur dekat machine learning metode support vector machine svm stacking svm data asal clinical anthropometric biochemical cab data sedia dataset cab kait data antropometri berat badan badan data klinis tekan darah hasil tes gula darah data biokimia tingkat hb konsumsi anak bawah umur 3 konsumsi asi konsumsi air susu hewan makan damping semisolid solid sayur hasil coba svm hasil akurasi baik 67 model svm parameter kernel poly cost 10 gamma 01 model stacking svm hasil akurasi 67 model model svm kernel linear c100 gamma1 svm kernel poly svm kernel poly c10 gamma01childrens health at an early age of life is very vulnerable to disease there is a disease that threatens death in children namely acute respiratory infection ari ispa is an acute infection of the upper respiratory tract this infection attacks the components of the upper respiratory tract such as the nose sinuses pharynx and larynx according to the world health organization who child mortality due to this disease is quite high ispa causes the death of nearly 20 of underfive deaths worldwide there are various factors that cause children to get sick one of which is related to child nutrition problems therefore this study will create a predictive model based on data on childrens nutritional needs to prevent children from contracting ari this research develops a model to predict ari in children under the age of five using a machine learning approach the method used is support vector machine svm and svm stacking while the data used comes from clinical anthropometric biochemical cab the data available in the cab dataset relates to anthropometric data such as body weight and height clinical data such as blood pressure blood sugar test results biochemical data such as hb level and consumption when children are under 3 years old such as when consuming breast milk when starting to consume water animal milk semisolid and solid complementary foods and vegetables the results of the experiment using svm alone produce the best accuracy of 67 this svm model uses kernel parameters poly cost 10 and gamma 01 while the svm stacking model produces the same accuracy of 67 with the following models svm model with a linear kernel c100 gamma1 svm with poly kernels and svm with poly kernel c10 gamma01
"Perancangan dan Implementasi Chatbot Pembelajaran
Candi Borobudur pada Metaversitas.","Dewanata, Rere Arga",http://repository.its.ac.id/105516/,"Magang bersertifikat adalah salah satu program yang termasuk dalam Merdeka Belajar Kampus Merdeka (MBKM) yang diselenggarakan oleh Kementerian Pendidikan, Kebudayaan,Riset, dan Teknologi (Kemendikbudristek). Kegiatan ini memberikan kesempatan kepada mahasiswa untuk turut serta dalam praktik kerja secara langsung di berbagai mitra. Tak hanya sebagai penyelenggara, Kemendikbudristek juga berperan sebagai mitra penulis melalui Direktorat Jenderal Pendidikan Tinggi, Riset, dan Teknologi (Ditjen Diktiristek). Pada batch ke-5 ini, Ditjen Diktiristek melakukan pengembangan sistem pembelajaran interaktif pada Metaversitas mengenai Candi Borobudur yang dilengkapi asisten virtual berupa chatbot. Pengembangan sistem dilakukan menggunakan Large Language Model (LLM) opensource “Asyafiqe/Merak-7B-v3-Mini-Orca-Indo” yang dilakukan penambahan konteks dengan dataset mengenai Candi Borobudur dari jurnal dan buku agar terjaga kredibilitasnya.",ancang implementasi chatbot ajar candi borobudur metaversitas,magang sertifikat salah program merdeka ajar kampus merdeka mbkm selenggara menteri didik kebudayaanriset teknologi kemendikbudristek giat sempat mahasiswa praktik kerja langsung mitra selenggara kemendikbudristek peran mitra tulis direktorat jenderal didik riset teknologi ditjen diktiristek batch ke5 ditjen diktiristek kembang sistem ajar interaktif metaversitas candi borobudur lengkap asisten virtual chatbot kembang sistem large language model llm opensource  asyafiqemerak7bv3miniorcaindo  tambah konteks dataset candi borobudur jurnal buku jaga kredibilitas
Prototipe Sistem Deteksi Perintah Dan Klasifikasi Kelompok Usia Berbasis Suara Pada Perangkat Tiny Machine Learning (TINYML).,"Dewandra, Abadila Barasmara Bias",http://repository.its.ac.id/106094/,"Suara merupakan identitas seseorang yang memiliki ciri-ciri unik. Seiring bertambahnya usia, suara mengalami perubahan dan menunjukkan karakteristik khusus pada berbagai tahapan kehidupan. Meskipun sistem klasifikasi suara telah banyak diintegrasikan dalam berbagai perangkat pintar untuk melaksanakan tugas tertentu, masih terdapat beberapa kelemahan, terutama dalam bidang keamanan, di mana sistem cenderung tidak memperhatikan faktor usia pengguna dan hanya menerima suara perintah tertentu. Penelitian ini bertujuan untuk mengembangkan prototipe sistem suara yang mampu menerima perintah suara sekaligus mengklasifikasikan usia pengguna. Pengembangan menggunakan model One-Dimensional Convolutional Neural Network (1D CNN) dengan ekstraksi fitur menggunakan Mel Frequency Cepstral Coefficient (MFCC) dan membandingkannya dengan model klasifikasi usia sebelumnya di berbagai dataset. Model diintegrasikan ke perangkat Arduino Nano 33 BLE Sense Lite dan dikembangkan menggunakan platform Edge Impulse. Pengujian dilakukan dengan variasi skenario kelompok usia dan perintah 'buka' dan 'tutup'. Skenario terbaik akan dipilih berdasarkan jumlah label terbanyak dengan akurasi terbaik. Sistem pada skenario terbaik memiliki akurasi terkuantisasi sebesar 89.59%. Setelah proses optimasi, akurasi meningkat menjadi 97.91%. Model akan dikembangkan menjadi gerendel pintar yang menggerakkan kunci sesuai jenjang usia tertentu. Hasil ini menunjukkan potensi sistem untuk diterapkan dalam konteks keamanan dan autentikasi suara dengan sumber daya terbatas====================================================================================================================================Voice is the identity of a person who has unique characteristics. As we age, the voice changes and exhibits special characteristics at different stages of life. Although voice classification systems have been widely integrated in various smart devices to carry out certain tasks, there are still some weaknesses, especially in the field of security, where the systems tend not to pay attention to the user's age and only accept certain voice commands. This research aims to develop a voice system prototype that is capable of receiving voice commands while classifying the user's age. The development uses a One-Dimensional Convolutional Neural Network (1D CNN) model with feature extraction using the Mel Frequency Cepstral Coefficient (MFCC) and compares it with previous age classification models in various datasets. The model is integrated into an Arduino Nano 33 BLE Sense Lite device and developed using the Edge Impulse platform. Testing was carried out with a variety of age group scenarios and 'open' and 'close' commands. The best scenario will be selected based on the largest number of labels with the best accuracy. The system in the best scenario has a quantized accuracy of 89.59%. After the optimization process, the accuracy increased to 97.91%. The model will be developed into a smart deadbolt that moves the key according to certain age levels. These results demonstrate the system's potential for application in resource-limited voice security and authentication contexts.",prototipe sistem deteksi perintah klasifikasi kelompok usia bas suara perangkat tiny machine learning tinyml,suara identitas milik ciriciri unik iring tambah usia suara alami ubah karakteristik khusus tahap hidup sistem klasifikasi suara integrasi perangkat pintar laksana tugas lemah bidang aman sistem cenderung perhati faktor usia guna terima suara perintah teliti tuju kembang prototipe sistem suara terima perintah suara klasifikasi usia guna kembang model onedimensional convolutional neural network 1d cnn ekstraksi fitur mel frequency cepstral coefficient mfcc banding model klasifikasi usia dataset model integrasi perangkat arduino nano 33 ble sense lite kembang platform edge impulse uji variasi skenario kelompok usia perintah buka tutup skenario baik pilih dasar label akurasi baik sistem skenario baik milik akurasi terkuantisasi 8959 proses optimasi akurasi tingkat 9791 model kembang gerendel pintar gerak kunci sesuai jenjang usia hasil potensi sistem terap konteks aman autentikasi suara sumber daya terbatasvoice is the identity of a person who has unique characteristics as we age the voice changes and exhibits special characteristics at different stages of life although voice classification systems have been widely integrated in various smart devices to carry out certain tasks there are still some weaknesses especially in the field of security where the systems tend not to pay attention to the users age and only accept certain voice commands this research aims to develop a voice system prototype that is capable of receiving voice commands while classifying the users age the development uses a onedimensional convolutional neural network 1d cnn model with feature extraction using the mel frequency cepstral coefficient mfcc and compares it with previous age classification models in various datasets the model is integrated into an arduino nano 33 ble sense lite device and developed using the edge impulse platform testing was carried out with a variety of age group scenarios and open and close commands the best scenario will be selected based on the largest number of labels with the best accuracy the system in the best scenario has a quantized accuracy of 8959 after the optimization process the accuracy increased to 9791 the model will be developed into a smart deadbolt that moves the key according to certain age levels these results demonstrate the systems potential for application in resourcelimited voice security and authentication contexts
REAL-TIME RELIABILITY PREDICTION PADA MOTOR DC MENGGUNAKAN PARTICLE FILTERING.,"Dewani, Niken Dian Rahma",http://repository.its.ac.id/76846/,"Keamanan dan kehandalan operasi sistem pada suatu plant sangat berpengaruh terhadap kinerja dan keselamatan proses, sehingga diperlukan suatu cara untuk dapat mengetahui kehandalan dari suatu plant. Salah satu instrumen yang paling sering digunakan di industri adalah motor listrik, dan salah satu jenis dari motor listrik ini adalah motor DC. Penurunan performansi pada motor DC dapat menyebabkan penurunan keandalannya, sehingga diperlukan prediksi reliabilitas untuk motor DC. Tujuan dari Tugas Akhir ini adalah untuk dapat merancang sistem monitoring keandalan pada motor DC dengan algoritma particle filtering dan mengetahui tingkat ketelitian dan performansi sistem monitoring keandalan pada motor DC dengan algoritma particle filtering. Tahapan-tahapan yang dilakukan antara lain perancangan pemodelan sistem kontrol motor DC dengan kesalahan sensor, perancangan algoritma particle filtering untuk mengestimasi kesalahan, perancangan algoritma exponential smoothing, serta perancangan sistem prediksi keandalan. Pengujian dilakukan dengan parameter Holt a=0.1 dan b=0.1 dengan batas atas kecepatan motor sebesar 2,3 m/s. Pada uji algoritma prediksi keandalan dengan 3 jenis step, didapatkan hasil prediksi keandalan dengan sepuluh step memiliki ketelitian paling baik dan ketiga step mencapai R=0 pada detik ke 13.606 detik, lebih lambat 6 detik dari keadaan sebenarnya yaitu pada detik ke-13.600,08.========================================================================================================================Security and reliability of a system operation at a plant is very influential on the performance and safety of the process, so we need to find a way to be able to determine the reliability of a plant. One of the most commonly used instrument in the industry is electric motor, and one of them is DC motor. A decrease in the performance of the DC motor can cause the decrease in its reliability, so a reliability prediction system is needed for a DC motor. The purpose of this Final Project is to be able to design a reliability monitoring system on a DC motor with a particle filtering algorithm and determine the level of accuracy and performance of a reliability monitoring system on a DC motor with a particle filtering algorithm. The steps taken include designing a DC motor control system with sensor error, designing a particle filtering algorithm to estimate errors, designing an exponential smoothing algorithm, and designing a predictive reliability system. The test was carried out with Holt’s parameters a = 0.1 and b = 0.1 with the upper limit of the motor speed of 2.3 m/s. From the reliability prediction algorithm test with 3 types of steps, the results obtained from the reliability predictions system are that the ten steps prediction has the best performance from all the steps predictions and the 3 types of prediction steps reach R=0 at 13.606 seconds, 6 seconds slower than the the real condition that reach the same point at 13.600,08 seconds.",realtime reliability prediction motor dc particle filtering,aman kehandalan operasi sistem plant pengaruh kerja selamat proses kehandalan plant salah instrumen industri motor listrik salah jenis motor listrik motor dc turun performansi motor dc sebab turun andal prediksi reliabilitas motor dc tuju tugas rancang sistem monitoring andal motor dc algoritma particle filtering tingkat teliti performansi sistem monitoring andal motor dc algoritma particle filtering tahapantahapan ancang model sistem kontrol motor dc salah sensor ancang algoritma particle filtering estimasi salah ancang algoritma exponential smoothing ancang sistem prediksi andal uji parameter holt a01 b01 batas cepat motor 23 ms uji algoritma prediksi andal 3 jenis step dapat hasil prediksi andal puluh step milik teliti tiga step capai r0 detik 13606 detik lambat 6 detik detik ke1360008security and reliability of a system operation at a plant is very influential on the performance and safety of the process so we need to find a way to be able to determine the reliability of a plant one of the most commonly used instrument in the industry is electric motor and one of them is dc motor a decrease in the performance of the dc motor can cause the decrease in its reliability so a reliability prediction system is needed for a dc motor the purpose of this final project is to be able to design a reliability monitoring system on a dc motor with a particle filtering algorithm and determine the level of accuracy and performance of a reliability monitoring system on a dc motor with a particle filtering algorithm the steps taken include designing a dc motor control system with sensor error designing a particle filtering algorithm to estimate errors designing an exponential smoothing algorithm and designing a predictive reliability system the test was carried out with holt  s parameters a 01 and b 01 with the upper limit of the motor speed of 23 ms from the reliability prediction algorithm test with 3 types of steps the results obtained from the reliability predictions system are that the ten steps prediction has the best performance from all the steps predictions and the 3 types of prediction steps reach r0 at 13606 seconds 6 seconds slower than the the real condition that reach the same point at 1360008 seconds
Analisis dan Prediksi Biaya Penanganan Penyakit Pasien Terdaftar BPJS Menggunakan Machine Learning.,"Dharmawan, Dewangga",http://repository.its.ac.id/106620/,"BPJS Kesehatan bertanggung jawab untuk memberikan bantuan dana bagi seluruh penduduk Indonesia. Tetapi, persebaran sumber daya medis di Indonesia merupakan salah satu yang terendah dibandingkan dengan negara Asia Tenggara lainnya. Sumber daya medis juga menipis selama masa pandemi COVID-19. Salah satu cara untuk mengatasi permasalahan tersebut adalah mengalokasikan sumber daya medis, terutama waktu, bagi staf medis agar dapat menyeimbangkan keperluan dari masing-masing kunjungan pasien. Selain itu, pasien yang akan mengunjungi fasilitas kesehatan ingin mengetahui biaya yang akan mereka bayar untuk mendapatkan layanan kesehatan tersebut agar mereka dapat memiliki kepercayaan terhadap fasilitas kesehatan yang mereka kunjungi dan tidak memiliki permasalahan finansial yang ada dalam pembayaran pelayanan tersebut. Berdasarkan permasalahan tersebut, tugas akhir ini mengusulkan untuk memprediksi lama dan biaya kunjungan fasilitas kesehatan menggunakan regresi yang berguna bagi staf medis, pasien, dan pihak manapun yang memerlukan prediksi tersebut. Data yang digunakan adalah data dari BPJS dari 2015 sampai 2020 yang terdiri dari dataset peserta BPJS, dataset kunjungan FKRTL, dan dataset kunjungan FKTP non-kapitasi. Data dari BPJS dilakukan persiapan data dan pre-processing agar mendapatkan data yang lebih bersih. Data tersebut lalu dilakukan modeling dengan beberapa algoritma, yaitu Ensemble Learning (Random Forest, Gradient Boosting, XGBoost, LightGBM, dan CatBoost), regresi linear, SVR, dan Decision Tree. Masing-masing model dibandingkan untuk mencari model yang terbaik berdasarkan metrik R2, RMSE, dengan nRMSE sebagai pelengkap, dan MAPE. Dalam proses modeling, terdapat beberapa uji coba untuk meningkatkan nilai-nilai metrik dari masing-masing model yang terdiri dari normalisasi, seleksi fitur, clustering, dan tuning hyperparameter. Setelah proses uji coba, masing-masing model dipilih berdasarkan nilai-nilai metrik sebelumnya untuk menemukan model terbaik untuk memprediksi biaya dan lama kunjungan fasilitas kesehatan. Berdasarkan hasil uji coba, terdapat dua hasil yang berbeda diantara dua dataset kunjungan yang berbeda. Algoritma CatBoost menjadi algoritma yang terbaik untuk memprediksi biaya dan lama kunjungan FKRTL dengan nilai rata-rata R2 sebesar 85,93%, nilai rata-rata RMSE dan nRMSE sebesar 1,1768 dan 8,2%, dan nilai rata-rata MAPE sebesar 13,43%. Tetapi, algoritma Random Forest memiliki nilai rata-rata MAPE yang lebih rendah dengan nilai 12,79%. Dalam dataset kunjungan FKTP non-kapitasi, hanya biaya kunjungan yang diprediksi karena lama kunjungan hanya memiliki satu nilai saja, yaitu satu hari. Algoritma LightGBM menjadi algoritma terbaik untuk memprediksi biaya kunjungan FKTP non-kapitasi dengan nilai R2 sebesar 80,23% dan nilai RMSE dan nRMSE sebesar 0,6504 dan 11,02%. Tetapi, dalam proses uji coba terhadap dataset kunjungan FKTP non-kapitasi, nilai MAPE cenderung lebih besar daripada uji coba dataset kunjungan FKRTL, dengan nilai MAPE terkecil terletak pada model Decision Tree dengan nilai 69,16%. Secara keseluruhan, metode Ensemble Learning memiliki nilai metrik yang lebih tinggi. Dengan demikian, metode yang diusulkan dapat memprediksi biaya dan lama waktu kunjungan dengan performa yang cukup baik dan diharapkan bahwa tugas akhir ini dapat membantu pasien untuk mendapatkan ekspektasi biaya dan lama kunjungan ke fasilitas kesehatan dan staf untuk menentukan sumber daya medis yang digunakan.=================================================================================================================================Health BPJS is responsible for giving financial aid to the whole population of Indonesia. However, the spread of medical resources in Indonesia is one of the least spread compared to the rest of Southeast Asia. Medical resources become thinner during the COVID-19 pandemic. One of the ways to deal with said problem is to allocate medical resources, especially time, for the medical staff to balance the resources. Other than that, patients who visit a health facility want to know the projected price to get the health service so that they would put their trust onto the health facility they visit and not to have financial issues during the payment of the service. Based on said problem, this final project proposes to predict the price and the length of health facility services using regression that is useful for medical staff, patients, and anyone who needs it. The data that is used is the data from BPJS from 2015 to 2020 which consists of BPJS members, FKRTL visits, and non-capitation FKTP visits. The BPJS data is to be prepared and pre-processed to get clearer data. Said data is then modeled with several algorithms, that is Ensemble Learning (Random Forest, Gradient Boosting, XGBoost, LightGBM, and CatBoost), linear regression, SVR, and Decision Tree. Each model is compared to find the best model based on R2, RMSE, with nRMSE as the complement, and MAPE metrics. During the modeling process, there are several tests to increase the metric score from each model that consists of normalization, feature selection, clustering, and hyperparameter tuning. After the testing process, each model is choosed based on the metric scores before to find the best model to predict the price and the length of health facility services. Based on the testing, there are two different results between the two visits' data. CatBoost algorithm is the best algorithm to predict the price and length of FKRTL visits with an average score of R2 is 85,93%, average score of RMSE and nRMSE are 1,1768 and 8,2%, and average score of MAPE is 13,43%. However, Random Forest has the lower average MAPE score of 12,79%. On the non-capitation FKTP dataset, only the price is to be predicted because there is only one day on the length of the visit. LightGBM is the best algorithm to predict the price of non-capitation FKTP visits with the R2 score of 80,23% and RMSE and nRMSE scores of 0,6504 and 11,02%. However, during the testing process on the non-capitation FKTP visits dataset, the MAPE score has a rather higher score than the FKRTL visits, with the lowest MAPE score on the Decision Tree model with a score of 69,16%. As a whole, the Ensemble Learning method has a higher score. With that said, the method that is proposed could predict the price and the length of visits with better performance and hoped that this final project could help the patient to get the price and the length of health facility visits expectation and medical staff to manage the medical resources that is to be used.",analisis prediksi biaya tangan sakit pasien daftar bpjs machine learning,bpjs sehat tanggung bantu dana duduk indonesia sebar sumber daya medis indonesia salah rendah banding negara asia tenggara sumber daya medis tip pandemi covid19 salah atas masalah alokasi sumber daya medis staf medis imbang perlu masingmasing kunjung pasien pasien unjung fasilitas sehat biaya bayar layan sehat milik percaya fasilitas sehat kunjung milik masalah finansial bayar layan dasar masalah tugas usul prediksi biaya kunjung fasilitas sehat regresi guna staf medis pasien mana prediksi data data bpjs 2015 2020 dataset serta bpjs dataset kunjung fkrtl dataset kunjung fktp nonkapitasi data bpjs siap data preprocessing data bersih data modeling algoritma ensemble learning random forest gradient boosting xgboost lightgbm catboost regresi linear svr decision tree masingmasing model banding cari model baik dasar metrik r2 rmse nrmse lengkap mape proses modeling uji coba tingkat nilainilai metrik masingmasing model normalisasi seleksi fitur clustering tuning hyperparameter proses uji coba masingmasing model pilih dasar nilainilai metrik temu model baik prediksi biaya kunjung fasilitas sehat dasar hasil uji coba hasil beda dataset kunjung beda algoritma catboost algoritma baik prediksi biaya kunjung fkrtl nilai ratarata r2 8593 nilai ratarata rmse nrmse 11768 82 nilai ratarata mape 1343 algoritma random forest milik nilai ratarata mape rendah nilai 1279 dataset kunjung fktp nonkapitasi biaya kunjung prediksi kunjung milik nilai algoritma lightgbm algoritma baik prediksi biaya kunjung fktp nonkapitasi nilai r2 8023 nilai rmse nrmse 06504 1102 proses uji coba dataset kunjung fktp nonkapitasi nilai mape cenderung uji coba dataset kunjung fkrtl nilai mape kecil letak model decision tree nilai 6916 metode ensemble learning milik nilai metrik metode usul prediksi biaya kunjung performa harap tugas bantu pasien ekspektasi biaya kunjung fasilitas sehat staf tentu sumber daya medis digunakanhealth bpjs is responsible for giving financial aid to the whole population of indonesia however the spread of medical resources in indonesia is one of the least spread compared to the rest of southeast asia medical resources become thinner during the covid19 pandemic one of the ways to deal with said problem is to allocate medical resources especially time for the medical staff to balance the resources other than that patients who visit a health facility want to know the projected price to get the health service so that they would put their trust onto the health facility they visit and not to have financial issues during the payment of the service based on said problem this final project proposes to predict the price and the length of health facility services using regression that is useful for medical staff patients and anyone who needs it the data that is used is the data from bpjs from 2015 to 2020 which consists of bpjs members fkrtl visits and noncapitation fktp visits the bpjs data is to be prepared and preprocessed to get clearer data said data is then modeled with several algorithms that is ensemble learning random forest gradient boosting xgboost lightgbm and catboost linear regression svr and decision tree each model is compared to find the best model based on r2 rmse with nrmse as the complement and mape metrics during the modeling process there are several tests to increase the metric score from each model that consists of normalization feature selection clustering and hyperparameter tuning after the testing process each model is choosed based on the metric scores before to find the best model to predict the price and the length of health facility services based on the testing there are two different results between the two visits data catboost algorithm is the best algorithm to predict the price and length of fkrtl visits with an average score of r2 is 8593 average score of rmse and nrmse are 11768 and 82 and average score of mape is 1343 however random forest has the lower average mape score of 1279 on the noncapitation fktp dataset only the price is to be predicted because there is only one day on the length of the visit lightgbm is the best algorithm to predict the price of noncapitation fktp visits with the r2 score of 8023 and rmse and nrmse scores of 06504 and 1102 however during the testing process on the noncapitation fktp visits dataset the mape score has a rather higher score than the fkrtl visits with the lowest mape score on the decision tree model with a score of 6916 as a whole the ensemble learning method has a higher score with that said the method that is proposed could predict the price and the length of visits with better performance and hoped that this final project could help the patient to get the price and the length of health facility visits expectation and medical staff to manage the medical resources that is to be used
Perbandingan Kinerja Klasifikasi Profil Pengguna Rekening Listrik Dengan Machine Learning.,"Faadhilah, Naufal",http://repository.its.ac.id/112076/,"Listrik merupakan salah satu kebutuhan dasar manusia pada zaman yang serba modern ini. Konsumsi tenaga listrik di Indonesia cukup besar dengan jangkauan yang luas. Penetapan tarif tenaga listrik ditentukan dengan penggolongan yang mengacu pada keperluan penggunaan listrik dan besar tenaga listrik yang digunakan agar penyediaan tenaga listrik dapat menjadi suatu layanan yang terjangkau bagi rakyat Indonesia untuk berbagai kepentingan. Konsekuensi keterlambatan pembayaran dapat berupa denda hingga pemutusan layanan listrik. Urgensi dari tugas akhir ini adalah untuk melakukan klasifikasi perilaku pelanggan listrik dalam hal ketepatan waktu pembayaran tagihan. Adanya proses identifikasi kemungkinan pelanggan listrik yang membayar melewati batas waktunya dapat mengoptimalkan penanganan terhadap pelanggan yang memiliki potensi untuk terlambat membayar tagihan listriknya. tugas akhir ini juga berusaha untuk mencari variabel dengan pengaruh besar terhadap perilaku pelanggan listrik dalam hal ketepatan waktu pembayaran tagihan listrik. 	Tugas akhir ini akan mengembangkan model klasifikasi perilaku pelanggan dalam membayar listrik dengan pendekatan model machine learning. Terdapat beberapa penelitian yang membahas fenomena yang berkaitan dengan pembayaran, seperti penelitian oleh (Karunathunge dkk., 2022), (Ala’raj dkk., 2021), dan (Altinisik & Yilmaz, 2019). Sebelum pengembangan dilakukan, digunakan pengkodean data dan teknik Synthetic Minority Oversampling Technique (SMOTE) untuk mengatasi ketidakseimbangan yang ditemukan pada dataset. Kemudian, digunakan Random Forest, Support Vector Machine, dan Logistic Regression untuk pengembangan model klasifikasi perilaku pelanggan dalam membayar listrik. Kinerja dari model yang telah dikembangkan akan diuji dengan metrik F1 Score dan Area Under the Curve (AUC). Kemudian, untuk melakukan identifikasi faktor yang berpengaruh besar dalam keterlambatan pembayaran tagihan listrik akan digunakan teknik feature importance.	Model dengan kinerja terbaik diraih oleh model Random Forest yang menggunakan pengkodean data dan tanpa SMOTE oversampling meraih kinerja terbaik dengan metrik evaluasi F1 Score sebesar 95,09% dan metrik evaluasi AUC sebesar 96,01%. Dari berbagai uji coba, variabel paling berpengaruh adalah variabel “”RpPTL” yang menyatakan besar tagihan listrik, diikuti oleh “Bank Supporting” yang menyatakan bank yang digunakan untuk pembayaran, dan “kWh” yang menyatakan besar energi listrik yang digunakan.==========================================================Electricity is one of the basic human needs in this modern era. Electricity consumption in Indonesia is quite large with a wide range. Determination of electric power tariff is determined by classification that refers to the needs of electricity use and the amount of electric power used so that the provision of electricity can be an affordable service for the people of Indonesia for various purposes. The consequences of late payment can be in the form of fines to disconnection of electricity services. The urgency of this undergraduate thesis is to predict the behavior of electricity customers in terms of timeliness of bill payments. The process of identifying the possibility of electricity customers who pay past the deadline can optimize the handling of customers who have the potential to pay their electricity bills late. This undergraduate thesis also seeks to find variables with a large influence on the behavior of electricity customers in terms of timeliness of payment of electricity bills. 	This undergraduate thesis will develop a model for predicting customer behavior in paying electricity with a machine learning model approach. There are several studies that discuss phenomena related to payment, such as research by (Karunathunge dkk., 2022), (Ala’raj dkk., 2021), and (Altinisik & Yilmaz, 2019). Prior to the development, data encoding and Synthetic Minority Oversampling Technique (SMOTE) were used to overcome the imbalance found in the dataset. Then, Random Forest, Support Vector Machine, and Logistic Regression are used to develop a prediction model for customer behavior in paying electricity. The performance of the developed model will be tested with F1 Score and Area Under the Curve (AUC) metrics. Then, to identify factors that have a major influence on late payment of electricity bills, feature importance techniques will be used.	The model with the best performance was achieved by the Random Forest model using data coding and without SMOTE oversampling achieved the best performance with F1 Score evaluation metric of 95.09% and AUC evaluation metric of 96.01%. From various trials, the most influential variable is the variable “RpPTL” which states the amount of electricity bills, followed by “Bank Supporting” which states the bank used for payment, and “kWh” which states the amount of electrical energy used.",banding kerja klasifikasi profil guna rekening listrik machine learning,listrik salah butuh dasar manusia zaman serba modern konsumsi tenaga listrik indonesia jangkau luas tetap tarif tenaga listrik tentu golong acu perlu guna listrik tenaga listrik sedia tenaga listrik layan jangkau rakyat indonesia penting konsekuensi lambat bayar denda putus layan listrik urgensi tugas klasifikasi perilaku langgan listrik tepat bayar tagih proses identifikasi langgan listrik bayar lewat batas optimal tangan langgan milik potensi lambat bayar tagih listrik tugas usaha cari variabel pengaruh perilaku langgan listrik tepat bayar tagih listrik tugas kembang model klasifikasi perilaku langgan bayar listrik dekat model machine learning teliti bahas fenomena kait bayar teliti karunathunge dkk 2022 ala  raj dkk 2021 altinisik yilmaz 2019 kembang kode data teknik synthetic minority oversampling technique smote atas ketidakseimbangan temu dataset random forest support vector machine logistic regression kembang model klasifikasi perilaku langgan bayar listrik kerja model kembang uji metrik f1 score area under the curve auc identifikasi faktor pengaruh lambat bayar tagih listrik teknik feature importance model kerja baik raih model random forest kode data smote oversampling raih kerja baik metrik evaluasi f1 score 9509 metrik evaluasi auc 9601 uji coba variabel pengaruh variabel   rpptl  tagih listrik ikut  bank supporting  bank bayar  kwh  energi listrik digunakanelectricity is one of the basic human needs in this modern era electricity consumption in indonesia is quite large with a wide range determination of electric power tariff is determined by classification that refers to the needs of electricity use and the amount of electric power used so that the provision of electricity can be an affordable service for the people of indonesia for various purposes the consequences of late payment can be in the form of fines to disconnection of electricity services the urgency of this undergraduate thesis is to predict the behavior of electricity customers in terms of timeliness of bill payments the process of identifying the possibility of electricity customers who pay past the deadline can optimize the handling of customers who have the potential to pay their electricity bills late this undergraduate thesis also eks to find variables with a large influence on the behavior of electricity customers in terms of timeliness of payment of electricity bills this undergraduate thesis will develop a model for predicting customer behavior in paying electricity with a machine learning model approach there are several studies that discuss phenomena related to payment such as research by karunathunge dkk 2022 ala  raj dkk 2021 and altinisik yilmaz 2019 prior to the development data encoding and synthetic minority oversampling technique smote were used to overcome the imbalance found in the dataset then random forest support vector machine and logistic regression are used to develop a prediction model for customer behavior in paying electricity the performance of the developed model will be tested with f1 score and area under the curve auc metrics then to identify factors that have a major influence on late payment of electricity bills feature importance techniques will be used the model with the best performance was achieved by the random forest model using data coding and without smote oversampling achieved the best performance with f1 score evaluation metric of 9509 and auc evaluation metric of 9601 from various trials the most influential variable is the variable  rpptl  which states the amount of electricity bills followed by  bank supporting  which states the bank used for payment and  kwh  which states the amount of electrical energy used
Segmentasi White Matter Hyperintensity Pada Citra MRI Otak Menggunakan U-Net.,"Fahlevi, Muhammad Hashfi",http://repository.its.ac.id/108783/,"Gray matter dan white matter adalah bagian pada otak yang memiliki fungsi yang sangat krusial dalam kerja otak. Gray matter adalah tempat di mana sel-sel saraf dan akson berada. Gray matter menempati mayoritas bagian cerebrum, cerebellum, dan batang otak. Beberapa fungsi gray matter adalah mengontrol sistem gerak manusia, pemrosesan emosi, dan ingatan. Berbeda dengan gray matter, white matter adalah bagian pada otak di mana kumpulan akson berada dan kebanyakan terletak di bagian tengah otak. Fungsi dari white matter adalah memproses dan mengirimkan sinyal ke sumsum tulang belakang. Menjadi salah satu bagian yang paling krusial pada tubuh manusia, kerusakan pada dua bagian ini tentunya dapat menyebabkan penyakit dan kelainan pada sistem saraf tubuh manusia. Salah satu kelainan yang umum terjadi adalah WMH (white matter hyperintensity), yaitu gangguan di mana intensitas white matter melebihi intensitas yang seharusnya dan menjadi salah satu tanda beberapa penyakit seperti Alzheimer dan kelainan kognitif. Dengan pencitraan MRI, bagian otak yang mengalami WMH dapat terlihat dan dianalisis untuk tindakan lebih lanjut. Salah satu cara menganalisis citra MRI adalah dengan melakukan segmentasi pada citra MRI, khususnya menggunakan arsitektur U-Net. Berdasarkan hasil percobaan, didapatkan hasil bahwa segmentasi WMH pada citra MRI dengan menggunakan arsitektur U-Net menghasilkan segmentasi yang cukup akurat.=================================================================================================================================Gray matter and white matter are parts of the brain that play crucial roles in its functioning. Gray matter is where nerve cells and axons are located. It occupies the majority of the cerebrum, cerebellum, and brainstem. Some functions of gray matter include controlling human motor systems, processing emotions, and managing memory. In contrast, white matter is the part of the brain where bundles of axons are found, mostly situated in the central regions of the brain. The function of white matter is to process and transmit signals to the spinal cord. As one of the most crucial parts of the human body, damage to these two components can lead to diseases and disorders in the human nervous system. One common disorder is white matter hyperintensity (WMH), where the intensity of white matter exceeds normal levels, serving as a sign of certain conditions such as Alzheimer’s and cognitive disorders. With MRI imaging, areas of the brain experiencing WMH can be observed and analyzed for further action. One method of analyzing MRI images is by performing segmentation, particularly using the U-Net architecture. Based on experimental results, it was found that WMH segmentation in MRI images using the U-Net architecture produces reasonably accurate segmentation.",segmentasi white matter hyperintensity citra mri otak unet,gray matter white matter otak milik fungsi krusial kerja otak gray matter selsel saraf akson gray matter tempat mayoritas cerebrum cerebellum batang otak fungsi gray matter kontrol sistem gerak manusia pemrosesan emosi ingat beda gray matter white matter otak kumpul akson banyak letak otak fungsi white matter proses kirim sinyal sumsum tulang salah krusial tubuh manusia rusa sebab sakit lain sistem saraf tubuh manusia salah lain wmh white matter hyperintensity ganggu intensitas white matter lebih intensitas salah tanda sakit alzheimer lain kognitif citra mri otak alami wmh analis tindak salah analis citra mri segmentasi citra mri arsitektur unet dasar hasil coba dapat hasil segmentasi wmh citra mri arsitektur unet hasil segmentasi akuratgray matter and white matter are parts of the brain that play crucial roles in its functioning gray matter is where nerve cells and axons are located it occupies the majority of the cerebrum cerebellum and brainstem some functions of gray matter include controlling human motor systems processing emotions and managing memory in contrast white matter is the part of the brain where bundles of axons are found mostly situated in the central regions of the brain the function of white matter is to process and transmit signals to the spinal cord as one of the most crucial parts of the human body damage to these two components can lead to diseases and disorders in the human nervous system one common disorder is white matter hyperintensity wmh where the intensity of white matter exceeds normal levels serving as a sign of certain conditions such as alzheimer  s and cognitive disorders with mri imaging areas of the brain experiencing wmh can be observed and analyzed for further action one method of analyzing mri images is by performing segmentation particularly using the unet architecture based on experimental results it was found that wmh segmentation in mri images using the unet architecture produces reasonably accurate segmentation
Penentuan Safety Integrity Level (SIL) pada Safety Instrumented System Air Compressor Berdasarkan Nilai Probability Failure on Demand (PFD) dengan Metode K-Nearest Neighbor.,"Faizah, Nova Auliyarul",http://repository.its.ac.id/115480/,"Terdapat adanya resiko berbahaya yang dapat terjadi pada air compressor, sehingga diperlukan adanya suatu sistem pengamanan. Sistem pengamanan ini dibangun untuk diimplementasikan pada air compressor, dimana sistem ini mendapat sinyal dari field berupa push button dan output dari transmitter yang terdiri dari pressure, vibration dan temperature. Kinerja dari Safety Instrumented System (SIS) dapat dilihat dari tingkat integrasi keselamatan atau Safety Integrity Level (SIL) saat menjalankan fungsinya. Parameter untuk mengetahui tingkat SIL yaitu Probability Failure on Demand (PFD) dan Risk Reduction Factor (RRF). Oleh karena itu, pada proyek akhir ini dilakukan perhitungan Safety Integrity Level pada Safety Instrumented System Air Compressor berdasarkan algoritma K-Nearest Neighbor (KNN). Klasifikasi tingkat SIL ini berdasarkan nilai PFD dan RRF yang telah dihitung sebelumnya. KNN akan mengklasifikasikan data berdasarkan ukuran kesamaan atau fungsi jarak. Metode KNN terbukti memiliki akurasi yang tinggi sebesar 100% dalam mengklasifikasikan SIL dengan proporsi perbandingan data training dan data testing sebesar 80%:20%. Dengan nilai k=6, KNN memiliki akurasi tertinggi dibandingkan dengan nilai k lainnya. Evaluasi yang dilakukan dengan membandingkan kinerja KNN dengan metode penentuan SIL lainnya, ditemukan bahwa K-NN memiliki keunggulan dalam hal efisiensi dan akurasi. Sehingga dapat disimpulkan bahwa model KNN menawarkan solusi yang lebih baik dan praktis dalam penentuan tingkat SIL dibandingkan dengan model klasifikasi lainnya.=================================================================================================================================A dangerous risk can occur in an air compressor, so a security system is needed. This security system is built to be implemented on an air compressor, where this system gets a signal from the field in the form of a push button and output from a transmitter consisting of pressure, vibration, and temperature. The performance of the Safety Instrumented System (SIS) can be seen from the level of safety integration or Safety Integrity Level (SIL) when carrying out its function. The parameters to determine the SIL level are Probability Failure on Demand (PFD) and Risk Reduction Factor (RRF). Therefore, in this final project, the calculation of the Safety Integrity Level on the Safety Instrumented System Air Compressor based on the K-Nearest Neighbor (KNN) algorithm is carried out. This SIL level classification is based on the PFD and RRF values that have been calculated previously. KNN will classify data based on a similar measure or distance function. The KNN method has been proven to have a high accuracy of 100% in classifying SIL, with a proportion of training data and a testing data ratio of 80%: 20%. With a value of k=6, KNN has the highest accuracy compared to other k values. Evaluation conducted by comparing the performance of KNN with other SIL determination methods found that K-NN has advantages in terms of efficiency and accuracy. So, it can be concluded that the KNN model offers a better and practical solution for SIL determination.",tentu safety integrity level sil safety instrumented system air compressor dasar nilai probability failure on demand pfd metode knearest neighbor,resiko bahaya air compressor sistem aman sistem aman bangun implementasi air compressor mana sistem sinyal field push button output transmitter pressure vibration temperature kerja safety instrumented system sis tingkat integrasi selamat safety integrity level sil jalan fungsi parameter tingkat sil probability failure on demand pfd risk reduction factor rrf proyek hitung safety integrity level safety instrumented system air compressor dasar algoritma knearest neighbor knn klasifikasi tingkat sil dasar nilai pfd rrf hitung knn klasifikasi data dasar ukur sama fungsi jarak metode knn bukti milik akurasi 100 klasifikasi sil proporsi banding data training data testing 8020 nilai k6 knn milik akurasi tinggi banding nilai k evaluasi banding kerja knn metode tentu sil temu knn milik unggul efisiensi akurasi simpul model knn tawar solusi praktis tentu tingkat sil banding model klasifikasi lainnyaa dangerous risk can occur in an air compressor so a security system is needed this security system is built to be implemented on an air compressor where this system gets a signal from the field in the form of a push button and output from a transmitter consisting of pressure vibration and temperature the performance of the safety instrumented system sis can be seen from the level of safety integration or safety integrity level sil when carrying out its function the parameters to determine the sil level are probability failure on demand pfd and risk reduction factor rrf therefore in this final project the calculation of the safety integrity level on the safety instrumented system air compressor based on the knearest neighbor knn algorithm is carried out this sil level classification is based on the pfd and rrf values that have been calculated previously knn will classify data based on a similar measure or distance function the knn method has been proven to have a high accuracy of 100 in classifying sil with a proportion of training data and a testing data ratio of 80 20 with a value of k6 knn has the highest accuracy compared to other k values evaluation conducted by comparing the performance of knn with other sil determination methods found that knn has advantages in terms of efficiency and accuracy so it can be concluded that the knn model offers a better and practical solution for sil determination
Pengembangan Metode Rekonstruksi dan Segmentasi Citra 3D DICOM Magnetic Resonance Imaging Otak.,"Fajar, Aziz",http://repository.its.ac.id/106553/,"Saat ini operasi otak sangat bergantung pada kemampuan dokter yang melakukan operasi. Dalam melakukan operasi, dokter menggunakan citra Magnetic Resonance Imaging (MRI) berupa citra Digital Imaging and Communications in Medicine (DICOM) untuk membantu menentukan lokasi yang akan dioperasi. Hasil dari scan MRI ini adalah beberapa citra yang apabila digabungkan dapat membentuk citra 3D yang merepresentasikan otak.  Untuk melakukan pendidikan pada dokter pemula, dokter senior masih menggunakan citra 2D DICOM yang dapat membuat dokter pemula harus membayangkan bagaimana bentuk 3D dari bagian otak yang sedang dibahas. Kasus lain dimana citra 3D dibutuhkan adalah ketika melakukan segmentasi citra DICOM. Citra DICOM memiliki spacing between slices dalam metadatanya. Apabila citra DICOM memiliki space diantara slice maka ada bagian dari keseluruhan citra yang hilang. Dengan rekonstruksi 3D, bagian ini juga direkonstruksi.  Namun, membentuk 3D dari citra-citra DICOM bukan hal yang sederhana, karena apabila hanya digabungkan tanpa ada konfigurasi, maka citra yang dihasilkan tidak mirip dengan bentuk otak yang mirip dengan aslinya. Sehingga, penelitian ini mengusulkan metode untuk merekonstruksi citra 3D berdasarkan slices citra 2D DICOM. Metode rekonstruksi ini terdiri dari beberapa langkah. Metode ini terdiri dari image enhancement menggunakan histogram equalization, rekonstruksi 3D citra DICOM, interpolasi menggunakan trilinear interpolation dan resize citra 3D. Selanjutnya, dilakukan segmentasi pada citra 3D DICOM yang didapat dari dokter di Surabaya maupun BraTS 2021 sebagai dataset publik dengan menggunakan Deep Learning. Segmentasi dilakukan pada citra 3D otak karena apabila menggunakan data 2D maka struktur keseluruhan otak tidak terlihat dengan sempurna, sedangkan anatomi manusia memang sama, namun morfologi atau bentuk dari anatominya dapat berbeda-beda. Pada penelitian sebelumnya, Spatially Localized Atlas Network Tiles (SLANT) memiliki performa yang bagus, namun dalam proses training dibutuhkan sumber daya yang sangat besar dan waktu yang lama. Sedangkan, arsitektur yang digunakan adalah arsitektur Deep Learning U-Net memiliki performa yang sedikit lebih rendah namun memiliki waktu pelatihan yang jauh lebih cepat. Sehingga U-Net, Res U-Net, dan Dense U-Net termasuk arsitektur yang sering digunakan untuk segmentasi data medis  Yang terakhir, penelitian ini mengusulkan metode untuk learning rate tuning menggunakan exponential moving average dan cyclical learning rate (CLR) untuk meningkatkan hasil segmentasi. Metode ini dikembangkan berdasarkan penelitian sebelumnya. Penelitian sebelumnya melakukan learning rate test menggunakan datapoint yang didapat dari tiap akhir epoch. Sedangkan, penelitian ini menggunakan datapoint yang didapat dari tiap akhir batch pada saat proses training model. Performa dari CLR yang diusulkan ini dibandingkan dengan metode CLR pada penelitian sebelumnya.  Kinerja dari metode segmentasi dievaluasi dengan cara membandingkan hasil segmentasi dengan ground truth yang didapatkan dari dokter bedah syaraf untuk segmentasi anatomi otak. Sedangkan, metode tuning learning rate yang diusulkan dalam penelitian ini digunakan untuk segmentasi tumor pada dataset BraTS 2021 dan melakukan validasi secara online. Hal ini dilakukan untuk mengetahui performa dari metode yang diusulkan untuk tuning learning rate pada dataset publik. Untuk mengukur kemampuan dari model segmentasi, penelitian ini menggunakan Dice Similarity Coefficient (DSC).  Hasilnya, metode tuning learning rate yang disusulkan memiliki hasil yang lebih baik daripada hasil dari penelitian sebelumnya. Hasil training model pada training set menunjukkan bahwa arsitektur U-Net yang memiliki nilai DSC sebesar 81,725 % dalam 140 epochs meningkat menjadi 82% dalam 121 epochs. Arsitektur Res U-Net juga mengalami peningkatan nilai DSC dari 82,875% menjadi 83,575% namun membutuhkan jumlah epoch yang lebih banyak untuk mencapai convergence, dari 142 menjadi 152 epoch. Nilai DSC dari Dense U-Net juga meningkat dari 81,875% dalam 224 epochs menjadi 81,95% dalam 170 epochs===================================================================================================================================Currently brain surgery is very dependent on the ability of the doctor performing the operation. When carrying out surgery, doctors use Magnetic Resonance Imaging (MRI) images in the form of Digital Imaging and Communications in Medicine (DICOM) images to help determine the location to be operated on. The result of this MRI scan is several images which, when combined, can form a 3D image that represents the brain. To educate novice doctors, senior doctors still use 2D DICOM images which can make novice doctors have to imagine what the 3D shape of the part of the brain being discussed is like. Another case where 3D images are needed is when segmenting DICOM images. DICOM images have spacing between slices in their metadata. If a DICOM image has space between slices then part of the entire image is lost. With 3D reconstruction, this part is also reconstructed. However, forming 3D from DICOM images is not a simple thing, because if they are only combined without any configuration, the resulting image will not resemble the original brain shape. Thus, this research proposes a method for reconstructing 3D images based on 2D DICOM image slices. This reconstruction method consists of several steps. This method consists of image enhancement using histogram equalization, 3D reconstruction of DICOM images, interpolation using trilinear interpolation and 3D image resizing. Next, segmentation was carried out on 3D DICOM images obtained from doctors in Surabaya and BraTS 2021 as a public dataset using Deep Learning. Segmentation is carried out on 3D images of the brain because when using 2D data the overall structure of the brain cannot be seen perfectly, while human anatomy is the same, but the morphology or shape of the anatomy can vary. In previous research, Spatially Localized Atlas Network Tiles (SLANT) had good performance, but the training process required very large resources and a long time. Meanwhile, the architecture used is the U-Net Deep Learning architecture which has slightly lower performance but has a much faster training time. So U-Net, Res U-Net, and Dense U-Net are architectures that are often used for medical data segmentation. Lastly, this research proposes a method for learning rate tuning using exponential moving average and cyclical learning rate (CLR) to improve segmentation results . This method was developed based on previous research. Previous research conducted a learning rate test using data points obtained at the end of each epoch. Meanwhile, this research uses data points obtained from the end of each batch during the model training process. The performance of the proposed CLR is compared with the CLR method in previous research. The performance of the segmentation method was evaluated by comparing the segmentation results with ground truth obtained from a neurosurgeon for brain anatomical segmentation. Meanwhile, the learning rate tuning method proposed in this research is used for tumor segmentation in the BraTS 2021 dataset and carries out online validation. This was done to determine the performance of the proposed method for tuning learning rate on public datasets. To measure the ability of the segmentation model, this research uses the Dice Similarity Coefficient (DSC). As a result, the proposed learning rate tuning method has better results than the results from previous research. The results of model training on the training set show that the U-Net architecture which has a DSC value of 81.725% in 140 epochs increases to 82% in 121 epochs. The Res U-Net architecture also experienced an increase in the DSC value from 82.875% to 83.575% but required a greater number of epochs to achieve convergence, from 142 to 152 epochs. The DSC value of Dense U-Net also increased from 81.875% in 224 epochs to 81.95% in 170 epochs",kembang metode rekonstruksi segmentasi citra 3d dicom magnetic resonance imaging otak,operasi otak gantung mampu dokter operasi operasi dokter citra magnetic resonance imaging mri citra digital imaging and communications in medicine dicom bantu tentu lokasi operasi hasil scan mri citra gabung bentuk citra 3d representasi otak didik dokter mula dokter senior citra 2d dicom dokter mula bayang bentuk 3d otak bahas mana citra 3d butuh segmentasi citra dicom citra dicom milik spacing between slices metadatanya citra dicom milik space slice citra hilang rekonstruksi 3d rekonstruksi bentuk 3d citracitra dicom sederhana gabung konfigurasi citra hasil bentuk otak asli teliti usul metode rekonstruksi citra 3d dasar slices citra 2d dicom metode rekonstruksi langkah metode image enhancement histogram equalization rekonstruksi 3d citra dicom interpolasi trilinear interpolation resize citra 3d segmentasi citra 3d dicom dokter surabaya brats 2021 dataset publik deep learning segmentasi citra 3d otak data 2d struktur otak sempurna anatomi manusia morfologi bentuk anatomi berbedabeda teliti spatially localized atlas network tiles slant milik performa bagus proses training butuh sumber daya arsitektur arsitektur deep learning unet milik performa rendah milik latih cepat unet res unet dense unet arsitektur segmentasi data medis teliti usul metode learning rate tuning exponential moving average cyclical learning rate clr tingkat hasil segmentasi metode kembang dasar teliti teliti learning rate test datapoint epoch teliti datapoint batch proses training model performa clr usul banding metode clr teliti kerja metode segmentasi evaluasi banding hasil segmentasi ground truth dapat dokter bedah syaraf segmentasi anatomi otak metode tuning learning rate usul teliti segmentasi tumor dataset brats 2021 validasi online performa metode usul tuning learning rate dataset publik ukur mampu model segmentasi teliti dice similarity coefficient dsc hasil metode tuning learning rate susul milik hasil hasil teliti hasil training model training set arsitektur unet milik nilai dsc 81725 140 epochs tingkat 82 121 epochs arsitektur res unet alami tingkat nilai dsc 82875 83575 butuh epoch capai convergence 142 152 epoch nilai dsc dense unet tingkat 81875 224 epochs 8195 170 epochscurrently brain surgery is very dependent on the ability of the doctor performing the operation when carrying out surgery doctors use magnetic resonance imaging mri images in the form of digital imaging and communications in medicine dicom images to help determine the location to be operated on the result of this mri scan is several images which when combined can form a 3d image that represents the brain to educate novice doctors senior doctors still use 2d dicom images which can make novice doctors have to imagine what the 3d shape of the part of the brain being discussed is like another case where 3d images are needed is when segmenting dicom images dicom images have spacing between slices in their metadata if a dicom image has space between slices then part of the entire image is lost with 3d reconstruction this part is also reconstructed however forming 3d from dicom images is not a simple thing because if they are only combined without any configuration the resulting image will not resemble the original brain shape thus this research proposes a method for reconstructing 3d images based on 2d dicom image slices this reconstruction method consists of several steps this method consists of image enhancement using histogram equalization 3d reconstruction of dicom images interpolation using trilinear interpolation and 3d image resizing next segmentation was carried out on 3d dicom images obtained from doctors in surabaya and brats 2021 as a public dataset using deep learning segmentation is carried out on 3d images of the brain because when using 2d data the overall structure of the brain can not be seen perfectly while human anatomy is the same but the morphology or shape of the anatomy can vary in previous research spatially localized atlas network tiles slant had good performance but the training process required very large resources and a long time meanwhile the architecture used is the unet deep learning architecture which has slightly lower performance but has a much faster training time so unet res unet and dense unet are architectures that are often used for medical data segmentation lastly this research proposes a method for learning rate tuning using exponential moving average and cyclical learning rate clr to improve segmentation results this method was developed based on previous research previous research conducted a learning rate test using data points obtained at the end of each epoch meanwhile this research uses data points obtained from the end of each batch during the model training process the performance of the proposed clr is compared with the clr method in previous research the performance of the segmentation method was evaluated by comparing the segmentation results with ground truth obtained from a neurosurgeon for brain anatomical segmentation meanwhile the learning rate tuning method proposed in this research is used for tumor segmentation in the brats 2021 dataset and carries out online validation this was done to determine the performance of the proposed method for tuning learning rate on public datasets to measure the ability of the segmentation model this research uses the dice similarity coefficient dsc as a result the proposed learning rate tuning method has better results than the results from previous research the results of model training on the training set show that the unet architecture which has a dsc value of 81725 in 140 epochs increases to 82 in 121 epochs the res unet architecture also experienced an increase in the dsc value from 82875 to 83575 but required a greater number of epochs to achieve convergence from 142 to 152 epochs the dsc value of dense unet also increased from 81875 in 224 epochs to 8195 in 170 epochs
Rancang Bangun Dashboard Prediksi Harga Bitcoin dengan Menggunakan Long Short Term Memory (LSTM) Memory.,"Farihah, Tatik Farihatul",http://repository.its.ac.id/116019/,"Era teknologi saat ini, investasi pada cryptocurrency telah tumbuh signifikan, terutama di Indonesia yang menduduki peringkat ketujuh dunia pada Maret 2024. Bitcoin, sebagai cryptocurrency dominan, menunjukkan volatilitas harga yang tinggi, menawarkan peluang investasi besar namun dengan risiko tinggi. Oleh karena itu, diperlukan alat prediksi efektif untuk membantu investor dalam pengambilan keputusan. Penelitian ini berfokus pada pemodelan prediksi harga Bitcoin menggunakan Long Short Term Memory (LSTM) Network dari Januari 2023 hingga Juli 2024. Tiga skenario model prediksi dibandingkan: model berdasarkan data historis harga Bitcoin, model dengan variabel internal dan eksternal, serta model yang mengombinasikan kedua jenis variabel tersebut. Evaluasi performa model dilakukan menggunakan Mean Absolute Percentage Error (MAPE) untuk menemukan model terbaik. Penelitian ini diharapkan membantu investor dalam pengambilan keputusan yang lebih informasi, mendukung pengawasan pasar oleh BAPPEBTI, dan memberikan pemahaman lebih baik tentang dinamika pasar cryptocurrency bagi pemerintah. Penelitian ini juga mencakup pengembangan dashboard prediksi harga Bitcoin yang interaktif, memanfaatkan kecerdasan perangkat lunak. Data penelitian mencakup harga Bitcoin, volume perdagangan, Nasdaq, dan S&P 500. Langkah analisis meliputi pembersihan data, analisis pola harga, pemodelan LSTM, dan evaluasi performa model.=================================================================================================================================In the current technological era, cryptocurrency investment has grown significantly, especially in Indonesia, which ranked seventh globally in March 2024. Bitcoin, as the dominant cryptocurrency, exhibits high price volatility, offering substantial investment opportunities but with high risk. Therefore, an effective prediction tool is necessary to assist investors in decision-making. This study focuses on modeling Bitcoin price predictions using the Long Short Term Memory (LSTM) Network from January 2023 to July 2024. Three prediction model scenarios are compared: a model based on historical Bitcoin price data, a model incorporating internal and external variables, and a model combining both types of variables. Model performance is evaluated using Mean Absolute Percentage Error (MAPE) to identify the best model. This research aims to assist investors in making more informed decisions, support market supervision by BAPPEBTI, and provide the government with a better understanding of cryptocurrency market dynamics. The study also includes the development of an interactive Bitcoin price prediction dashboard, leveraging artificial intelligence. Data for this study encompassing Bitcoin prices, trading volume, Nasdaq, and S&P 500. The analysis steps include data cleaning, price pattern analysis, LSTM modeling, and model performance evaluation.",rancang bangun dashboard prediksi harga bitcoin long short term memory lstm memory,era teknologi investasi cryptocurrency tumbuh signifikan indonesia duduk peringkat tujuh dunia maret 2024 bitcoin cryptocurrency dominan volatilitas harga tawar peluang investasi risiko alat prediksi efektif bantu investor ambil putus teliti fokus model prediksi harga bitcoin long short term memory lstm network januari 2023 juli 2024 skenario model prediksi banding model dasar data historis harga bitcoin model variabel internal eksternal model kombinasi jenis variabel evaluasi performa model mean absolute percentage error mape temu model baik teliti harap bantu investor ambil putus informasi dukung awas pasar bappebti paham dinamika pasar cryptocurrency perintah teliti cakup kembang dashboard prediksi harga bitcoin interaktif manfaat cerdas perangkat lunak data teliti cakup harga bitcoin volume dagang nasdaq sp 500 langkah analisis liput bersih data analisis pola harga model lstm evaluasi performa modelin the current technological era cryptocurrency investment has grown significantly especially in indonesia which ranked seventh globally in march 2024 bitcoin as the dominant cryptocurrency exhibits high price volatility offering substantial investment opportunities but with high risk therefore an effective prediction tool is necessary to assist investors in decisionmaking this study focuses on modeling bitcoin price predictions using the long short term memory lstm network from january 2023 to july 2024 three prediction model scenarios are compared a model based on historical bitcoin price data a model incorporating internal and external variables and a model combining both types of variables model performance is evaluated using mean absolute percentage error mape to identify the best model this research aims to assist investors in making more informed decisions support market supervision by bappebti and provide the government with a better understanding of cryptocurrency market dynamics the study also includes the development of an interactive bitcoin price prediction dashboard leveraging artificial intelligence data for this study encompassing bitcoin prices trading volume nasdaq and sp 500 the analysis steps include data cleaning price pattern analysis lstm modeling and model performance evaluation
Sistem Rekomendasi Musik Menenangkan untuk Ibu Berisiko Postpartum Depression berdasarkan Fitur Musik dan Klasifikasi Genre menggunakan SVM.,"Fatichin, Mochammad Rizqul",http://repository.its.ac.id/98550/,"Postpartum Depression (PPD) adalah suatu gangguan kesehatan mental yang biasanya terjadi 2-6 minggu pada ibu pasca persalinan. Gangguan ini ditandai dengan perasaan depresi, kecemasan berlebih, rasa bersalah, insomnia, hingga perubahan berat badan. PPD merupakan kondisi serius yang jarang diperhatikan, dimana penelitian melaporkan bahwa 20% ibu baru pertama melahirkan mengalami depresi. Sementara di Indonesia, 50-70% ibu mengalami depresi pasca melahirkan anak pertama. Dukungan sosial yang baik serta beberapa treatment, seperti perubahan gaya hidup, psikoterapi, hingga penggunaan obat dan suplemen dapat dilakukan untuk mengurangi keparahan gejala. Terapi musik merupakan salah satu treatment perubahan gaya hidup yang dapat memberikan ketenangan dan mudah untuk diaplikasikan. Dalam pemberian terapi, pemilihan musik yang dapat memberikan ketenangan dan sesuai dengan keinginan menjadi hal yang diperhatikan. Oleh karena itu, diperlukan sistem yang dapat memberikan rekomendasi musik menenangkan bagi ibu berisiko PPD. Penelitian bertujuan untuk menghasilkan sistem rekomendasi musik menenangkan untuk ibu berisiko PPD. Sistem rekomendasi dibuat berdasarkan kemiripan antar musik, dengan mempertimbangkan hasil klasifikasi genre yang telah terbukti memberikan hasil rekomendasi yang baik. Data yang digunakan adalah data audio musik dari GTZAN Dataset, Free Music Archive, dan Audio Library dengan tempo kurang dari 80 bpm. Klasifikasi genre memanfaatkan fitur-fitur pada audio musik serta menggunakan algoritma Support Vector Machine (SVM) dalam pembuatan model klasifikasi. Musik diklasifikasi menjadi lima genre yaitu Ambient, Classical, Country-Folk, Jazz-Blues, dan RnB-Soul. Selanjutnya lima rekomendasi musik dihasilkan berdasarkan kemiripan antar fitur musik serta dengan mempertimbangkan hasil dari klasifikasi genre. Hasil yang didapatkan dari penelitian ini adalah sistem yang dapat merekomendasikan musik menenangkan untuk ibu berisiko PPD. Model klasifikasi genre yang menjadi bagian dari sistem rekomendasi memiliki nilai akurasi sebesar 80% dengan presisi 82% dan recall 80%. Hasil penelitian menunjukkan bahwa model yang dibangun menggunakan pendekatan One-vs- Rest (SVM - OVR) memiliki performa klasifikasi yang lebih baik daripada menggunakan pendekantan One-vs-One (SVM - OVO). Model klasifikasi genre terbaik dibangun menggunakan kernel poly dengan nilai hyperparameter C sebesar 0.1, Coef0 sebesar 1.0, dan Gamma sebesar 0.1==================================================================================================================================Postpartum Depression (PPD) is a mental health disorder that usually occurs 2-6 weeks in postpartum mothers. It is characterized by feelings of depression, excessive anxiety, guilt, insomnia, and weight changes. PPD is a serious condition that is rarely considered, where studies report that 20% of first-time mothers experience depression. Meanwhile in Indonesia, 50-70% of mothers experience depression after giving birth to their first child. Good social support and several treatments, such as lifestyle changes, psychotherapy, and the use of drugs and supplements can be done to reduce the severity of symptoms. Music therapy is one of lifestyle change treatment that can provide soothness and is easy to apply. In providing therapy, the selection of music that can provide soothness and in accordance with the wishes is a matter of concern. Therefore, a system that can provide soothing music recommendations for mothers at risk of PPD is needed. This study aims to produce a soothing music recommendation system for mothers at risk of PPD. The recommendation system is made based on similarities between music and the results of genre classifications, that have been proven to give good recommendation results. The data used is audio music data from GTZAN Dataset, Free Music Archive, and Audio Library with a tempo of less than 80 bpm. Genre classification utilizes features in audio music and uses the Support Vector Machine (SVM) algorithm in creating a classification model. Music is classified into five genres namely Ambient, Classical, Country-Folk, Jazz-Blues, and RnB-Soul. Furthermore, five music recommendations are generated based on similarities between musical features and by considering the results of genre classification. The results obtained from this study are a system that can recommend soothing music for mothers at risk of PPD. The genre classification model that is part of the recommendation system has an accuracy value of 80% with 82% precision and 80% recall. The results showed that the model built using the One-vs-Rest approach (SVM - OVR) has better classification performance than using the One-vs-One (SVM - OVO) approach. The best genre classification model was built using a poly kernel with hyperparameter C values of 0.1, Coef0 of 1.0, and Gamma of 0.1.",sistem rekomendasi musik tenang risiko postpartum depression dasar fitur musik klasifikasi genre svm,postpartum depression ppd ganggu sehat mental 26 minggu pasca salin ganggu tanda asa depresi cemas lebih salah insomnia ubah berat badan ppd kondisi serius jarang perhati mana teliti lapor 20 lahir alami depresi indonesia 5070 alami depresi pasca lahir anak dukung sosial treatment ubah gaya hidup psikoterapi guna obat suplemen kurang parah gejala terapi musik salah treatment ubah gaya hidup tenang mudah aplikasi beri terapi pilih musik tenang sesuai perhati sistem rekomendasi musik tenang risiko ppd teliti tuju hasil sistem rekomendasi musik tenang risiko ppd sistem rekomendasi dasar mirip musik timbang hasil klasifikasi genre bukti hasil rekomendasi data data audio musik gtzan dataset free music archive audio library tempo 80 bpm klasifikasi genre manfaat fiturfitur audio musik algoritma support vector machine svm buat model klasifikasi musik klasifikasi genre ambient classical countryfolk jazzblues rnbsoul rekomendasi musik hasil dasar mirip fitur musik timbang hasil klasifikasi genre hasil dapat teliti sistem rekomendasi musik tenang risiko ppd model klasifikasi genre sistem rekomendasi milik nilai akurasi 80 presisi 82 recall 80 hasil teliti model bangun dekat onevs rest svm ovr milik performa klasifikasi pendekantan onevsone svm ovo model klasifikasi genre baik bangun kernel poly nilai hyperparameter c 01 coef0 10 gamma 01postpartum depression ppd is a mental health disorder that usually occurs 26 weeks in postpartum mothers it is characterized by feelings of depression excessive anxiety guilt insomnia and weight changes ppd is a serious condition that is rarely considered where studies report that 20 of firsttime mothers experience depression meanwhile in indonesia 5070 of mothers experience depression after giving birth to their first child good social support and several treatments such as lifestyle changes psychotherapy and the use of drugs and supplements can be done to reduce the severity of symptoms music therapy is one of lifestyle change treatment that can provide soothness and is easy to apply in providing therapy the selection of music that can provide soothness and in accordance with the wishes is a matter of concern therefore a system that can provide soothing music recommendations for mothers at risk of ppd is needed this study aims to produce a soothing music recommendation system for mothers at risk of ppd the recommendation system is made based on similarities between music and the results of genre classifications that have been proven to give good recommendation results the data used is audio music data from gtzan dataset free music archive and audio library with a tempo of less than 80 bpm genre classification utilizes features in audio music and uses the support vector machine svm algorithm in creating a classification model music is classified into five genres namely ambient classical countryfolk jazzblues and rnbsoul furthermore five music recommendations are generated based on similarities between musical features and by considering the results of genre classification the results obtained from this study are a system that can recommend soothing music for mothers at risk of ppd the genre classification model that is part of the recommendation system has an accuracy value of 80 with 82 precision and 80 recall the results showed that the model built using the onevsrest approach svm ovr has better classification performance than using the onevsone svm ovo approach the best genre classification model was built using a poly kernel with hyperparameter c values of 01 coef0 of 10 and gamma of 01
Smart Monitoring Kadar Formalin Berbasis Artificial Neural Network untuk Deteksi Keamanan Pangan.,"Fatoni, M. Imam",http://repository.its.ac.id/117503/,"Penggunaan formalin sebagai pengawet makanan pada bahan pangan seperti ikan segar, ikan asin, tahu, tempe, dan ayam telah menjadi permasalahan serius karena dapat membahayakan kesehatan manusia. Oleh karena itu, diperlukan perangkat yang praktis, sensitif, dan akurat untuk mendeteksi keberadaan formalin pada bahan pangan. Penelitian ini mengembangkan alat pengukur kandungan formalin berbasis Artificial Neural Network (ANN) yang dilengkapi dengan sensor Grove HCHO, DHT-22, TGS-822 untuk mendeteksi formalin dan sensor RTD PT-100 untuk monitoring temperatur. Sistem pada alat dirancang untuk mendeteksi formalin pada berbagai variasi konsentrasi yang diaplikasikan pada tiga sampel bahan pangan, yaitu ikan segar, ikan asin, dan tahu. Pengujian menunjukkan bahwa alat telah mampu menjaga suhu pemanas pada set point 70°C secara otomatis dengan akurasi tinggi. Sensor yang digunakan juga menunjukkan kinerja optimal, dengan tingkat akurasi masing-masing sebesar 98,63% (Grove HCHO), 95,95% (TGS-822), 98,66% (DHT-22), dan 95,94% (RTD PT-100). Optimasi ANN menghasilkan hyperparameter terbaik yang meningkatkan akurasi prediksi hingga 95,31% pada ikan asin, 93,89% pada ikan segar, dan 88,78% pada tahu. Hasil penelitian tersebut membuktikan bahwa alat berbasis ANN efektif dan akurat dalam mendeteksi kandungan formalin pada bahan pangan. Dengan keunggulan tersebut, perangkat ini diharapkan dapat menjadi solusi praktis untuk meningkatkan pengawasan keamanan pangan serta mengurangi risiko penggunaan bahan tambahan berbahaya seperti formalin.==============================================================================================================================The use of formalin as a food preservative in products such as fresh fish, salted fish, tofu, tempeh, and chicken has become a serious issue due to its potential health hazards. Therefore, a practical, sensitive, and accurate device is needed to detect the presence of formalin in food products. This study developed a formalin content measurement device based on an Artificial Neural Network (ANN), equipped with Grove HCHO, DHT-22, and TGS-822 sensors for detecting formalin, and an RTD PT-100 sensor for temperature monitoring. The system is designed to detect formalin at various concentrations applied to three food samples: fresh fish, salted fish, and tofu. Testing demonstrated that the device effectively maintained the heater temperature at the set point of 70°C with high accuracy. The sensors used also showed optimal performance, with accuracy levels of 98.63% (Grove HCHO), 95.95% (TGS-822), 98.66% (DHT-22), and 95.94% (RTD PT-100). ANN optimization resulted in the best hyperparameters, improving prediction accuracy to 95,31% for salted fish, 93,89% for fresh fish, and 88.78% for tofu. These findings confirm that the ANN-based device is effective and accurate in detecting formalin content in food products. With these advantages, this device is expected to serve as a practical solution for enhancing food safety monitoring and reducing the risks associated with hazardous additives such as formalin.",smart monitoring kadar formalin bas artificial neural network deteksi aman pangan,guna formalin awet makan bahan pangan ikan segar ikan asin tempe ayam masalah serius bahaya sehat manusia perangkat praktis sensitif akurat deteksi ada formalin bahan pangan teliti kembang alat ukur kandung formalin bas artificial neural network ann lengkap sensor grove hcho dht22 tgs822 deteksi formalin sensor rtd pt100 monitoring temperatur sistem alat rancang deteksi formalin variasi konsentrasi aplikasi sampel bahan pangan ikan segar ikan asin uji alat jaga suhu panas set point 70 c otomatis akurasi sensor kerja optimal tingkat akurasi masingmasing 9863 grove hcho 9595 tgs822 9866 dht22 9594 rtd pt100 optimasi ann hasil hyperparameter baik tingkat akurasi prediksi 9531 ikan asin 9389 ikan segar 8878 hasil teliti bukti alat bas ann efektif akurat deteksi kandung formalin bahan pangan unggul perangkat harap solusi praktis tingkat awas aman pangan kurang risiko guna bahan tambah bahaya formalinthe use of formalin as a food preservative in products such as fresh fish salted fish tofu tempeh and chicken has become a serious issue due to its potential health hazards therefore a practical sensitive and accurate device is needed to detect the presence of formalin in food products this study developed a formalin content measurement device based on an artificial neural network ann equipped with grove hcho dht22 and tgs822 sensors for detecting formalin and an rtd pt100 sensor for temperature monitoring the system is designed to detect formalin at various concentrations applied to three food samples fresh fish salted fish and tofu testing demonstrated that the device effectively maintained the heater temperature at the set point of 70 c with high accuracy the sensors used also showed optimal performance with accuracy levels of 9863 grove hcho 9595 tgs822 9866 dht22 and 9594 rtd pt100 ann optimization resulted in the best hyperparameters improving prediction accuracy to 9531 for salted fish 9389 for fresh fish and 8878 for tofu these findings confirm that the annbased device is effective and accurate in detecting formalin content in food products with these advantages this device is expected to serve as a practical solution for enhancing food safety monitoring and reducing the risks associated with hazardous additives such as formalin
Model Prediksi Permintaan Batu Bara Menggunakan Metode Machine Learning (Study kasus PLTU Balikpapan).,"Febriani, Kristina",http://repository.its.ac.id/105923/,"Peramalan kebutuhan permintaan batu bara penting untuk dilakukan agar dapat meminimalkan biaya operasional. Dengan adanya peramalan akan membantu perusahaan dalam menentukan jumlah dan waktu yang tepat untuk pemesanan batu bara dari pemasok.  Penelitian tentang peramalan batu bara di Indonesia umumnya menggunakan pendekatan statistika dan belum melakukan analisis kinerja model peramalan yang lain. Penelitian ini bertujuan melakukan peramalan kebutuhan batu bara dengan menggunakan metode statistika dan machine learning yaitu ARIMA, Exponential Smoothing, Support Vector Regression (SVR), Recurrent Neural Network (RNN) dan Long Short-Term Memory (LSTM). Metode evaluasi yang digunakan untuk menganalisis kinerja peramalan yaitu Mean Absolute Error (MAE) dan  Mean Absolute Percentage Error (MAPE).  Data permintaan baru bara yang digunakan sebanyak 1097 data harian diambil dari Januari 2021 sampai dengan Desember 2022 yang berbentuk timeseries dan bersifat stasioner yang telah diuji menggunakan Augmented Dickey-Fuller (ADF). Hasil uji coba menunjukkan bahwa model ARIMA dengan nilai MAPE 5.11%, MAE 2.91 dan R-Square 0.925, Exponential Smoothing MAPE 1.07%, MAE 0.55 dan R-Square 0.997,  SVR dengan nilai MAPE 5.48%, MAE 3.16 dan R-Square 0.88, RNN dengan nilai MAPE 5.19%, MAE 2.91 dan R-Square 0.896,  LSTM dengan nilai MAPE 4.83%, MAE 2.84 dan R-Square 0.897. Dari hasil pengujian didapatkan bahwa exponential smoothing memiliki nilai error yang paling kecil diantara model lain. Dengan hasil peramalan yang memiliki tingkat error yang kecil maka dapat membantu manajemen dalam pengambilan keputusan untuk dapat meminimalkan biaya dalam pemesanan batu bara dan manajemen pergudangan=====================================================================================================================================Forecasting coal demand needs is important to minimize operational costs. Forecasting will help companies determine the right amount and time to order coal from suppliers. Research on coal forecasting in Indonesia generally uses a statistical approach and has not analyzed the performance of other forecasting models. This research aims to forecast coal demand using statistical and machine learning methods, namely ARIMA, Exponential Smoothing, Support Vector Regression (SVR), Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM). The evaluation methods used to analyze forecasting performance are Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE). The new coal demand data used is 1097 daily data taken from January 2021 to December 2022 in the form of a timeseries and is stationary which has been tested using Augmented Dickey-Fuller (ADF). The test results show that the ARIMA model has a MAPE value of 5.11%, MAE 2.91 and R-Square 0.925, Exponential Smoothing MAPE 1.07%, MAE 0.55 and R-Square 0.997, SVR with a MAPE value of 5.48%, MAE 3.16 and R-Square 0.88, RNN with a MAPE value of 5.19%, MAE 2.91 and R-Square 0.896, LSTM with a MAPE value of 4.83%, MAE 2.84 and R-Square 0.897. From the test results it was found that exponential smoothing had the smallest error value among other models. With forecasting results that have a small error rate, it can help management in making decisions to minimize costs in coal ordering and warehousing management",model prediksi minta batu bara metode machine learning study pltu balikpapan,amal butuh minta batu bara minimal biaya operasional amal bantu usaha tentu mesan batu bara pasok teliti amal batu bara indonesia dekat statistika analisis kerja model amal teliti tuju amal butuh batu bara metode statistika machine learning arima exponential smoothing support vector regression svr recurrent neural network rnn long shortterm memory lstm metode evaluasi analis kerja amal mean absolute error mae mean absolute percentage error mape data minta bara 1097 data hari ambil januari 2021 desember 2022 bentuk timeseries sifat stasioner uji augmented dickeyfuller adf hasil uji coba model arima nilai mape 511 mae 291 rsquare 0925 exponential smoothing mape 107 mae 055 rsquare 0997 svr nilai mape 548 mae 316 rsquare 088 rnn nilai mape 519 mae 291 rsquare 0896 lstm nilai mape 483 mae 284 rsquare 0897 hasil uji dapat exponential smoothing milik nilai error model hasil amal milik tingkat error bantu manajemen ambil putus minimal biaya mesan batu bara manajemen pergudanganforecasting coal demand needs is important to minimize operational costs forecasting will help companies determine the right amount and time to order coal from suppliers research on coal forecasting in indonesia generally uses a statistical approach and has not analyzed the performance of other forecasting models this research aims to forecast coal demand using statistical and machine learning methods namely arima exponential smoothing support vector regression svr recurrent neural network rnn and long shortterm memory lstm the evaluation methods used to analyze forecasting performance are mean absolute error mae and mean absolute percentage error mape the new coal demand data used is 1097 daily data taken from january 2021 to december 2022 in the form of a timeseries and is stationary which has been tested using augmented dickeyfuller adf the test results show that the arima model has a mape value of 511 mae 291 and rsquare 0925 exponential smoothing mape 107 mae 055 and rsquare 0997 svr with a mape value of 548 mae 316 and rsquare 088 rnn with a mape value of 519 mae 291 and rsquare 0896 lstm with a mape value of 483 mae 284 and rsquare 0897 from the test results it was found that exponential smoothing had the smallest error value among other models with forecasting results that have a small error rate it can help management in making decisions to minimize costs in coal ordering and warehousing management
Aplikasi Metode Support Vector Machine (SVM) untuk Klasifikasi Sentimen Masyarakat Terhadap E-Tilang pada Media Sosial Twitter.,"Febriyanti, Nabila Isnaini",http://repository.its.ac.id/100476/,"E-tilang merupakan salah satu inovasi dari Kepolisian RI dalam pembaharuan  pelayanan publik di bidang ketertiban dan keamanan. Keberadaan e-tilang diharapkan dapat menjadi solusi untuk mendisiplinkan para pengendera kendaraan bermotor dari pelanggaran berlalu-lintas dan dapat mencegah kecurangan oknum penegak hukum dari pungutan liar. Meskipun sudah lama sejak diberlakukannya e-tilang, namun masih saja menimbulkan beragam komentar dari masyarakat. Berdasarkan penelitian mengenai e-tilang yang telah dilakukan sebelumnya mengatakan bahwa lebih banyak masyarakat yang memberikan komentar negatif mengenai e-tilang. Hal ini perlu menjadi perhatian pihak kepolisian untuk mengatur strategi dan cara sosialisasi pemberlakuan e-tilang agar tujuannya dapat tercapai dan dapat dimanfaatkan sebagai bahan evaluasi dalam membuat kebijakan. Suatu cara mengetahui opini masyarakat mengenai e-tilang adalah dengan melakukan analisis sentimen. sehingga pada penelitian ini dilakukan analsis sentimen terhadap e-tilang. Metode klasifikasi yang digunakan adalah Support Vector Machine (SVM) karena SVM merupakan salah satu metode yang dapat mengatasi problem non-linear secara efisien. Hasil dari penelitian ini didapatkan bahwa tweet masyarakat mayoritas bersentimen positif sebesar 62%, sedangkan tweet masyarakat yang bersentimen negatif sebesar 38%. Hasil analisis klasifikasi menghasilkan nilai akurasi sebesar 81,58%, sensitivitas sebesar 88,68%, spesifikasi sebesar 79,17%, dan nilai AUC sebesar 83,92%. sehingga model yang terbentuk terbukti mampu untuk mendeteksi tweet bersentimen positif dengan baik karena memiliki nilai akurasi dengan kategori good classification dan didukung nilai AUC yang masuk kategori baik, serta nilai sensitivitas yang lebih besar daripada nilai spesifikasi.================================================================================================================================ETLE is one of the innovations of the Indonesian National Police in the renewal of public services in the field of order and security. The existence of ETLE is expected to be a solution to discipline motorists from traffic violations and can prevent misappropriation by law enforcementofficers from illegal levies. Although it has been in effect for a long time, the implementation of e-tickets still raises various comments from the public. Based on research on e-tickets that has been done before, it is said that more people give negative comments about ETLE. This needs to be a concern for the police to set strategies and ways of socializing the implementation of ETLE so that the objectives can be achieved and can be used as evaluation material in making policies. One way to find out publicopinion about ETLE is to conduct sentiment analysis. so that in this study a sentiment analysis of e-tickets was carried out. The classification method used is Support Vector Machine (SVM) becauseSVM is one method that can solve non-linear problems efficiently. The results of this study found that the majority of public tweets had a positive sentiment of 62%, while public tweets with negative sentiment amounted to 38%. Classification analysis resulted in an accuracy value of 81.58%, a sensitivity of 88.68%, a specification of 79.17%, and an AUC value of 83.92%. so that the modelformed is proven to be able to detect positive tweets well because it has an accuracy value with a good classification category and is supported by an AUC value that is in the good category, as well as a sensitivity value that is greater than the specification value.",aplikasi metode support vector machine svm klasifikasi sentimen masyarakat etilang media sosial twitter,etilang salah inovasi polisi ri baharu layan publik bidang tertib aman ada etilang harap solusi disiplin pengendera kendara motor langgar berlalulintas cegah curang oknum tegak hukum pungut liar laku etilang timbul agam komentar masyarakat dasar teliti etilang masyarakat komentar negatif etilang perhati polisi atur strategi sosialisasi laku etilang tuju capai manfaat bahan evaluasi bijak opini masyarakat etilang analisis sentimen teliti analsis sentimen etilang metode klasifikasi support vector machine svm svm salah metode atas problem nonlinear efisien hasil teliti dapat tweet masyarakat mayoritas sentimen positif 62 tweet masyarakat sentimen negatif 38 hasil analisis klasifikasi hasil nilai akurasi 8158 sensitivitas 8868 spesifikasi 7917 nilai auc 8392 model bentuk bukti deteksi tweet sentimen positif milik nilai akurasi kategori good classification dukung nilai auc masuk kategori nilai sensitivitas nilai spesifikasietle is one of the innovations of the indonesian national police in the renewal of public services in the field of order and security the existence of etle is expected to be a solution to discipline motorists from traffic violations and can prevent misappropriation by law enforcementofficers from illegal levies although it has been in effect for a long time the implementation of etickets still raises various comments from the public based on research on etickets that has been done before it is said that more people give negative comments about etle this needs to be a concern for the police to set strategies and ways of socializing the implementation of etle so that the objectives can be achieved and can be used as evaluation material in making policies one way to find out publicopinion about etle is to conduct sentiment analysis so that in this study a sentiment analysis of etickets was carried out the classification method used is support vector machine svm becausesvm is one method that can solve nonlinear problems efficiently the results of this study found that the majority of public tweets had a positive sentiment of 62 while public tweets with negative sentiment amounted to 38 classification analysis resulted in an accuracy value of 8158 a sensitivity of 8868 a specification of 7917 and an auc value of 8392 so that the modelformed is proven to be able to detect positive tweets well because it has an accuracy value with a good classification category and is supported by an auc value that is in the good category as well as a sensitivity value that is greater than the specification value
Klasifikasi Kelulusan Siswa Dalam Seleksi Masuk Perguruan Tinggi Negeri Melalui Jalur Nilai Rapor Menggunakan Metode Support Vector Machine (SVM).,"Findiana, Rachmawati",http://repository.its.ac.id/87598/,"Seleksi Masuk Perguruan Tinggi Negeri melalui jalur nilai rapor merupakan salah satu cara penerimaan mahasiswa baru di Perguruan Tinggi Negeri yang tidak dipungut biaya pendaftaran dan tanpa ujian tertulis. Di Mojokerto keikutsertaan siswa dalam proses seleksi ini masih dilakukan secara manual sehingga hasilnya belum maksimal dimana disaat siswa yang mempunyai nilai rapor baik belum tentu diterima dan sebaliknya siswa yang nilai rapornya cukup baik bisa diterima di salah satu Perguruan Tinggi Negeri. Oleh karena itu diperlukan klasifikasi untuk memprediksi kelulusan siswa pada Perguruan Tinggi Negeri melalui jalur. Penelitian ini akan melakukan klasifikasi dengan menggunakan metode Support Vector Machine (SVM) dan Fuzzy Mamdani untuk menentukan kelulusan siswa pada SNMPTN, SPAN PTKIN, SNMPN, dan Tidak Lulus dengan menggunakan nilai hasil ekstraksi fitur dari nilai rapor semester 1 sampai dengan nilai rapor semester 5. Berdasarkan hasil pengujian dan evaluasi untuk mengetahui seberapa baik hasil klasifikasi yang dilakukan dengan mengukur tingkat akurasi dari hasil klasifikasi data kelulusan siswa di SMA/MA Negeri di Mojokerto pada tahun 2018 dan 2019 dengan menggunakan metode Support Vector Machine mendapatkan hasil lebih baik dibandingkan dengan metode Fuzzy Mamdani dengan hasil akurasi terbaik 87% sedangkan nilai akurasi Fuzzy Mamdani 80%.======================================================================================================Entrance selection Public Higher Education through report card grades path is one way of accepting new students at Public Higher Education, free of registration fees, and without written examinations. To date, in Mojokerto, thestudents’ participation in the selection process is still done manually, so the resultshave not been maximized. Students with good report cards are not necessarily accepted, and vice versa, students with average report cards can be one GeneralHigher Education through this pathway. Therefore, classification is needed to predict student graduation at State Universities through pathways. This study will classify using the Support Vector Machine (SVM) and Fuzzy Mamdani methods to determine student graduation at SNMPTN, SPAN PTKIN, SNMPN, and Failed by using the value of feature extraction results from semester 1 report cards to semester 5 report cards. Based on the results of testing and evaluation to find out how well the classification results are carried out by measuring the accuracy of the classification results of student graduation data at SMA/MA Negeri in Mojokerto in 2018 and 2019 using the Support Vector Machine method, the results are better than the fuzzy mamdani method. with the best accuracy of 87% while the Mamdani fuzzy accuracy value is 80%.",klasifikasi kelulus siswa seleksi masuk guru negeri jalur nilai rapor metode support vector machine svm,seleksi masuk guru negeri jalur nilai rapor salah terima mahasiswa guru negeri pungut biaya daftar uji tulis mojokerto keikutsertaan siswa proses seleksi manual hasil maksimal mana saat siswa nilai rapor terima siswa nilai rapor terima salah guru negeri klasifikasi prediksi kelulus siswa guru negeri jalur teliti klasifikasi metode support vector machine svm fuzzy mamdani tentu kelulus siswa snmptn span ptkin snmpn lulus nilai hasil ekstraksi fitur nilai rapor semester 1 nilai rapor semester 5 dasar hasil uji evaluasi hasil klasifikasi ukur tingkat akurasi hasil klasifikasi data kelulus siswa smama negeri mojokerto 2018 2019 metode support vector machine hasil banding metode fuzzy mamdani hasil akurasi baik 87 nilai akurasi fuzzy mamdani 80entrance selection public higher education through report card grades path is one way of accepting new students at public higher education free of registration fees and without written examinations to date in mojokerto thestudents  participation in the selection process is still done manually so the resultshave not been maximized students with good report cards are not necessarily accepted and vice versa students with average report cards can be one generalhigher education through this pathway therefore classification is needed to predict student graduation at state universities through pathways this study will classify using the support vector machine svm and fuzzy mamdani methods to determine student graduation at snmptn span ptkin snmpn and failed by using the value of feature extraction results from semester 1 report cards to semester 5 report cards based on the results of testing and evaluation to find out how well the classification results are carried out by measuring the accuracy of the classification results of student graduation data at smama negeri in mojokerto in 2018 and 2019 using the support vector machine method the results are better than the fuzzy mamdani method with the best accuracy of 87 while the mamdani fuzzy accuracy value is 80
Estimasi Bahan Bakar pada Kapal KRI Bima Suci menggunakkan Machine Learning.,"Firdaus, Mahendra Alfath",http://repository.its.ac.id/92962/,"Adanya permasalahan dalam bahan bakar pada KRI Bima Suci, seperti kekurangan bahan bakar saat sedang berlayar disebabkan karena perhtiungan estimasi yang masi terbilang manual. Belum adanya penggunaan komputerisasi juga salah satu penyebab timbulnya permasalahan. Oleh karena itu, studi ini dilakukan untuk membuat penyelesaian dalam permasalahan tersebut, estimasi konsumsi bahan bakar akan dilakukan menggunakan machine learning. Machine learning ialah suatu bagian dari Artificial Intelligence dimana bisa melakukan suatu prediksi dengan metode regresi. Dengan menggunakkan 4 variabel diantaranya kecepatan kapal, kekuatan angin, kondisi laut, dan engine rpm diharapkan bisa mengestimasi konsumsi bahan bakar dengan baik. Penelitian dalam studi ini menghasilkan suatu klasifikasi dan estimasi yang tergolong baik. Untuk akurasi yang diperoleh dalam metode klasifikasi, K Nearest Neighbor merupakan yang tertinggi diantara metode klasifikasi yang lainnya, dengan tingkat akurasi terbesar mencapai 84.95%. untuk akurasi yang diperoleh dalam metode regresi, Polinomial Regresi merupakan yang terbaik diantara metode regresi yang lainnya, dengan tingkat akurasi sebesar 98.99% dan rata rata error hanya 13.66. Dalam memudahkan pihak KRI Bima Suci dalam menggunakkan metode machine learning, dibuatkan suatu prototipe website yang berfungsi untuk pengolahan data baru yang bisa dimasukkan sebagai data tambahan agar metode klasifikasi dan regresi bertambah baik====================================================================================================There were problems in fuel on the KRI Bima Suci, such as a lack of fuel when sailing due to the estimation calculations, which were still reasonably manual. The absence of computers is also one of the causes of problems. Therefore, this study was conducted to make a solution to this problem, the estimation of fuel consumption will be carried out using machine learning. Machine learning is a part of Artificial Intelligence that can make predictions using the regression method. By using four variables, including ship speed, wind strength, sea conditions, and engine rpm, it is expected to be able to estimate fuel consumption correctly. The research in this study resulted in classification and estimation that were classified as good. For the accuracy obtained in the classification method, K Nearest Neighbor is the highest among other classification methods, with the highest accuracy rate reaching 84.95%. For the accuracy obtained in the regression method, Regression Polynomial is the best among other regression methods, with an accuracy rate of 98.99% and an average error of only 13.66. To make it easier for KRI Bima Suci to use machine learning methods, a website prototype was created to process new data that can be entered as additional data so that the classification and regression methods are better",estimasi bahan bakar kapal kri bima suci menggunakkan machine learning,masalah bahan bakar kri bima suci kurang bahan bakar layar sebab perhtiungan estimasi mas bilang manual guna komputerisasi salah sebab timbul masalah studi selesai masalah estimasi konsumsi bahan bakar machine learning machine learning artificial intelligence mana prediksi metode regresi menggunakkan 4 variabel cepat kapal kuat angin kondisi laut engine rpm harap estimasi konsumsi bahan bakar teliti studi hasil klasifikasi estimasi golong akurasi oleh metode klasifikasi k nearest neighbor tinggi metode klasifikasi tingkat akurasi besar capai 8495 akurasi oleh metode regresi polinomial regresi baik metode regresi tingkat akurasi 9899 error 1366 mudah kri bima suci menggunakkan metode machine learning buat prototipe website fungsi olah data masuk data tambah metode klasifikasi regresi tambah baikthere were problems in fuel on the kri bima suci such as a lack of fuel when sailing due to the estimation calculations which were still reasonably manual the absence of computers is also one of the causes of problems therefore this study was conducted to make a solution to this problem the estimation of fuel consumption will be carried out using machine learning machine learning is a part of artificial intelligence that can make predictions using the regression method by using four variables including ship speed wind strength sea conditions and engine rpm it is expected to be able to estimate fuel consumption correctly the research in this study resulted in classification and estimation that were classified as good for the accuracy obtained in the classification method k nearest neighbor is the highest among other classification methods with the highest accuracy rate reaching 8495 for the accuracy obtained in the regression method regression polynomial is the best among other regression methods with an accuracy rate of 9899 and an average error of only 1366 to make it easier for kri bima suci to use machine learning methods a website prototype was created to process new data that can be entered as additional data so that the classification and regression methods are better
Model Prediksi Waktu Penyelesaian Proyek Pada Kegiatan Usaha Hulu Migas Menggunakan Support Vector Regression Growth Model.,"Ghullam, Arif Abadil",http://repository.its.ac.id/82541/,"Cadangan minyak dan gas bumi yang dimiliki Indonesia saat ini rata-rata telah berumur tua yang dari tahun ke tahun dan mengalami penurunan secara alami. Langkah – langkah yang dilakukan Satuan Kerja Khusus Pelaksana Kegiatan Usaha Hulu Minyak dan Gas Bumi (SKK Migas) bersama Kontraktor Kontrak Kerja Sama (KKKS) dalam mempertahankan tingkat produksi nasional diantaranya melalui proyek – proyek penambahan kapasitas produksi serta proyek pengembangan lapangan migas baru. Proyek yang berhasil diselesaikan tepat waktu akan mengisi celah tingkat penurunan produksi alamiah dari lapangan yang telah ada. Namun sayangnya, masih banyak proyek KKKS yang mengalami keterlambatan karena berbagai macam faktor.Selama ini, prediksi waktu penyelesaian proyek dilakukan menggunakan metoda Earned Value Management (EVM). Salah satu kelemahan dari metoda prediksi EVM adalah penggunaan asumsi berjalannya proyek yang digambarkan dalam bentuk kurva linier. Padahal dalam kenyataannya, progress pelaksanaan proyek konstruksi cenderung non-linear. Penelitian ini mengusulkan model prediksi Earned Value berbasis Support Vector Regression (SVR). Support Vector Regression digunakan untuk menangkap karakter non linear dari simulasi data historis dan memprediksi waktu penyelesaian proyek. Untuk validasi model, pada penelitian ini Proyek kegiatan Usaha Hulu Migas yang beroperasi di wilayah Perwakilan Jawa, Bali dan Nusa Tenggara digunakan sebagai studi kasus.Hasil akhir dari penelitian ini mendapatkan pemodelan yang dapat memberikan prediksi waktu penyelesaian proyek dengan tingkat penyimpangan sebesar 2,164% atau 0,541 bulan dari waktu penyelesaian proyek aktual. Berdasarkan hasil uji sensitifitas menunjukkan bahwa metode pemodelan yang dusulkan pada penelitian ini dapat memberikan hasil prediksi waktu penyelesaian yang konsisten meski hanya menggunakan data tahap awal dari proyek aktual yang berjalan.=====================================================================================================The Indonesian reservoar are mostly produced on the mature reservoar and face natural declinement during their production phase. Satuan Kerja Khusus Pelaksana Kegiatan Usaha Hulu Minyak dan Gas Bumi (SKK Migas) as the Upstream Oil & Gas Indonesian Government Representative Agencies with PSC’s contactor are taking various method to keep the stability of national production level by upgrading existing facilities and new oil & gas development projects. The project completion time is the most important key to fill the production gap that caused by those existing natural declinement. Unfortunately, many of those projects were delayed due to various obstacles.The prediction of project completion time previously was done using the Earned Value Management (EVM) method. One of the weaknesses of the EVM prediction method is the use of assumptions that are projects described in the form of linear EVM curves. Whereas in reality, the stages of Oil & Gas construction projects tend to be non-linear EVM curves. This study proposes a prediction model based on integration Earned Value based and Support Vector Regression (SVR). SVR is used to capture non-linear  characteristic from simulation of the similar projects historical data. The prediction model was validated using a case study in the Upstream Oil and Gas Projects which operates in the Jawa, Bali and Nusa Tenggara Representative Office.This proposed model provide the project time completion predictions accuracy with error equal to 2,164% or 0,541 months from the actual project time completion. Based on the sensitivity test results to proposed model concluded that the proposed model give project time completion prediction consistently from early actual progress project data.",model prediksi selesai proyek giat usaha hulu migas support vector regression growth model,cadang minyak gas bumi milik indonesia ratarata umur tua alami turun alami langkah  langkah satu kerja khusus laksana giat usaha hulu minyak gas bumi skk migas kontraktor kontrak kerja kkks tahan tingkat produksi nasional proyek  proyek tambah kapasitas produksi proyek kembang lapang migas proyek hasil selesai isi celah tingkat turun produksi alamiah lapang sayang proyek kkks alami lambat faktorselama prediksi selesai proyek metoda earned value management evm salah lemah metoda prediksi evm guna asumsi jalan proyek gambar bentuk kurva linier nyata progress laksana proyek konstruksi cenderung nonlinear teliti usul model prediksi earned value bas support vector regression svr support vector regression tangkap karakter non linear simulasi data historis prediksi selesai proyek validasi model teliti proyek giat usaha hulu migas operasi wilayah wakil jawa bal nusa tenggara studi kasushasil teliti model prediksi selesai proyek tingkat simpang 2164 0541 selesai proyek aktual dasar hasil uji sensitifitas metode model dusulkan teliti hasil prediksi selesai konsisten data tahap proyek aktual berjalanthe indonesian reservoar are mostly produced on the mature reservoar and face natural declinement during their production phase satu kerja khusus laksana giat usaha hulu minyak gas bumi skk migas as the upstream oil gas indonesian government representative agencies with psc  s contactor are taking various method to keep the stability of national production level by upgrading existing facilities and new oil gas development projects the project completion time is the most important key to fill the production gap that caused by those existing natural declinement unfortunately many of those projects were delayed due to various obstaclesthe prediction of project completion time previously was done using the earned value management evm method one of the weaknesses of the evm prediction method is the use of assumptions that are projects described in the form of linear evm curves whereas in reality the stages of oil gas construction projects tend to be nonlinear evm curves this study proposes a prediction model based on integration earned value based and support vector regression svr svr is used to capture nonlinear characteristic from simulation of the similar projects historical data the prediction model was validated using a case study in the upstream oil and gas projects which operates in the jawa bal and nusa tenggara representative officethis proposed model provide the project time completion predictions accuracy with error equal to 2164 or 0541 months from the actual project time completion based on the sensitivity test results to proposed model concluded that the proposed model give project time completion prediction consistently from early actual progress project data
Implementasi Segmentasi Pakaian Menggunakan Metode Mask R-CNN.,"Gita, Kartika Diva Asmara",http://repository.its.ac.id/116398/,"Implementasi Mask R-CNN merupakan pendekatan untuk segmentasi objek fashion yang menggunakan dataset berisi 15.000 gambar.  Mask R-CNN, dengan backbone ResNet101 dan arsitektur Feature Pyramid Network (FPN), digunakan untuk mendeteksi dan menghasilkan mask segmentasi dengan presisi tinggi. Penelitian ini bertujuan untuk mengevaluasi kinerja model dalam mengenali dan memisahkan berbagai jenis pakaian berdasarkan citra. Hasil pengujian menunjukkan bahwa konfigurasi model dengan jumlah epoch dan langkah per epoch yang terbatas belum mampu mencapai kinerja optimal yang hanya mampu mencapai nilai rerata IoU dan Accuracy hanya sebesar 36.93% dan 90.75%. Sedangkan rata-rata IoU dan Accuracy untuk metode superpixel sebanyak 49.29% dan 92.12%. Faktor seperti jumlah epoch, kualitas dataset, dan pengaturan hyperparameter berperan signifikan dalam mempengaruhi hasil segmentasi. Penyesuaian lebih lanjut diperlukan untuk meningkatkan akurasi dan efisiensi model. Penelitian ini memberikan kontribusi pada pengembangan teknologi segmentasi objek di industri fashion dan e-commerce, khususnya dalam analisis visual berbasis citra. ============================================================================================================================Mask R-CNN implementation is an approach for fashion object segmentation that using a dataset of 15,000 images.  Mask R-CNN, with the ResNet101 backbone and the Feature Pyramid Network (FPN) architecture, is used to detect and generate a high-precision segmentation mask with high precision. This study aims to evaluate the performance of model in recognizing and separating different types of clothing based on images. The results of The test results show that the model configuration with a limited number of epochs and steps per epoch has not been able to achieve optimal performance. model configuration with a limited number of epochs and steps per epoch has not been able to achieve optimal performance which is only able to achieve an average value of IoU and Accuracy are only 36.93% and 90.75%. While the average IoU and Accuracy for the superpixel method are 49.29% and 92.12%. Factors such as number of epochs, quality of quality of the dataset, and hyperparameter settings play a significant role in influencing the segmentation results. segmentation results. Further adjustments are needed to improve the accuracy and efficiency of the model. model. This research contributes to the development of object segmentation technology in the fashion and e-commerce industries, especially in image-based visual analysis. fashion and e-commerce industries, especially in image-based visual analysis.",implementasi segmentasi pakai metode mask rcnn,implementasi mask rcnn dekat segmentasi objek fashion dataset isi 15000 gambar mask rcnn backbone resnet101 arsitektur feature pyramid network fpn deteksi hasil mask segmentasi presisi teliti tuju evaluasi kerja model nali pisah jenis pakai dasar citra hasil uji konfigurasi model epoch langkah epoch batas capai kerja optimal capai nilai rerata iou accuracy 3693 9075 ratarata iou accuracy metode superpixel 4929 9212 faktor epoch kualitas dataset atur hyperparameter peran signifikan pengaruh hasil segmentasi sesuai tingkat akurasi efisiensi model teliti kontribusi kembang teknologi segmentasi objek industri fashion ecommerce analisis visual bas citra mask rcnn implementation is an approach for fashion object segmentation that using a dataset of 15000 images mask rcnn with the resnet101 backbone and the feature pyramid network fpn architecture is used to detect and generate a highprecision segmentation mask with high precision this study aims to evaluate the performance of model in recognizing and separating different types of clothing based on images the results of the test results show that the model configuration with a limited number of epochs and steps epoch has not been able to achieve optimal performance model configuration with a limited number of epochs and steps epoch has not been able to achieve optimal performance which is only able to achieve an average value of iou and accuracy are only 3693 and 9075 while the average iou and accuracy for the superpixel method are 4929 and 9212 factors such as number of epochs quality of quality of the dataset and hyperparameter settings play a significant role in influencing the segmentation results segmentation results further adjustments are needed to improve the accuracy and efficiency of the model model this research contributes to the development of object segmentation technology in the fashion and ecommerce industries especially in imagebased visual analysis fashion and ecommerce industries especially in imagebased visual analysis
Klasifikasi Aritmia Sinyal ECG Menggunakan Transformasi Wavelet Dan Analisa Statistik.,"Gusnam, Mu'thiana",http://repository.its.ac.id/95953/,"Pengenalan kelainan aritmia seseorang diketahui dengan melakukan rekam aktivitas jantung menggunakan Electrocardiogram (ECG). Rekaman ECG detak jantung dibagi menjadi gelombang P, QRS, dan T yang menunjukkan aktivitas kelistrikan jantung seperti depolarisasi atrium dari gelombang P, depolarisasi ventrikel dari kompleks QRS dan repolarisasi ventrikel maupun atrium dari segmen ST.",klasifikasi aritmia sinyal ecg transformasi wavelet analisa statistik,kenal lain aritmia rekam aktivitas jantung electrocardiogram ecg rekam ecg detak jantung bagi gelombang p qrs t aktivitas listrik jantung depolarisasi atrium gelombang p depolarisasi ventrikel kompleks qrs repolarisasi ventrikel atrium segmen st
"Klasifikasi Jenis Tumor Otak Meningioma, Glioma, Dan Pituitari Berbasis Hybrid Vgg-16 Dan Svm Untuk Diagnosis Praoperasi.","Hajjanto, Ariq  Dreiki",http://repository.its.ac.id/110912/,"Berdasarkan Global Cancer Statistic pada tahun 2020, kasus baru tumor otak dan CNS mencapai 308.102 dengan kematian mencapai 251.329 di seluruh dunia.  Di Indonesia sendiri, estimasi kejadian dan kematian pada tahun 2016 mencapai 6.337 dan 5.405 kasus. Banyak jenis tumor otak dengan variasi lokasi, ukuran, dan tingkat keganasan membuat melokalisasi dan klasifikasi tumor kompleks bagi ahli medis secara konvensional, menyebabkan kesalahan dalam penentuan jenis tumor otak karena perlu membaca hasil citra dalam jumlah yang sangat banyak. Keakuratan klasifikasi konvensional dapat dipengaruhi oleh beberapa faktor, seperti perbedaan subjektivitas individu dalam mengenali lokasi tumor, waktu, ketelitian, kelelahan, dan faktor manusia lainnya. Maka dari itu, dibutuhkan suatu metode dalam menghasilkan diagnosis tumor yang akurat dengan machine learning. Akan tetapi, penelitian yang menggunakan pendekatan machine learning sangat rentan akan overfitting disebabkan kurangnya dataset ataupun model arsitektur yang digunakan dan juga lamanya proses komputasi yang dibutuhkan. Oleh sebab itu, Pada penelitian ini diusulkan sistem klasifikasi hibrida dengan bantuan machine learning, yaitu menggunakan arsitektur/model VGG-16 dan Support Vector Machine (SVM). VGG-16 memiliki keunggulan dalam ekstraksi fitur hierarkis dan invariansi spasial yang memungkinkan identifikasi tumor dengan akurasi lebih tinggi. Output fitur jenis tumor otak dari VGG-16 direduksi menggunakan Principal Component Analysis (PCA), lalu diklasifikasi dengan bantuan SVM serta dioptimalkan dengan pengujian kombinasi kernel dan hyperparameter. Performa arsitektur dievaluasi menggunakan performance metrics dan komparasi model sebelumnya, yang memungkinkan penilaian objektif terhadap hasil yang dicapai. Hasil penelitian memberikan hasil untuk masing-masing metrik akurasi, presisi, recall¸f1-score, dan spesifisitas secara berturut-turut sebesar 96.9%, 97.3%, 96.67%, 96.67%, dan 99.97% dengan menggunakan kernel polynomial dengan hyperparameter C, degree, dan coef0 sebesar 10, 3, dan 0.5.============================================================According to the 2020 Global Cancer Statistics, there were 308,102 new cases of brain and CNS tumors, resulting in 251,329 deaths worldwide. In Indonesia alone, the estimated incidence and mortality in 2016 were 6,337 and 5,405 cases, respectively. The various types of brain tumors, with variations in location, size, and malignancy levels, make localization and classification complex for conventional medical professionals, leading to errors in brain tumor determination due to the need to analyze a vast amount of imaging results. Conventional classification accuracy can be influenced by factors such as individual subjectivity in recognizing tumor locations, timing, precision, fatigue, and other human factors. Therefore, a method is needed to produce accurate tumor diagnoses using machine learning. However, research using machine learning approaches is highly susceptible to overfitting due to the lack of datasets or the architectural models used and the lengthy computational processes required. Hence, this study proposes a hybrid classification system with the assistance of machine learning, utilizing the VGG-16 architecture/model and Support Vector Machine (SVM). VGG-16 excels in hierarchical feature extraction and spatial invariance, enabling higher accuracy in tumor identification. The output features of brain tumor types from VGG-16 are reduced using Principal Component Analysis (PCA) and then classified with the help of SVM, optimized by testing combinations of kernels and hyperparameters. The architecture performance is evaluated using performance metrics and comparison with previous models, allowing for an objective assessment of the achieved results. The study results for each metric of accuracy, precision, recall, f1-score, and specificity were 96.9%, 97.3%, 96.67%, 96.67%, and 99.97%, respectively, using the polynomial kernel with hyperparameters C, degree, and coef0 of 10, 3, and 0.5.",klasifikasi jenis tumor otak meningioma glioma pituitari bas hybrid vgg16 svm diagnosis praoperasi,dasar global cancer statistic 2020 tumor otak cns capai 308102 mati capai 251329 dunia indonesia estimasi jadi mati 2016 capai 6337 5405 jenis tumor otak variasi lokasi ukur tingkat ganas lokalisasi klasifikasi tumor kompleks ahli medis konvensional sebab salah tentu jenis tumor otak baca hasil citra akurat klasifikasi konvensional pengaruh faktor beda subjektivitas individu nali lokasi tumor teliti lelah faktor manusia butuh metode hasil diagnosis tumor akurat machine learning teliti dekat machine learning rentan overfitting sebab kurang dataset model arsitektur proses komputasi butuh teliti usul sistem klasifikasi hibrida bantu machine learning arsitekturmodel vgg16 support vector machine svm vgg16 milik unggul ekstraksi fitur hierarkis invariansi spasial identifikasi tumor akurasi output fitur jenis tumor otak vgg16 reduksi principal component analysis pca klasifikasi bantu svm optimal uji kombinasi kernel hyperparameter performa arsitektur evaluasi performance metrics komparasi model nilai objektif hasil capai hasil teliti hasil masingmasing metrik akurasi presisi recall f1score spesifisitas berturutturut 969 973 9667 9667 9997 kernel polynomial hyperparameter c degree coef0 10 3 05according to the 2020 global cancer statistics there were 308102 new cases of brain and cns tumors resulting in 251329 deaths worldwide in indonesia alone the estimated incidence and mortality in 2016 were 6337 and 5405 cases respectively the various types of brain tumors with variations in location size and malignancy levels make localization and classification complex for conventional medical professionals leading to errors in brain tumor determination due to the need to analyze a vast amount of imaging results conventional classification accuracy can be influenced by factors such as individual subjectivity in recognizing tumor locations timing precision fatigue and other human factors therefore a method is needed to produce accurate tumor diagnoses using machine learning however research using machine learning approaches is highly susceptible to overfitting due to the lack of datasets or the architectural models used and the lengthy computational processes required hence this study proposes a hybrid classification system with the assistance of machine learning utilizing the vgg16 architecturemodel and support vector machine svm vgg16 excels in hierarchical feature extraction and spatial invariance enabling higher accuracy in tumor identification the output features of brain tumor types from vgg16 are reduced using principal component analysis pca and then classified with the help of svm optimized by testing combinations of kernels and hyperparameters the architecture performance is evaluated using performance metrics and comparison with previous models allowing for an objective assessment of the achieved results the study results for each metric of accuracy precision recall f1score and specificity were 969 973 9667 9667 and 9997 respectively using the polynomial kernel with hyperparameters c degree and coef0 of 10 3 and 05
Pembuatan Sistem Visual Question Answering Berbasis Web Untuk Mendukung Pembelajaran Visual Anak TK Berbahasa Indonesia Menggunakan Deep Learning.,"Hanifah, Asiyah",http://repository.its.ac.id/102392/,"Seiring pesatnya perkembangan teknologi, Indonesia semakin gencar melakukan persiapan transformasi digital untuk menghadapi perubahan teknologi. Salah satunya adalah implementasi e-learning di berbagai sektor, termasuk pendidikan. E-learning telah diterapkan dalam pembelajaran taman kanak-kanak, termasuk pembelajaran visual. Bentuk pembelajaran visual pada e-learning dapat dibuat dengan pembangunan sistem visual question answering. Beberapa penelitian telah dibuat untuk pembangunan sistem visual question answering dan berhasil membuat sistem visual question answering dengan ilmu patologi dalam bahasa inggris, dan dataset objek di sekitar monas dalam bahasa indonesia. Oleh karena itu, dilakukan pengajuan pembuatan sistem visual question answering dengan dataset yang lebih umum dan dapat dikenali oleh anak TK berbahasa indonesia. Dadanya penelitian ini akan dapat membantu tenaga pendidik dalam kegiatan belajar mengajar yang lebih interaktif dalam e-learning. Penelitian ini menggunakan model Bootstrapping Language-Image Pre-training (BLIP) untuk proses pembuatan sistem visual question answering dan mengimplementasikan model No Language Left Behind (NLLB) pada input-output pertanyaan untuk menerjemahkan bahasa yang digunakan. Hasil implementasi kedua model BLIP dan NLLB berhasil membangun sistem visual question answering berbahasa indonesia. Berdasarkan hasil pengujiannya, dari beberapa pertanyaan yang mengandung 6 jenis jawaban: ya/tidak, kata benda, kata kerja, kata sifat, kata keterangan, dan numeral, sistem ini berhasil menjawab tepat untuk jenis jawaban ya/tidak, kata benda, kata kerja, dan kata keterangan dengan nilai ketepatan jawaban ya/tidak 100, kata benda 100, kata kerja 100, dan kata keterangan 87.5.===============================================================================================================================Along with the rapid development of technology, Indonesia is increasingly intensifying its digital transformation preparations to face the existing technological advancements. With the rapid development of technology, Indonesia is increasingly intensifying its preparations for digital transformation to face technological changes. One of these preparations involves the implementation of e-learning across various sectors, including education. E-learning has been applied in kindergarten education, including visual learning. Visual learning in e-learning can be achieved through the development of a visual question answering system. Several studies have been conducted on visual question answering systems and have successfully created such systems using pathology images in English and object datasets around Monas (National Monument) in Indonesian. Therefore, the author proposes the creation of a visual question answering system with a more general dataset that can be recognized by Indonesian-speaking kindergarten children. The purpose of this research is to assist educators in conducting more interactive e-learning activities. The research utilizes the Bootstrapping Language-Image Pre-training (BLIP) model for the development of the visual question answering system and implements the No Language Left Behind (NLLB) model for translating the language used in the input-output questions. The implementation results of both the BLIP and NLLB models successfully build a visual question answering system in the Indonesian language. Based on testing, the system can provide accurate answers for yes/no, nouns, verbs, and adverbial questions, with accuracy rates of 100% for yes/no, 100% for nouns, 100% for verbs, and 87.5% for adverbial questions, all of which contain six types of answers: yes/no, nouns, verbs, adjectives, adverbs, and numerals.",buat sistem visual question answering bas web dukung ajar visual anak tk bahasa indonesia deep learning,iring pesat kembang teknologi indonesia gencar siap transformasi digital hadap ubah teknologi salah satu implementasi elearning sektor didik elearning terap ajar taman kanakkanak ajar visual bentuk ajar visual elearning bangun sistem visual question answering teliti bangun sistem visual question answering hasil sistem visual question answering ilmu patologi bahasa inggris dataset objek monas bahasa indonesia aju buat sistem visual question answering dataset nali anak tk bahasa indonesia dada teliti bantu tenaga didik giat ajar ajar interaktif elearning teliti model bootstrapping languageimage pretraining blip proses buat sistem visual question answering implementasi model no language left behind nllb inputoutput terjemah bahasa hasil implementasi model blip nllb hasil bangun sistem visual question answering bahasa indonesia dasar hasil uji kandung 6 jenis yatidak benda kerja sifat terang numeral sistem hasil jenis yatidak benda kerja terang nilai tepat yatidak 100 benda 100 kerja 100 terang 875along with the rapid development of technology indonesia is increasingly intensifying its digital transformation preparations to face the existing technological advancements with the rapid development of technology indonesia is increasingly intensifying its preparations for digital transformation to face technological changes one of these preparations involves the implementation of elearning across various sectors including education elearning has been applied in kindergarten education including visual learning visual learning in elearning can be achieved through the development of a visual question answering system several studies have been conducted on visual question answering systems and have successfully created such systems using pathology images in english and object datasets around monas national monument in indonesian therefore the author proposes the creation of a visual question answering system with a more general dataset that can be recognized by indonesianspeaking kindergarten children the purpose of this research is to assist educators in conducting more interactive elearning activities the research utilizes the bootstrapping languageimage pretraining blip model for the development of the visual question answering system and implements the no language left behind nllb model for translating the language used in the inputoutput questions the implementation results of both the blip and nllb models successfully build a visual question answering system in the indonesian language based on testing the system can provide accurate answers for yesno nouns verbs and adverbial questions with accuracy rates of 100 for yesno 100 for nouns 100 for verbs and 875 for adverbial questions all of which contain six types of answers yesno nouns verbs adjectives adverbs and numerals
Analisis Prediksi Faktor Intensitas Tegangan Pada Sambungan Tubular Jacket Platform Berbasis Surrogate Model.,"Hardian, Muhammad Akbar",http://repository.its.ac.id/98455/,"Berdasarkan data SKK migas pada tahun 2016, 54,65% anjungan lepas pantai di Indonesia telah berumur lebih dari 20 tahun. Struktur yang telah melebihi umur operasinya perlu ditinjau ulang dari segi kekuatan struktur apakah masih mampu untuk beroperasi. Dalam penelitian ini, penulis akan berfokus pada analisis prediksi faktor intensitas tegangan pada struktur jacket berkaki empat berbasis surrogate model. Faktor intensitas tegangan merupakan faktor yang menentukan kelelahan pada sambungan tubular dengan metode fracture mechanics. Dalam rangkat meningkatkan akurasi dan mengoptimalkan waktu analisis dikembangkan surrogate model dari analisis variasi retak yang didapat dengan metode elemen hingga. Metode analisis yang digunakan dalam penelitian ini meliputi analisis statis inplace untuk analisis tegangan struktur secara global, analisis lokal sambungan tubular kritis, analisis retak pada tubular dengan titik tegangan kritis tertinggi, dan pemodelan faktor intensitas tegangan berbasis surrogate model menggunakan machine learning model SVM berdasarkan variasi kedalaman retak dan panjang retak. Analisis retak menggunakan 30 variasi model retak yang berada pada tegangan maksimum di analisis lokal metode elemen hingga. Analisis lokal struktur berdasarkan hasil analisis statis inplace global struktur dengan sambungan kritisnya adalah sambungan tubular multiplanar DKT. Diperoleh tegangan von-mises tertinggi pada brace 5 dengan tegangan sebesar 327 MPa. Hasil surrogate model variasi model retak dengan algoritma RBF memberikan hasil prediksi dengan validasi R2 dengan variabel rasio (a/2c) sebesar 1 lalu dengan algoritma SVM memberikan hasil prediksi dengan validasi R2 dengan variabel rasio (a/2c) sebesar 0,99.=================================================================================================================================Based on SKK Migas data in 2016, 54.65% of offshore platforms in Indonesia were over 20 years old. Structures that have exceeded their operational life need to be reviewed in terms of their structural strength to determine if they are still capable of operating. In this study, the author will focus on predicting the stress intensity factor on a four-legged jacket structure based on a surrogate model. The stress intensity factor is a factor that determines fatigue in tubular connections using fracture mechanics methods. To improve accuracy and optimize analysis time, a surrogate model was developed from the analysis of crack variations obtained using the finite element method. The analysis methods used in this study include static analysis in-place for global structural stress analysis, local critical tubular connection analysis, crack analysis in tubular with the highest critical stress point, and modeling of stress intensity factors based on a surrogate model using a machine learning SVM model based on variations in crack depth and crack length. Crack analysis used 30 crack model variations located at maximum stress in the local analysis of the finite element method. Local structural analysis is based on the results of global in-place static analysis of the structure with its critical connection, which is the DKT multiplanar tubular connection. The highest von-Mises stress was obtained at brace 5 with a stress of 327 MPa. The surrogate model results of crack model variations with the RBF algorithm provided a prediction result with a validation R2 value of 1 for the ratio variable (a/2c), while the SVM algorithm provided a prediction result with a validation R2 value of 0.99 for the ratio variable (a/2c).",analisis prediksi faktor intensitas tegang sambung tubular jacket platform bas surrogate model,dasar data skk migas 2016 5465 anjung lepas pantai indonesia umur 20 struktur lebih umur operasi tinjau ulang segi kuat struktur operasi teliti tulis fokus analisis prediksi faktor intensitas tegang struktur jacket kak bas surrogate model faktor intensitas tegang faktor tentu lelah sambung tubular metode fracture mechanics rangkat tingkat akurasi optimal analisis kembang surrogate model analisis variasi retak metode elemen metode analisis teliti liput analisis statis inplace analisis tegang struktur global analisis lokal sambung tubular kritis analisis retak tubular titik tegang kritis tinggi model faktor intensitas tegang bas surrogate model machine learning model svm dasar variasi dalam retak retak analisis retak 30 variasi model retak tegang maksimum analisis lokal metode elemen analisis lokal struktur dasar hasil analisis statis inplace global struktur sambung kritis sambung tubular multiplanar dkt oleh tegang vonmises tinggi brace 5 tegang 327 mpa hasil surrogate model variasi model retak algoritma rbf hasil prediksi validasi r2 variabel rasio a2c 1 algoritma svm hasil prediksi validasi r2 variabel rasio a2c 099based on skk migas data in 2016 5465 of offshore platforms in indonesia were over 20 years old structures that have exceeded their operational life need to be reviewed in terms of their structural strength to determine if they are still capable of operating in this study the author will focus on predicting the stress intensity factor on a fourlegged jacket structure based on a surrogate model the stress intensity factor is a factor that determines fatigue in tubular connections using fracture mechanics methods to improve accuracy and optimize analysis time a surrogate model was developed from the analysis of crack variations obtained using the finite element method the analysis methods used in this study include static analysis inplace for global structural stress analysis local critical tubular connection analysis crack analysis in tubular with the highest critical stress point and modeling of stress intensity factors based on a surrogate model using a machine learning svm model based on variations in crack depth and crack length crack analysis used 30 crack model variations located at maximum stress in the local analysis of the finite element method local structural analysis is based on the results of global inplace static analysis of the structure with its critical connection which is the dkt multiplanar tubular connection the highest vonmises stress was obtained at brace 5 with a stress of 327 mpa the surrogate model results of crack model variations with the rbf algorithm provided a prediction result with a validation r2 value of 1 for the ratio variable a2c while the svm algorithm provided a prediction result with a validation r2 value of 099 for the ratio variable a2c
Surrogate-Assisted Model Untuk Prediksi Umur Kelelahan Pada Sambungan Tubular Multiplanar Jacket Platform Berbasis Mekanika Kepecahan.,"Hardian, Muhammad Akbar",http://repository.its.ac.id/108251/,"Berdasarkan informasi yang disampaikan dalam presentasi SKK Migas pada The 3rd Indo Decomm in Oil and Gas Conference, Indonesia telah mengoperasikan 613 unit anjungan lepas pantai terpancang sejak produksi komersial pertama di daerah lepas pantai. Dari total anjungan, sebanyak 54.65% telah berusia lebih dari 20 tahun, sementara 24.63% memiliki usia antara 16-20 tahun. Dengan perpanjangan waktu operasinya, integritas struktur platform tua tentu akan menurun. Salah satu akibatnya potensial terjadi kegagalan struktur karena beban siklis dengan adanya retak yang mayoritas bermula dari bagian las sambungan tubular pada strukturnya. Penelitian ini bertujuan untuk mengembangkan model baru dalam memprediksi umur lelah sambungan tubular multi-planar DKT berbasis Mekanika Kepecahan (Fracture Mechanics) dengan lebih efektif melalui surrogate model. Dengan menganalisis parameter geometri yang dapat mempengaruhi keretakan dan membangkitkan surrogate model yang lebih akurat untuk memprediksi umur kelelahan sambungan tubular multi-planar DKT kritis pada pembebanan aksial, IPB, OPB, dan gabungan. Analisis tersebut berhasil mendapatkan tegangan kritis yang terdapat pada brace 5. Umur lelah hingga kedalaman retak kritis juga didapatkan pada pembebanan aksial, IPB, OPB, dan gabungan untuk digunakan sebagai data training pada pembangkitan surrogate model dengan 2 variasi algoritma machine learning. Penelitian ini menyimpulkan bahwa algoritma radial basis function memberikan hasil yang lebih baik pada pembangkitan surrogate model daripada algoritma kriging. Hasil error yang diberikan pada algoritma radial basis function adalah 0.3%====================================================================================================================================Based on information presented in SKK Migas' presentation at The 3rd Indo Decomm in Oil and Gas Conference, Indonesia has operated 613 units of offshore platforms since the first commercial production in offshore areas. Of the total platforms, 54.65% are more than 20 years old, while 24.63% are between 16-20 years old. With the extension of its operation time, the structural integrity of the old platform will certainly decrease. One of the potential consequences is structural failure due to cyclical loading with cracks, the majority of which originate in the welds of tubular joints in the structure. This research aims to develop a new model to more effectively predict the fatigue life of DKT multi-planar tubular joints based on Fracture Mechanics through a surrogate model. By analysing geometry parameters that can affect cracking and generating a more accurate surrogate model to predict the fatigue life of critical DKT multi-planar tubular joints under axial, IPB, OPB and combined loading. The analysis successfully obtained the critical stress located at brace 5. The fatigue life to critical crack depth was also obtained under axial, IPB, OPB, and combined loading to be used as training data for surrogate model generation with 2 variations of machine learning algorithms. This study concluded that radial basis function algorithm gives better results in surrogate model generation than kriging algorithm. The error result given in the radial basis function algorithm is 0.3%.",surrogateassisted model prediksi umur lelah sambung tubular multiplanar jacket platform bas mekanika pecah,dasar informasi presentasi skk migas the 3rd indo decomm in oil and gas conference indonesia operasi 613 unit anjung lepas pantai pancang produksi komersial daerah lepas pantai total anjung 5465 usia 20 2463 milik usia 1620 panjang operasi integritas struktur platform tua turun salah akibat potensial gagal struktur beban siklis retak mayoritas las sambung tubular struktur teliti tuju kembang model prediksi umur lelah sambung tubular multiplanar dkt bas mekanika pecah fracture mechanics efektif surrogate model analis parameter geometri pengaruh kereta bangkit surrogate model akurat prediksi umur lelah sambung tubular multiplanar dkt kritis beban aksial ipb opb gabung analisis hasil tegang kritis brace 5 umur lelah dalam retak kritis dapat beban aksial ipb opb gabung data training bangkit surrogate model 2 variasi algoritma machine learning teliti simpul algoritma radial basis function hasil bangkit surrogate model algoritma kriging hasil error algoritma radial basis function 03based on information presented in skk migas presentation at the 3rd indo decomm in oil and gas conference indonesia has operated 613 units of offshore platforms since the first commercial production in offshore areas of the total platforms 5465 are more than 20 years old while 2463 are between 1620 years old with the extension of its operation time the structural integrity of the old platform will certainly decrease one of the potential consequences is structural failure due to cyclical loading with cracks the majority of which originate in the welds of tubular joints in the structure this research aims to develop a new model to more effectively predict the fatigue life of dkt multiplanar tubular joints based on fracture mechanics through a surrogate model by analysing geometry parameters that can affect cracking and generating a more accurate surrogate model to predict the fatigue life of critical dkt multiplanar tubular joints under axial ipb opb and combined loading the analysis successfully obtained the critical stress located at brace 5 the fatigue life to critical crack depth was also obtained under axial ipb opb and combined loading to be used as training data for surrogate model generation with 2 variations of machine learning algorithms this study concluded that radial basis function algorithm gives better results in surrogate model generation than kriging algorithm the error result given in the radial basis function algorithm is 03
"Perancangan Sistem Deteksi Keausan Pahat Pada Mesin Milling Menggunakan ""Cubic SVM"".","Hikmah, Zahra Putri Nurul",http://repository.its.ac.id/100911/,"Kerusakan suatu mesin dapat terjadi begitu saja tanpa timbulnya suatu indikasi tertentu. Sehingga dibutuhkan suatu sistem monitoring yang dapat digunakan untuk mendeteksi suatu anomali dalam proses permesinan. Deteksi anomali merupakan suatu proses untuk mengidentifikasikan suatu error atau peristiwa yang tidak terduga. Penelitian ini bertujuan untuk mengetahui sinyal vibrasi atau sinyal arus, sinyal yang paling tepat digunakan untuk mendeteksi keausan pahat pada mesin milling 3 axis Matsura 510 menggunakan model machine learning cubic SVM dan juga untuk mengetahui pengaruh penggunaan dekomposisi sinyal EMD terhadap hasil klasifikasi data yang dihasilkan. Penelitian dimulai dari pengambilan data untuk mendapatkan sinyal arus dan sinyal vibrasi kemudian masing-masing sinyal di-prepocessing. Lalu setelah itu sinyal diubah menjadi numerical features melalui proses features extraction. Numerical features yang sudah didapatkan kemudian diseleksi menggunakan ANOVA supaya menghasilkan hasil performance metrics yang baik. Sebelum features diklasifikasikan dengan model machine learning, maka diperlukan validasi model untuk menghindari overfitting dan underfitting. Setelah itu features dapat diklasifikasikan dengan menggunakan dua proses yaitu proses training dan proses testing sehingga didapatkan prediksi mengenai kondisi mesin. Berdasarkan penelitian yang telah dilakukan dapat disimpulkan bahwa ternyata sinyal vibrasi dalam domain frekuensi yang diolah tanpa menggunakan EMD dapat digunakan untuk mendeteksi keasuan pahat pada mesin milling 3 axis Matsura 510. Hal tersebut dapat dibuktikan dengan nilai precision dan recall yang dihasilkan dari proses training dan testing. Pada proses training didapatkan nilai precision sebesar 94,7% dan recall sebesar 84,7%. Kemudian pada proses testing didapatkan nilai precision sebesar 90,1% dan recall sebesar 90,1%. ==============================================================================================================================Damage to a machine can occur without any indication. Therefore require monitoring system can be used to detect an anomaly in the machining process. Anomaly detection is a process to identify an error or unexpected event. This research aims to find out between vibration signals and current signals, which signals are the best to detect tool wear on Matsura 510 3-axis milling machine using a cubic SVM machine learning algorithm. In addition, this research also aims to determine the effect of using EMD signal decomposition on the resulting data classification results. The research begins with data collection to obtain current signals and vibration signals, then each signal is preprocessed. Then after that, the signal is converted into numerical features through the features extraction process. Numerical features that have been obtained are then selected using ANOVA to produce good performance metrics. Before features are classified with a machine learning model, it is necessary to validate the model to avoid overfitting and underfitting. After that, the features can be classified using two processes, the training process and the testing process so that predictions about the condition of the machine can be obtained. Based on the research that has been done, it would be concluded that it turns out that the vibration signal processed in frequency domain without using EMD can be used to detect the acidity of the tool on the Matsura 510 3-axis milling machine. That could be proved by the precision and recall values produced in training and testing data. In the training process, the precision value having a percentage of 94,7% and 84,7%. Then in the testing process obtained precision value of 90,1% and recall of 90,1%.",ancang sistem deteksi aus pahat mesin milling cubic svm,rusa mesin timbul indikasi butuh sistem monitoring deteksi anomali proses mesin deteksi anomali proses identifikasi error peristiwa duga teliti tuju sinyal vibrasi sinyal arus sinyal deteksi aus pahat mesin milling 3 axis matsura 510 model machine learning cubic svm pengaruh guna dekomposisi sinyal emd hasil klasifikasi data hasil teliti ambil data sinyal arus sinyal vibrasi masingmasing sinyal diprepocessing sinyal ubah numerical features proses features extraction numerical features dapat seleksi anova hasil hasil performance metrics features klasifikasi model machine learning validasi model hindar overfitting underfitting features klasifikasi proses proses training proses testing dapat prediksi kondisi mesin dasar teliti simpul sinyal vibrasi domain frekuensi olah emd deteksi asu pahat mesin milling 3 axis matsura 510 bukti nilai precision recall hasil proses training testing proses training dapat nilai precision 947 recall 847 proses testing dapat nilai precision 901 recall 901 damage to a machine can occur without any indication therefore require monitoring system can be used to detect an anomaly in the machining process anomaly detection is a process to identify an error or unexpected event this research aims to find out between vibration signals and current signals which signals are the best to detect tool wear on matsura 510 3axis milling machine using a cubic svm machine learning algorithm in addition this research also aims to determine the effect of using emd signal decomposition on the resulting data classification results the research begins with data collection to obtain current signals and vibration signals then each signal is preprocessed then after that the signal is converted into numerical features through the features extraction process numerical features that have been obtained are then selected using anova to produce good performance metrics before features are classified with a machine learning model it is necessary to validate the model to avoid overfitting and underfitting after that the features can be classified using two processes the training process and the testing process so that predictions about the condition of the machine can be obtained based on the research that has been done it would be concluded that it turns out that the vibration signal processed in frequency domain without using emd can be used to detect the acidity of the tool on the matsura 510 3axis milling machine that could be proved by the precision and recall values produced in training and testing data in the training process the precision value having a percentage of 947 and 847 then in the testing process obtained precision value of 901 and recall of 901
Pengembangan Smart Meter untuk Mendukung Home Energy Management System (HEMS) Mempertimbangkan Kualitas Daya Peralatan Rumah.,"Ibrahim, Ditya Addo",http://repository.its.ac.id/87579/,"Pertumbuhan penduduk pada negara berkembang seperti Indonesia menyebabkan peningkatan kebutuhan energi menjadi tantangan yang harus dihadapi. Konsumsi listrik sektor rumah tangga menjadi salah satu faktor tingginya kenaikan beban listrik di mana diketahui sektor tersebut menghasilkan 30% kerugian dari energi terdistribusi. Sedangkan dalam pemenuhan energi listrik sebesar 88% suplai masih berasal dari energi fosil. Sehingga upaya konservasi energi perlu digiatkan terutama pada kelistrikan rumah tangga, salah satunya dengan konsep Home Energy Management System (HEMS) untuk mengoptimasi penggunaan listrik pada rumah. Pada penelitian tugas akhir ini dilakukan pengembangan pada sistem smart meter untuk monitoring konsumsi daya listrik rumah pendukung HEMS dengan Non-Intrusive Load Monitoring (NILM) untuk memantau penggunaan baik daya total dan per beban aktif dengan kualitas daya peralatan sebagai tambahan parameter identifikasi. Dengan adanya NILM maka sistem dapat mengidentifikasi jenis beban aktif rumah hanya menggunakan satu sensor pada saluran listrik utama sehingga proses monitoring menjadi lebih mudah serta memakan biaya dan energi yang lebih rendah. Proses identifikasi menggunakan model pelatihan dengan implementasi Artificial Neural Network (ANN) dalam mengolah data pengukuran untuk menentukan jenis beban yang sedang menyala. Hasil dari simulasi menunjukkan bahwa dengan konfigurasi 50 hidden neuron, pelatihan ANN dapat memperoleh akurasi dengan MAPE sebesar 2,201% dalam mengidentifikasi beban listrik.",kembang smart meter dukung home energy management system hems timbang kualitas daya alat rumah,tumbuh duduk negara kembang indonesia sebab tingkat butuh energi tantang hadap konsumsi listrik sektor rumah tangga salah faktor tinggi naik beban listrik sektor hasil 30 rugi energi distribusi penuh energi listrik 88 suplai asal energi fosil upaya konservasi energi giat listrik rumah tangga salah satu konsep home energy management system hems mengoptimasi guna listrik rumah teliti tugas kembang sistem smart meter monitoring konsumsi daya listrik rumah dukung hems nonintrusive load monitoring nilm pantau guna daya total beban aktif kualitas daya alat tambah parameter identifikasi nilm sistem identifikasi jenis beban aktif rumah sensor salur listrik utama proses monitoring mudah makan biaya energi rendah proses identifikasi model latih implementasi artificial neural network ann olah data ukur tentu jenis beban nyala hasil simulasi konfigurasi 50 hidden neuron latih ann oleh akurasi mape 2201 identifikasi beban listrik
"Implementasi Aplikasi Artificial Neural Network (ANN) Backpropagation untuk Prediksi Debit Harian pada Stasiun Pos Duga Air, DAS Serang-Lusi, Jawa Tengah.","Ilahi, Rizqi Noer",http://repository.its.ac.id/113000/,"Hubungan antara hujan dan limpasan sangat erat. Sebagian hujan yang turun dari permukaan bumi terserap ke dalam tanah yang memungkinkan terjadi infiltrasi, dan sebagian lainnya mengalir ke saluran kecil hingga mencapai aliran sungai. Di tempat ini, limpasan terjadi ketika daratan tergenang oleh air hingga dapat menyebabkan banjir. Adanya sistem analisis yang dapat memprediksi dengan baik diperlukan untuk mengatasi masalah yang ada. Dalam praktiknya, memilih model untuk menganalisis dan menilai sistem DAS sangat sulit, namun, ini tidak berarti bahwa model yang ada tidak baik, salah satu model yang tersedia adalah penggunaan Jaringan Syaraf Tiruan (JST) atau Artificial Neural Network (ANN). Studi ini menyelidiki hasil perhitungan debit pemodelan Artificial Neural Network yang dilakukan menggunakan Matlab dan Python. Tujuan dari Tugas Akhir ini adalah untuk menghasilkan debit pemodelan ANN yang optimal dari model arsitektur jaringan yang digunakan. Untuk masukan program ANN, digunakan data curah hujan, evapotranspirasi, dan koefisien aliran. Data hujan dilakukan Uji konsistensi kurva massa ganda untuk menguji konsisteni data curah hujan. Selanjutnya, diambil hujan rerata kawasan menggunakan Polygon Thiessen. Sementara untuk luaran debit pemodelan dari program ANN ini adalah data debit yang diambil dari stasiun pos duga air. Hasil penelitian menunjukkan bahwa dalam pemodelan debit menggunakan ANN metode backpropagation memiliki kinerja yang sangat baik dengan nilai mean square error (MSE) terbaik adalah 0,032 untuk training, sedangkan untuk testing memiliki nilai MSE 0,047. Nilai keandalan atau akurasi program ANN ini mencapai 98%, yang artinya program ANN ini layak dijadikan metode pendekatan debit lapangan.=================================================================================================================================The relationship between rain and runoff is very close. Some of the rain that falls from the earth's surface is absorbed into the ground, which allows infiltration to occur, and some of it flows into small channels until it reaches the flow of rivers. In this place, runoff occurs when the land is flooded by water so that it can cause flooding. The existence of an analysis system that can predict well is necessary to overcome existing problems. In practice, choosing a model to analyze and assess a watershed system is very difficult, however, this does not mean that the existing model is not good, one of the available models is the use of Artificial Neural Network (JST) or Artificial Neural Network (ANN). This study investigated the results of the calculation of the Artificial Neural Network modeling discharge  conducted using Matlab and Python. The purpose of this Final Project is to produce optimal ANN modeling discharge from the network architecture model used. For the input of the ANN program, rainfall, evapotranspiration, and flow coefficient data are used. Rainfall data was carried out Double mass curve consistency test to test the consistency of rainfall data. Next, the average rainfall of the area was taken using Thiessen's Polygon. Meanwhile, the modeling discharge output of the ANN program is discharge data taken from the suspected water post station. The results show that in the discharge modeling using ANN, the backpropagation  method has excellent performance with  the best mean square error (MSE) value of 0.032 for training, while for testing it has an MSE value of 0.047. The reliability or accuracy value of this ANN program reaches 98%, which means that this ANN program is worthy of being used as a field debit approach method.",implementasi aplikasi artificial neural network ann backpropagation prediksi debit hari stasiun pos duga air das seranglusi jawa,hubung hujan limpas erat hujan turun muka bumi serap tanah infiltrasi alir salur capai alir sungai limpas darat genang air sebab banjir sistem analisis prediksi atas praktik pilih model analis nilai sistem das sulit model salah model sedia guna jaring syaraf tiru jst artificial neural network ann studi selidik hasil hitung debit model artificial neural network matlab python tuju tugas hasil debit model ann optimal model arsitektur jaring masuk program ann data curah hujan evapotranspirasi koefisien alir data hujan uji konsistensi kurva massa ganda uji konsisten data curah hujan ambil hujan rerata kawasan polygon thiessen luar debit model program ann data debit ambil stasiun pos duga air hasil teliti model debit ann metode backpropagation milik kerja nilai mean square error mse baik 0032 training testing milik nilai mse 0047 nilai andal akurasi program ann capai 98 program ann layak jadi metode dekat debit lapanganthe relationship between rain and runoff is very close some of the rain that falls from the earths surface is absorbed into the ground which allows infiltration to occur and some of it flows into small channels until it reaches the flow of rivers in this place runoff occurs when the land is flooded by water so that it can cause flooding the existence of an analysis system that can predict well is necessary to overcome existing problems in practice choosing a model to analyze and assess a watershed system is very difficult however this does not mean that the existing model is not good one of the available models is the use of artificial neural network jst or artificial neural network ann this study investigated the results of the calculation of the artificial neural network modeling discharge conducted using matlab and python the purpose of this final project is to produce optimal ann modeling discharge from the network architecture model used for the input of the ann program rainfall evapotranspiration and flow coefficient data are used rainfall data was carried out double mass curve consistency test to test the consistency of rainfall data next the average rainfall of the area was taken using thiessens polygon meanwhile the modeling discharge output of the ann program is discharge data taken from the suspected water post station the results show that in the discharge modeling using ann the backpropagation method has excellent performance with the best mean square error mse value of 0032 for training while for testing it has an mse value of 0047 the reliability or accuracy value of this ann program reaches 98 which means that this ann program is worthy of being used as a field debit approach method
Klasifikasi Diagnosa Pasien Berdasarkan Rekam Medis Elektronik Menggunakan Text Mining Dan Support Vector Machine.,"Jamaluddin, M.",http://repository.its.ac.id/86313/,"Rekam Medis Elektronik (RME) adalah elemen penting dari teknologi informasi di bidang kesehatan. RME adalah catatan elektronik yang berisi informasi terkait kesehatan pasien yang dapat dibuat dan dikelola oleh dokter dan staf yang berwenang di organisasi pelayanan kesehatan. RME adalah kerangka kerja untuk menentukan diagnosis dan pengobatan kepada pasien. RME memiliki format teks bebas dan tidak terstruktur yang membuat lebih sulit untuk menggali informasi tersembunyi sebagai sistem pendukung keputusan. Dalam thesis ini, dilakukan penelitian untuk klasifikasi dari RME berbahasa Indonesia sebagai Clinical Decision Support System (CDSS) dalam mengklasifikasikan diagnosis pasien menggunakan Term Frequency-Inverse Document Frequency (Tf-Idf) untuk ekstraksi fitur dan Support Vector Machine (SVM) untuk metode klasifikasi. Diagnosa yang diklasifikasikan dalam thesis ini adalah tuberkulosis, kanker, diabetes mellitus, hipertensi, dan gagal ginjal yang memiliki angka prevalensi tinggi di Indonesia.Model dibangun dengan mempertimbangkan fungsi kernel SVM serta penggunaan stopword removal atau tanpa stopword removal. Akurasi tertinggi didapatkan pada kernel RBF menggunakan stopword removal dan model n-gram (1-3) dengan nilai akurasi 91,71%. Hasil penelitian menunjukkan bahwa metode Tf-Idf dan SVM dapat digunakan secara efektif untuk memprediksi diagnosis.=====================================================================================================Electronic Medical Record (EMR) is an important element of information technology in health sector. EMR is an electronic record containing health-related information on an patient that can be created and managed by authorized physician and staff in a health service organization. EMR is a framework for determining diagnosis and treatment. EMR has free text and unstructured format which makes it more difficult to extract the hidden information as a decision support system. This study performs classification from Indonesian EMR for clinical decision support system (CDSS) in classifying patient diagnosis using Term Frequency-Inverse Document Frequency (Tf-Idf) for feature extraction and Support Vector Machine (SVM) for classifier method. The focus diagnoses classified in this paper are tuberculosis, cancer, diabetes mellitus, hypertension, and kidney failure which have high prevalence rates in Indonesia. The model is built by considering the kernel function and the use of stopword removal or without stopword removal. The highest accuracy is obtained in the RBF kernel with stopword removal and n-gram (1-3) by an accuracy value of 91.71%. The result showed that Tf-Idf and SVM method could be used effectively to predict diagnosis.",klasifikasi diagnosa pasien dasar rekam medis elektronik text mining support vector machine,rekam medis elektronik rme elemen teknologi informasi bidang sehat rme catat elektronik isi informasi kait sehat pasien kelola dokter staf wenang organisasi layan sehat rme kerangka kerja tentu diagnosis obat pasien rme milik format teks bebas struktur sulit gali informasi sembunyi sistem dukung putus thesis teliti klasifikasi rme bahasa indonesia clinical decision support system cdss klasifikasi diagnosis pasien term frequencyinverse document frequency tfidf ekstraksi fitur support vector machine svm metode klasifikasi diagnosa klasifikasi thesis tuberkulosis kanker diabetes mellitus hipertensi gagal ginjal milik angka prevalensi indonesiamodel bangun timbang fungsi kernel svm guna stopword removal stopword removal akurasi tinggi dapat kernel rbf stopword removal model ngram 13 nilai akurasi 9171 hasil teliti metode tfidf svm efektif prediksi diagnosiselectronic medical record emr is an important element of information technology in health sector emr is an electronic record containing healthrelated information on an patient that can be created and managed by authorized physician and staff in a health service organization emr is a framework for determining diagnosis and treatment emr has free text and unstructured format which makes it more difficult to extract the hidden information as a decision support system this study performs classification from indonesian emr for clinical decision support system cdss in classifying patient diagnosis using term frequencyinverse document frequency tfidf for feature extraction and support vector machine svm for classifier method the focus diagnoses classified in this paper are tuberculosis cancer diabetes mellitus hypertension and kidney failure which have high prevalence rates in indonesia the model is built by considering the kernel function and the use of stopword removal or without stopword removal the highest accuracy is obtained in the rbf kernel with stopword removal and ngram 13 by an accuracy value of 9171 the result showed that tfidf and svm method could be used effectively to predict diagnosis
Analisis Modifikasi Algoritma YOLO dengan Implementasi Convolutional Block Attention Module (CBAM) terhadap Performa Deteksi Penyu di Lingkungan Bawah Laut.,"Juliantono, Fadly Rachman Drajad",http://repository.its.ac.id/112272/,"Eksplorasi biota laut di seluruh dunia, termasuk Indonesia, memainkan peran penting dalam memahami keanekaragaman hayati dan ekosistem bawah air. Indonesia, bagian dari segitiga karang dunia, memiliki keragaman spesies yang luar biasa, namun penelitian terhadap potensi ini masih terbatas. Penyu, reptil laut yang telah ada selama jutaan tahun, sering menjadi daya tarik wisata utama dan memainkan peran penting dalam ekosistem laut. Konservasi penyu menjadi perhatian penting karena ancaman dari aktivitas manusia dan perubahan iklim. Dengan berkembangnya modernisasi, sektor pariwisata maritim di Indonesia tumbuh pesat, menempatkan tekanan pada ekosistem laut dan menegaskan kebutuhan akan manajemen dan pemantauan yang berkelanjutan. Sistem deteksi objek di lingkungan laut menghadapi tantangan seperti air keruh dan variasi pencahayaan yang mengurangi efektivitas teknologi tradisional. Oleh karena itu, pengembangan model berbasis Deep Learning seperti You Only Look Once (YOLO) menjadi sangat relevan. Penelitian ini mengeksplorasi penerapan YOLO yang dilengkapi dengan Convolutional Block Attention Module (CBAM) dalam pengaruh performa deteksi penyu di lingkungan bawah laut dan bertujuan untuk menguji akurasi dan kinerja model deteksi pada kamera bawah laut yang menggunakan mesin Jetson Nano Dev Kit. Model dengan performa tingkat akurasi tinggi didapatkan oleh YOLOv8n dengan CBAM dengan hasil mAP@0,5: 0,95 senilai 57,1% dan beban Param 8.0M serta FLOPs 8.3. Nilai ini naik sebesar 4% dibandingkan dengan YOLOv8n tanpa CBAM. Dengan performa yang dimiliki, model yang dideploy dapat mendeteksi objek secara real-time dan mendapatkan hingga 10 fps. Dengan pembuatan model ini, dapat digunakan sebagai groundtruth dari sistem deteksi penyu secara akurat dan dapat dikembangkan dengan fitur klasifikasi untuk di masa yang akan datang.===============================================================================================Exploration of marine biota worldwide, including Indonesia, plays a crucial role in understanding biodiversity and underwater ecosystems. Indonesia, being part of the world's coral triangle, boasts an extraordinary diversity of species, yet research into this potential remains limited. Sea turtles, marine reptiles that have existed for millions of years, often become major tourist attractions and play a vital role in marine ecosystems. Turtle conservation is a pressing concern due to threats from human activities and climate change. As modernization progresses, the maritime tourism sector in Indonesia is rapidly growing, putting pressure on marine ecosystems and underscoring the need for ongoing management and monitoring. Object detection systems in marine environments face challenges such as turbid water and varying lighting conditions that reduce the effectiveness of traditional technologies. Therefore, the development of Deep Learning-based models like You Only Look Once (YOLO) becomes highly relevant. This research explores the application of YOLO equipped with the Convolutional Block Attention Module (CBAM) to study its impact on the performance of turtle detection in underwater environments and aims to test the accuracy and performance of the detection model on underwater cameras using the Jetson Nano Dev Kit. The model enhanced by YOLOv8n with CBAM achieved high-performance metrics with a mean Average Precision (mAP) @ 0,5 of 57.1% and a parameter load of 8.0M and FLOPs of 8.3, showing a 4% improvement compared to YOLOv8n without CBAM. With its current capabilities, the deployed model can detect objects in real-time at a rate of 10 fps. With the creation of this model, it can serve as the ground truth for accurately detecting turtles and can be further developed with classification features for future applications.",analisis modifikasi algoritma yolo implementasi convolutional block attention module cbam performa deteksi penyu lingkung laut,eksplorasi biota laut dunia indonesia main peran paham keanekaragaman hayati ekosistem air indonesia segitiga karang dunia milik ragam spesies teliti potensi batas penyu reptil laut juta daya tarik wisata utama main peran ekosistem laut konservasi penyu perhati ancam aktivitas manusia ubah iklim kembang modernisasi sektor pariwisata maritim indonesia tumbuh pesat tempat tekan ekosistem laut butuh manajemen pantau lanjut sistem deteksi objek lingkung laut hadap tantang air keruh variasi cahaya kurang efektivitas teknologi tradisional kembang model bas deep learning you only look once yolo relevan teliti eksplorasi terap yolo lengkap convolutional block attention module cbam pengaruh performa deteksi penyu lingkung laut tuju uji akurasi kerja model deteksi kamera laut mesin jetson nano dev kit model performa tingkat akurasi dapat yolov8n cbam hasil map05 095 nila 571 beban param 80m flops 83 nilai 4 banding yolov8n cbam performa milik model dideploy deteksi objek realtime 10 fps buat model groundtruth sistem deteksi penyu akurat kembang fitur klasifikasi datangexploration of marine biota worldwide including indonesia plays a crucial role in understanding biodiversity and underwater ecosystems indonesia being part of the worlds coral triangle boasts an extraordinary diversity of species yet research into this potential remains limited sea turtles marine reptiles that have existed for millions of years often become major tourist attractions and play a vital role in marine ecosystems turtle conservation is a pressing concern due to threats from human activities and climate change as modernization progresses the maritime tourism sector in indonesia is rapidly growing putting pressure on marine ecosystems and underscoring the need for ongoing management and monitoring object detection systems in marine environments face challenges such as turbid water and varying lighting conditions that reduce the effectiveness of traditional technologies therefore the development of deep learningbased models like you only look once yolo becomes highly relevant this research explores the application of yolo equipped with the convolutional block attention module cbam to study its impact on the performance of turtle detection in underwater environments and aims to test the accuracy and performance of the detection model on underwater cameras using the jetson nano dev kit the model enhanced by yolov8n with cbam achieved highperformance metrics with a mean average precision map 05 of 571 and a parameter load of 80m and flops of 83 showing a 4 improvement compared to yolov8n without cbam with its current capabilities the deployed model can detect objects in realtime at a rate of 10 fps with the creation of this model it can serve as the ground truth for accurately detecting turtles and can be further developed with classification features for future applications
Klasifikasi Kanker Kulit Dari Citra Dermatoskopi Berbasis Convolutional Neural Network U-Net Dan Support Vector Machine.,"Junior, Amanda Sharon Purwanti",http://repository.its.ac.id/111710/,"Global Burden of Cancer Study (Globocan) dari World Health Organization (WHO), mencatat jumlah kasus kanker di Indonesia pada tahun 2020 mencapai 396.914 kasus, sementara total kematian akibat kanker mencapai 234.511 kasus. 5,9 – 7,8% dari total kasus kanker yang terjadi merupakan kanker kulit.  Tingkat kesembuhan dari kanker kulit dapat meningkat hingga 90% jika ditemukan sejak dini, namun deteksi dini dinilai cukup kompleks  dan cenderung subjektif sehingga diagnosis kanker kulit ini seringkali mengalami keterlambatan. Maka dari itu, mulai dikembangkan Computer-Aided Diagnostic (CAD), sebuah sistem diagnosis otomatis yang dirancang dengan tujuan meningkatkan akurasi diagnosis. Diagnosis otomatis pada citra dermatoskopi masih terhambat oleh variasi kompleks dalam tampilan. Dalam penelitian ini, diusulkan sistem yang terdiri dari preprocessing citra yang dilakukan untuk meningkatkan kualitas citra, segmentasi citra menggunakan U-Net yang dilakukan untuk memisahkan lesi dari latar citra, ekstraksi fitur menggunakan metode GLCM untuk menghitung kontras, energi, homogeneity, dan entropi citra pada sudut 0⁰, 45⁰, 90⁰, dan 135⁰ serta metode ABCD yang mengambil beberapa fitur bentuk dan warna pada citra yaitu asimetri(A), tepian atau border (B), warna atau colour (C), dan diameter(D). Terakhir dilakukan klasifikasi multilabel menggunakan Support Vector Machine dengan pendekatan One-Vs-Rest. Model dengan hasil terbaik dalam penelitian didapatkan dengan metode penyeimbangan data SMOTEENN yang merupakan gabungan dari metode SMOTE (Synthetic Minority Over-sampling Technique) dan ENN (Edited Nearest Neighbors) dengan penggunaan kernel Radial Basis Function (RBF) parameter C dan Gamma sebesar 1000 dan 0,1 dengan memakai 21 fitur. Hasil yang didapatkan dari model ini adalah nilai akurasi, presisi, sensitivitas, spesifisitas, dan MCC (Matthews Correlation Coefficient) sebesar 95,25%, 95,25%, 95,24%, 99,02%, dan 0,94.============================================================The Global Burden of Cancer Study (Globocan) by the World Health Organization (WHO) reported that the number of cancer cases in Indonesia in 2020 reached 396,914, with total cancer-related deaths reaching 234,511 cases. Skin cancer accounted for 5.9 - 7.8% of the total cancer cases. The cure rate can increase up to 90% with early detection, but early detection is considered complex and subjective, often leading to delayed skin cancer diagnosis. Consequently, a Computer-Aided Diagnostic (CAD) system, designed to enhance diagnostic accuracy, has been developed. Automated diagnosis of dermatoscopic images faces challenges due to complex variations in appearance. In this study, a system is proposed consisting of image preprocessing which is done to improve image quality, image segmentation using U-Net which is done to separate the lesion from the image background, feature extraction using the GLCM method to calculate contrast, energy, homogeneity, and entropy of the image at angles of 0⁰, 45⁰, 90⁰, and 135⁰ and the ABCD method which takes several shape and color features in the image, namely asymmetry (A), edge or border (B), color or color (C), and diameter (D). Finally, multilabel classification is performed using Support Vector Machine with One-Vs-Rest approach. The model with the best results in the study was obtained with the SMOTEENN data balancing method which is a combination of the SMOTE (Synthetic Minority Over-sampling Technique) and ENN (Edited Nearest Neighbors) methods with the use of Radial Basis Function (RBF) kernels with C and Gamma parameters of 1000 and 0,1 using 21 features. The results obtained from this model are the values of accuracy, precision, sensitivity, specificity, and MCC (Matthews Correlation Coefficient) of 95,25%, 95,25%, 95,24%, 99,02%, and 0,94.",klasifikasi kanker kulit citra dermatoskopi bas convolutional neural network unet support vector machine,global burden of cancer study globocan world health organization who catat kanker indonesia 2020 capai 396914 total mati akibat kanker capai 234511 59  78 total kanker kanker kulit tingkat sembuh kanker kulit tingkat 90 temu deteksi nilai kompleks cenderung subjektif diagnosis kanker kulit seringkali alami lambat kembang computeraided diagnostic cad sistem diagnosis otomatis rancang tuju tingkat akurasi diagnosis diagnosis otomatis citra dermatoskopi hambat variasi kompleks tampil teliti usul sistem preprocessing citra tingkat kualitas citra segmentasi citra unet pisah lesi latar citra ekstraksi fitur metode glcm hitung kontras energi homogeneity entropi citra sudut 0 45 90 135 metode abcd ambil fitur bentuk warna citra asimetria tepi border b warna colour c diameterd klasifikasi multilabel support vector machine dekat onevsrest model hasil baik teliti dapat metode imbang data smoteenn gabung metode smote synthetic minority oversampling technique enn edited nearest neighbors guna kernel radial basis function rbf parameter c gamma 1000 01 pakai 21 fitur hasil dapat model nilai akurasi presisi sensitivitas spesifisitas mcc matthews correlation coefficient 9525 9525 9524 9902 094the global burden of cancer study globocan by the world health organization who reported that the number of cancer cases in indonesia in 2020 reached 396914 with total cancerrelated deaths reaching 234511 cases skin cancer accounted for 59 78 of the total cancer cases the cure rate can increase up to 90 with early detection but early detection is considered complex and subjective often leading to delayed skin cancer diagnosis consequently a computeraided diagnostic cad system designed to enhance diagnostic accuracy has been developed automated diagnosis of dermatoscopic images faces challenges due to complex variations in appearance in this study a system is proposed consisting of image preprocessing which is done to improve image quality image segmentation using unet which is done to separate the lesion from the image background feature extraction using the glcm method to calculate contrast energy homogeneity and entropy of the image at angles of 0 45 90 and 135 and the abcd method which takes several shape and color features in the image namely asymmetry a edge or border b color or color c and diameter d finally multilabel classification is performed using support vector machine with onevsrest approach the model with the best results in the study was obtained with the smoteenn data balancing method which is a combination of the smote synthetic minority oversampling technique and enn edited nearest neighbors methods with the use of radial basis function rbf kernels with c and gamma parameters of 1000 and 01 using 21 features the results obtained from this model are the values of accuracy precision sensitivity specificity and mcc matthews correlation coefficient of 9525 9525 9524 9902 and 094
Prediksi Tingkat Peringatan Kebakaran Semak di Perth Australia Barat menggunakan Metode Support Vector Machine dan Random Forest.,"Kanedi, Fidela Jovita",http://repository.its.ac.id/116645/,"Australia mengalami peningkatan cuaca ekstrem akibat suhu lebih tinggi dan kekeringan yang parah dalam beberapa dekade terakhir. Pada musim semi 2023, bagian barat daya Australia Barat mengalami suhu maksimum bulanan jauh di atas rata-rata untuk Agustus, September, dan Oktober, mencatat suhu terpanas sejak 1910 dan termasuk dalam 10% teratas tahun-tahun paling panas yang tercatat. Perth, ibu kota Australia Barat, adalah kota keempat terpadat di Australia pada 2020 dengan tingkat rawan kebakaran semak mencapai 90%, yang menjadi masalah serius karena populasi yang padat. Perubahan iklim meningkatkan frekuensi dan intensitas cuaca ekstrem seperti gelombang panas lebih panjang dan kekeringan lebih parah. Untuk meningkatkan respons terhadap kebakaran semak di Perth, pendekatan prediktif sangat penting. Prediksi yang akurat tentang potensi kebakaran membantu pihak berwenang mengalokasikan sumber daya secara efisien dan merencanakan strategi pemadaman yang tepat. Tugas Akhir ini bertujuan memprediksi tingkat peringatan kebakaran semak di Perth menggunakan metode Support Vector Machine (SVM) dan Random Forest. Data dikumpulkan melalui teknik data scraping dari laman resmi Biro Meteorologi Australia Barat, diproses, dianalisis, dan digunakan untuk melatih model. Model terbaik dari Random Forest dan SVM menggunakan proporsi data latih sebesar 80%, data uji sebesar 20%, dan sembilan fitur terbaik. Model Random Forest mampu menghasilkan akurasi 93,93% dan F1-score 93,77%, sedangkan Model SVM mampu menghasilkan akurasi 91,5% dan F1-score 91,5%. Model yang dikembangkan diharapkan membantu pemerintah meminimalisir kebakaran semak di masa depan. =================================================================================================================================Australia has experienced increased extreme weather due to higher temperatures and severe droughts in recent decades. In the spring of 2023, the southwest part of Western Australia saw monthly maximum temperatures well above average for August, September, and October, recording the hottest temperatures since 1910 and ranking among the top 10% of the hottest years on record. Perth, the capital of Western Australia, was the fourth most populous city in Australia in 2020 with a bushfire vulnerability rate reaching 90%, posing a serious issue due to its dense population. Climate change is amplifying the frequency and intensity of extreme weather events such as prolonged heatwaves and more severe droughts. To enhance the response to bushfires in Perth, predictive approaches are crucial. Accurate predictions of fire potential assist authorities in allocating resources efficiently and planning appropriate firefighting strategies. This research aims to predict bushfire alert levels in Perth using Support Vector Machine (SVM) and Random Forest methods. Data was collected through web scraping techniques from the official website of the Bureau of Meteorology Western Australia, processed, analyzed, and used to train the models. The best model of Random Forest and SVM used a proportion of training data of 80%, test data of 20%, and nine best features. The Random Forest model was able to produce an accuracy of 93.93% and an F1-score of 93.77%, while the SVM model was able to produce an accuracy of 91.5% and an F1-score of 91.5%. The developed model is expected to provide insights that can be utilized by relevant government authorities to reduce the incidence of bushfires.",prediksi tingkat ingat bakar semak perth australia barat metode support vector machine random forest,australia alami tingkat cuaca ekstrem akibat suhu kering parah dekade musim semi 2023 barat daya australia barat alami suhu maksimum bulan ratarata agustus september oktober catat suhu panas 1910 10 atas tahuntahun panas catat perth kota australia barat kota empat padat australia 2020 tingkat rawan bakar semak capai 90 serius populasi padat ubah iklim tingkat frekuensi intensitas cuaca ekstrem gelombang panas kering parah tingkat respons bakar semak perth dekat prediktif prediksi akurat potensi bakar bantu wenang alokasi sumber daya efisien rencana strategi madam tugas tuju prediksi tingkat ingat bakar semak perth metode support vector machine svm random forest data kumpul teknik data scraping laman resmi biro meteorologi australia barat proses analis latih model model baik random forest svm proporsi data latih 80 data uji 20 sembilan fitur baik model random forest hasil akurasi 9393 f1score 9377 model svm hasil akurasi 915 f1score 915 model kembang harap bantu perintah meminimalisir bakar semak australia has experienced increased extreme weather due to higher temperatures and severe droughts in recent decades in the spring of 2023 the southwest part of western australia saw monthly maximum temperatures well above average for august september and october recording the hottest temperatures since 1910 and ranking among the top 10 of the hottest years on record perth the capital of western australia was the fourth most populous city in australia in 2020 with a bushfire vulnerability rate reaching 90 posing a serious issue due to its dense population climate change is amplifying the frequency and intensity of extreme weather events such as prolonged heatwaves and more severe droughts to enhance the response to bushfires in perth predictive approaches are crucial accurate predictions of fire potential assist authorities in allocating resources efficiently and planning appropriate firefighting strategies this research aims to predict bushfire alert levels in perth using support vector machine svm and random forest methods data was collected through web scraping techniques from the official website of the bureau of meteorology western australia processed analyzed and used to train the models the best model of random forest and svm used a proportion of training data of 80 test data of 20 and nine best features the random forest model was able to produce an accuracy of 9393 and an f1score of 9377 while the svm model was able to produce an accuracy of 915 and an f1score of 915 the developed model is expected to provide insights that can be utilized by relevant government authorities to reduce the incidence of bushfires
Perancangan Model untuk Prediksi Potensi Churn pada Debitur KPR dengan Regresi Logistik.,"Kasidi, Josua Christanto",http://repository.its.ac.id/92487/,"Kredit Kepemilikan Rumah (KPR) merupakan sistem pembiayaan dimana perbankan memberikan pinjaman kepada nasabah untuk mendapatkan rumah, dan melakukan pelunasan dalam waktu yang ditentukan. Oleh sebab itu, dalam persaingan bank di Indonesia, baik bank pemerintah maupun swasta kini berusaha untuk menawarkan program KPR kepada nasabah yang bertujuan agar nasabah merasa puas dengan pelayanan perbankan tersebut. Seiring dengan perjalanan umur KPR debitur, peristiwa churn customers (pelanggan yang meninggalkan perusahaan) dapat menjadi hal yang berdampak bagi pertumbuhan portfolio KPR serta membuat turunnya hubungan antara bank dengan nasabah.Hingga kini, salah satu bank yang terus berusaha untuk mengatasi permasalahan churn customers adalah Bank Mandiri. Namun dalam menjawab tantangan tersebut terdapat beberapa permasalahan yang menjadi halangan untuk dapat menyelesaikannya. Salah satu permasalahan tersebut adalah kurangnya informasi mengenai faktor yang mempengaruhi churn customers akibat analisis yang terbatas karena jumlah perbandingan populasi yang tidak seimbang.. Oleh sebab itu, tujuan dari penelitian ini adalah untuk membuat model prediktif yang mampu melakukan klasifikasi terhadap nasabah churn pada produk KPR agar Bank Mandiri dapat melakukan retensi sedini mungkin.Proses yang dilakukan untuk dapat mencapai tujuan tersebut dapat dimulai dengan mengelompokan kelompok nasabah menjadi data biner, dimana akan terdapat nasabah churn dan nasabah loyal. Kemudian penelitian dilanjutkan dengan mengumpulkan faktor-faktor yang terduga mempengaruhi nasabah churn, antara lain Recency, Frequency, dan Monetary (RFM), saldo tabungan, penghasilan, tagihan, Debt Burden Ratio (DBR), usia, rate, dan Debt Equity Ratio (DER), dan sisa plafon. Data yang digunakan pada penelitian ini adalah data sejarah transaksi, dana, dan kredit nasabah yang dimulai pada tahun 2019 – Mei 2021 yang terdiri dari 50,000 nasabah KPR. Data yang diperoleh akan dilanjutkan dengan melakukan pemodelan menggunakan regresi logistik biner. Untuk hasil pengujian, model yang digunakan akan diuji menggunakan nilai Receiver Operating Characteristic (ROC) dan Area Under Curve (AUC) sebagai nilai kelayakan dalam pengujian model data. Hasil akhir dari model ini diperoleh 7 variabel yang berpengaruh terhadap model disertai dengan nlai AUC dari logistik biner original sebesar 0.68 dan logistik biner SMOTE sebesar 0.72.================================================================================================A mortgage is a loan or financing system whereas banks provide loans to customers to get houses and make repayments within a specified time. Therefore, in banking competition in Indonesia, both state and private banks are now trying to offer mortgage to customers so that customers feel satisfied with banking services. The more customers who take mortgages will certainly have an impact on the quality of a bank's mortgage portfolio. Along with the age of mortgage loan, churn customers can have an impact on the growth of the mortgage portfolio and reduce the relationship between the bank and the customer.	Until now, one of the banks that continues to try to overcome the problem of churn customers is Bank Mandiri. However, in responding to these challenges, there are several problems that become obstacles to solve them. The lack of information about factor that affect churn customers still limited due to lack of information in unbalanced population. As a result, it will have an impact on mitigation actions that can be taken by banks before customer’s churn. Therefore, the purpose of this study is to create a predictive model that is able to classify churn customers on mortgage products so that Bank Mandiri can do retention just in time.	The process carried out to achieve this goal can be started by grouping customer groups into binary data, where there will be churn customers and loyal customers. Then the research continued by collecting factors that were suspected of influencing churn customers, including Recency, Frequency, and Monetary (RFM), savings balances, income, bills, Debt Burden Ratio (DBR), age, rate, Debt Equity Ratio (DER) and outstanding amount. The data used in this study is transaction history data, funds, and customer credit starting in 2019 – May 2021, consisting of 50,000 mortgage customers. The data obtained will be continued by modeling using binary logistic regression algorithm. For model validation, the model used will be tested using the Receiver Operating Characteristic (ROC) and Area Under Curve (AUC) values as the value of the feasibility of testing the data model. Then from the test results will be obtained a model to look for opportunities or predictive value and identification of the significant parameters that influence it based on the value of the important features. The final result of this model obtained 7 variabels that affect the model accompanied by the AUC value of the original binary logistic of 0.68 and the SMOTE binary logistic of 0.72.",ancang model prediksi potensi churn debitur kpr regresi logistik,kredit milik rumah kpr sistem biaya mana perban pinjam nasabah rumah lunas tentu saing bank indonesia bank perintah swasta usaha tawar program kpr nasabah tuju nasabah puas layan perban iring jalan umur kpr debitur peristiwa churn customers langgan tinggal usaha dampak tumbuh portfolio kpr turun hubung bank nasabahhingga salah bank usaha atas masalah churn customers bank mandiri tantang masalah halang selesai salah masalah kurang informasi faktor pengaruh churn customers akibat analisis batas banding populasi imbang tuju teliti model prediktif klasifikasi nasabah churn produk kpr bank mandiri retensi din mungkinproses capai tuju kelompok kelompok nasabah data biner mana nasabah churn nasabah loyal teliti lanjut kumpul faktorfaktor duga pengaruh nasabah churn recency frequency monetary rfm saldo tabung hasil tagih debt burden ratio dbr usia rate debt equity ratio der sisa plafon data teliti data sejarah transaksi dana kredit nasabah 2019  mei 2021 50000 nasabah kpr data oleh lanjut model regresi logistik biner hasil uji model uji nilai receiver operating characteristic roc area under curve auc nilai layak uji model data hasil model oleh 7 variabel pengaruh model serta nlai auc logistik biner original 068 logistik biner smote 072a mortgage is a loan or financing system whereas banks provide loans to customers to get houses and make repayments within a specified time therefore in banking competition in indonesia both state and private banks are now trying to offer mortgage to customers so that customers feel satisfied with banking services the more customers who take mortgages will certainly have an impact on the quality of a banks mortgage portfolio along with the age of mortgage loan churn customers can have an impact on the growth of the mortgage portfolio and reduce the relationship between the bank and the customer until now one of the banks that continues to try to overcome the problem of churn customers is bank mandiri however in responding to these challenges there are several problems that become obstacles to solve them the lack of information about factor that affect churn customers still limited due to lack of information in unbalanced population as a result it will have an impact on mitigation actions that can be taken by banks before customer  s churn therefore the purpose of this study is to create a predictive model that is able to classify churn customers on mortgage products so that bank mandiri can do retention just in time the process carried out to achieve this goal can be started by grouping customer groups into binary data where there will be churn customers and loyal customers then the research continued by collecting factors that were suspected of influencing churn customers including recency frequency and monetary rfm savings balances income bills debt burden ratio dbr age rate debt equity ratio der and outstanding amount the data used in this study is transaction history data funds and customer credit starting in 2019  may 2021 consisting of 50000 mortgage customers the data obtained will be continued by modeling using binary logistic regression algorithm for model validation the model used will be tested using the receiver operating characteristic roc and area under curve auc values as the value of the feasibility of testing the data model then from the test results will be obtained a model to look for opportunities or predictive value and identification of the significant parameters that influence it based on the value of the important features the final result of this model obtained 7 variabels that affect the model accompanied by the auc value of the original binary logistic of 068 and the smote binary logistic of 072
Rancang Bangun Plugin Ekstraksi Materi Belajar Berdasarkan Materi Prasyarat pada LMS Moodle.,"Khairunnisa, Aprilia",http://repository.its.ac.id/78014/,"Saat ini banyak instansi pendidikan yang melakukan sistem pembelajaran menggunakan e-learning, begitu juga dengan Departemen Informatika Institut Teknologi Sepuluh Nopember (ITS). Proses pembelajaran menggunakan e-learning memiliki banyak manfaat salah satunya adalah memungkinkan mahasiswa untuk dapat belajar secara mandiri. Saat proses belajar mandiri, mahasiswa dapat menentukan sendiri mata kuliah apa yang ingin dipelajari. Dalam suatu mata kuliah terdapat mata kuliah prasyarat yang harus dipenuhi untuk dapat melanjutkan ke mata kuliah berikutnya. Mata kuliah prasyarat sangat penting untuk mengetahui gambaran materi apa saja yang akan dipelajari dalam mata kuliah tertentu. Namun pada saat ini sistem pembelajaran berbasis e-learning seperti Moodle, belum memberikan fitur untuk dapat mengetahui mata kuliah prasyarat dari sebuah mata kuliah. Selain itu, mata kuliah prasyarat seringkali dicantumkan dalam deskripsi mata kuliah. Hal ini dapat dimanfaatkan untuk mengetahui mata kuliah prasyarat secara lebih mudah.Untuk menentukan mata kuliah prasyarat dari suatu deskripsi diperlukan ekstraksi untuk mendeteksi entitas mata kuliah. Named Entity Recognition (NER) dapat digunakan sebagai solusi untuk melakukan ekstraksi entitas kata. Proses ekstraksi diawali dengan membuat model NER berbahasa Indonesia dengan menggunakan SpaCy dan alat bantu anotasi Prodigy. Selanjutnya hasil anotasi akan diintegrasikan kedalam plugin moodle. Plugin yang akan dibangun bertipe block, dimana plugin ini menampilkan data mata kuliah berserta mata kuliah prasyarat.Maka dari itu, pembuatan plugin ekstraksi materi belajar berdasarkan materi prasyarat pada LMS (Learning Management System) Moodle ini diusulkan sebagai solusi dari permasalahan diatas. Plugin ini dikembangkan melalui Moodle dikarenakan Moodle merupakan salah satu LMS berbasis web yang banyak digunakan pada e-learning. Dengan adanya plugin ini, pengguna yaitu mahasiswa maupun tenaga pengajar dapat melihat mata kuliah prasyarat dari suatu mata kuliah dengan mudah.=========================================================At present many of educational institutions are conducting learning system using e-learning based, as well as in Information Departement Sepuluh Nopember Institute of Technology (ITS). The learning process of e-learning based has many benefits, one of them is for students to be able to learn independently. In the process of independent learning, students can determine their own subjects what they what to learn. In a course, the are certainly prerequisite courses that must be finished to be able to proceed to the next course. The prerequisite courses are very important to know what material will be studied in certain course. But at this time learning sistem based of e-learning such as Moodle, have not provided features to be able to know the prerequisite courses from a course. Beside that, course prerequisite are often indicated in course description. This can be used to find out what is the course prerequisite easily.To determine the prerequisite courses from a description, extraction is needed to detect entity subjects. Named Entity Recognition (NER) can be used as a solution for doing extraction word entities. The extraction process begins by creating an Indonesan-language NER model using SpaCy and Prodigy annotation tools. Then the annotation results will be integrated into moodle plugin. Plugin that will be built are block type, where the plugin will display course data along with prerequisite courses.Therefore, the creation of a learning material extraction plugin based on the prerequisite material on the Moodle LMS (Learning Management System) is proposed as a solution to the above problem. This plugin will be developed through Moodle because Moodle is one of the web-based LMS that is widely used in e-learning system. With this plugin, users which are students and teachers, can see prerequisite courses from a subject easily.",rancang bangun plugin ekstraksi materi ajar dasar materi prasyarat lms moodle,instansi didik sistem ajar elearning departemen informatika institut teknologi puluh nopember its proses ajar elearning milik manfaat salah satu mahasiswa ajar mandiri proses ajar mandiri mahasiswa tentu mata kuliah ajar mata kuliah mata kuliah prasyarat penuh lanjut mata kuliah mata kuliah prasyarat gambar materi ajar mata kuliah sistem ajar bas elearning moodle fitur mata kuliah prasyarat mata kuliah mata kuliah prasyarat seringkali cantum deskripsi mata kuliah manfaat mata kuliah prasyarat mudahuntuk tentu mata kuliah prasyarat deskripsi ekstraksi deteksi entitas mata kuliah named entity recognition ner solusi ekstraksi entitas proses ekstraksi awal model ner bahasa indonesia spacy alat bantu anotasi prodigy hasil anotasi integrasi dalam plugin moodle plugin bangun tipe block mana plugin tampil data mata kuliah serta mata kuliah prasyaratmaka buat plugin ekstraksi materi ajar dasar materi prasyarat lms learning management system moodle usul solusi masalah atas plugin kembang moodle moodle salah lms bas web elearning plugin guna mahasiswa tenaga ajar mata kuliah prasyarat mata kuliah mudahat present many of educational institutions are conducting learning system using elearning based as well as in information departement puluh nopember institute of technology its the learning process of elearning based has many benefits one of them is for students to be able to learn independently in the process of independent learning students can determine their own subjects what they what to learn in a course the are certainly prerequisite courses that must be finished to be able to proceed to the next course the prerequisite courses are very important to know what material will be studied in certain course but at this time learning sistem based of elearning such as moodle have not provided features to be able to know the prerequisite courses from a course beside that course prerequisite are often indicated in course description this can be used to find out what is the course prerequisite easilyto determine the prerequisite courses from a description extraction is needed to detect entity subjects named entity recognition ner can be used as a solution for doing extraction word entities the extraction process begins by creating an indonesanlanguage ner model using spacy and prodigy annotation tools then the annotation results will be integrated into moodle plugin plugin that will be built are block type where the plugin will display course data along with prerequisite coursestherefore the creation of a learning material extraction plugin based on the prerequisite material on the moodle lms learning management system is proposed as a solution to the above problem this plugin will be developed through moodle because moodle is one of the webbased lms that is widely used in elearning system with this plugin users which are students and teachers can see prerequisite courses from a subject easily
Rancang Bangun Stetoskop Elektronik Berbasis Android untuk Identifikasi Sinyal Suara Jantung.,"Khansa, Shalfienna Alya",http://repository.its.ac.id/102340/,"Penyakit jantung merupakan salah satu penyebab utama kematian di dunia dan masih menjadi penyebab kematian tertinggi di Indonesia. Kondisi geografis Indonesia yang terdiri dari 7000 pulau menyebabkan proses penanganan penyakit jantung lebih sulit, terutama pada daerah terpencil. Proses deteksi dini penyakit jantung perlu dilakukan sebagai upaya mengurangi angka kematian. Namun proses deteksi dini dari penyakit jantung menjadi tantangan yang sulit, karena membutuhkan biaya yang mahal dan bergantung dengan petugas medis untuk hasil deteksi yang akurat. Seiring berkembangnya teknologi, smartphone mulai bermunculan dengan kemampuan yang semakin canggih dan dapat mendukung perkembangan aplikasi mobile health sebagai solusi untuk pemantauan kesehatan jarak jauh. Dalam Tugas Akhir ini, dirancang stetoskop yang terhubung dengan smartphone berbasis android untuk proses analisa sinyal suara jantung menggunakan aplikasi. Aplikasi akan dilengkapi metode identifikasi suara sehingga dapat mengurangi ketergantungan pengguna dengan petugas medis. Sinyal suara jantung akan diproses menggunakan metode Discrete Wavelet Transform untuk denoising dan metode Linear Envelope untuk pemrosesan suara jantung. Alat dirancang dengan menggunakan stetoskop berbiaya rendah yang membedakan dengan stetoskop elektronik di pasaran. Dari proses identifikasi sinyal suara jantung yang dilakukan dengan 20 subjek, 75% dari data perekaman sinyal jantung menghasilkan keluaran identifikasi yang akurat. Data sinyal PCG, pemrosesan, dan hasil ditampilkan pada aplikasi android secara optimal.===================================================================================================================================Heart disease is one of the leading causes of death worldwide and the highest cause of death in Indonesia. The geographic conditions of Indonesia, comprising over 7000 islands, engender significant challenges in managing heart disease, particularly in remote and underdeveloped areas. Early detection is critical for reducing mortality rates associated with heart disease. However, this process poses challenges due to its high cost and reliance on clinicians for accurate detection. With technological advancements, smartphones have emerged with increasingly advanced capabilities, supporting the development of mobile health applications for remote health monitoring. This research aims to create an electronic stethoscope that connects to an Android-based smartphone application for heart sound signal identification. The application offers a reliable validation method to reduce dependency on clinicians. The process of heart sound signal uses the 5^th levels of the Discrete Wavelet Transform method for denoising and the Linear Envelope method for heart sound identification. The instrument design incorporates a cost-effective stethoscope, distinguishing it from existing electronic stethoscopes in the market. The heart sound identification method was applied to 20 individuals, revealing that 75% of the recorded heart signal data generated precise identification results. The Android application effectively showcases PCG signal data, processing, and outcomes.",rancang bangun stetoskop elektronik bas android identifikasi sinyal suara jantung,sakit jantung salah sebab utama mati dunia sebab mati tinggi indonesia kondisi geografis indonesia 7000 pulau sebab proses tangan sakit jantung sulit daerah pencil proses deteksi sakit jantung upaya kurang angka mati proses deteksi sakit jantung tantang sulit butuh biaya mahal gantung tugas medis hasil deteksi akurat iring kembang teknologi smartphone muncul mampu canggih dukung kembang aplikasi mobile health solusi pantau sehat jarak tugas rancang stetoskop hubung smartphone bas android proses analisa sinyal suara jantung aplikasi aplikasi lengkap metode identifikasi suara kurang gantung guna tugas medis sinyal suara jantung proses metode discrete wavelet transform denoising metode linear envelope pemrosesan suara jantung alat rancang stetoskop biaya rendah beda stetoskop elektronik pasar proses identifikasi sinyal suara jantung 20 subjek 75 data rekam sinyal jantung hasil keluar identifikasi akurat data sinyal pcg pemrosesan hasil tampil aplikasi android optimalheart disease is one of the leading causes of death worldwide and the highest cause of death in indonesia the geographic conditions of indonesia comprising over 7000 islands engender significant challenges in managing heart disease particularly in remote and underdeveloped areas early detection is critical for reducing mortality rates associated with heart disease however this process poses challenges due to its high cost and reliance on clinicians for accurate detection with technological advancements smartphones have emerged with increasingly advanced capabilities supporting the development of mobile health applications for remote health monitoring this research aims to create an electronic stethoscope that connects to an androidbased smartphone application for heart sound signal identification the application offers a reliable validation method to reduce dependency on clinicians the process of heart sound signal uses the 5th levels of the discrete wavelet transform method for denoising and the linear envelope method for heart sound identification the instrument design incorporates a costeffective stethoscope distinguishing it from existing electronic stethoscopes in the market the heart sound identification method was applied to 20 individuals revealing that 75 of the recorded heart signal data generated precise identification results the android application effectively showcases pcg signal data processing and outcomes
Pengujian dan Kalibrasi Bubble Detector Photoelectric Infrared pada Mesin Hemodialisis.,"Kirana, Berliana Shafa",http://repository.its.ac.id/112721/,"Hemodialisis adalah prosedur medis yang digunakan untuk menggantikan fungsi ginjal yang rusak. Selama dialisis untuk pasien gagal ginjal dapat muncul gelembung udara dalam darah. Detektor gelembung merupakan salah satu bagian penting dalam proses ini, karena detektor gelembung akan mendeteksi adanya bubble dalam aliran Venous Catheter. Kehadiran bubble dalam sistem vena dapat mengakibatkan kondisi syok atau henti jantung yang berpotensi fatal. Studi sebelumnya telah mengembangkan detektor microbubble menggunakan teknologi Photoelectric Infrared. Sebelumnya dalam memaksimalkan pembacaan dilakukan penyesuaian pancaran sinar infrared dalam memaksimalkan pancaran saja dan belum dilakukan kalibrasi dan pengujian menggunakan darah. Dilakukan  pengujian menggunakan air, performa deteksi bubble setelah dilakukan kalibrasi meningkat dimana error yang dimilikin oleh sensor infrared 0,01060071, dan menjadi 0,00003964, sedangkan akurasi sensor 0,9 menjadi 0,99 dan presisi 0,85 menjadi 0,99. Hasil kalibrasi menggunakan air menunjukkan adanya peningkatan performa deteksi bubble. Kalibrasi sensor ini dilakukan dengan menggunakan metode logistik regresi dengan intercept dan slope yang didapat yakni 65,0197325226436 dan -0,06463164465137253. Pada pengujian menggunakan darah, didapat hasil pembacaan sensor memiliki penurunan performa pembacaan dimana presisi, 0,7158, akurasi 77,45 dan error sebanyak 0,2845. Hasil dari pengujian ini menunjukkan adanya penurunan performa saat pengujian menggunakan darah. Pengujian pada golongan darah yang berbeda (A, B, dan AB) menunjukkan hasil variatif. Darah golongan A memiliki performa yang cukup baik dengan error 0,041666667, akurasi 0,92, dan presisi 0,6. Namun, darah golongan B menunjukkan hasil pembacaan yang terus menerus 1, disebabkan oleh viskositas tinggi yang berbeda jauh dari darah A. Pada darah golongan AB, hasil kalibrasi menunjukkan error 0,073394495, akurasi 0,874, dan presisi 0,868. Hasil ini menegaskan bahwa performa deteksi bubble pada sensor infrared sangat dipengaruhi oleh viskositas medium. Kalibrasi dengan medium yang memiliki viskositas serupa penting untuk memastikan akurasi dan presisi pembacaan sensor.===========================================================================Hemodialysis is a medical procedure used to replace damaged kidney function. During dialysis for kidney failure patients, air bubbles may appear in the blood. The bubble detector is an important part of this process, because the bubble detector will detect the presence of bubbles in the Venous Catheter flow. The presence of bubbles in the venous system can result in potentially fatal shock or cardiac arrest. Previous studies have developed microbubble detectors using Infrared Photoelectric technology. Previously, to maximize readings, adjustments were made to the infrared beam to maximize the beam only and calibration and testing using blood had not been carried out. Testing using water was carried out, the bubble detection performance after calibration increased, where the error of the infrared sensor was 0,01060071, and became 0,00003964, while the sensor accuracy was 0,9 to 0,99 and the precision was 0,85 to 0,99. The results of calibration using water show an increase in bubble detection performance. Calibration of this sensor was carried out using the logistik regression method with the intercept and slope obtained, namely 65,0197325226436 and -0,06463164465137253. In testing using blood, it was found that the sensor reading results had a decrease in reading performance, where the precision was 0,7158, the accuracy was 77,45 and the error was 0,2845. The results of this test show a decrease in performance when testing using blood. Testing on different blood types (A, B, and AB) shows varied results. Type A blood has quite good performance with an error of 0,041666667, accuracy of 0,92, and precision of 0,6. However, type B blood shows a continuous reading of 1, caused by the high viscosity which is very different from blood A. For type AB blood, the calibration results show an error of 0,073394495, an accuracy of 0,874, and a precision of 0,868. These results confirm that the bubble detection performance of the infrared sensor is strongly influenced by the viscosity of the medium. Calibration with a medium that has a similar viscosity is important to ensure the accuracy and precision of sensor readings.",uji kalibrasi bubble detector photoelectric infrared mesin hemodialisis,hemodialisis prosedur medis ganti fungsi ginjal rusak dialisis pasien gagal ginjal muncul gelembung udara darah detektor gelembung salah proses detektor gelembung deteksi bubble alir venous catheter hadir bubble sistem vena akibat kondisi syok henti jantung potensi fatal studi kembang detektor microbubble teknologi photoelectric infrared maksimal baca sesuai pancar sinar infrared maksimal pancar kalibrasi uji darah uji air performa deteksi bubble kalibrasi tingkat mana error dimilikin sensor infrared 001060071 000003964 akurasi sensor 09 099 presisi 085 099 hasil kalibrasi air tingkat performa deteksi bubble kalibrasi sensor metode logistik regresi intercept slope 650197325226436 006463164465137253 uji darah hasil baca sensor milik turun performa baca mana presisi 07158 akurasi 7745 error 02845 hasil uji turun performa uji darah uji golong darah beda a b ab hasil variatif darah golong a milik performa error 0041666667 akurasi 092 presisi 06 darah golong b hasil baca terus 1 sebab viskositas beda darah a darah golong ab hasil kalibrasi error 0073394495 akurasi 0874 presisi 0868 hasil performa deteksi bubble sensor infrared pengaruh viskositas medium kalibrasi medium milik viskositas akurasi presisi baca sensorhemodialysis is a medical procedure used to replace damaged kidney function during dialysis for kidney failure patients air bubbles may appear in the blood the bubble detector is an important part of this process because the bubble detector will detect the presence of bubbles in the venous catheter flow the presence of bubbles in the venous system can result in potentially fatal shock or cardiac arrest previous studies have developed microbubble detectors using infrared photoelectric technology previously to maximize readings adjustments were made to the infrared beam to maximize the beam only and calibration and testing using blood had not been carried out testing using water was carried out the bubble detection performance after calibration increased where the error of the infrared sensor was 001060071 and became 000003964 while the sensor accuracy was 09 to 099 and the precision was 085 to 099 the results of calibration using water show an increase in bubble detection performance calibration of this sensor was carried out using the logistik regression method with the intercept and slope obtained namely 650197325226436 and 006463164465137253 in testing using blood it was found that the sensor reading results had a decrease in reading performance where the precision was 07158 the accuracy was 7745 and the error was 02845 the results of this test show a decrease in performance when testing using blood testing on different blood types a b and ab shows varied results type a blood has quite good performance with an error of 0041666667 accuracy of 092 and precision of 06 however type b blood shows a continuous reading of 1 caused by the high viscosity which is very different from blood a for type ab blood the calibration results show an error of 0073394495 an accuracy of 0874 and a precision of 0868 these results confirm that the bubble detection performance of the infrared sensor is strongly influenced by the viscosity of the medium calibration with a medium that has a similar viscosity is important to ensure the accuracy and precision of sensor readings
Penerapan Metode K-Means dan Fuzzy C-Means pada Pengelompokkan Kabupaten/Kota di Provinsi Jawa Barat Berdasarkan Indikator Kemiskinan.,"Kiranadhewi, Afi Iffa Praba",http://repository.its.ac.id/119039/,"Kemiskinan adalah masalah sentral yang dihadapi negara-negara berkembang, termasuk Indonesia. Meski beberapa negara telah menunjukkan kemajuan ekonomi, kemiskinan tetap menjadi tantangan signifikan. Di Indonesia, tingkat kemiskinan yang tinggi memerlukan perhatian khusus dari pemerintah pusat dan daerah. Provinsi Jawa Barat, yang memiliki potensi besar dalam berbagai sektor, masih berjuang melawan masalah kemiskinan. Untuk mengatasi ini, diperlukan sistem yang dapat mengelompokkan kabupaten/kota berdasarkan indikator kemiskinan sehingga program pembangunan dapat dirancang dan dilaksanakan lebih efektif. Penelitian ini bertujuan untuk mengelompokkan kabupaten/kota di Jawa Barat berdasarkan faktor-faktor yang mempengaruhi kemiskinan tahun 2023 menggunakan metode K-Means dan Fuzzy C-Means (FCM). Langkah awal penelitian ini adalah melakukan standardisasi data. Selanjutnya, dilakukan analisis deskriptif untuk memahami karakteristik data sebelum melakukan pengelompokan. Hasil pengelompokan kedua metode tersebut dibandingkan untuk menentukan metode yang lebih efektif. Sebagai output akhir, dibuat dashboard untuk memetakan kabupaten/kota di Jawa Barat berdasarkan indikator kemiskinan. Hasil penelitian ini diharapkan dapat memberikan gambaran kondisi kemiskinan di Jawa Barat dan berfungsi sebagai alat monitoring bagi pemerintah dan lembaga terkait dalam upaya mencapai target Sustainable Development Goals (SDGs) 2030 dalam mengurangi kemiskinan.================================================================================================================================Poverty is a central issue facing developing countries, including Indonesia. Although some countries have shown economic progress, poverty remains a significant challenge. In Indonesia, the high poverty rate requires special attention from the central and local governments. West Java Province, which has great potential in various sectors, is still struggling against the problem of poverty. To address this, a system is needed that can cluster districts / municipalities based on poverty indicators so that development programs can be designed and implemented more effectively. This study aims to cluster districts/cities in West Java based on factors affecting poverty in 2023 using the K-Means and Fuzzy C-Means (FCM) methods. The first step of this research is testing the multivariate normal assumption and Bartlett's test to assess the suitability of the data. Next, descriptive analysis was conducted to understand the characteristics of the data before clustering. The clustering results of the two methods were compared to determine the more effective method. As a final output, a dashboard was created to map districts/cities in West Java based on poverty indicators. The results of this research are expected to provide an overview of poverty conditions in West Java and serve as a monitoring tool for the government and related institutions in an effort to achieve the 2030 Sustainable Development Goals (SDGs) target in reducing poverty.",terap metode kmeans fuzzy cmeans kelompok kabupatenkota provinsi jawa barat dasar indikator miskin,miskin sentral hadap negaranegara kembang indonesia negara maju ekonomi miskin tantang signifikan indonesia tingkat miskin perhati khusus perintah pusat daerah provinsi jawa barat milik potensi sektor juang lawan miskin atas sistem kelompok kabupatenkota dasar indikator miskin program bangun rancang laksana efektif teliti tuju kelompok kabupatenkota jawa barat dasar faktorfaktor pengaruh miskin 2023 metode kmeans fuzzy cmeans fcm langkah teliti standardisasi data analisis deskriptif paham karakteristik data kelompok hasil kelompok metode banding tentu metode efektif output dashboard meta kabupatenkota jawa barat dasar indikator miskin hasil teliti harap gambar kondisi miskin jawa barat fungsi alat monitoring perintah lembaga kait upaya capai target sustainable development goals sdgs 2030 kurang kemiskinanpoverty is a central issue facing developing countries including indonesia although some countries have shown economic progress poverty remains a significant challenge in indonesia the high poverty rate requires special attention from the central and local governments west java province which has great potential in various sectors is still struggling against the problem of poverty to address this a system is needed that can cluster districts municipalities based on poverty indicators so that development programs can be designed and implemented more effectively this study aims to cluster districtscities in west java based on factors affecting poverty in 2023 using the kmeans and fuzzy cmeans fcm methods the first step of this research is testing the multivariate normal assumption and bartletts test to assess the suitability of the data next descriptive analysis was conducted to understand the characteristics of the data before clustering the clustering results of the two methods were compared to determine the more effective method as a final output a dashboard was created to map districtscities in west java based on poverty indicators the results of this research are expected to provide an overview of poverty conditions in west java and serve as a monitoring tool for the government and related institutions in an effort to achieve the 2030 sustainable development goals sdgs target in reducing poverty
"Pengenalan Ekspresi Wajah dengan Variasi Pencahayaan Menggunakan Local Ternary Pattern, Convolutional Neural Network dan Extreme Learning Machine.","Krisnahati, Ice",http://repository.its.ac.id/95909/,"Pengenalan ekspresi wajah secara otomatis banyak dimanfaatkan pada interaksi manusia dan robot, permainan visual interaktif, dan deteksi gangguan mental. Oleh karena itu, pengenalan ekspresi wajah secara otomatis masih menjadi perhatian peneliti di bidang visi komputer. Berbagai macam metode telah diusulkan untuk mengatasi masalah variasi pencahayaan. Berdasarkan penelitian sebelumnya, citra Local Ternary Pattern (LTP) yang diklasifikasikan dengan metode Convolutional Neural Network (CNN) mampu mengatasi variasi pencahayaan. CNN merupakan metode klasifikasi yang handal, tetapi memiliki waktu pelatihan yang lebih lama untuk arsitektur yang lebih rumit. Pada penelitian lain, Extreme Learning Machine (ELM) dimanfaatkan untuk memodifikasi CNN pada lapisan klasifikasi untuk mengatasi waktu pelatihan yang lama.  Penelitian ini menggabungkan metode yang sudah diteliti sebelumnya dengan memanfaatkan kelebihan masing-masing metode. Citra LTP digunakan untuk mengatasi masalah pencahayaan. Kemudian, citra LTP tersebut digunakan sebagai input pada arsitektur CNN untuk proses ekstraksi fitur. Pada lapisan klasifikasi, CNN dimodifikasi dengan menghilangkan lapisan fully connected dan menggantinya dengan metode ELM. Tujuan dari modifikasi CNN tersebut adalah untuk mengatasi pelatihan yang memakan waktu pada backpropagation. Sehingga, penelitian ini membangun model dengan kombinasi metode LTP, CNN, dan ELM.  Pengujian metode menggunakan dataset KDEF dengan total 980 citra wajah dan tujuh kelas ekspresi wajah, yaitu marah, senang, sedih, takut, netral, jijik, dan terkejut dengan variasi pencahayaan mulai dari agak gelap sampai agak terang. Hasil pola kombinasi yang dihitung berdasarkan rata-rata dari pola atas dan pola bawah citra LTP menghasilkan akurasi paling tinggi jika dibandingkan dengan pola atas dan pola bawah citra LTP. Evaluasi menggunakan 10-fold cross-validation menunjukkan bahwa kinerja kombinasi metode LTP, CNN, dan ELM menghasilkan nilai akurasi sebesar 85,51% dengan waktu pelatihan 1.876 detik. Nilai akurasi ini meningkat bila dibandingkan dengan penelitian sebelumnya. Berdasarkan hasil tersebut, penelitian ini mampu mengatasi masalah pencahayaan pada kasus pengenalan ekspresi wajah============================================================================================================================Automatic facial expression recognition is widely used in human-robot interactions, interactive visual games, and mental disorder detection. Therefore, automatic facial expression recognition is still an exciting task for researchers in computer vision. Various methods have been proposed to solve the lighting variation problem. Based on previous research, Local Ternary Pattern (LTP) images classified by the Convolutional Neural Network (CNN) method can handle lighting variations. CNN is a reliable classification method but has a longer training time for more complex architectures. In another study, Extreme Learning Machine (ELM) was used to modify CNN at the classification layer to overcome the long training problem. This study combines methods that have been previously studied by exploiting the advantages of each method. LTP images are used to solve lighting problems. Then, the LTP image is used as input to the CNN architecture for the feature extraction process. At the classification layer, CNN is modified by removing the fully connected layer and replacing it with the ELM method. The purpose of the CNN modification is to overcome the time-consuming training on backpropagation. Thus, this study builds a model combining LTP, CNN, and ELM methods. This research used the KDEF dataset with 980 facial images (frontal face) and seven facial expressions: angry, happy, sad, scared, neutral, disgusted, and surprised, with lighting variations ranging from dark to bright. The combination pattern results calculated based on the average of the top and bottom patterns of the LTP image produce the highest accuracy compared to the top and bottom patterns of the LTP image. Evaluation using 10-fold cross-validation shows that the performance of the combination of LTP, CNN, and ELM methods produce an accuracy value of 85.51% with a training time of 1,876 seconds. This accuracy value increases when compared to previous studies. Based on these results, this study was able to overcome the lighting problem in the case of facial expression recognition",kenal ekspresi wajah variasi cahaya local ternary pattern convolutional neural network extreme learning machine,kenal ekspresi wajah otomatis manfaat interaksi manusia robot main visual interaktif deteksi ganggu mental kenal ekspresi wajah otomatis perhati teliti bidang visi komputer metode usul atas variasi cahaya dasar teliti citra local ternary pattern ltp klasifikasi metode convolutional neural network cnn atas variasi cahaya cnn metode klasifikasi handal milik latih arsitektur rumit teliti extreme learning machine elm manfaat modifikasi cnn lapis klasifikasi atas latih teliti gabung metode teliti manfaat lebih masingmasing metode citra ltp atas cahaya citra ltp input arsitektur cnn proses ekstraksi fitur lapis klasifikasi cnn modifikasi hilang lapis fully connected ganti metode elm tuju modifikasi cnn atas latih makan backpropagation teliti bangun model kombinasi metode ltp cnn elm uji metode dataset kdef total 980 citra wajah tujuh kelas ekspresi wajah marah senang sedih takut netral jijik kejut variasi cahaya gelap terang hasil pola kombinasi hitung dasar ratarata pola pola citra ltp hasil akurasi banding pola pola citra ltp evaluasi 10fold crossvalidation kerja kombinasi metode ltp cnn elm hasil nilai akurasi 8551 latih 1876 detik nilai akurasi tingkat banding teliti dasar hasil teliti atas cahaya kenal ekspresi wajahautomatic facial expression recognition is widely used in humanrobot interactions interactive visual games and mental disorder detection therefore automatic facial expression recognition is still an exciting task for researchers in computer vision various methods have been proposed to solve the lighting variation problem based on previous research local ternary pattern ltp images classified by the convolutional neural network cnn method can handle lighting variations cnn is a reliable classification method but has a longer training time for more complex architectures in another study extreme learning machine elm was used to modify cnn at the classification layer to overcome the long training problem this study combines methods that have been previously studied by exploiting the advantages of each method ltp images are used to solve lighting problems then the ltp image is used as input to the cnn architecture for the feature extraction process at the classification layer cnn is modified by removing the fully connected layer and replacing it with the elm method the purpose of the cnn modification is to overcome the timeconsuming training on backpropagation thus this study builds a model combining ltp cnn and elm methods this research used the kdef dataset with 980 facial images frontal face and seven facial expressions angry happy sad scared neutral disgusted and surprised with lighting variations ranging from dark to bright the combination pattern results calculated based on the average of the top and bottom patterns of the ltp image produce the highest accuracy compared to the top and bottom patterns of the ltp image evaluation using 10fold crossvalidation shows that the performance of the combination of ltp cnn and elm methods produce an accuracy value of 8551 with a training time of 1876 seconds this accuracy value increases when compared to previous studies based on these results this study was able to overcome the lighting problem in the case of facial expression recognition
Pengembangan Kursi Roda Otonom Berbasis YOLOV8 Untuk Penghindaran Obstacle.,"Kusuma, I Gst Ngr Agung Hari Vijaya",http://repository.its.ac.id/111406/,"Pengembangan kursi roda otonom telah menjadi semakin penting dalam meningkatkan mobilitas bagi individu dengan mobilitas terbatas. Studi ini mengusulkan pengembangan sistem kursi roda otonom berbasis YOLOv8 untuk menghindari obstacle, khususnya fokus pada deteksi obstacle manusia. Dengan memanfaatkan kemampuan deteksi objek yang canggih dari YOLOv8, sistem yang diusulkan bertujuan untuk mendeteksi dan menghindari obstacle manusia secara efektif. Sistem tersebut mendeteksi manusia melalui video menggunakan Intel NUC dan Kamera. Obstacle yang terdeteksi membuat NUC mengirim perintah ke ESP32 untuk menjalankan motor untuk melakukan manuver penghindaran. Pengujian performa keberhasilan penghindaran dilakukan dengan 30 kali percobaan pada objek manusia yang diam. Hasil pengujian menunjukkan bahwa kursi roda berhasil menghindar sebanyak 30 kali tanpa gagal, memberikan tingkat keberhasilan sebesar 100%. Hal ini menunjukkan bahwa sistem kursi roda otonom yang dirancang mampu melakukan penghindaran rintangan dengan sangat baik.=========================================================================================================",kembang kursi roda otonom bas yolov8 hindar obstacle,kembang kursi roda otonom tingkat mobilitas individu mobilitas batas studi usul kembang sistem kursi roda otonom bas yolov8 hindar obstacle fokus deteksi obstacle manusia manfaat mampu deteksi objek canggih yolov8 sistem usul tuju deteksi hindar obstacle manusia efektif sistem deteksi manusia video intel nuc kamera obstacle deteksi nuc kirim perintah esp32 jalan motor manuver hindar uji performa hasil hindar 30 kali coba objek manusia diam hasil uji kursi roda hasil hindar 30 kali gagal tingkat hasil 100 sistem kursi roda otonom rancang hindar rintang
Analisis Sentimen Warga Indonesia Terhadap Penanganan Kasus COVID-19 Menggunakan Metode Naïve Bayes Dan Support Vector Machine (SVM).,"Lestari, Dhany Nastiti",http://repository.its.ac.id/91616/,"Kehidupan masyarakat zaman sekarang mengalami banyak perubahan akibat dari perkembangan ilmu pengetahuan  dan teknologi. Masyarakat menjadi lebih reaktif menanggapi fenomena disekitar, termasuk  berita, kebijakan, serta upaya-upaya pemerintah menanggulangi pandemi COVID-19. Feedback masyarakat mengenai upaya-upaya pemerintah menanggulangi bencana dapat dijadikan bahan evaluasi untuk meningkatkan kinerja. Untuk mendapatkan hasil yang dapat dilihat secara jelas maka digunakan proses klasifikasi terhadap opini-opini masyarakat menjadi opini dengan sentimen positif serta sentimen negatif. Data teks yang didapat dari tweet masyarakat Indonesia akan di preprocessing menggunakan tokenisasi, case folding, serta penghapusan stopwords. Data hasil preprocessing akan dilakukan ektraksi fitur Term Frequency-Inverse Document Frequency (TF-IDF), dengan satu term adalah sebuah n-grams dan akan dilakukan klasifikasi menggunakan metode naïve Bayes dan Support Vector Machine (SVM). Hasil dari klasifikasi sentiment menunjukkan bahwa metode SVM lebih baik daripada Naïve Bayes, khususnya SVM dengan menggunakan kernel radial basis karena memiliki F1-score, recall, dan accuracy yang lebih tinggi.===================================================================================================Life in our current society undergoes many changes as a result of the development of science and technology. People have become more reactive in responding to phenomena around them, including news, policies, and government efforts to tackle the COVID-19 pandemic. Public feedback regarding the government's efforts to cope with disasters can be used as evaluation material to improve performance. To get results that can be seen clearly, a classification process is used to classify public opinions into opinions with positive sentiments and negative sentiments. Text data obtained from Indonesian people's tweets will be preprocessed using tokenization, case folding, and removal of stop words. The data from the preprocessing will be extracted with Term Frequency-Inverse Document Frequency (TF-IDF), with one term being n-grams and will be classified using the Nave Bayes method and Support Vector Machine (SVM). The results of the sentiment classification show that the SVM method is better than Naïve Bayes, especially SVM using a radial basis kernel because it has a higher mean  F1-score, recall, and accuracy.",analisis sentimen warga indonesia tangan covid19 metode na ve bayes support vector machine svm,hidup masyarakat zaman alami ubah akibat kembang ilmu tahu teknologi masyarakat reaktif tanggap fenomena sekitar berita bijak upayaupaya perintah tanggulang pandemi covid19 feedback masyarakat upayaupaya perintah tanggulang bencana jadi bahan evaluasi tingkat kerja hasil proses klasifikasi opiniopini masyarakat opini sentimen positif sentimen negatif data teks tweet masyarakat indonesia preprocessing tokenisasi case folding hapus stopwords data hasil preprocessing ektraksi fitur term frequencyinverse document frequency tfidf term ngrams klasifikasi metode na ve bayes support vector machine svm hasil klasifikasi sentiment metode svm na ve bayes svm kernel radial basis milik f1score recall accuracy tinggilife in our current society undergoes many changes as a result of the development of science and technology people have become more reactive in responding to phenomena around them including news policies and government efforts to tackle the covid19 pandemic public feedback regarding the governments efforts to cope with disasters can be used as evaluation material to improve performance to get results that can be seen clearly a classification process is used to classify public opinions into opinions with positive sentiments and negative sentiments text data obtained from indonesian peoples tweets will be preprocessed using tokenization case folding and removal of stop words the data from the preprocessing will be extracted with term frequencyinverse document frequency tfidf with one term being ngrams and will be classified using the nave bayes method and support vector machine svm the results of the sentiment classification show that the svm method is better than na ve bayes especially svm using a radial basis kernel because it has a higher mean f1score recall and accuracy
Aspect-Based Sentiment Analysis Pada Ulasan Konsumen Terhadap Kualitas Layanan PT Citilink Indonesia.,"Lestarie, Maisa Haifa",http://repository.its.ac.id/107066/,"Transportasi udara yang menjadi moda transportasi paling sering digunakan oleh konsumen Indonesia. Terciptanya konsep penerbangan Low-Cost Carier (LCC) dimana penerbangan menerapkan strategi penurunan biaya operasional dan mengoptikmalkan biaya disetiap lini. Kompetisi maskapai penerbangan lowcost carrier yang tinggi mendorong perusahaan untuk menguatkan merek dan mengembangkan strategi. Salah satu maskapai LCC di bawah naungan Garuda Indonesia yaitu PT Citilink Indonesia sebagai upaya Garuda Indonesia untuk bersaing pada segment budget traveler. Pada pelaksanaannya PT Citilink Indonesia dinilai memberi informasi delay secara mendadak dan juga penurunan layanan call center dalam menangani keluhan penumpang. Kualitas layanan berpengaruh pada brand image dan brand trust sebagai faktor yang menentukan loyalitas konsumen. Berdasarkan hal tersebut dapat dilakukan analisis sentimen untuk mengetahui pandangan konsumen terhadap PT Citilink Indonesia dengan mengukur kualitas layanan berdasarkan aspek. Metode yang digunakan adalah Aspect Based Sentiment Analysis dengan algoritma Naïve Bayes Classifier dan word2vec. Hasil dari penelitian ini berupa sentimen negatif terhadap aspek tangible, responsiveness, reliability, dan assurance dengan aspect-based sentiment analysis menghasilkan akurasi klasifikasi kelas sentimen sebesar 89% dan kelas aspek sebesar 62%.=============================================================================================================================Air transportation is the most frequently used mode of transportation by Indonesian consumers. The creation of the Low-Cost Carrier (LCC) flight concept where flights implement a strategy of reducing operational costs and optimizing costs in every line. High low-cost carrier airline competition encourages companies to strengthen brands and develop strategies. One of the LCC airlines under Garuda Indonesia is PT Citilink Indonesia as Garuda Indonesia's effort to compete in the budget traveler segment. In its implementation, PT Citilink Indonesia is considered to provide sudden delay information also a decrease in call center services in handling passenger complaints. Service quality affects brand image and brand trust as factors that determine consumer loyalty. Based on this, sentiment analysis can be carried out to determine consumer views on PT Citilink Indonesia by measuring service quality based on aspects. The method used is Aspect Based Sentiment Analysis with the Naïve Bayes Classifier algorithm and word2vec. The results of this study are negative sentiments towards tangible, responsive, reliability, and assurance aspects with aspect-based sentiment analysis resulting in a sentiment class classification accuracy of 89% and an aspect class of 62%.",aspectbased sentiment analysis ulas konsumen kualitas layan pt citilink indonesia,transportasi udara moda transportasi konsumen indonesia cipta konsep terbang lowcost carier lcc mana terbang terap strategi turun biaya operasional mengoptikmalkan biaya tiap lini kompetisi maskapai terbang lowcost carrier dorong usaha kuat merek kembang strategi salah maskapai lcc naung garuda indonesia pt citilink indonesia upaya garuda indonesia saing segment budget traveler laksana pt citilink indonesia nilai informasi delay dadak turun layan call center tangan keluh tumpang kualitas layan pengaruh brand image brand trust faktor tentu loyalitas konsumen dasar analisis sentimen pandang konsumen pt citilink indonesia ukur kualitas layan dasar aspek metode aspect based sentiment analysis algoritma na ve bayes classifier word2vec hasil teliti sentimen negatif aspek tangible responsiveness reliability assurance aspectbased sentiment analysis hasil akurasi klasifikasi kelas sentimen 89 kelas aspek 62air transportation is the most frequently used mode of transportation by indonesian consumers the creation of the lowcost carrier lcc flight concept where flights implement a strategy of reducing operational costs and optimizing costs in every line high lowcost carrier airline competition encourages companies to strengthen brands and develop strategies one of the lcc airlines under garuda indonesia is pt citilink indonesia as garuda indonesias effort to compete in the budget traveler segment in its implementation pt citilink indonesia is considered to provide sudden delay information also a decrease in call center services in handling passenger complaints service quality affects brand image and brand trust as factors that determine consumer loyalty based on this sentiment analysis can be carried out to determine consumer views on pt citilink indonesia by measuring service quality based on aspects the method used is aspect based sentiment analysis with the na ve bayes classifier algorithm and word2vec the results of this study are negative sentiments towards tangible responsive reliability and assurance aspects with aspectbased sentiment analysis resulting in a sentiment class classification accuracy of 89 and an aspect class of 62
Pengembangan Model Prediksi Dan Model Bisnis Pada Pembiayaan Kendaraan Berbasis Data Mining.,"Lupitadevi, Citra Judith",http://repository.its.ac.id/92534/,"Pembiayaan kendaraan merupakan salah satu kebutuhan yang diperlukan oleh konsumen pada saat membeli kendaraan. PT Mandiri Tunas Finance (MTF) merupakan salah satu perusahaan pembiayaan kendaraan di Indonesia. Total pembiayaan kendaraan yang telah disalurkan di 2020 adalah sebesar 16.7 trilun. Kondisi Pandemi Covid-19 yang terjadi sejak akhir tahun 2019, memberikan dampak yang signifikan terdapat bisnis perusahaan pembiayaan. Perusahaan pembiayaan mengalami penurunan sebesar 40%, hal ini didorong juga karena penurunan penjualan mobil sebesar 44.6% pada Tahun 2020 dibandingkan Tahun 2019. Sumber order PT Mandiri Tunas Finance mayoritas berasal dari penjualan dealer kendaraan. Turunnya penjualan mobil, berdampak langsung pada bisnis PT Mandiri Tunas Finance. Untuk mengatasi hal tersebut, perlu dikembangkan sumber order lain terutama yang berasal dari pengolahan database customer perusahaan (data mining). Dalam penelitian ini, akan dilakukan penerapan model prediksi dengan regresi logistik biner. Hal ini dilakukan dengan mengembangkan model untuk memprediksi customer yang akan melakukan pengambilan pembiayaan. Tingkat akurasi model prediksi akan diukur dengan menggunakan nilai Area Under Curve (AUC). Selain pengembangan model prediksi, juga dilakukan pengembangan model bisnis pembiayaan berbasis data mining dengan menggunakan pendekatan Businees Model Canvass. Hasil model regresi logistik biner, diketahui variabel prediktor yang mempengaruhi customer dalam mengambil pembiayaan mobil kembali adalah jangka waktu dari pembiayaan sebelumnya, penghasilan customer, jenis produk yang dibiayai, status kepemilikan rumah, status pernikahan, jenis pekerjaan customer dan pendidikan. Dengan pendekatan Area Under Curve diketahui akurasi model yang terbentuk adalah 95,803% yang artinya model ini baik untuk digunakan. Dalam menjalankan model bisnis berbasis data mining ini, perusahaan perlu membentuk fungsi data analytic dan penawaran secara aktif kepada customer.========================================================================================================================================Vehicle financing is one of the financing products needed by consumers when buying a vehicle. PT Mandiri Tunas Finance (MTF) is one of the vehicle financing companies in Indonesia. The total vehicle financing that has been disbursed by MTF in 2020 is 16.7 trillion. The Covid-19 Pandemic condition that has occurred since the end of 2019, has had a significant impact on the financing company business. Finance company’s disbursement decreased by 40%, this was also driven by a 44.6% decline in car sales in 2020 compared to 2019. The main source of orders for MTF comes from vehicle dealer sales. The decline in car sales had a direct impact on MTF’s business. To overcome this, it is necessary to develop other order sources, especially those from the company's customer database processing (data mining). In this research, the prediction model with binary logistic regression will be applied. A model will be used to predict which customers will take financing. The accuracy of the prediction model will be measured using Area Under Curve (AUC) values. In addition, the development of a data mining-based financing business model is also carried out using the Business Model Canvass approach. The results of binary logistic regression models, predictor variables that affect customers in car financing are the period of previous financing, salary, type of product financed, homeownership status, marital status, customer employment type, and education. With the Area Under Curve approach, the accuracy of the model formed is 95.803% which means that this model is good to use. In carrying out this data mining-based business model, companies need to form data analytic functions and build offer activities to customers.",kembang model prediksi model bisnis biaya kendara bas data mining,biaya kendara salah butuh konsumen beli kendara pt mandiri tunas finance mtf salah usaha biaya kendara indonesia total biaya kendara salur 2020 167 trilun kondisi pandemi covid19 2019 dampak signifikan bisnis usaha biaya usaha biaya alami turun 40 dorong turun jual mobil 446 2020 banding 2019 sumber order pt mandiri tunas finance mayoritas asal jual dealer kendara turun jual mobil dampak langsung bisnis pt mandiri tunas finance atas kembang sumber order asal olah database customer usaha data mining teliti terap model prediksi regresi logistik biner kembang model prediksi customer ambil biaya tingkat akurasi model prediksi ukur nilai area under curve auc kembang model prediksi kembang model bisnis biaya bas data mining dekat businees model canvass hasil model regresi logistik biner variabel prediktor pengaruh customer ambil biaya mobil jangka biaya hasil customer jenis produk biaya status milik rumah status nikah jenis kerja customer didik dekat area under curve akurasi model bentuk 95803 model jalan model bisnis bas data mining usaha bentuk fungsi data analytic tawar aktif customervehicle financing is one of the financing products needed by consumers when buying a vehicle pt mandiri tunas finance mtf is one of the vehicle financing companies in indonesia the total vehicle financing that has been disbursed by mtf in 2020 is 167 trillion the covid19 pandemic condition that has occurred since the end of 2019 has had a significant impact on the financing company business finance company  s disbursement decreased by 40 this was also driven by a 446 decline in car sales in 2020 compared to 2019 the main source of orders for mtf comes from vehicle dealer sales the decline in car sales had a direct impact on mtf  s business to overcome this it is necessary to develop other order sources especially those from the companys customer database processing data mining in this research the prediction model with binary logistic regression will be applied a model will be used to predict which customers will take financing the accuracy of the prediction model will be measured using area under curve auc values in addition the development of a data miningbased financing business model is also carried out using the business model canvass approach the results of binary logistic regression models predictor variables that affect customers in car financing are the period of previous financing salary type of product financed homeownership status marital status customer employment type and education with the area under curve approach the accuracy of the model formed is 95803 which means that this model is good to use in carrying out this data miningbased business model companies need to form data analytic functions and build offer activities to customers
Model Manajemen Persediaan Spare Part Pada Alat Berat Pelabuhan Untuk Meningkatkan Availability.,"Mahardika, I Gede Widya",http://repository.its.ac.id/117176/,"Penelitian ini mengkaji permasalahan pada salah satu terminal petikemas di Indonesia yang menghadapi tantangan dalam pengelolaan suku cadang kritis yang berdampak pada operasional dan ketersediaan alat. Data operasional perusahaan menunjukkan tingkat availability alat straddle carrier hanya mencapai 69,33% pada tahun 2023, di bawah target KPI. Data historis menunjukkan bahwa sekitar 56% dari total downtime disebabkan oleh waktu menunggu ketersediaan suku cadang. Untuk mengatasi permasalahan tersebut, dikembangkan model optimasi manajemen persediaan berbasis continuous review (Q, r) yang mengintegrasikan variabel lead time dan ketidakpastian permintaan berdasarkan pola distribusi permintaan historis. Pengujian model ini dilakukan melalui simulasi Monte Carlo dengan mengaplikasikan berbagai skenario kebutuhan pada 10 jenis spare part yang dipilih berdasarkan tingkat kekritisannya. Performa model dievaluasi menggunakan tiga parameter utama, yaitu total inventory cost (TIC), service level, dan availability. Hasil validasi menunjukkan bahwa model mampu merepresentasikan kondisi aktual dengan perbedaan hanya 1,6% dari data nyata, yang masih berada dalam batas toleransi kesalahan 5%. Implementasi skenario perbaikan dengan modifikasi setup pemesanan pada interval tiga bulan menghasilkan optimasi signifikan berupa reduksi TIC sebesar 33%, peningkatan service level spare part sebesar 7,8% mencapai 95%, serta peningkatan availability alat sebesar 4,9% menjadi 75%.===================================================================================================================================This research examines challenges faced by a container terminal in Indonesia in managing critical spare parts, which impact operations and equipment availability. Operational data from the company reveals that the availability rate of straddle carriers only reached 69.33% in 2023, falling below the KPI target. Historical data indicates that approximately 56% of total downtime was caused by delays in spare part availability. To address this issue, an optimization model for inventory management based on continuous review (Q, r) was developed, integrating lead time and demand uncertainty variables derived from historical demand distribution patterns. The model was tested through Monte Carlo simulations applied to various demand scenarios for 10 types of spare parts, selected based on their criticality. The model's performance was evaluated using three key parameters: total inventory cost (TIC), service level, and equipment availability. Validation results demonstrated that the model accurately represented actual conditions, with a deviation of only 1.6% from real-world data, well within the acceptable error margin of 5%. The implementation of improvement scenarios, involving modifications to ordering setups at three-month intervals, achieved significant optimization, including a 33% reduction in TIC, a 7.8% increase in spare parts service level to 95%, and a 4.9% improvement in equipment availability to 75%.",model manajemen sedia spare part alat berat labuh tingkat availability,teliti kaji masalah salah terminal petikemas indonesia hadap tantang kelola suku cadang kritis dampak operasional sedia alat data operasional usaha tingkat availability alat straddle carrier capai 6933 2023 target kpi data historis 56 total downtime sebab tunggu sedia suku cadang atas masalah kembang model optimasi manajemen sedia bas continuous review q r integrasi variabel lead time ketidakpastian minta dasar pola distribusi minta historis uji model simulasi monte carlo aplikasi skenario butuh 10 jenis spare part pilih dasar tingkat kritis performa model evaluasi parameter utama total inventory cost tic service level availability hasil validasi model representasi kondisi aktual beda 16 data nyata batas toleransi salah 5 implementasi skenario baik modifikasi setup mesan interval hasil optimasi signifikan reduksi tic 33 tingkat service level spare part 78 capai 95 tingkat availability alat 49 75this research examines challenges faced by a container terminal in indonesia in managing critical spare parts which impact operations and equipment availability operational data from the company reveals that the availability rate of straddle carriers only reached 6933 in 2023 falling below the kpi target historical data indicates that approximately 56 of total downtime was caused by delays in spare part availability to address this issue an optimization model for inventory management based on continuous review q r was developed integrating lead time and demand uncertainty variables derived from historical demand distribution patterns the model was tested through monte carlo simulations applied to various demand scenarios for 10 types of spare parts selected based on their criticality the models performance was evaluated using three key parameters total inventory cost tic service level and equipment availability validation results demonstrated that the model accurately represented actual conditions with a deviation of only 16 from realworld data well within the acceptable error margin of 5 the implementation of improvement scenarios involving modifications to ordering setups at threemonth intervals achieved significant optimization including a 33 reduction in tic a 78 increase in spare parts service level to 95 and a 49 improvement in equipment availability to 75
Implementasi 2D-CNN dengan Teknik Augmentasi EEG untuk Mendeteksi Kejang Epilepsi pada Dataset Siena Scalp EEG.,"Malinus, Azzura Mahendra Putra",http://repository.its.ac.id/117872/,"Epilepsi adalah sebuah penyakit otak dengan gejala yang dialami penderitanya berupa kejang epileptik yang berulang. Untuk mendiagnosis epilepsi, ahli neurologi menganalisis rekaman sinyal otak Electroencephalography (EEG) yang diperoleh dari pasien epilepsi. Masalah yang ditemui adalah proses analisis sinyal EEG untuk menentukan kejadian kejang epilepsi dapat memakan waktu cukup lama karena sinyal EEG memiliki karakteristik yang kompleks dan durasi yang panjang. Oleh karena itu, diperlukan sebuah sistem yang mampu melakukan hal tersebut secara otomatis untuk mempermudah pekerjaan para ahli neurologi. Pada tugas akhir ini, dibuat sebuah sistem yang dapat melakukan anotasi kejadian kejang epilepsi pada rekaman sinyal EEG secara otomatis. Sistem tersebut terdiri dari sebuah model deep learning dengan arsitekstur 2D Convolutional Neural Network (CNN) untuk mengklasifikasi segmen-segmen rekaman EEG dan sebuah aplikasi antarmuka yang menampilkan visualisasi sinyal dari input rekaman EEG dan hasil deteksi dari model deep learning tersebut. Dataset Siena Scalp EEG digunakan sebagai input pengembangan model dan diterapkan beberapa tahap preprocessing, seperti penamaan ulang dan pengurangan durasi, down sampling, bipolar montage, filter Butterworth bandpass, dan segmentasi dengan sliding window. Dari tahap preprocessing, diperoleh beberapa variasi input dengan menggunakan beberapa nilai pada variabel window, stride, dan chunk saat proses segmentasi dengan sliding window. Input-input yang dihasilkan digunakan untuk melatih model dengan menerapkan 5-Fold Cross Validation dan teknik augmentasi EEG, seperti time reverse, sign flip, fourier transform surrogate, dan frequency shift. Aplikasi antarmuka dikembangkan menggunakan HTML, CSS, dan JavaScript untuk sisi klien dan Flask untuk sisi server. Dari seluruh uji coba pengembangan model yang telah dilakukan, diperoleh hasil terbaik pada uji coba penerapan teknik augmentasi fourier transform surrogate dengan gangguan fase 0.8 terhadap model dasar 2D-CNN. Pada uji coba tersebut, input window 15 detik dengan stride 2.5 detik memberikan kinerja model terbaik, yaitu accuracy 91.80%, sensitivity 93.25%, specificity 90.37%, dan mean AUC 97%.===================================================================================================================================Epilepsy is a brain disease whose symptoms include recurrent epileptic seizures. To diagnose epilepsy, neurologists analyze Electroencephalography (EEG) brain signal recordings obtained from epilepsy patients. The problem encountered is that the process of analyzing EEG signals to determine the occurrence of epileptic seizures can take a long time because EEG signals have complex characteristics and long duration. Therefore, a system that is able to do this automatically is needed to facilitate the work of neurologists. In this undergraduate thesis, a system that can annotate epileptic seizure events on EEG signal recordings automatically is created. The system consists of a deep learning model with 2D Convolutional Neural Network (CNN) architecture to classify EEG recording segments and an interface application that displays signal visualization of EEG recording input and detection results from the deep learning model. The Siena Scalp EEG dataset is used as input for model development and several preprocessing stages are applied, such as renaming and duration reduction, down sampling, bipolar montage, Butterworth bandpass filter, and segmentation with sliding window. From the preprocessing stage, several input variations were obtained by using several values for the window, stride, and chunk variables during the sliding window segmentation process. The resulting inputs are used to train the model by applying 5-Fold Cross Validation and EEG augmentation techniques, such as time reverse, sign flip, fourier transform surrogate, and frequency shift. The application interface was developed using HTML, CSS, and JavaScript for the client side and Flask for the server side. From all the model development trials that have been conducted, the best results were obtained in the trial of applying the fourier transform surrogate augmentation technique with a phase noise of 0.8 to the 2D-CNN base model. In this trial, the 15-second input window and 2.5 second stride provide the best model performance, namely accuracy of 91.80%, sensitivity of 93.25%, specificity of 90.37%, and mean AUC of 97%.",implementasi 2dcnn teknik augmentasi eeg deteksi kejang epilepsi dataset siena scalp eeg,epilepsi sakit otak gejala alami derita kejang epileptik ulang diagnosis epilepsi ahli neurologi analis rekam sinyal otak electroencephalography eeg oleh pasien epilepsi temu proses analisis sinyal eeg tentu jadi kejang epilepsi makan sinyal eeg milik karakteristik kompleks durasi sistem otomatis mudah kerja ahli neurologi tugas sistem anotasi jadi kejang epilepsi rekam sinyal eeg otomatis sistem model deep learning arsitekstur 2d convolutional neural network cnn klasifikasi segmensegmen rekam eeg aplikasi antarmuka tampil visualisasi sinyal input rekam eeg hasil deteksi model deep learning dataset siena scalp eeg input kembang model terap tahap preprocessing nama ulang kurang durasi down sampling bipolar montage filter butterworth bandpass segmentasi sliding window tahap preprocessing oleh variasi input nilai variabel window stride chunk proses segmentasi sliding window inputinput hasil latih model terap 5fold cross validation teknik augmentasi eeg time reverse sign flip fourier transform surrogate frequency shift aplikasi antarmuka kembang html css javascript sisi klien flask sisi server uji coba kembang model oleh hasil baik uji coba terap teknik augmentasi fourier transform surrogate ganggu fase 08 model dasar 2dcnn uji coba input window 15 detik stride 25 detik kerja model baik accuracy 9180 sensitivity 9325 specificity 9037 mean auc 97epilepsy is a brain disease whose symptoms include recurrent epileptic seizures to diagnose epilepsy neurologists analyze electroencephalography eeg brain signal recordings obtained from epilepsy patients the problem encountered is that the process of analyzing eeg signals to determine the occurrence of epileptic seizures can take a long time because eeg signals have complex characteristics and long duration therefore a system that is able to do this automatically is needed to facilitate the work of neurologists in this undergraduate thesis a system that can annotate epileptic seizure events on eeg signal recordings automatically is created the system consists of a deep learning model with 2d convolutional neural network cnn architecture to classify eeg recording segments and an interface application that displays signal visualization of eeg recording input and detection results from the deep learning model the siena scalp eeg dataset is used as input for model development and several preprocessing stages are applied such as renaming and duration reduction down sampling bipolar montage butterworth bandpass filter and segmentation with sliding window from the preprocessing stage several input variations were obtained by using several values for the window stride and chunk variables during the sliding window segmentation process the resulting inputs are used to train the model by applying 5fold cross validation and eeg augmentation techniques such as time reverse sign flip fourier transform surrogate and frequency shift the application interface was developed using html css and javascript for the client side and flask for the server side from all the model development trials that have been conducted the best results were obtained in the trial of applying the fourier transform surrogate augmentation technique with a phase noise of 08 to the 2dcnn base model in this trial the 15second input window and 25 second stride provide the best model performance namely accuracy of 9180 sensitivity of 9325 specificity of 9037 and mean auc of 97
Integrasi Servqual Dan Quality Function Deployment Sebagai Upaya Peningkatan Pelayanan Minimarket.,"Maslikhan, Akhmad",http://repository.its.ac.id/109569/,"ABSTRAKMinimarket Minimarket menyediakan produk sehari-hari dengan akses mudah dan jam buka panjang, berfungsi tidak hanya sebagai tempat berbelanja tetapi juga sebagai bagian dari perubahan bisnis dan ritel yang beradaptasi dengan kebutuhan masyarakat. Meskipun lebih kecil dari supermarket, minimarket berusaha menyediakan berbagai produk seperti makanan, minuman, barang rumah tangga, buku, dan kitab keagamaan. Tantangan utama yang dihadapi adalah meningkatnya ketidakpuasan pelanggan yang dapat berdampak negatif pada profitabilitas Minimarket Darut Taqwa yang telah beroperasi sejak 2004, menekankan kenyamanan, kepuasan pelanggan, dan pelayanan terbaik, serta bertujuan mengembangkan keterampilan wirausaha di kalangan santri. Untuk mengatasi ketidakpuasan pelanggan, digunakan analisis dengan metode SERVQUAL dan QFD. Penelitian ini menggunakan tujuh aspek penilaian SERVQUAL yaitu tangibility, reliability, responsiveness, assurance, empathy, communication, dan security. QFD digunakan untuk mengintegrasikan keinginan pelanggan yang diverifikasi oleh perusahaan. Hasil analisis QFD menunjukkan nilai Customer Importance tertinggi (4,60) pada indikator ""Biaya/harga produk sesuai dengan kualitas yang diberikan"" dan terendah (4,02) pada indikator ""Pegawai minimarket melantunkan sapaan kepada customer yang baru berkunjung"". Nilai Customer Satisfaction Level (SCL) tertinggi (4,20) pada indikator ""Kesigapan dan ketegasan keamanan dalam mengamankan serta menertibkan area minimarket"" dan terendah (3,69) pada indikator ""Minimarket sering mengadakan event (promo) atau potongan harga"". Pengolahan data menurut penilaian Techical Requirement menyoroti bahwa prioritas perbaikan tertinggi jatuh pada ""Pelatihan Skill Komunikasi oleh Pihak Manajemen"" dengan bobot total 72 (7,16%) karena kontribusinya yang signifikan terhadap peningkatan kepuasan pelanggan. Prioritas kedua adalah ""Pelatihan karyawan dalam melayani konsumen"" dengan bobot 63 (6,27%) untuk meningkatkan keterampilan layanan pelanggan. Prioritas ketiga adalah ""Memberikan pelatihan dan briefing kepada karyawan"" dengan bobot 53 (5,27%) untuk meningkatkan pengetahuan dan pemahaman tugas. Sedangkan prioritas terendah adalah ""Instore Promo sebagai upaya peningkatan penjulan pada periode tertentu"" dengan bobot 5 (0,50%) karena kontribusi yang rendah terhadap peningkatan pelayanan minimarket.",integrasi servqual quality function deployment upaya tingkat layan minimarket,abstrakminimarket minimarket sedia produk seharihari akses mudah jam buka fungsi belanja ubah bisnis ritel adaptasi butuh masyarakat supermarket minimarket usaha sedia produk makan minum barang rumah tangga buku kitab agama tantang utama hadap tingkat ketidakpuasan langgan dampak negatif profitabilitas minimarket darut taqwa operasi 2004 tekan nyaman puas langgan layan baik tuju kembang terampil wirausaha kalang santri atas ketidakpuasan langgan analisis metode servqual qfd teliti tujuh aspek nilai servqual tangibility reliability responsiveness assurance empathy communication security qfd integrasi langgan verifikasi usaha hasil analisis qfd nilai customer importance tinggi 460 indikator biayaharga produk sesuai kualitas rendah 402 indikator pegawai minimarket lantun sapa customer kunjung nilai customer satisfaction level scl tinggi 420 indikator sigap tegas aman aman tertib area minimarket rendah 369 indikator minimarket ada event promo potong harga olah data nilai techical requirement sorot prioritas baik tinggi jatuh latih skill komunikasi manajemen bobot total 72 716 kontribusi signifikan tingkat puas langgan prioritas latih karyawan layan konsumen bobot 63 627 tingkat terampil layan langgan prioritas tiga latih briefing karyawan bobot 53 527 tingkat tahu paham tugas prioritas rendah instore promo upaya tingkat penjulan periode bobot 5 050 kontribusi rendah tingkat layan minimarket
Klasifikasi NSCLC dengan Arsitektur DenseNet dan GLCM Untuk Deteksi Dini Kanker Paru-Paru Pada Citra CT-Scan.,"Maulana, Irgi Azarya Putra",http://repository.its.ac.id/112781/,"Kanker paru-paru atau kanker pulmoner merupakan penyakin yang memiliki variasi keganasan tergantung kondisi. Kanker paru-paru terjadi ketika sel-sel di dalam paru-paru mengalami pertumbuhan yang tidak terkendali dan menjadi ganas. Ada dua jenis kanker paru-paru utama yaitu Non-Small Cell Lung Cancer (NSCLC) dan Small Cell Lung Cancer (SCLC). NSCLC adalah jenis kanker paru-paru yang paling umum, mencakup sekitar 85% dari semua kasus kanker paru-paru. NSCLC terbagi menjadi beberapa subjenis, termasuk Pulmonary Adenocarcinoma (ADC), dan Pulmonary Squamous Cell Carcinoma (SqCC). Sedangkan SCLC lebih jarang terjadi dan tumbuh lebih cepat daripada NSCLC. SCLC juga lebih cenderung menyebar ke bagian tubuh lain pada saat diagnosis dibandingkan NSCLC. Skrining menggunakan CT scan dosis rendah, yang diizinkan saat ini, seringkali memiliki tingkat sensitivitas yang rendah dan tingkat positif palsu yang tinggi. Lebih dari 90% dari hasil positif sebenarnya tidak menunjukkan adanya kanker. Selain itu, saat ini tidak ada biomarker tambahan yang dapat meningkatkan sensitivitas skrining CT dosis rendah, terutama pada pasien yang memiliki nodul paru-paru yang tidak jelas. Maka dari itu pengembangan machine learning untuk pendiagnosaan kanker paru-paru memudahkan pendiagnosaan dan meningkatkan efisiensi dalam pendiagnosaan non-invasif. Menggunakan metode Gray Level Co-occurance Matrix (GLCM) dan Convolutional Neural Network (CNN) menggunakan arsitektur Densely Connected Convolutional Network (DenseNet) yang digabungkan untuk klasifikasi tipe berdasarkan tekstur yang dilihat dari keabuan dan bentuk serta ukuran nodul.=================================================================================================================================Lung cancer, or pulmonary cancer, is a disease with varying degrees of malignancy depending on the condition. Lung cancer occurs when cells within the lungs experience uncontrolled growth and become malignant. There are two primary types of lung cancer: Non-Small Cell Lung Cancer (NSCLC) and Small Cell Lung Cancer (SCLC). NSCLC is the most common type of lung cancer, accounting for approximately 85% of all lung cancer cases. NSCLC is further divided into subtypes, including pulmonary adenocarcinoma (ADC) and pulmonary squamous cell carcinoma (SqCC). In contrast, SCLC is less common and tends to grow more rapidly than NSCLC, with a higher tendency to spread to other parts of the body at the time of diagnosis. Screening using low-dose CT scans, as currently permitted, often has low sensitivity and a high rate of false positives. More than 90% of positive results do not actually indicate the presence of cancer. Additionally, there are currently no additional biomarkers available to improve the sensitivity of low-dose CT screening, particularly for patients with unclear lung nodules. Therefore, the development of machine learning for lung cancer diagnosis would facilitate non-invasive diagnosis and improve diagnostic efficiency. Using methods such as the Gray Level Co-occurrence Matrix (GLCM) and Convolutional Neural Network (CNN) with the DenseNet architecture combined for classification based on texture, grayscale, shape, and size of nodules.",klasifikasi nsclc arsitektur densenet glcm deteksi kanker paruparu citra ctscan,kanker paruparu kanker pulmoner penyakin milik variasi ganas gantung kondisi kanker paruparu selsel paruparu alami tumbuh kendali ganas jenis kanker paruparu utama nonsmall cell lung cancer nsclc small cell lung cancer sclc nsclc jenis kanker paruparu cakup 85 kanker paruparu nsclc bagi subjenis pulmonary adenocarcinoma adc pulmonary squamous cell carcinoma sqcc sclc jarang tumbuh cepat nsclc sclc cenderung sebar tubuh diagnosis banding nsclc skrining ct scan dosis rendah izin seringkali milik tingkat sensitivitas rendah tingkat positif palsu 90 hasil positif kanker biomarker tambah tingkat sensitivitas skrining ct dosis rendah pasien milik nodul paruparu kembang machine learning pendiagnosaan kanker paruparu mudah pendiagnosaan tingkat efisiensi pendiagnosaan noninvasif metode gray level cooccurance matrix glcm convolutional neural network cnn arsitektur densely connected convolutional network densenet gabung klasifikasi tipe dasar tekstur abu bentuk ukur nodullung cancer or pulmonary cancer is a disease with varying degrees of malignancy depending on the condition lung cancer occurs when cells within the lungs experience uncontrolled growth and become malignant there are two primary types of lung cancer nonsmall cell lung cancer nsclc and small cell lung cancer sclc nsclc is the most common type of lung cancer accounting for approximately 85 of all lung cancer cases nsclc is further divided into subtypes including pulmonary adenocarcinoma adc and pulmonary squamous cell carcinoma sqcc in contrast sclc is less common and tends to grow more rapidly than nsclc with a higher tendency to spread to other parts of the body at the time of diagnosis screening using lowdose ct scans as currently permitted often has low sensitivity and a high rate of false positives more than 90 of positive results do not actually indicate the presence of cancer additionally there are currently no additional biomarkers available to improve the sensitivity of lowdose ct screening particularly for patients with unclear lung nodules therefore the development of machine learning for lung cancer diagnosis would facilitate noninvasive diagnosis and improve diagnostic efficiency using methods such as the gray level cooccurrence matrix glcm and convolutional neural network cnn with the densenet architecture combined for classification based on texture grayscale shape and size of nodules
Reidentifikasi Orang pada Data Visible-Infrared Menggunakan Klasifier Swin Transformer.,"Maulana, Muhammad Azhar",http://repository.its.ac.id/111781/,"Reidentifikasi orang menjadi topik penelitian yang sangat hanget dalam beberapa tahun terakhir dalam visi komputer. Dalam penelitian ini mengusulkan pendekatan reidentifikasi orang yang menggunakan klasifier Swin Transformer pada data citra visual-infrared. Swin Transformer, sebuah arsitektur Transformer yang terkenal karena kinerjanya yang unggul dalam tugas-tugas visi komputer dalam citra visible, diadaptasi untuk tugas reidentifikasi orang dalam citra visible-infrared. Dataset visible-infrared yang digunakan pada penelitian ini adalah dataset RegDB, kemudian model Swin Transformer diaplikasikan sebagai klasifier. Pendekatan ini memungkinkan penangkapan fitur yang efektif dari citra visual dan inframerah, memanfaatkan keunggulan Swin Transformer dalam menangkap dependensi lokal dan global.",reidentifikasi orang data visibleinfrared klasifier swin transformer,reidentifikasi orang topik teliti hanget visi komputer teliti usul dekat reidentifikasi orang klasifier swin transformer data citra visualinfrared swin transformer arsitektur transformer kenal kerja unggul tugastugas visi komputer citra visible adaptasi tugas reidentifikasi orang citra visibleinfrared dataset visibleinfrared teliti dataset regdb model swin transformer aplikasi klasifier dekat tangkap fitur efektif citra visual inframerah manfaat unggul swin transformer tangkap dependensi lokal global
Kontrol Formasi Kooperatif dan Penghindaran Rintangan pada Multiple Unmanned Aerial Vehicle dengan Guidance Route dan Artificial Potential Field.,"Maynad, Vincentius Charles",http://repository.its.ac.id/95976/,"Dalam beberapa tahun terakhir, kontrol kooperatif sistem multi-UAV (Unmanned Aerial Vehicle) telah menjadi topik penelitian yang hangat di bidang kontrol penerbangan. Diantaranya, pengendalian formasi dan penghindaran rintangan adalah salah dua tema yang penting untuk diteliti karena kompleksitas kondisi permasalahan yang ingin diselesaikan selalu meningkat seiring waktu. Problema riil ini dapat dimodelkan sebagai permasalahan kontrol penghindaran rintangan pada formasi quadcopter. Sekelompok quadcopter ditugaskan untuk membentuk formasi (berupa bentuk V), bergerak dalam formasi menuju titik tujuan, menghindari tabrakan antar robot, dan menghindari tabrakan dengan rintangan. Model quadcopter yang digunakan adalah Quanser Qdrone dengan enam derajat kebebasan. Quadcopter dikontrol menggunakan fuzzy state feedback controller untuk melacak tujuan. Pada tugas akhir ini dirancang suatu sistem pengaturan formasi menggunakan pendekatan guidance route dengan penghindaran rintangan menggunakan metode Artificial Potential Field (APF). Selain itu, akan dibandingkan dua strategi penghindaran, penghindaran total dan penghindaran minimal. Berdasarkan hasil simulasi, algoritma kontrol yang dikembangkan berhasil melaksanakan tugas pengaturan formasi dan penghindaran rintangan pada sekelompok quadcopter. Hal ini dibuktikan dengan rata-rata indeks performansi formasi bernilai 0.800025 untuk strategi penghindaran total dan 1.2227125 untuk strategi penghindaran minimal serta trayektori masing-masing quadcopteryang bebas tabrakan. ==============================================================================================In recent years, cooperative control of multi-UAV (Unmanned Aerial Vehicle) systems has become a hot research topic in the field of flight control. Among them, formation control and obstacle avoidance are two important themes to study because the complexity of the problem conditions to be solved always increases with time. This real problem can be modeled as an obstacle avoidance control problem in a quadcopter formation. A group of quadcopters is assigned to form a formation (in the form of a V shape), move in formation towards a destination point, avoid collisions between robots, and avoid collisions with obstacles. The quadcopter model used is the Quanser Qdrone with six degrees of freedom. The quadcopter is controlled using a fuzzy state feedback controller to track objectives. In this final project, a formation management system is designed using the guidance route approach with obstacle avoidance using the Artificial Potential Field (APF) method. Moreover, two avoidance strategies will be compared, total avoidance and minimum avoidance. Based on the simulation results, the developed control algorithm successfully performs the task of setting formation and obstacle avoidance on a group of quadcopters. This is evidenced by the average formation performance index of 0.800025 for total avoidance strategy and 1.2227125 for minimum avoidance strategy with the collision-free trajectories of each quadcopter.",kontrol formasi kooperatif hindar rintang multiple unmanned aerial vehicle guidance route artificial potential field,kontrol kooperatif sistem multiuav unmanned aerial vehicle topik teliti hangat bidang kontrol terbang kendali formasi hindar rintang salah tema teliti kompleksitas kondisi masalah selesai tingkat iring problema riil model masalah kontrol hindar rintang formasi quadcopter kelompok quadcopter tugas bentuk formasi bentuk v gerak formasi titik tuju hindar tabrak robot hindar tabrak rintang model quadcopter quanser qdrone enam derajat bebas quadcopter kontrol fuzzy state feedback controller lacak tuju tugas rancang sistem atur formasi dekat guidance route hindar rintang metode artificial potential field apf banding strategi hindar hindar total hindar minimal dasar hasil simulasi algoritma kontrol kembang hasil laksana tugas atur formasi hindar rintang kelompok quadcopter bukti ratarata indeks performansi formasi nila 0800025 strategi hindar total 12227125 strategi hindar minimal trayektori masingmasing quadcopteryang bebas tabrak in recent years cooperative control of multiuav unmanned aerial vehicle systems has become a hot research topic in the field of flight control among them formation control and obstacle avoidance are two important themes to study because the complexity of the problem conditions to be solved always increases with time this real problem can be modeled as an obstacle avoidance control problem in a quadcopter formation a group of quadcopters is assigned to form a formation in the form of a v shape move in formation towards a destination point avoid collisions between robots and avoid collisions with obstacles the quadcopter model used is the quanser qdrone with six degrees of freedom the quadcopter is controlled using a fuzzy state feedback controller to track objectives in this final project a formation management system is designed using the guidance route approach with obstacle avoidance using the artificial potential field apf method moreover two avoidance strategies will be compared total avoidance and minimum avoidance based on the simulation results the developed control algorithm successfully performs the task of setting formation and obstacle avoidance on a group of quadcopters this is evidenced by the average formation performance index of 0800025 for total avoidance strategy and 12227125 for minimum avoidance strategy with the collisionfree trajectories of each quadcopter
Sistem Multi-UAV untuk Pelacakan Multi-Target dalam Ruang Tiga Dimensi.,"Maynad, Vincentius Charles",http://repository.its.ac.id/111865/,"Penelitian ini berkaitan dengan sistem multi-UAV untuk melacak multi-target yang dapat diamati sebagian di lingkungan tiga dimensi yang ber-noise. Permasalahan ini biasa ditemui dalam sistem pertahanan dan pengawasan. Penelitian yang dilakukan merupakan perluasan dari penelitian-penelitian terdahulu yang berfokus terutama pada pengaturan dua dimensi, dapat diamati sepenuhnya, dan atau terukur secara sempurna. Target dimodelkan sebagai sistem linear time-invariant dengan noise Gaussian dan UAV pengejar direpresentasikan dalam model standar enam derajat kebebasan. Persamaan yang diperlukan untuk menggambarkan hubungan antara observasi mengenai target dan state pengejar diturunkan dan direpresentasikan sebagai model Gauss-Markov. Target yang dapat diobservasi sebagian mengharuskan para pengejarnya untuk mempertahankan nilai-nilai keyakinan untuk posisi target. Di hadapan lingkungan yang ber-noise, extended Kalman filter digunakan untuk memperkirakan dan memperbarui keyakinan tersebut. Algoritma Multi-Agent Reinforcement Learning (MARL) terdesentralisasi yang dikenal sebagai Soft Double Q-Learning diusulkan untuk mempelajari kontrol koordinasi di antara para pengejar. Algoritma ini diperkaya dengan regulasi entropi untuk melatih kebijakan stokastik tertentu dan memungkinkan interaksi antar pengejar untuk mendorong perilaku kooperatif. Pengembangan ini mendorong algoritma untuk melakukan eksplorasi area pencarian yang lebih luas dan tidak diketahui yang penting untuk sistem pelacakan multi-target. Algoritma dilatih sebelum diterapkan untuk menyelesaikan beberapa skenario. Percobaan menggunakan berbagai kemampuan sensor menunjukkan bahwa algoritma yang diusulkan memiliki tingkat keberhasilan yang lebih tinggi dibandingkan dengan algoritma dasarnya, hingga 4 kali lipat pada skenario tertentu. Penjelasan tentang banyak perbedaan antara lingkungan dua dimensi dan tiga dimensi juga disediakan.=======================================================================================================This research deals with multi-UAV systems to track partially observable multi-targets in a noisy three-dimensional environment. This problem is commonly encountered in defense and surveillance systems.It is a far extension from previous research which focused primarily on two-dimensional, fully observable, and or perfect measurement settings. The targets are modeled as a linear time-invariant system with Gaussian noise and the pursuers UAV are represented in a standard six degrees of freedom model. The equations required to describe the relationship between observations regarding the targets and the pursuer’sstate are derived and represented as a Gauss-Markov model. Partially observable targets require pursuers to maintain belief values for the target position. In the presence of a noisy environment, an extended Kalman filter is used to imagine and describe the belief. A decentralized Multi-Agent Reinforcement Learning (MARL) algorithm known as Soft Double Q-Learning is proposed to study coordination control among pursuers. The algorithm is enriched with entropy regulation to train specific stochastic policies and allows interaction between pursuers to encourage cooperative behavior. This development encourages the algorithm to perform exploration of wider and unknown search areas which is important for multi-target tracking systems. The algorithm is trained before being applied to complete several scenarios. Experiments using various sensor capabilities show that the proposed algorithm has a higher success rate compared to the baseline algorithm, up to 4 times in certain scenarios. An explanation of the many differences between two-dimensional and three-dimensional environments is also provided",sistem multiuav lacak multitarget ruang dimensi,teliti kait sistem multiuav lacak multitarget amat lingkung dimensi bernoise masalah temu sistem tahan awas teliti luas penelitianpenelitian fokus atur dimensi amat sepenuh ukur sempurna target model sistem linear timeinvariant noise gaussian uav kejar representasi model standar enam derajat bebas sama gambar hubung observasi target state kejar turun representasi model gaussmarkov target observasi harus kejar tahan nilainilai yakin posisi target hadap lingkung bernoise extended kalman filter baru yakin algoritma multiagent reinforcement learning marl desentralisasi kenal soft double qlearning usul ajar kontrol koordinasi kejar algoritma kaya regulasi entropi latih bijak stokastik interaksi kejar dorong perilaku kooperatif kembang dorong algoritma eksplorasi area cari luas sistem lacak multitarget algoritma latih terap selesai skenario coba mampu sensor algoritma usul milik tingkat hasil banding algoritma dasar 4 kali lipat skenario jelas beda lingkung dimensi dimensi disediakanthis research deals with multiuav systems to track partially observable multitargets in a noisy threedimensional environment this problem is commonly encountered in defense and surveillance systemsit is a far extension from previous research which focused primarily on twodimensional fully observable and or perfect measurement settings the targets are modeled as a linear timeinvariant system with gaussian noise and the pursuers uav are represented in a standard six degrees of freedom model the equations required to describe the relationship between observations regarding the targets and the pursuer  sstate are derived and represented as a gaussmarkov model partially observable targets require pursuers to maintain belief values for the target position in the presence of a noisy environment an extended kalman filter is used to imagine and describe the belief a decentralized multiagent reinforcement learning marl algorithm known as soft double qlearning is proposed to study coordination control among pursuers the algorithm is enriched with entropy regulation to train specific stochastic policies and allows interaction between pursuers to encourage cooperative behavior this development encourages the algorithm to perform exploration of wider and unknown search areas which is important for multitarget tracking systems the algorithm is trained before being applied to complete several scenarios experiments using various sensor capabilities show that the proposed algorithm has a higher success rate compared to the baseline algorithm up to 4 times in certain scenarios an explanation of the many differences between twodimensional and threedimensional environments is also provided
Identifikasi  dan Klasifikasi  Tingkat Ketidakseimbangan Statis Sela Udara Motor Induksi Berbasis Transformasi Wavelet Arus Stator.,"Mualim, Latif",http://repository.its.ac.id/82331/,"Tugas akhir ini membahas tentang pengidentifikasian dan klasifikasi ketidakseimbangan sela udara pada motor induksi dengan menggunakan transformasi wavelet diskrit yang mana dari wavelet ini diambil nilai statistik dari level tertentu komponen transformasi wavelet untuk dijadikan nilai input pada analisa jaringan saraf tiruan. Dengan memanfaatkan nntool pada MATLAB dibuatlah neuron network dengan input berupa 12 nilai statistik dan target data berupa kondisi motor. Neuron network yang sudah di training menggunakan data arus yang diukur pada tugas akhir ini. Hasilnya adalah neuron network mampu mengidentifikasi dan mengklasifikasi data arus untuk mengetahui keadaan motor tetapi terbatas hanya pada motor induksi yang digunakan pada tugas akhir ini karena keterbatasan data arus dari motor lain =====================================================================================================This final project discusses the identification and classification of airgap eccentricity in induction motors using discrete wavelet transforms, from which the statistical values of certain levels of wavelet transform components are taken to be used as input values in the analysis of artificial neural networks. By utilizing nntool in MATLAB, a neuron network was created with input in the form of 12 statistical values and target data in the form of motor conditions. Neuron networks that have been trained use current data measured in this final project. The result is that the neuron network is able to identify and classify current data of induction motor but it is limited to the induction motor used in this final project due to the limitation of current data from other motors.",identifikasi klasifikasi tingkat ketidakseimbangan statis udara motor induksi bas transformasi wavelet arus stator,tugas bahas identifikasi klasifikasi ketidakseimbangan udara motor induksi transformasi wavelet diskrit wavelet ambil nilai statistik level komponen transformasi wavelet jadi nilai input analisa jaring saraf tiru manfaat nntool matlab buat neuron network input 12 nilai statistik target data kondisi motor neuron network training data arus ukur tugas hasil neuron network identifikasi klasifikasi data arus motor batas motor induksi tugas batas data arus motor this final project discusses the identification and classification of airgap eccentricity in induction motors using discrete wavelet transforms from which the statistical values of certain levels of wavelet transform components are taken to be used as input values in the analysis of artificial neural networks by utilizing nntool in matlab a neuron network was created with input in the form of 12 statistical values and target data in the form of motor conditions neuron networks that have been trained use current data measured in this final project the result is that the neuron network is able to identify and classify current data of induction motor but it is limited to the induction motor used in this final project due to the limitation of current data from other motors
Rancang Bangun Sistem Elektronik untuk Menyimak dan Mengetes Hafalan Al-Quran Berbasis Arabic Speech to Text dan Metode Levenshtein Distance.,"Muayyad, Ahmad Saad",http://repository.its.ac.id/87298/,"Al-Quran merupakan kitab suci agama Islam yang secara luas dibaca, dihafalkan, dipelajari, dan diajarkan oleh para pemeluknya. Indonesia merupakan negara dengan pemeluk agama Islam terbanyak di dunia, maka jumlah institusi dimana Al-Quran itu dihafal dan diajarkan juga sangat banyak. Berdasarkan hal tersebut, pada Tugas Akhir ini telah dibuat sebuah sistem untuk menyimak dan mengetes hafalan Al-Quran. Sistem ini menggunakan Arabic Speech-to-Text untuk mengubah input suara menjadi teks bahasa Arab, yang kemudian dibandingkan dengan data teks Al-Quran menggunakan metode Levenshtein Distance. Bila nilai perbandingan antara input dan data teks yang tersimpan melewati batas dan logika yang sudah didesain, maka sistem akan memberikan peringatan melalui output berupa suara dan tampilan visual. Sistem yang dirancang diimplementasikan menggunakan Raspberry Pi 3B+ yang dilengkapi dengan microphone, buzzer, dan Touch Screen Display. Sistem elektronik ini menggunakan data Al-Quran yang diinput secara manual dan data Al-Quran dari PyQuran sebagai rujukan. Dihasilkan persentase error sebesar 0,45% untuk penggunaan data manual dan 3,52% untuk penggunaan data PyQuran dalam pengujian 3 halaman di juz pertama Al-Quran. Latency rata-rata yang dihasilkan untuk satu kata yang diproses dengan kecepatan internet 10 Mbps adalah 0,1292 s. Kedepannya, kualitas sistem koreksi dapat ditambahkan terutama untuk PyQuran agar sistem elektronik ini dapat digunakan untuk 30 juz Al-Quran secara lengkap sehingga dapat membantu para penghafal Al-Quran =====================================================================================================Al-Quran is Islam’s Holy Book that widely recited, memorized, studied, and taught by its followers. Indonesia is a country with the largest number of Muslim, in which many intitutions where Al-Quran are memorized and taught. Based on that, in this Final Project, an electronic system for correcting and testing Al-Quran memorization was designed. This system uses Arabic Speech-to-Text to convert audio input to Arabic text that was compared to Al-Quran text data with Levenshtein Distance Method. If the comparison value between audio input and Al-Quran text data exceeds the limit and logic that has been designed, the system will give a warning by audio and visual output. This system is designed using Raspberry Pi 3B+ equipped with microphone, buzzer, and Touch Screen Display. This electronic system uses Al-Quran data that manually input and PyQuran data as its reference. An error percentage of 0,45% was obtained using Al-Quran manual data and 3,52% was obtained using PyQuran data for 3 pages from the first juz testing. Average latency that was obtained for each word processing for 10 Mbps internet speed is 0,1292 s. In the future research, the quality of correction system can be upgraded especially for PyQuran so this system can be used for 30 juz perfectly and will be a huge benefit for Al-Quran memorizer.",rancang bangun sistem elektronik simak ketes hafal alquran bas arabic speech to text metode levenshtein distance,alquran kitab suci agama islam luas baca hafal ajar ajar peluk indonesia negara peluk agama islam dunia institusi mana alquran hafal ajar dasar tugas sistem simak ketes hafal alquran sistem arabic speechtotext ubah input suara teks bahasa arab banding data teks alquran metode levenshtein distance nilai banding input data teks simpan lewat batas logika desain sistem ingat output suara tampil visual sistem rancang implementasi raspberry pi 3b lengkap microphone buzzer touch screen display sistem elektronik data alquran diinput manual data alquran pyquran rujuk hasil persentase error 045 guna data manual 352 guna data pyquran uji 3 halaman juz alquran latency ratarata hasil proses cepat internet 10 mbps 01292 s depan kualitas sistem koreksi pyquran sistem elektronik 30 juz alquran lengkap bantu hafal alquran alquran is islam  s holy book that widely recited memorized studied and taught by its followers indonesia is a country with the largest number of muslim in which many intitutions where alquran are memorized and taught based on that in this final project an electronic system for correcting and testing alquran memorization was designed this system uses arabic speechtotext to convert audio input to arabic text that was compared to alquran text data with levenshtein distance method if the comparison value between audio input and alquran text data exceeds the limit and logic that has been designed the system will give a warning by audio and visual output this system is designed using raspberry pi 3b equipped with microphone buzzer and touch screen display this electronic system uses alquran data that manually input and pyquran data as its reference an error percentage of 045 was obtained using alquran manual data and 352 was obtained using pyquran data for 3 pages from the first juz testing average latency that was obtained for each word processing for 10 mbps internet speed is 01292 s in the future research the quality of correction system can be upgraded especially for pyquran so this system can be used for 30 juz perfectly and will be a huge benefit for alquran memorizer
Prediksi Financial Distress Perusahaan Sektor Industri di Indonesia dengan Metode Klasifikasi dan Melibatkan Synthetic Features Generation.,"Muda, Muhammad Adlansyah",http://repository.its.ac.id/83474/,"Masalah kondisi financial distress dapat berakhir dengan kebangkrutan apabila tidak segera ditanggulangi. Untuk mengantisipasi dan meminimalisir dampak dari bangkrutnya suatu perusahaan terutama pada sektor industri, maka dilakukan prediksi financial distress untuk menilai kondisi keuangan perusahaan dan perspektif masa depannya. Pada penelitian ini prediksi financial distress dilakukan dengan metode klasifikasi seperti Generalized Extreme Value Regression, Logistic Regression, Support Vector Machine, dan Extreme Gradient Boosting dengan melibatkan synthetic features generation secara serentak dan seleksi variabel. Berdasarkan nilai accuracy, AUC, dan F1-score dari hasil evaluasi model menggunakan data testing didapatkan bahwa metode synthetic features generation tidak selalu memberikan performansi klasifikasi terbaik pada tiap size. Pada size 0 dan size 1 disimpulkan bahwa model Extreme Gradient Boosting dengan melibatkan synthetic features generation dan seleksi variabel merupakan model dengan performansi klasifikasi terbaik, sedangkan pada size 2 dan size 3 didapatkan bahwa model Extreme Gradient Boosting tanpa melibatkan synthetic features generation dengan seleksi variabel merupakan model dengan performansi klasifikasi terbaik dalam memprediksi kondisi keuangan perusahaan sektor industri di Indonesia.====================================================================================================================The problem of financial distress can lead to bankruptcy if it is not addressed immediately. To anticipate and minimize the impact of a company bankruptcy, especially in the industrial sector, financial distress predictions are made to assess the company’s financial condition and its future perspective. In this study, prediction of financial distress is carried out using classification methods such as Generalized Extreme Value Regression, Logistic Regression, Support Vector Machine, and Extreme Gradient Boosting by involving synthetic features generation simultaneously and variable selection. Based on the accuracy, AUC, and F1-score from the results of model evaluation using data testing, it is found that the synthetic features generation method does not always provide the best classification performance for each size. At size 0 and size 1, it can be concluded that the Extreme Gradient Boosting model involving synthetic features generation with variable selection is the model with the best classification performance, whereas at size 2 and size 3, it is found that the Extreme Gradient Boosting model without involving synthetic features generation with variabel selection is the model with the best classification performance in predicting the financial condition of industrial sector companies in Indonesia.",prediksi financial distress usaha sektor industri indonesia metode klasifikasi libat synthetic features generation,kondisi financial distress bangkrut tanggulang antisipasi meminimalisir dampak bangkrut usaha sektor industri prediksi financial distress nilai kondisi uang usaha perspektif depan teliti prediksi financial distress metode klasifikasi generalized extreme value regression logistic regression support vector machine extreme gradient boosting libat synthetic features generation serentak seleksi variabel dasar nilai accuracy auc f1score hasil evaluasi model data testing dapat metode synthetic features generation performansi klasifikasi baik size size 0 size 1 simpul model extreme gradient boosting libat synthetic features generation seleksi variabel model performansi klasifikasi baik size 2 size 3 dapat model extreme gradient boosting libat synthetic features generation seleksi variabel model performansi klasifikasi baik prediksi kondisi uang usaha sektor industri indonesiathe problem of financial distress can lead to bankruptcy if it is not addressed immediately to anticipate and minimize the impact of a company bankruptcy especially in the industrial sector financial distress predictions are made to assess the company  s financial condition and its future perspective in this study prediction of financial distress is carried out using classification methods such as generalized extreme value regression logistic regression support vector machine and extreme gradient boosting by involving synthetic features generation simultaneously and variable selection based on the accuracy auc and f1score from the results of model evaluation using data testing it is found that the synthetic features generation method does not always provide the best classification performance for each size at size 0 and size 1 it can be concluded that the extreme gradient boosting model involving synthetic features generation with variable selection is the model with the best classification performance whereas at size 2 and size 3 it is found that the extreme gradient boosting model without involving synthetic features generation with variabel selection is the model with the best classification performance in predicting the financial condition of industrial sector companies in indonesia
Secure Indoor Positioning System Model Menggunakan Serangan Boundary Attack Berbasis Aplikasi Mobile.,"Muhammad, Banabil Fawazaim",http://repository.its.ac.id/106076/,"Selama dekade terakhir, perangkat seluler telah berevolusi tidak hanya berfungsi sebagai komunikasi jarak jauh, namun juga sebagai perangkat navigasi menggunakan Global Positioning System (GPS). Karena keterbatasan GPS dalam ruangan, dikembangkan IPS (Indoor Positioning System) sebagai pengganti dari GPS pada saat di dalam ruangan.  Studi ini menyoroti kurangnya perhatian terhadap keamanan dan privasi dalam pengembangan IPS, terutama dalam menghadapi serangan keamanan seperti serangan Boundary Attack.  Penelitian ini bertujuan untuk membuat IPS yang tahan terhadap serangan Boundary Attack dengan mengembangkan model menggunakan data sidik jari Channel State Information (CSI).  Tujuan dari penelitian ini mencakup membandingkan kinerja antara model IPS dan model rekan terhadap serangan serangan perimeter, dan mengintegrasikan model dengan aplikasi seluler untuk menampilkan lokasi pengguna secara real time. Metode penelitiannya antara lain mengumpulkan dataset dari Tower 2 ITS, membangun dan melatih model IPS menggunakan data yang diserang dan tidak diserang, menerapkan serangan Boundary Attack, dan membuat aplikasi seluler terintegrasi.  Hasil penelitian meliputi evaluasi akurasi model sebelum dan sesudah serangan serta perbandingan dengan model pembanding dalam kondisi serangan. Model IPS berhasil dibangun yang dapat menahan serangan Boundary Attack dan menjaga akurasi bahkan setelah serangan tersebut. Membandingkan model IPS dengan model pembanding menunjukkan ketahanan yang baik terhadap serangan.  Dengan mengintegrasikan aplikasi mobile dengan IPS melalui Flask, pengguna dapat melihat lokasinya dengan akurasi tinggi dan real time.=================================================================================================================================Over the past decade, mobile devices have evolved to function not only as long-distance communication, but also as navigation devices using the Global Positioning System (GPS). Due to the limitations of indoor GPS, IPS (Indoor Positioning System) was developed as a replacement for GPS when indoors. This study highlights the lack of attention to security and privacy in the development of IPS, especially in the face of security attacks such as Boundary Attack. This research aims to create an IPS that is resistant to Boundary Attack by developing a model using Channel State Information (CSI) fingerprint data. The objectives of this research include comparing the performance between the IPS model and the peer model against perimeter attack attacks, and integrating the model with a mobile application to display the user's location in real time. The research methods included collecting datasets from Tower 2 ITS, building and training the IPS model using attacked and unattacked data, applying the Boundary Attack, and creating an integrated mobile application. The results include an evaluation of the accuracy of the model before and after the attack as well as a comparison with the comparison model under attack conditions. An IPS model was successfully built that can withstand Boundary Attack attacks and maintain accuracy even after such attacks. Comparing the IPS model with the comparison model shows good resistance to attacks. By integrating a mobile application with the IPS through Flask, users can view their location with high accuracy and in real time.",secure indoor positioning system model serang boundary attack bas aplikasi mobile,dekade perangkat seluler evolusi fungsi komunikasi jarak perangkat navigasi global positioning system gps batas gps ruang kembang ips indoor positioning system ganti gps ruang studi sorot kurang perhati aman privasi kembang ips hadap serang aman serang boundary attack teliti tuju ips tahan serang boundary attack kembang model data sidik jari channel state information csi tuju teliti cakup banding kerja model ips model rekan serang serang perimeter integrasi model aplikasi seluler tampil lokasi guna real time metode teliti kumpul dataset tower 2 its bangun latih model ips data serang serang terap serang boundary attack aplikasi seluler integrasi hasil teliti liput evaluasi akurasi model serang banding model banding kondisi serang model ips hasil bangun tahan serang boundary attack jaga akurasi serang banding model ips model banding tahan serang integrasi aplikasi mobile ips flask guna lokasi akurasi real timeover the past decade mobile devices have evolved to function not only as longdistance communication but also as navigation devices using the global positioning system gps due to the limitations of indoor gps ips indoor positioning system was developed as a replacement for gps when indoors this study highlights the lack of attention to security and privacy in the development of ips especially in the face of security attacks such as boundary attack this research aims to create an ips that is resistant to boundary attack by developing a model using channel state information csi fingerprint data the objectives of this research include comparing the performance between the ips model and the peer model against perimeter attack attacks and integrating the model with a mobile application to display the users location in real time the research methods included collecting datasets from tower 2 its building and training the ips model using attacked and unattacked data applying the boundary attack and creating an integrated mobile application the results include an evaluation of the accuracy of the model before and after the attack as well as a comparison with the comparison model under attack conditions an ips model was successfully built that can withstand boundary attack attacks and maintain accuracy even after such attacks comparing the ips model with the comparison model shows good resistance to attacks by integrating a mobile application with the ips through flask users can view their location with high accuracy and in real time
Sistem Informasi Pengelolaan Keuangan Sekolah (Sipks) Dengan Electronic Dan Digital Signature Recognition Menggunakan Algoritma MobileNet.,"Mukhlishah, Chaniyah Zulfa",http://repository.its.ac.id/83295/,"Pengelolaan anggaran sekolah merupakan aktivitas yang sering dilakukan di berbagai Sekolah, terutama sekolah negeri. Pengelolaan anggaran pun dapat mencakup dalam berbagai hal. Seperti kegiatan penganggaran dana akademik, organisasi, maupun administrasi yang mutlak membutuhkan alokasi dana dalam pelaksanaannya. Oleh karena itu, kegiatan pengelolaan keuangan sekolah membutuhkan perhatian, terutama dalam hal teknis pelaksanaannya agar dapat diimplementasikan lebih mudah. Pada era digital saat ini, metode penganggaran dana yang manual merupakan sebuah permasalahan dimana metode manual ini sering dikhawatirkan oleh pihak sekolah dalam hal pencatatan dan keamanannya.",sistem informasi kelola uang sekolah sipks electronic digital signature recognition algoritma mobilenet,kelola anggar sekolah aktivitas sekolah sekolah negeri kelola anggar cakup giat anggar dana akademik organisasi administrasi mutlak butuh alokasi dana laksana giat kelola uang sekolah butuh perhati teknis laksana implementasi mudah era digital metode anggar dana manual masalah mana metode manual khawatir sekolah catat aman
Aplikasi Discrete Wavelets Transform pada Analisis Regresi Spektrum Tumpang Tindih Senyawa Parasetamol dan Kafein.,"Mulyaningtias, Nadia",http://repository.its.ac.id/90046/,"Obat umumnya berisi kombinasi dari beberapa senyawa aktif. Parasetamol sering digunakan sebagai obat analgesik dan anti piretik. Kafein adalah stimulan sistem saraf pusat (SSP). Dalam pemasaran obat sakit kepala di masyarakat, pemeriksaan mutu obat diperlukan untuk menjamin bahwa obat menggandung bahan aktif dengan mutu dan jumlah sesuai dengan kandungan yang tertera pada label obat. Sehingga diperlukan metode yang efisien tanpa pemisahan, dengan bantuan spektrofotometer UV-Vis, metode Discrete Wavelets Transform dan analisis multikomponen. Sebanyak 25 larutan training set disiapkan dan dianalisis absorbansinya menggunakan metode Multiple Linier Regression, metode Support Vector Regression (SVR), metode Partial Least Square (PLS) Regression, metode AdaBoost Regression. Model yang didapat divalidasi dengan tes data sebelum diaplikasikan pada obat sakit kepala. Penentuan kadar obat yang sesuai dengan kadar dalam label obat, yaitu pada metode Support Vector Regression dimana rata-rata kadar obat prediksi parasetamol sebesar 512,5473 mg dan pada kafein sebesar 67,1091 mg. Sehingga metode berhasil digunakan untuk menetapkan kadar dalam tablet obat sakit kepala.=======================================================================================================Medicine generally contain active ingredients. Paracetamol is often used as an analgesic and anti-pyretic medicine. Caffeine is a central nervous system (CNS) stimulant. In marketing headache medicine in the community, quality inspection of medicine is needed to ensure that the medicine contains active ingredients with the quality and quantity according to the content stated on the medicine label. So an efficient method without separation is needed, with the help of a UV-Vis spectrophotometer, the Discrete Wavelets Transform method and multivariate analysis. A total of 25 training set solutions were prepared and their absorbance analyzed using the Multiple Linear Regression method, the Support Vector Regression (SVR) method, the Partial Least Square (PLS) Regression method, the AdaBoost Regression method. The model obtained was validated by testing the data before it was applied to headache medicine. Determination of medicine levels in accordance with the levels on the medicine label, namely the Support Vector Regression method where the average level of the predicted medicine parasetamol is 512.5473 mg and the caffeine is 67.1091 mg. So that the method was successfully used to determine the levels in headache medicine tablets.",aplikasi discrete wavelets transform analisis regresi spektrum tumpang tindih senyawa parasetamol kafein,obat isi kombinasi senyawa aktif parasetamol obat analgesik anti piretik kafein stimulan sistem saraf pusat ssp pasar obat sakit kepala masyarakat periksa mutu obat jamin obat gandung bahan aktif mutu sesuai kandung tera label obat metode efisien pisah bantu spektrofotometer uvvis metode discrete wavelets transform analisis multikomponen 25 larut training set siap analis absorbansinya metode multiple linier regression metode support vector regression svr metode partial least square pls regression metode adaboost regression model divalidasi tes data aplikasi obat sakit kepala tentu kadar obat sesuai kadar label obat metode support vector regression mana ratarata kadar obat prediksi parasetamol 5125473 mg kafein 671091 mg metode hasil tetap kadar tablet obat sakit kepalamedicine generally contain active ingredients paracetamol is often used as an analgesic and antipyretic medicine caffeine is a central nervous system cns stimulant in marketing headache medicine in the community quality inspection of medicine is needed to ensure that the medicine contains active ingredients with the quality and quantity according to the content stated on the medicine label so an efficient method without separation is needed with the help of a uvvis spectrophotometer the discrete wavelets transform method and multivariate analysis a total of 25 training set solutions were prepared and their absorbance analyzed using the multiple linear regression method the support vector regression svr method the partial least square pls regression method the adaboost regression method the model obtained was validated by testing the data before it was applied to headache medicine determination of medicine levels in accordance with the levels on the medicine label namely the support vector regression method where the average level of the predicted medicine parasetamol is 5125473 mg and the caffeine is 671091 mg so that the method was successfully used to determine the levels in headache medicine tablets
Optimasi Convolutional Neural Network melalui Fungsi Aktivasi dan Inisialisasi Kernel untuk Pengenalan Tulisan Huruf Hijaiyah.,"Nasty, Khairuddin",http://repository.its.ac.id/117839/,"Penelitian ini mengoptimalkan model Convolutional Neural Network (CNN) untuk pengenalan tulisan tangan huruf Hijaiyah dengan menganalisis kombinasi fungsi aktivasi (ReLU, Leaky ReLU, Sigmoid, Tanh) dan metode inisialisasi kernel (He normal, He uniform, LeCun normal, LeCun uniform, Glorot normal, Glorot uniform). Dataset yang digunakan adalah Hossam Magdy Balaha Dataset (HMBD) yang dimodifikasi—dengan penambahan tanda baca fathah, kasrah, dan dhammah—untuk mengevaluasi 24 kombinasi parameter. Hasil eksperimen menunjukkan bahwa kombinasi He normal-ReLU mencapai performa terbaik dengan akurasi 93,84%, presisi 93,96%, recall 93,77%, dan F1-score 93,71%. Analisis konvergensi mengungkapkan kombinasi ini stabil setelah epoch ke-10, dengan validation loss di bawah 0,5, serta fluktuasi akurasi kurang dari ±1%. Kesalahan klasifikasi tertinggi terjadi pada pasangan dengan kemiripan visual, yaitu Ain fathah-Haa fathah (14,63%) yang diidentifikasi melalui confusion matrix. Konversi model ke TensorFlow Lite berhasil mengurangi ukuran dari 29,4 MB menjadi 9,8 MB (66,67%) tanpa penurunan performa, dengan akurasi tetap 93,84%. Temuan ini membuktikan bahwa optimasi inisialisasi kernel dan fungsi aktivasi secara signifikan meningkatkan akurasi dan efisiensi model, sekaligus memberikan panduan implementasi CNN untuk aplikasi mobile edukasi berbasis tulisan tangan non-Latin.==================================================================================================================================This study optimized a Convolutional Neural Network (CNN) model for recognizing handwritten Hijaiyah characters by analyzing combinations of activation functions (ReLU, Leaky ReLU, Sigmoid, Tanh) and kernel initialization methods (He normal, He uniform, LeCun normal, LeCun uniform, Glorot normal, Glorot uniform). The modified Hossam Magdy Balaha Dataset (HMBD)—augmented with diacritical marks (fathah, kasrah, dhammah)—was used to evaluate 24 parameter combinations. Experimental results demonstrated that the He normal-ReLU combination achieved the best performance, with 93.84% accuracy, 93.96% precision, 93.77% recall, and 93.71% F1-score. Convergence analysis revealed this combination stabilized after the 10th epoch, with validation loss below 0.5 and accuracy fluctuations within ±1%. The highest misclassification rate (14.63%) occurred between visually similar pairs, specifically Ain fathah-Haa fathah, as identified through confusion matrices. Model conversion to TensorFlow Lite successfully reduced its size from 29.4 MB to 9.8 MB (66.67%) without performance degradation, maintaining 93.84% accuracy. These findings prove that optimizing kernel initialization and activation functions significantly enhances model accuracy and efficiency, while providing a practical guideline for implementing CNNs in mobile-based educational applications for non-Latin handwriting recognition.",optimasi convolutional neural network fungsi aktivasi inisial kernel kenal tulis huruf hijaiyah,teliti optimal model convolutional neural network cnn kenal tulis tangan huruf hijaiyah analis kombinasi fungsi aktivasi relu leaky relu sigmoid tanh metode inisial kernel he normal he uniform lecun normal lecun uniform glorot normal glorot uniform dataset hossam magdy balaha dataset hmbd modifikasi dengan tambah tanda baca fathah kasrah dhammah untuk evaluasi 24 kombinasi parameter hasil eksperimen kombinasi he normalrelu capai performa baik akurasi 9384 presisi 9396 recall 9377 f1score 9371 analisis konvergensi kombinasi stabil epoch ke10 validation loss 05 fluktuasi akurasi 1 salah klasifikasi tinggi pasang mirip visual ain fathahhaa fathah 1463 identifikasi confusion matrix konversi model tensorflow lite hasil kurang ukur 294 mb 98 mb 6667 turun performa akurasi 9384 temu bukti optimasi inisial kernel fungsi aktivasi signifikan tingkat akurasi efisiensi model pandu implementasi cnn aplikasi mobile edukasi bas tulis tangan nonlatinthis study optimized a convolutional neural network cnn model for recognizing handwritten hijaiyah characters by analyzing combinations of activation functions relu leaky relu sigmoid tanh and kernel initialization methods he normal he uniform lecun normal lecun uniform glorot normal glorot uniform the modified hossam magdy balaha dataset hmbd augmented with diacritical marks fathah kasrah dhammah was used to evaluate 24 parameter combinations experimental results demonstrated that the he normalrelu combination achieved the best performance with 9384 accuracy 9396 precision 9377 recall and 9371 f1score convergence analysis revealed this combination stabilized after the 10th epoch with validation loss below 05 and accuracy fluctuations within 1 the highest misclassification rate 1463 occurred between visually similar pairs specifically ain fathahhaa fathah as identified through confusion matrices model conversion to tensorflow lite successfully reduced its size from 294 mb to 98 mb 6667 without performance degradation maintaining 9384 accuracy these findings prove that optimizing kernel initialization and activation functions significantly enhances model accuracy and efficiency while providing a practical guideline for implementing cnns in mobilebased educational applications for nonlatin handwriting recognition
Penyaringan Surel Bersifat Spam Dengan Menggunakan Online Active Ensemble Learning.,"Naufal, Muhammad Rafif Fadhil",http://repository.its.ac.id/107850/,"Surel merupakan salah satu bentuk komunikasi yang sangat umum digunakan di seluruh dunia. Hal ini mengakibatkan traffic keluar-masuk surel yang berkembang di tiap tahunnya. Salah satu masalah yang sering terjadi pada surel adalah adanya surel yang bersifat spam. Spam merupakan surel yang tidak diinginkan oleh penerimanya dan biasanya berisi iklan, penipuan, atau konten yang tidak senonoh. Penyaringan surel merupakan salah satu upaya mewujudkan Pembangunan Berkelanjutan (SDGs). Pada Penelitian ini, akan dibuat sebuah model untuk melakukan penyaringan surel bersifat spam dengan menggunakan metode Online Active Ensemble Learning. Metode ini merupakan perpaduan antara online active learning dengan model klasifikasi ensemble. Model ini akan diimplementasikan menggunakan bahasa pemrograman Python. Dataset yang digunakan penelitian ini merupakan dataset public bernama enron-spam. Dataset ini terdiri dari kumpulan email 6 pegawai Enron. Total email yang terdapat pada dataset ini adalah 33.716 email. Hasil eksperimen menunjukkan bahwa model yang menggunakan metode Online Active Ensemble Learning memiliki performa yang lebih baik dibandingkan dengan model single learning. Hal ini ditunjukkan dengan nilai akurasi, presisi, recall, dan f1-score yang lebih tinggi. Selain itu, penggunaan resource yang dibutuhkan untuk melakukan prediksi dan learning juga lebih rendah, sehingga semakin mendukung efisiensi dan keberlanjutan. Kesimpulannya, metode Online Active Ensemble Learning dapat digunakan untuk melakukan penyaringan surel bersifat spam dengan performa yang baik dan efisien dalam penggunaan resource, sehingga turut berkontribusi terhadap pencapaian beberapa SDGs.============================================================================================================================Email is one of the most common forms of communication used worldwide, leading to a growing volume of incoming and outgoing email traffic each year. One of the recurring issues with email is the presence of spam, which refers to unwanted emails typically containing advertisements, scams, or inappropriate content. Email filtering is one approach to realizing Sustainable Development Goals (SDGs). In this research, a model will be developed to filter spam emails using the Online Active Ensemble Learning method, which combines online active learning with ensemble classification models. This model will be implemented using the Python programming language. The dataset used in this study is a public dataset called enron-spam, consisting of a collection of emails from six Enron employees totaling 33,716 emails. Experimental results indicate that the model utilizing the Online Active Ensemble Learning method outperforms single learning models, as evidenced by higher accuracy, precision, recall, and f1-score values. Additionally, the resource requirements for prediction and learning are lower, further supporting efficiency and sustainability. In conclusion, the Online Active Ensemble Learning method can be employed for effective and resource-efficient spam email filtering, thereby contributing to the achievement of several SDGs.",nyaring surel sifat spam online active ensemble learning,surel salah bentuk komunikasi dunia akibat traffic keluarmasuk surel kembang tahun salah surel surel sifat spam spam surel terima isi iklan tipu konten senonoh nyaring surel salah upaya wujud bangun lanjut sdgs teliti model nyaring surel sifat spam metode online active ensemble learning metode padu online active learning model klasifikasi ensemble model implementasi bahasa pemrograman python dataset teliti dataset public nama enronspam dataset kumpul email 6 pegawai enron total email dataset 33716 email hasil eksperimen model metode online active ensemble learning milik performa banding model single learning nilai akurasi presisi recall f1score guna resource butuh prediksi learning rendah dukung efisiensi lanjut simpul metode online active ensemble learning nyaring surel sifat spam performa efisien guna resource kontribusi capai sdgsemail is one of the most common forms of communication used worldwide leading to a growing volume of incoming and outgoing email traffic each year one of the recurring issues with email is the presence of spam which refers to unwanted emails typically containing advertisements scams or inappropriate content email filtering is one approach to realizing sustainable development goals sdgs in this research a model will be developed to filter spam emails using the online active ensemble learning method which combines online active learning with ensemble classification models this model will be implemented using the python programming language the dataset used in this study is a public dataset called enronspam consisting of a collection of emails from six enron employees totaling 33716 emails experimental results indicate that the model utilizing the online active ensemble learning method outperforms single learning models as evidenced by higher accuracy precision recall and f1score values additionally the resource requirements for prediction and learning are lower further supporting efficiency and sustainability in conclusion the online active ensemble learning method can be employed for effective and resourceefficient spam email filtering thereby contributing to the achievement of several sdgs
Segmentasi Jantung Pada Citra Short-Axis View Magnetic Resonance Imaging Menggunakan 2D U-Net.,"Nindita, Nabil Virio Akhsan",http://repository.its.ac.id/108687/,"Penyakit kardiovaskular merupakan masalah kesehatan yang signifikan secara global, menyebabkan banyak kematian, terutama disebabkan oleh penyakit jantung. Diagnosis penyakit jantung yang akurat dan tepat waktu sangat penting untuk pengobatan yang efektif. Adanya kemajuan teknologi medis telah meningkatkan pemahaman dan pengambilan tindakan terhadap penyakit tersebut. Penelitian ini berfokus pada segmentasi struktur jantung pada citra Short Axis Magnetic Resonance Imaging ( SAX MRI) menggunakan model deep learning dengan arsitektur U-Net 2D. Tujuan utama dari penelitian ini adalah untuk mengembangkan model deep learning yang dapat mensegmentasi struktur jantung, yaitu ventrikel kiri (LV), ventrikel kanan (RV), dan miokardium. Penelitian ini menggunakan dataset Automated Cardiac Diagnosis Challenge (ACDC) 2017, yang mencakup pemindaian MRI dari 150 pasien dengan berbagai kondisi jantung. Model segmentasi berbasis U-Net 2D yang diusulkan diharapkan menghasilkan akurasi tinggi, sehingga berpotensi untuk memberi manfaat bagi penanganan penyakit jantung. Berdasarkan pengujian yang telah dilakukan dari skenario-skenario penelitian didapatkan hasil Dice dan IoU Score oleh model sebesar 0,8806 dan 0,7663.=================================================================================================================================Segmentasi Cardiovascular disease is a significant health problem globally, causing many deaths , mainly caused by heart disease. Accurate and timely diagnosis of heart disease is essential for effective treatment. Advances in medical technology have improved the understanding and treatment of these diseases. This research focuses on segmenting cardiac structures in Short Axis Magnetic Resonance Imaging (SAX MRI) images using deep learning model with 2D U-Net architecture. The main objective of this research is to develop a deep learning model that can segment the heart structures, namely the left ventricle (LV), right ventricle (RV), and myocardium. This study uses the Automated Cardiac Diagnosis Challenge (ACDC) 2017 dataset, which includes MRI scans of 150 patients with various heart conditions. The proposed 2D U-Net-based segmentation model is expected to yield high accuracy, potentially benefiting the treatment of heart disease. Based on the tests that have been carried out from the scenarios of this research the Dice and IoU Score results obtained by the model are 0,8806 and 0,7663.Jantung Pada Citra Short-Axis View Magnetic Resonance Imaging Menggunakan 2d U-Net",segmentasi jantung citra shortaxis view magnetic resonance imaging 2d unet,sakit kardiovaskular sehat signifikan global sebab mati sebab sakit jantung diagnosis sakit jantung akurat obat efektif maju teknologi medis tingkat paham ambil tindak sakit teliti fokus segmentasi struktur jantung citra short axis magnetic resonance imaging sax mri model deep learning arsitektur unet 2d tuju utama teliti kembang model deep learning segmentasi struktur jantung ventrikel kiri lv ventrikel kanan rv miokardium teliti dataset automated cardiac diagnosis challenge acdc 2017 cakup pindai mri 150 pasien kondisi jantung model segmentasi bas unet 2d usul harap hasil akurasi potensi manfaat tangan sakit jantung dasar uji skenarioskenario teliti dapat hasil dice iou score model 08806 07663segmentasi cardiovascular disease is a significant health problem globally causing many deaths mainly caused by heart disease accurate and timely diagnosis of heart disease is essential for effective treatment advances in medical technology have improved the understanding and treatment of these diseases this research focuses on segmenting cardiac structures in short axis magnetic resonance imaging sax mri images using deep learning model with 2d unet architecture the main objective of this research is to develop a deep learning model that can segment the heart structures namely the left ventricle lv right ventricle rv and myocardium this study uses the automated cardiac diagnosis challenge acdc 2017 dataset which includes mri scans of 150 patients with various heart conditions the proposed 2d unetbased segmentation model is expected to yield high accuracy potentially benefiting the treatment of heart disease based on the tests that have been carried out from the scenarios of this research the dice and iou score results obtained by the model are 08806 and 07663jantung citra shortaxis view magnetic resonance imaging 2d unet
Intergrasi Nonlinear Programming (NLP) dan Cost Benefit Analysis (CBA) untuk Pengelolaan Limbah Fly Ash Dan Bottom Ash (FABA) Industri Pupuk (Studi Kasus : PT. Pupuk Indonesia).,"Nubail, Ahmad Azrial",http://repository.its.ac.id/107885/,"Limbah Fly Ash dan Bottom Ash (FABA) pada industri pupuk berdasarkan PP No 22 Tahun 2021 tidak termasuk dalam kategori B3 dimana proses pembakaran batubaranya menggunakan teknologi tungku industri (stocker boiler). Dengan PP No 22 Tahun 2021, maka perlu dilakukan penelitian untuk menentukan skema pengelolaan limbah FABA terbaik antara kondisi eksisting dan skenario perbaikan dengan mempertimbangkan manfaat optimal dari setiap opsi pengelolaan limbah FABA. Perlu dilakukan Cost-Benefit Analysis, menghitung Benefit-Cost Ratio, dan dilanjutkan dengan analisis sensitivitas untuk menghilangkan satu solusi yang mendominasi dari skenario yang dipilih untuk mendapatkan skema pengelolaan terbaik. Untuk melakukan perhitungan dan analisis diperlukan kajian terkait Pupuk Indonesia dan anak perusahaan terkait, pengelolaan FABA, Cost-Benefit Analysis (CBA), Nonlinier Programming (NLP), dan analisis sensitivitas. Berdasarkan analisis kondisi eksisting proses bisnis pengelolaan limbah, diperoleh empat skenario pengelolaan limbah FABA untuk masing-masing perusahaan. Dari keempat skenario perbaikan, dipilih dua skenario untuk dilakukan analisis lanjutan. Kedua skenario tersebut adalah kondisi eksisting dan skenario yang berfokus pada kerjasama pengelolaan limbah FABA dengan mengoptimalkan manfaat yang diperoleh. Hasil perhitungan menunjukkan bahwa dengan skenario perbaikan, biaya pengelolaan limbah yang dikeluarkan oleh perusahaan dapat turun hingga 60% dari kondisi eksisting. Perhitungan Benefit-Cost Ratio (BCR) dari skenario perbaikan untuk masing-masing perusahaan menghasilkan angka dari 1.109 hingga 1.602 dalam kondisi ideal. Pada skenario perbaikan, dilakukan analisis sensitivitas, dan ditemukan bahwa perubahan %bagi hasil dan batas bawah pengelolaan tidak mempengaruhi kelayakan skenario. Sedangkan %penyerapan FABA dan %manfaat lingkungan mempengaruhi kelayakan skenario. Dapat disimpulkan bahwa skenario perbaikan yang diusulkan layak untuk diterapkan dengan mempertimbangkan kondisi masing-masing parameter yang mempengaruhi kelayakan skenario.===================================================================================================================================Fly Ash and Bottom Ash (FABA) waste in the fertilizer industry, based on PP No. 22 of 2021, is excluded from B3 category where the coal combustion process uses industrial furnace technology (stocker boiler). With PP No. 22 of 2021, it is necessary to research to determine the best FABA waste management scheme between existing conditions and improvement scenarios by considering the optimal benefits of each FABA waste management option. It is necessary to do a cost-benefit analysis, calculate the benefit-cost ratio, and proceed with a sensitivity analysis to eliminate one dominating solution from the selected scenario to get the best management scheme. To carry out the necessary calculations and analysis, a study related to Pupuk Indonesia and its related subsidiaries, FABA management, Cost-Benefit Analysis (CBA), Nonlinear Programming (NLP), and sensitivity analysis. Based on the analysis of the existing condition of the existing waste management business process, four FABA waste management scenarios were obtained for each company. From the four scenarios, two scenarios were chosen for further analysis. The two scenarios are the existing condition and the scenario that focuses on cooperation in FABA waste management by optimizing the benefits obtained. The results of the calculations show that with the improvement scenario, the waste management costs incurred by the company can decrease by up to 60% from the existing condition. The calculation of the benefit-cost ratio (BCR) from the improvement scenario for each company produces numbers from 1.109 to 1.602 under ideal conditions. In the improvement scenario, a sensitivity analysis was carried out, and it was found that changes in % profit sharing and the lower management limit did not affect the feasibility of the scenario. Meanwhile, the % absorption of FABA and % environmental benefits influence the feasibility of the scenario. It can be concluded that the proposed improvement scenario is feasible to be applied by considering the conditions of each parameter that affect the feasibility of the scenario.",intergrasi nonlinear programming nlp cost benefit analysis cba kelola limbah fly ash bottom ash faba industri pupuk studi pt pupuk indonesia,limbah fly ash bottom ash faba industri pupuk dasar pp no 22 2021 kategori b3 mana proses bakar batubaranya teknologi tungku industri stocker boiler pp no 22 2021 teliti tentu skema kelola limbah faba baik kondisi eksisting skenario baik timbang manfaat optimal opsi kelola limbah faba costbenefit analysis hitung benefitcost ratio lanjut analisis sensitivitas hilang solusi dominasi skenario pilih skema kelola baik hitung analisis kaji kait pupuk indonesia anak usaha kait kelola faba costbenefit analysis cba nonlinier programming nlp analisis sensitivitas dasar analisis kondisi eksisting proses bisnis kelola limbah oleh skenario kelola limbah faba masingmasing usaha empat skenario baik pilih skenario analisis lanjut skenario kondisi eksisting skenario fokus kerjasama kelola limbah faba optimal manfaat oleh hasil hitung skenario baik biaya kelola limbah keluar usaha turun 60 kondisi eksisting hitung benefitcost ratio bcr skenario baik masingmasing usaha hasil angka 1109 1602 kondisi ideal skenario baik analisis sensitivitas temu ubah hasil batas kelola pengaruh layak skenario serap faba manfaat lingkung pengaruh layak skenario simpul skenario baik usul layak terap timbang kondisi masingmasing parameter pengaruh layak skenariofly ash and bottom ash faba waste in the fertilizer industry based on pp no 22 of 2021 is excluded from b3 category where the coal combustion process uses industrial furnace technology stocker boiler with pp no 22 of 2021 it is necessary to research to determine the best faba waste management scheme between existing conditions and improvement scenarios by considering the optimal benefits of each faba waste management option it is necessary to do a costbenefit analysis calculate the benefitcost ratio and proceed with a sensitivity analysis to eliminate one dominating solution from the selected scenario to get the best management scheme to carry out the necessary calculations and analysis a study related to pupuk indonesia and its related subsidiaries faba management costbenefit analysis cba nonlinear programming nlp and sensitivity analysis based on the analysis of the existing condition of the existing waste management business process four faba waste management scenarios were obtained for each company from the four scenarios two scenarios were chosen for further analysis the two scenarios are the existing condition and the scenario that focuses on cooperation in faba waste management by optimizing the benefits obtained the results of the calculations show that with the improvement scenario the waste management costs incurred by the company can decrease by up to 60 from the existing condition the calculation of the benefitcost ratio bcr from the improvement scenario for each company produces numbers from 1109 to 1602 under ideal conditions in the improvement scenario a sensitivity analysis was carried out and it was found that changes in profit sharing and the lower management limit did not affect the feasibility of the scenario meanwhile the absorption of faba and environmental benefits influence the feasibility of the scenario it can be concluded that the proposed improvement scenario is feasible to be applied by considering the conditions of each parameter that affect the feasibility of the scenario
Pengembangan Model Prediktif Analitik Untuk Menilai Tingkat Maintainabilitas Proyek Perangkat Lunak Di Github.,"Nugroho, Adi",http://repository.its.ac.id/95511/,"Pengembangan proyek perangkat lunak saat ini sudah tidak bisa dilepaskan dari penggunaan library atau produk open source. Terdapat jutaan produk open source dengan fungsi spesifik yang mampu digunakan dan diintegrasikan dalam pengembangan perangkat lunak. Tetapi untuk memilih produk open source yang bagus dan memiliki maintainabilitas yang baik tidaklah mudah. Github sebagai salah satu repositori open source berbasis git, saat ini menyimpan lebih dari 46 juta proyek open source. Pada sebuah repositori proyek open source di Github melekat puluhan fitur yang dapat dianalisis untuk menilai kualitas repositori tersebut. Banyaknya jumlah fitur ini mengakibatkan perlunya keahlian dan pengalaman untuk menilai kualitas repositori. Penelitian sebelumnya menggunakan metode Random Forest untuk menilai tingkat maintainabilitas pada sebuah repositori di Github secara otomatis. Penelitian ini akan memanfaatkan lebih banyak fitur dari repositori di Github serta menggunakan dan membandingkan metode machine learning antara lain Random Forest, Support Vector Machine, Extreme Gradient Boosting dan regresi logistik dalam pembuatan model untuk menilai tingkat maintainabilitas. Model dalam penelitian ini dikembangkan dengan menggunakan 17 variabel prediktor dan satu variabel respon. Hasil dari pengujian model menunjukkan model dari metode Random Forest dan Extreme Gradient Boosting menunjukkan tingkat akurasi yang tinggi masing-masing 94% dan 94,35%. Kedua model juga menunjukkan daftar variabel-variabel prediktor signifikan yang hampir mirip dalam penilaian maintainabilitas.==============================================================================================================================The development of software projects nowadays cannot be separated from open-source libraries or products. There are millions of open-source products with specific functionality that can be used when developing software. But choosing a good open-source product that has good maintainability is not an easy task. Github is one of the git-based open-source repositories and currently stores more than 46 million open-source projects. Lots of Github's repository features can be analyzed the repository quality. But manually assessing a repository's quality by analyzing its features needs skills and experience. Previous research used the Random Forest method to automatically assess the level of maintainability of a Github repository. This study will use more features from the repository and then compare the Random Forest, Support Vector Machine, Extreme Gradient Boosting and Logistic Regression methods in assessing Github's repository maintainability. 17 predictor variables and 1 respond variable were used to create machine learning models. Random Forest's and Extreme Gradient Boosting's models achieved almost similar accuracy rating with 94% and 94.35% respectively. Both models are also displayed almost similar list of significant features in assessing a repository's maintainability.",kembang model prediktif analitik nilai tingkat maintainabilitas proyek perangkat lunak github,kembang proyek perangkat lunak lepas guna library produk open source juta produk open source fungsi spesifik integrasi kembang perangkat lunak pilih produk open source bagus milik maintainabilitas mudah github salah repositori open source bas git simpan 46 juta proyek open source repositori proyek open source github lekat puluh fitur analis nilai kualitas repositori banyak fitur akibat ahli alam nilai kualitas repositori teliti metode random forest nilai tingkat maintainabilitas repositori github otomatis teliti manfaat fitur repositori github banding metode machine learning random forest support vector machine extreme gradient boosting regresi logistik buat model nilai tingkat maintainabilitas model teliti kembang 17 variabel prediktor variabel respon hasil uji model model metode random forest extreme gradient boosting tingkat akurasi masingmasing 94 9435 model daftar variabelvariabel prediktor signifikan nilai maintainabilitasthe development of software projects nowadays can not be separated from opensource libraries or products there are millions of opensource products with specific functionality that can be used when developing software but choosing a good opensource product that has good maintainability is not an easy task github is one of the gitbased opensource repositories and currently stores more than 46 million opensource projects lots of githubs repository features can be analyzed the repository quality but manually assessing a repositorys quality by analyzing its features needs skills and experience previous research used the random forest method to automatically assess the level of maintainability of a github repository this study will use more features from the repository and then compare the random forest support vector machine extreme gradient boosting and logistic regression methods in assessing githubs repository maintainability 17 predictor variables and 1 respond variable were used to create machine learning models random forests and extreme gradient boostings models achieved almost similar accuracy rating with 94 and 9435 respectively both models are also displayed almost similar list of significant features in assessing a repositorys maintainability
Klasifikasi Penutup Lahan Menggunakan DTM dan DSM LiDAR dengan Algoritma Support Vector Machine dan Random Forest (Studi Kasus: Institut Teknologi Sepuluh Nopember Kampus Sukolilo).,"Nuraini, Annisa",http://repository.its.ac.id/109916/,"LiDAR adalah teknologi penginderaan jauh aktif yang memanfaatkan sinar laser untuk mendeteksi objek di permukaan bumi. Airborne LiDAR merupakan salah satu jenis lidar yang menggunakan wahana udara untuk proses penyiaman objek. Dari data LiDAR ini dapat diperoleh Digital Surface Model (DSM) yang selanjutnya dapat diekstrak menjadi Digital Terrain Model (DTM). Dalam perkembangannya untuk pengolahan data LiDAR, telah banyak digunakan perangkat lunak maupun dengan menggunakan algoritma yang dibangun seperti machine learning. Tujuan dari penelitian ini adalah memanfaatkan data LiDAR untuk klasifikasi penutup lahan dengan menggunakan machine learning, yaitu dengan algoritma Support Vector Machine (SVM) dan Random Forest (RF). Klasifikasi yang diterapkan adalah supervised classification dimana dibutuhkan data training untuk melakukan klasifikasi. Kelas penutup lahan yang diprediksi pada penelitian ini terbatas pada objek bangunan, vegetasi, jalan, lahan terbuka, dan badan air. Data yang digunakan untuk klasifikasi adalah data turunan dari LiDAR yaitu DTM dan DSM. Skema klasifikasi yang digunakan adalah dengan input satu data dan kombinasi data, serta diterapkan juga skema splitting ratio training point yaitu 70:30, 75:25, 80:20, dan 90:10. Hasilnya skema input satu data belum memberikan hasil yang optimal. Input kombinasi data memberikan penambahan akurasi dan mengasilkan akurasi yang baik yaitu lebih besar dari 0,80. Hasil terbaik didapat dari input kombinasi data DSM dan DTM rasio training testing 75:25. Pada metode SVM dihasilkan overall accuracy 0,824 dan kappa 0,780. Sedangkan pada metode RF dihasilkan overall accuracy 0,832 dan kappa 0,790. Secara keseluruhan, metode RF memiliki keunggulan dalam mengklasifikasikan objek bangunan dan lahan kosong, sedangkan metode SVM memiliki keunggulan dalam mengklasifikasikan objek jalan.=================================================================================================================================LiDAR is an active remote sensing technology that utilizes laser beams to detect objects on the earth's surface. Airborne LiDAR is one type of lidar that uses airborne vehicles for the object's illumination process. From this LiDAR data, a Digital Surface Model (DSM) can be obtained which can then be extracted into a Digital Terrain Model (DTM). In its development for LiDAR data processing, software has been widely used as well as using algorithms built such as machine learning. The purpose of this research is to utilize LiDAR data for land cover classification using machine learning, namely with Support Vector Machine (SVM) and Random Forest (RF) algorithms. The classification applied is supervised classification where training data is required to perform classification. The predicted land cover classes in this study are limited to building objects, vegetation, roads, open land, and water bodies. The data used for classification is derived from LiDAR data, namely DTM and DSM. The classification scheme used is a single data input and a combination of data, and the splitting ratio training point scheme is also applied, namely 70:30, 75:25, 80:20, and 90:10. The result is that the one data input scheme has not provided optimal results. Input data combination provides additional accuracy and produces good accuracy which is greater than 0.80. The best results are obtained from the input of a combination of DSM and DTM data with a training testing ratio of 75:25. In the SVM method, the overall accuracy is 0.824 and kappa is 0.780. While the RF method produced an overall accuracy of 0.832 and kappa 0.790. Overall, the RF method has an advantage in classifying building objects and vacant land, while the SVM method has an advantage in classifying road objects.",klasifikasi tutup lahan dtm dsm lidar algoritma support vector machine random forest studi institut teknologi puluh nopember kampus sukolilo,lidar teknologi penginderaan aktif manfaat sinar laser deteksi objek muka bumi airborne lidar salah jenis lidar wahana udara proses siam objek data lidar oleh digital surface model dsm ekstrak digital terrain model dtm kembang olah data lidar perangkat lunak algoritma bangun machine learning tuju teliti manfaat data lidar klasifikasi tutup lahan machine learning algoritma support vector machine svm random forest rf klasifikasi terap supervised classification mana butuh data training klasifikasi kelas tutup lahan prediksi teliti batas objek bangun vegetasi jalan lahan buka badan air data klasifikasi data turun lidar dtm dsm skema klasifikasi input data kombinasi data terap skema splitting ratio training point 7030 7525 8020 9010 hasil skema input data hasil optimal input kombinasi data tambah akurasi asil akurasi 080 hasil baik input kombinasi data dsm dtm rasio training testing 7525 metode svm hasil overall accuracy 0824 kappa 0780 metode rf hasil overall accuracy 0832 kappa 0790 metode rf milik unggul klasifikasi objek bangun lahan kosong metode svm milik unggul klasifikasi objek jalanlidar is an active remote sensing technology that utilizes laser beams to detect objects on the earths surface airborne lidar is one type of lidar that uses airborne vehicles for the objects illumination process from this lidar data a digital surface model dsm can be obtained which can then be extracted into a digital terrain model dtm in its development for lidar data processing software has been widely used as well as using algorithms built such as machine learning the purpose of this research is to utilize lidar data for land cover classification using machine learning namely with support vector machine svm and random forest rf algorithms the classification applied is supervised classification where training data is required to perform classification the predicted land cover classes in this study are limited to building objects vegetation roads open land and water bodies the data used for classification is derived from lidar data namely dtm and dsm the classification scheme used is a single data input and a combination of data and the splitting ratio training point scheme is also applied namely 7030 7525 8020 and 9010 the result is that the one data input scheme has not provided optimal results input data combination provides additional accuracy and produces good accuracy which is greater than 080 the best results are obtained from the input of a combination of dsm and dtm data with a training testing ratio of 7525 in the svm method the overall accuracy is 0824 and kappa is 0780 while the rf method produced an overall accuracy of 0832 and kappa 0790 overall the rf method has an advantage in classifying building objects and vacant land while the svm method has an advantage in classifying road objects
Pengembangan Metode Seleksi Fitur Berbasis Chi-Square dan Algoritma Exhaustive untuk Meningkatkan Performa Deteksi pada Jaringan Komputer.,"Nururrahmah, Aulia Teaku",http://repository.its.ac.id/102506/,"Mendeteksi serangan intrusi pada jaringan telah menarik perhatian banyak peneliti. Sejauh ini terdapat dua metode, yakni berbasis signature dan anomaly. Mendeteksi serangan yang berbasis anomaly membutuhkan Machine Learning dalam proses klasifikasinya. Masalah yang banyak diteliti adalah topik tentang bagaimana mereduksi jumlah fitur sebelum dataset diserahkan ke proses klasifikasi. Metode seleksi fitur sendiri dilakukan untuk menentukan fitur relevan dan tidak relevan. Kami mengusulkan metode seleksi fitur berbasis uji chi-square dengan pencarian Exhaustive. Uji Chi-Square digunakan untuk menghitung skor statistik menggunakan uji independence level. Nilai statistik pada masing-masing fitur akan ditentukan relevansinya menggunakan taraf signifikan dan tabel distribusi chi-square. Dari proses uji chi-square maka diperoleh daftar fitur relevan dengan kelas target. Proses selanjutnya adalah mencari kombinasi terbaik antar fitur dengan menggunakan Exhaustive Algorithm. Penelitian ini diuji coba pada empat dataset yakni KDD Cup 99, NSL KDD, Kyoto 2006+, dan UNSW-NB15. Metode klasifikasi yang dimanfaatkan pada penelitian ini adalah Support Vector Machine (SVM), Decision Tree (DT), dan Naïve Bayes (NB). Berdasarkan penelitian yang sudah dilakukan, metode yang diusulkan terbukti memiliki performa yang lebih baik dibanding saat tanpa menggunalan seleksi fitur apapun. Performa terbaik didapatkan pada uji dataset UNSW-NB15 dengan akurasi mencapai 98,71%. Metode yang diusulkan juga melampaui performa dari metode lain===================================================================================================================================Detecting intrusion attacks on networks has attracted the attention of many researchers. So far, there are two methods, namely signature-based and anomaly-based. Detecting anomaly-based attacks requires Machine Learning in the classification process. The feature selection method itself is used to determine relevant and irrelevant features. Irrelevant features will be removed from the feature list. We propose a feature selection method based on the chi-square test with an Exhaustive search. The Chi-Square test is used to calculate statistical scores using the independence level test. The statistical value of each feature will be determined by its relevance using the significant level and the chi-square distribution table. A list of features relevant to the target class is obtained from the chi-square test process. The next process is to find the best combination between features using the Exhaustive Algorithm. This research was tested on four data: KDD Cup 99, NSL KDD, Kyoto 2006+, and UNSW-NB15. The classification methods used in this research are Support Vector Machine (SVM), Decision Tree (DT), and Naïve Bayes (NB). Based on the research that has been done, the proposed method is proven to have better performance than without using any feature selection. The best performance was obtained in the UNSW-NB15 dataset test with an accuracy of 98.71%. The proposed method also surpasses the performance of other methods.",kembang metode seleksi fitur bas chisquare algoritma exhaustive tingkat performa deteksi jaring komputer,deteksi serang intrusi jaring tarik perhati teliti metode bas signature anomaly deteksi serang bas anomaly butuh machine learning proses klasifikasi teliti topik reduksi fitur dataset serah proses klasifikasi metode seleksi fitur tentu fitur relevan relevan usul metode seleksi fitur bas uji chisquare cari exhaustive uji chisquare hitung skor statistik uji independence level nilai statistik masingmasing fitur tentu relevansi taraf signifikan tabel distribusi chisquare proses uji chisquare oleh daftar fitur relevan kelas target proses cari kombinasi baik fitur exhaustive algorithm teliti uji coba dataset kdd cup 99 nsl kdd kyoto 2006 unswnb15 metode klasifikasi manfaat teliti support vector machine svm decision tree dt na ve bayes nb dasar teliti metode usul bukti milik performa banding menggunalan seleksi fitur apa performa baik dapat uji dataset unswnb15 akurasi capai 9871 metode usul lampau performa metode laindetecting intrusion attacks on networks has attracted the attention of many researchers so far there are two methods namely signaturebased and anomalybased detecting anomalybased attacks requires machine learning in the classification process the feature selection method itself is used to determine relevant and irrelevant features irrelevant features will be removed from the feature list we propose a feature selection method based on the chisquare test with an exhaustive search the chisquare test is used to calculate statistical scores using the independence level test the statistical value of each feature will be determined by its relevance using the significant level and the chisquare distribution table a list of features relevant to the target class is obtained from the chisquare test process the next process is to find the best combination between features using the exhaustive algorithm this research was tested on four data kdd cup 99 nsl kdd kyoto 2006 and unswnb15 the classification methods used in this research are support vector machine svm decision tree dt and na ve bayes nb based on the research that has been done the proposed method is proven to have better performance than without using any feature selection the best performance was obtained in the unswnb15 dataset test with an accuracy of 9871 the proposed method also surpasses the performance of other methods
Aplikasi Deteksi Kejadian di Jalan Raya berdasarkan Data Twitter Menggunakan Metode Support Vector Machine.,"Oktavia, Vessa Rizky",http://repository.its.ac.id/50014/,"Twitter adalah salah satu media sosial yang populer belakangan ini. Salah satu karakteristik penting dari Twitter adalah layanannya yang bersifat fleksibel yaitu dapat diakses di mana saja dan kapan saja. Sebagai contoh, saat terjadi suatu kecelakaan atau kemacetan, banyak pengguna Twitter yang mengirimkan  informasi (tweets) tentang kejadian tersebut kepada Twitter. Hal ini memungkinkan dibuatnya sebuah sistem yang mendeteksi terjadinya kecelakaan atau kemacetan dengan melakukan observasi kepada tweet yang masuk.Dalam tugas akhir ini, tweet akan diambil menggunakan Twitter API dan dimasukkan ke dalam sebuah database. Selanjutnya, akan dilakukan preproses yang meliputi stemming, penghapusan stopwords, dan tokenizing. Selain itu, dilakukan juga labeling untuk menentukan kelas dari tweet (kecelakaan, kemacetan, atau lain-lain). Selanjutnya akan dilakukan ekstraksi fitur agar fitur dari setiap tweet dapat menjadi input dalam proses klasifikasi. Untuk mengklasifikasikan tweet, diimplementasikan sebuah metode klasifikasi Support Vector Machine dan parameter regularisasi berupa variabel nu. Model klasifikasi yang dibangun awalnya memberikan nilai akurasi 95,15%. Uji coba dilakukan dengan mengubah kernel dan parameter nu untuk menghasilkan akurasi yang terbaik. Berdasarkan hasil uji coba yang telah dilakukan, didapatkan hasil terbaik dari sistem dengan akurasi 96,25% dengan klasifikasi menggunakan metode SVM dengan menggunakan Kernel Sigmoid dan parameter nu sebesar 0,2.======================================================================================================Twitter is one of the most popular social media lately. One of the important characteristics of Twitter is its flexible service that can be accessed anywhere and anytime. For example, when an accident or traffic jam occurs, many Twitter users are sending tweets about the event to the Twitter. This allows the creation of a system that detects accident or congestion by observing the incoming tweets.In this thesis, tweet will be taken by using Twitter API and put into a database. Next, a preprocess will be done that includes stemming, stopwords removal, and tokenizing. In addition, there is also a labeling to determine the class of tweets (accidents, congestion, or others). Furthermore, feature extraction will be performed so that the features of each tweet can be the input to perform the classification process. To classify tweets, used a Support Vector Machine classification method andnu variable as a regularization parameters.The classification model that was originally built gave an accuracy of 95.15%. The test is done by changing the kernel and the nu parameters to produce the best accuracy. Based on result of experiment which have done, the best result from system is claimed with accuracy 96,25% by using classification using SVM method using Sigmoid Kernel and the number of parameter nu is 0,2.",aplikasi deteksi jadi jalan raya dasar data twitter metode support vector machine,twitter salah media sosial populer salah karakteristik twitter layan sifat fleksibel akses contoh celaka macet guna twitter kirim informasi tweets jadi twitter sistem deteksi celaka macet observasi tweet masukdalam tugas tweet ambil twitter api masuk database preproses liput stemming hapus stopwords tokenizing labeling tentu kelas tweet celaka macet lainlain ekstraksi fitur fitur tweet input proses klasifikasi klasifikasi tweet implementasi metode klasifikasi support vector machine parameter regularisasi variabel nu model klasifikasi bangun nilai akurasi 9515 uji coba ubah kernel parameter nu hasil akurasi baik dasar hasil uji coba dapat hasil baik sistem akurasi 9625 klasifikasi metode svm kernel sigmoid parameter nu 02twitter is one of the most popular social media lately one of the important characteristics of twitter is its flexible service that can be accessed anywhere and anytime for example when an accident or traffic jam occurs many twitter users are sending tweets about the event to the twitter this allows the creation of a system that detects accident or congestion by observing the incoming tweetsin this thesis tweet will be taken by using twitter api and put into a database next a preprocess will be done that includes stemming stopwords removal and tokenizing in addition there is also a labeling to determine the class of tweets accidents congestion or others furthermore feature extraction will be performed so that the features of each tweet can be the input to perform the classification process to classify tweets used a support vector machine classification method andnu variable as a regularization parametersthe classification model that was originally built gave an accuracy of 9515 the test is done by changing the kernel and the nu parameters to produce the best accuracy based on result of experiment which have done the best result from system is claimed with accuracy 9625 by using classification using svm method using sigmoid kernel and the number of parameter nu is 02
Multi-Objective Vehicle Routing Problem with Time Window and Drones (MO-VRPTW-D) Menggunakan Algoritma Simulated Annealing dan Ant Colony Optimization untuk Last-Mile Delivery.,"Pamungkas, Meidani Nuzul Tri",http://repository.its.ac.id/93815/,"Drone adalah kendaraan udara tanpa awak yang saat ini sedang marak digunakan dalam bidang fotografi dan bidang lainnya. Dalam kondisi khusus, drone digunakan untuk kendaraan logistik di mana barang-barang harus diangkut oleh truk yang dilengkapi dengan drone karena bentuk lahannya atau bahkan karena lokasinya vertikal (seperti apartemen, hotel, dll) yang tentunya tidak dapat dijangkau oleh truk. Multi-Objective Vehicle Routing Problem with Time Window and Drones (MO-VRPTW-D), di mana tujuannya adalah meminimasi biaya dengan cara mencari rute yang optimal agar konsumsi energi truk, konsumsi energi drone, dan jumlah truk yang dibutuhkan minimal. Problem ini menjadi kompleks apabila jumlah destinasi yang dikunjungi banyak. Pendekatan metaheuristik diperlukan untuk menyelesaikan problem ini karena kompleksitas yang tinggi walaupun solusi yang dihasilkan belum tentu optimal global. Algoritma Simulated Annealing dan Ant Colony Optimization dipilih karena terbukti cukup efektif untuk menyelesaikan problem kombinatorial semacam penentuan rute. Inovasi ini dapat diadopsi oleh perusahaan jasa pengiriman pada masa mendatang karena pengiriman akan menjadi lebih efisien, cepat, dan mengurangi biaya secara signifikan. Eksperimen dilakukan dalam 24 skenario dengan jumlah pelanggan 25 – 200. Algoritma ACO mampu menghasilkan solusi lebih baik daripada Algoritma SA sebanyak 15 dari total 24 skenario.================================================================================================Drone is remote controlled aerial vehicle that is currently being widely used in photography and other fields. In special conditions, drones are used for logistics vehicles where goods must be transported by trucks equipped with drones because of the shape of the land or even because of its vertical location (such as apartments, hotels, etc.) Multi-Objective Vehicle Routing Problem with Time Window and Drones (MO-VRPTW-D), where the goal is to minimize costs by finding the optimal route so that truck energy consumption, drone energy consumption, and the number of trucks needed are minimal. This problem becomes complex if the number of destinations visited is large. A metaheuristic approach is needed to solve this problem because of its high complexity, although the resulting solution is not necessarily global optimal. The Simulated Annealing and Ant Colony Optimization Algorithm was chosen because it proved to be quite effective in solving combinatorial problems such as route determination. This innovation can be applied by shipping service companies in the future because shipping will be more efficient, faster, and reduce costs significantly. Experiments were carried out in 24 scenarios with the number of customers 25 – 200. The ACO Algorithm was able to produce a better solution than the SA Algorithm by 15 out of a total of 24 scenarios.",multiobjective vehicle routing problem with time window and drones movrptwd algoritma simulated annealing ant colony optimization lastmile delivery,drone kendara udara awak marak bidang fotografi bidang kondisi khusus drone kendara logistik barangbarang angkut truk lengkap drone bentuk lahan lokasi vertikal apartemen hotel dll jangkau truk multiobjective vehicle routing problem with time window and drones movrptwd tuju meminimasi biaya cari rute optimal konsumsi energi truk konsumsi energi drone truk butuh minimal problem kompleks destinasi kunjung dekat metaheuristik selesai problem kompleksitas solusi hasil optimal global algoritma simulated annealing ant colony optimization pilih bukti efektif selesai problem kombinatorial tentu rute inovasi adopsi usaha jasa kirim kirim efisien cepat kurang biaya signifikan eksperimen 24 skenario langgan 25  200 algoritma aco hasil solusi algoritma sa 15 total 24 skenariodrone is remote controlled aerial vehicle that is currently being widely used in photography and other fields in special conditions drones are used for logistics vehicles where goods must be transported by trucks equipped with drones because of the shape of the land or even because of its vertical location such as apartments hotels etc multiobjective vehicle routing problem with time window and drones movrptwd where the goal is to minimize costs by finding the optimal route so that truck energy consumption drone energy consumption and the number of trucks needed are minimal this problem becomes complex if the number of destinations visited is large a metaheuristic approach is needed to solve this problem because of its high complexity although the resulting solution is not necessarily global optimal the simulated annealing and ant colony optimization algorithm was chosen because it proved to be quite effective in solving combinatorial problems such as route determination this innovation can be applied by shipping service companies in the future because shipping will be more efficient faster and reduce costs significantly experiments were carried out in 24 scenarios with the number of customers 25  200 the aco algorithm was able to produce a better solution than the sa algorithm by 15 out of a total of 24 scenarios
Implementasi Text Mining pada Data Perhotelan Menggunakan Support Vector Machine (SVM) dan Analisis Topik dengan Model Probabilistik.,"Panjaitan, Yana Rezki Kriswin",http://repository.its.ac.id/91857/,"Kota Bogor merupakan kota yang berpotensi menjadi objek wisata. Covid-19 menyebar secara masif keseluruh dunia termasuk Indonesia sehingga pemerintah mengambil kebijakan seluruh kegiatan dilakukan dari rumah. Perubahan tatanan kehidupan tersebut memberikan tantangan baru bagi pihak hotel untuk tidak memakai cara konvensional seperti kuesioner dalam mengetahui kepuasan tamu sehingga memaksa pihak hotel menggunakan media yang ada salah satunya situs TripAdvisor. Situs ini memuat harga, tipe hotel, ulasan pengunjung dan sebagainya. Hal ini membuat tamu tidak kesulitan mencari informasi hotel, sedangkan pihak hotel diuntungkan dengan ulasan yang ada. Namun jumlah ulasan yang banyak menyita waktu untuk memahami satu persatu ulasan, sehingga diperlukan text mining. Dalam proses text mining ulasan diklasifikasikan terlebih dahulu menjadi sentimen positif dan negatif menggunakan metode SVM. Klasifikasi hanya memberi informasi sentimen positif atau negatif, sehingga dibutuhkan LDA dan LSA untuk menemukan informasi tersembunyi guna mengetahui kepuasan tamu pada pelayanan hotel. Model klasifikasi terbaik dalam penelitian ini menggunakan SVM kernel linear pada data yang telah diatasi imbalancednya dengan SMOTE. Metode LDA menghasilkan topic coherence lebih tinggi dibanding LSA sehingga membentuk topik positif pada Novotel adalah breakfast dan dinner, hotel dapat menjadi tempat rapat, makanan variatif dan hotel ramah anak. Sedangkan topik negatifnya proses high season lambat, makanan habis tidak langsung di refill, hotel tidak sesuai dengan informasi booking online, area kolam pria dan wanita tidak dibedakan, akses menuju tempat bermain anak, drainage tidak baik, paving tidak rata, bau pesing, kamar deluxe kurang baik, bathup teras duduk mengkhawatirkan. Topik positif Grand Savero adalah sarapan variatif, pelayanan cepat, menu enak, ramah anak, konsep indoor modern, booking mudah, terdapat aneka bubur dan buah, kinerja team bagus, fasilitas lengkap, dan ruangan yang segar dan bersih, sedangkan topik negatifnya proses reserve dan akses menuju area hotel sulit dan extra bed berbayar. Topik positif pada Aston adalah menu breakfast variatif dan enak serta hotel ramah anak, sedangkan topik negatifnya sikap staf, menu dinner tidak sesuai harga, fying fox berbayar, area balkon bau, suara mengganggu, request tidak sesuai, tempat bermain anak rusak, bising, perabotan kamar kurang. =====================================================================================================Bogor City is a city that has the potential to become a tourist attraction. Covid-19 has spread massively throughout the world, including Indonesia, so the government has made a policy that all activities are carried out from home. The change in the order of life provides a new challenge for the hotel not to use conventional methods such as questionnaires to determine guest satisfaction, thus forcing the hotel to use media, one of which is the TripAdvisor site. This site contains prices, hotel types, visitor reviews and so on. This makes it easy for guests to find hotel information, while the hotel benefits from existing reviews. However, the large number of reviews takes time to understand one by one review, so text mining is needed. In the text mining process, reviews are classified first into positive and negative sentiments using the SVM method. Classification only provides information on positive or negative sentiments, so LDA and LSA are needed to find hidden information to find out guest satisfaction with hotel services. The best classification model in this study uses a linear kernel SVM on data that has been overcome with SMOTE imbalancednya. The LDA method produces higher topic coherence than LSA so that it forms positive topics at Novotel, namely breakfast and dinner, hotels can be used as meeting places, varied food and child-friendly hotels. While the negative topics are the slow high season process, food runs out not immediately refilled, hotels do not match online booking information, male and female pool areas are not distinguished, access to children's playgrounds, drainage is not good, paving is uneven, urine smells, deluxe rooms not good, the sitting terrace bathtub is worrying. The positive topics of Grand Savero are varied breakfasts, fast service, delicious menus, child friendly, modern indoor concepts, easy booking, there are various porridge and fruit, good team performance, complete facilities, and fresh and clean rooms, while the negative topics are the reserve process and access to the hotel area is difficult and extra beds are paid. Positive topics at Aston are varied and delicious breakfast menus and child-friendly hotels, while the negative topics are staff attitudes, dinner menus don't match the price, paid fying fox, smelly balcony area, annoying sound, inappropriate requests, damaged children's play area, noise, furniture less room.",implementasi text mining data hotel support vector machine svm analisis topik model probabilistik,kota bogor kota potensi objek wisata covid19 sebar masif seluruh dunia indonesia perintah ambil bijak giat rumah ubah tatanan hidup tantang hotel pakai konvensional kuesioner puas tamu paksa hotel media salah satu situs tripadvisor situs muat harga tipe hotel ulas unjung tamu sulit cari informasi hotel hotel untung ulas ulas sita paham satu ulas text mining proses text mining ulas klasifikasi sentimen positif negatif metode svm klasifikasi informasi sentimen positif negatif butuh lda lsa temu informasi sembunyi puas tamu layan hotel model klasifikasi baik teliti svm kernel linear data atas imbalancednya smote metode lda hasil topic coherence banding lsa bentuk topik positif novotel breakfast dinner hotel rapat makan variatif hotel ramah anak topik negatif proses high season lambat makan habis langsung refill hotel sesuai informasi booking online area kolam pria wanita beda akses main anak drainage paving bau pesing kamar deluxe bathup teras duduk khawatir topik positif grand savero sarap variatif layan cepat menu enak ramah anak konsep indoor modern booking mudah aneka bubur buah kerja team bagus fasilitas lengkap ruang segar bersih topik negatif proses reserve akses area hotel sulit extra bed bayar topik positif aston menu breakfast variatif enak hotel ramah anak topik negatif sikap staf menu dinner sesuai harga fying fox bayar area balkon bau suara ganggu request sesuai main anak rusak bising perabot kamar bogor city is a city that has the potential to become a tourist attraction covid19 has spread massively throughout the world including indonesia so the government has made a policy that all activities are carried out from home the change in the order of life provides a new challenge for the hotel not to use conventional methods such as questionnaires to determine guest satisfaction thus forcing the hotel to use media one of which is the tripadvisor site this site contains prices hotel types visitor reviews and so on this makes it easy for guests to find hotel information while the hotel benefits from existing reviews however the large number of reviews takes time to understand one by one review so text mining is needed in the text mining process reviews are classified first into positive and negative sentiments using the svm method classification only provides information on positive or negative sentiments so lda and lsa are needed to find hidden information to find out guest satisfaction with hotel services the best classification model in this study uses a linear kernel svm on data that has been overcome with smote imbalancednya the lda method produces higher topic coherence than lsa so that it forms positive topics at novotel namely breakfast and dinner hotels can be used as meeting places varied food and childfriendly hotels while the negative topics are the slow high season process food runs out not immediately refilled hotels do not match online booking information male and female pool areas are not distinguished access to childrens playgrounds drainage is not good paving is uneven urine smells deluxe rooms not good the sitting terrace bathtub is worrying the positive topics of grand savero are varied breakfasts fast service delicious nus child friendly modern indoor concepts easy booking there are various porridge and fruit good team performance complete facilities and fresh and clean rooms while the negative topics are the reserve process and access to the hotel area is difficult and extra beds are paid positive topics at aston are varied and delicious breakfast nus and childfriendly hotels while the negative topics are staff attitudes dinner nus dont match the price paid fying fox smelly balcony area annoying sound inappropriate requests damaged childrens play area noise furniture less room
Implementasi Model Formal untuk Rekonstruksi Peristiwa Forensik Digital.,"Pardede, Immanuel Maruli Tua",http://repository.its.ac.id/117622/,"Penggunaan perangkat digital yang makin meluas telah berdampak pada berbagai sektor, termasuk peningkatan kompleksitas kejahatan siber. Hal ini mendorong hadirnya penelitian tentang analisis forensik digital yang lebih variatif. Analisis forensik digital sering kali menghadapi tantangan seperti ukuran data yang besar dan sifat data yang heterogen. Sementara itu, metode konvensional memiliki keterbatasan dalam menangani data besar dan heterogen, sehingga memerlukan pendekatan alternatif. Penelitian ini mengusulkan implementasi model formal berbasis ontologi untuk mendukung rekonstruksi peristiwa forensik digital. Data digital yang dikumpulkan dianalisis menggunakan Aljabar Interval Allen, yang memungkinkan penentuan hubungan temporal antarperistiwa. Model ini tidak hanya mampu menyusun peristiwa secara kronologis, tetapi juga menganalisis hubungan semantik dan temporal antarentitas yang terlibat dalam peristiwa tersebut. Dengan menggunakan metode yang terstruktur, penelitian ini menganalisis studi kasus dugaan penyalahgunaan sumber daya perusahaan oleh seorang karyawan. Hasil penelitian menunjukkan bahwa model formal berbasis ontologi efektif untuk mendukung proses rekonstruksi peristiwa dan menghasilkan bukti digital yang kredibel. Penelitian ini membuktikan bahwa model formal berbasis ontologi dapat digunakan untuk memproses jejak digital, menerapkan model formal, dan mengukur kinerja rekonstruksi peristiwa dalam konteks forensik digital.==============================================================================================================================The increasingly widespread use of digital devices has had an impact on various sectors, including the increasing complexity of cyber crime. This has encouraged the presence of more varied research on digital forensic analysis. Digital forensic analysis often faces challenges such as large data sizes and heterogeneous data nature. Meanwhile, conventional methods have limitations in handling large and heterogeneous data, requiring alternative approaches. This study proposes the implementation of an ontology-based formal model to support digital forensic event reconstruction. The digital data collected uses Allen Interval Algebra, which allows the determination of temporal relationships between events. This model is not only able to organize events chronologically, but also analyzes the semantic and temporal relationships between entities involved in the event. Using a structured method, this study analyzes a case study of alleged corporate resource context by an employee. The results of the study show that an ontology-based formal model is effective in supporting the event reconstruction process and producing credible digital evidence. This study proves that an ontology-based formal model can be used to process digital traces, apply formal models, and measure event reconstruction performance in the context of digital forensics.",implementasi model formal rekonstruksi peristiwa forensik digital,guna perangkat digital luas dampak sektor tingkat kompleksitas jahat siber dorong hadir teliti analisis forensik digital variatif analisis forensik digital kali hadap tantang ukur data sifat data heterogen metode konvensional milik batas tangan data heterogen dekat alternatif teliti usul implementasi model formal bas ontologi dukung rekonstruksi peristiwa forensik digital data digital kumpul analis aljabar interval allen tentu hubung temporal antarperistiwa model susun peristiwa kronologis analis hubung semantik temporal antarentitas libat peristiwa metode struktur teliti analis studi duga penyalahgunaan sumber daya usaha karyawan hasil teliti model formal bas ontologi efektif dukung proses rekonstruksi peristiwa hasil bukti digital kredibel teliti bukti model formal bas ontologi proses jejak digital terap model formal ukur kerja rekonstruksi peristiwa konteks forensik digitalthe increasingly widespread use of digital devices has had an impact on various sectors including the increasing complexity of cyber crime this has encouraged the presence of more varied research on digital forensic analysis digital forensic analysis often faces challenges such as large data sizes and heterogeneous data nature meanwhile conventional methods have limitations in handling large and heterogeneous data requiring alternative approaches this study proposes the implementation of an ontologybased formal model to support digital forensic event reconstruction the digital data collected uses allen interval algebra which allows the determination of temporal relationships between events this model is not only able to organize events chronologically but also analyzes the semantic and temporal relationships between entities involved in the event using a structured method this study analyzes a case study of alleged corporate resource context by an employee the results of the study show that an ontologybased formal model is effective in supporting the event reconstruction process and producing credible digital evidence this study proves that an ontologybased formal model can be used to process digital traces apply formal models and measure event reconstruction performance in the context of digital forensics
Klasifikasi Multi-label Dangerous User Berdasarkan Fitur Struktural Twitter.,"Parwata, Anak Agung Yatestha",http://repository.its.ac.id/106584/,"Dangerous speech, atau ujaran berbahaya merupakan suatu ujaran yang dapat meningkatkan risiko seseorang atau suatu kelompok orang melakukan kejahatan terhadap orang lain atau kelompok orang lainnya. Dalam dangerous speech ini, terdapat 7 aspek, yaitu: konteks sosial, konteks historis, dehumanisasi, tuduhan, serangan terhadap wanita dan anak kecil, loyalitas suatu kelompok, dan ancaman terhadap suatu kelompok. Dangerous speech sendiri marak ditemukan di media sosial seperti Twitter. Dangerous user merupakan pengguna yang memiliki presentase tweet dangerous speech dan abusive language lebih banyak dibanding tweet neutral speech dan hate speech. Pada penelitian ini, telah dibuat suatu model yang dapat melakukan klasifikasi multi-label dangerous user berdasarkan fitur struktural yang diekstraksi dari graf pengguna yang terbentuk dari kemiripan unggahan Twitter. Fitur struktural yang digunakan adalah degree centrality, eigenvector centrality, betweenness centrality, closeness centrality, dan clustering coefficient. Tahapan yang dilalui mencakup pengolahan data tweet, ekstraksi fitur struktural pada jejaring berdasarkan kemiripan tweet, dan Klasifikasi pengguna dengan multi-label topik dangerous speech. Pengolahan data tweet dilakukan dengan cara pra-proses tweet, pemodelan topik menggunakan LDA, dan pseudo-label aspek dangerous speech menggunakan model IndoBERTweet, Naïve Bayes, dan Logistic Regresion. Tahapan selanjutnya adalah ekstraksi fitur struktural pada jejaring berdasarkan kemiripan tweet yang dilakukan dengan cara membuat graf dimana nodes nya merupakan pengguna twitter dan edgesnya merupakan nilai cosine similiarity atau kemiripan unggahan. Dilakukan pemilihan node dan edge mengunakan metode thresholding. Pengekstraksian fitur dilakukan dengan menggunakan pustaka networkx. Selanjutnya dilakukan pengklasifikasian pengguna dengan multi-label topik dangerous speech menggunakan Logistic Regression, Naïve Bayes, K-nearest Neighbors, Support Vector Classifier Decision Tree dan Random Forest. Pseudo-label aspek dangerous speech terbaik menggunakan model gabungan dari IndoBERTweet, Naïve Bayes, dan Logistic Regresion  dengan nilai akurasi diatas 80%. Dalam pemodelan topik, ditemukan jumlah topik terbaik adalah 6 berdasarkan nilai coherence score, namun masih terdapat sub-topik yang terbentuk, sehingga digunakan jumlah topik 19 berdasarkan nilai coherence scorenya dan ketiadaannya sub-topik baru. Ditemukan metode thresholding terbaik dengan minimal tiap pengguna memiliki average retweet lebih dari 1 dan nilai cosine similiarity lebih dari 0,149. Klasifikasi dangerous user terbaik terdapat pada model Naïve Bayes dengan fitur degree centrality, closeness centrality, dan eigenvecot centrality dengan nilai hamming loss sebesar 0,555.=============================================================================================================================Dangerous speech, or dangerous discourse, refers to a form of expression that can increase the risk of an individual or a group of people committing crimes against others or another group of people. In dangerous speech, there are 7 aspects, namely: social context, historical context, dehumanization, accusations, attacks against women and children, group loyalty, and threats against a group. Dangerous speech is often found on social media platforms like Twitter. A dangerous user is a user who has a higher percentage of dangerous speech and abusive language in their tweets compared to neutral speech and hate speech. In this final project, a model has been developed to perform multi-label classification of dangerous users based on structural features extracted from user graphs formed by the similarity of Twitter posts. The structural features used are degree centrality, eigenvector centrality, betweenness centrality, closeness centrality, and clustering coefficient. The steps involved include tweet data preprocessing, structural feature extraction on the network based on tweet similarity, and user classification with multi-label dangerous speech topics. Tweet data processing is done by pre-processing tweets, topic modeling using LDA, and pseudo-labeling of dangerous speech aspects using IndoBERTweet, Naïve Bayes, and Logistic Regression models. The next step is the extraction of structural features on the network based on tweet similarity, which is done by creating a graph where the nodes represent Twitter users and the edges represent cosine similarity values or post similarity. Node and edge selection is performed using thresholding methods. Feature extraction is done using the networkx library. User classification with multi-label dangerous speech topics is done using Logistic Regression, Naïve Bayes, K-nearest Neighbors, Support Vector Classifier Decision Tree, and Random Forest. The best pseudo-label for dangerous speech aspects is obtained using a combined model of IndoBERTweet, Naïve Bayes, and Logistic Regression with an accuracy above 80%. In topic modeling, it was found that the optimal number of topics is 19 based on their coherence score and the absence of new sub-topics. The best thresholding method involves each account having an average retweet count of more than 1 and a cosine similarity value of more than 0.149. The best classification of dangerous users is achieved with the Naïve Bayes model using degree centrality, closeness centrality, and eigenvector centrality features, with a hamming loss value of 0.555.",klasifikasi multilabel dangerous user dasar fitur struktural twitter,dangerous speech ujar bahaya ujar tingkat risiko kelompok orang jahat orang kelompok orang dangerous speech 7 aspek konteks sosial konteks historis dehumanisasi tuduh serang wanita anak loyalitas kelompok ancam kelompok dangerous speech marak temu media sosial twitter dangerous user guna milik presentase tweet dangerous speech abusive language banding tweet neutral speech hate speech teliti model klasifikasi multilabel dangerous user dasar fitur struktural ekstraksi graf guna bentuk mirip unggah twitter fitur struktural degree centrality eigenvector centrality betweenness centrality closeness centrality clustering coefficient tahap cakup olah data tweet ekstraksi fitur struktural jejaring dasar mirip tweet klasifikasi guna multilabel topik dangerous speech olah data tweet praproses tweet model topik lda pseudolabel aspek dangerous speech model indobertweet na ve bayes logistic regresion tahap ekstraksi fitur struktural jejaring dasar mirip tweet graf mana nodes nya guna twitter edgesnya nilai cosine similiarity mirip unggah pilih node edge mengunakan metode thresholding ekstraksi fitur pustaka networkx klasifikasi guna multilabel topik dangerous speech logistic regression na ve bayes knearest neighbors support vector classifier decision tree random forest pseudolabel aspek dangerous speech baik model gabung indobertweet na ve bayes logistic regresion nilai akurasi atas 80 model topik temu topik baik 6 dasar nilai coherence score subtopik bentuk topik 19 dasar nilai coherence scorenya tiada subtopik temu metode thresholding baik minimal guna milik average retweet 1 nilai cosine similiarity 0149 klasifikasi dangerous user baik model na ve bayes fitur degree centrality closeness centrality eigenvecot centrality nilai hamming loss 0555dangerous speech or dangerous discourse refers to a form of expression that can increase the risk of an individual or a group of people committing crimes against others or another group of people in dangerous speech there are 7 aspects namely social context historical context dehumanization accusations attacks against women and children group loyalty and threats against a group dangerous speech is often found on social media platforms like twitter a dangerous user is a user who has a higher percentage of dangerous speech and abusive language in their tweets compared to neutral speech and hate speech in this final project a model has been developed to perform multilabel classification of dangerous users based on structural features extracted from user graphs formed by the similarity of twitter posts the structural features used are degree centrality eigenvector centrality betweenness centrality closeness centrality and clustering coefficient the steps involved include tweet data preprocessing structural feature extraction on the network based on tweet similarity and user classification with multilabel dangerous speech topics tweet data processing is done by preprocessing tweets topic modeling using lda and pseudolabeling of dangerous speech aspects using indobertweet na ve bayes and logistic regression models the next step is the extraction of structural features on the network based on tweet similarity which is done by creating a graph where the nodes represent twitter users and the edges represent cosine similarity values or post similarity node and edge selection is performed using thresholding methods feature extraction is done using the networkx library user classification with multilabel dangerous speech topics is done using logistic regression na ve bayes knearest neighbors support vector classifier decision tree and random forest the best pseudolabel for dangerous speech aspects is obtained using a combined model of indobertweet na ve bayes and logistic regression with an accuracy above 80 in topic modeling it was found that the optimal number of topics is 19 based on their coherence score and the absence of new subtopics the best thresholding method involves each account having an average retweet count of more than 1 and a cosine similarity value of more than 0149 the best classification of dangerous users is achieved with the na ve bayes model using degree centrality closeness centrality and eigenvector centrality features with a hamming loss value of 0555
Identifikasi Diabetes Melitus Berdasarkan Biomarker pada Sekuens DNA Menggunakan Metode Deep Learning.,"Permatasari, Devindha",http://repository.its.ac.id/103748/,"Diabetes melitus merupakan salah satu penyakit kronis yang tidak dapat disembuhkan yang disebabkan oleh kekurangan atau tidak adanya hormon insulin. Menurut etiopatologi diabetes, ada tiga kategori klinis utama, yaitu: diabetes tipe 1 (DMT1), diabetes tipe 2 (DMT2), dan diabetes melitus gestasional (DMG), serta penyebab khusus lainnya. Diabetes merupakan salah satu penyebab utama kematian di seluruh dunia. Setiap tahunnya sekitar 2-5 juta pasien kehilangan nyawa karena diabetes. Individu dengan diabetes menghadapi risiko mengembangkan beberapa masalah kesehatan sekunder seperti penyakit jantung, kerusakan saraf dan berbagai masalah kesehatan lainnya. Dengan demikian, deteksi dini dan pengobatan diabetes dapat mencegah komplikasi dan membantu mengurangi risiko masalah kesehatan yang parah. Penelitian ini bertujuan untuk mengidentifikasi diabetes berdasarkan biomarker pada sekuens DNA dengan menggunakan metode berbasis deep learning. Pada penelitian ini digunakan data sekuens DNA yang direpresentasikan kedalam gambar spektogram. Data sekuens DNA diubah menjadi numerik menggunakan teknik mapping berbasis entropi yang merupakan turunan fraksional dari Shanon Entropi. Kemudian dibuat gambar spektogramnya menggunakan fungsi specgram yang ada pada libary matplotlib dengan menggunakan STFT untuk merangkai plot tiga dimensi dengan waktu, frekuensi, dan amplitudo yang diwakili oleh skala warna. Gambar spektogram dari sekuens DNA diekstraksi menggunakan modul ViT dan mendapatkan 100 fitur. 100 fitur tersebut diklasifikasi dengan menggunakan SVM dan mendapatkan hasil akurasi sebesar 99%================================================================================================================================Diabetes mellitus is an incurable chronic disease caused by a deficiency or absence of the hormone insulin. According to the etiopathology of diabetes, there are three main clinical categories, namely: type 1 diabetes (T1DM), type 2 diabetes (T2DM), and gestational diabetes mellitus (GDM), as well as other noteworthy causes. Diabetes is one of the leading causes of death worldwide. Every year around 2-5 million patients lose their lives due to diabetes. Individuals with diabetes risk developing secondary health problems, such as heart disease, nerve damage, and various other health problems. Thus, early detection and treatment of diabetes can prevent complications and help reduce the risk of severe health problems. This study aims to identify diabetes based on biomarkers in DNA sequences using a deep learning based method. The study utilizes DNA sequence data represented as spectrogram images. The DNA sequences are transformed into numeric values using entropy-based mapping techniques, which are fractional derivatives of Shannon Entropy. Spectrogram images are then created using the specgram function in the Matplotlib library, employing Short-Time Fourier Transform (STFT) to generate three-dimensional plots with time, frequency, and amplitude represented by color scale. Spectrogram images of DNA sequences extracted using the ViT module and obtaining 100 features. These 100 features are classified using SVM and obtain an accuracy of 99%",identifikasi diabetes melitus dasar biomarker sekuens dna metode deep learning,diabetes melitus salah sakit kronis sembuh sebab kurang hormon insulin etiopatologi diabetes kategori klinis utama diabetes tipe 1 dmt1 diabetes tipe 2 dmt2 diabetes melitus gestasional dmg sebab khusus diabetes salah sebab utama mati dunia tahun 25 juta pasien hilang nyawa diabetes individu diabetes hadap risiko kembang sehat sekunder sakit jantung rusa saraf sehat deteksi obat diabetes cegah komplikasi bantu kurang risiko sehat parah teliti tuju identifikasi diabetes dasar biomarker sekuens dna metode bas deep learning teliti data sekuens dna representasi dalam gambar spektogram data sekuens dna ubah numerik teknik mapping bas entropi turun fraksional shanon entropi gambar spektogram fungsi specgram libary matplotlib stft rangkai plot dimensi frekuensi amplitudo wakil skala warna gambar spektogram sekuens dna ekstraksi modul vit 100 fitur 100 fitur klasifikasi svm hasil akurasi 99diabetes mellitus is an incurable chronic disease caused by a deficiency or absence of the hormone insulin according to the etiopathology of diabetes there are three main clinical categories namely type 1 diabetes t1dm type 2 diabetes t2dm and gestational diabetes mellitus gdm as well as other noteworthy causes diabetes is one of the leading causes of death worldwide every year around 25 million patients lose their lives due to diabetes individuals with diabetes risk developing secondary health problems such as heart disease nerve damage and various other health problems thus early detection and treatment of diabetes can prevent complications and help reduce the risk of severe health problems this study aims to identify diabetes based on biomarkers in dna sequences using a deep learning based method the study utilizes dna sequence data represented as spectrogram images the dna sequences are transformed into numeric values using entropybased mapping techniques which are fractional derivatives of shannon entropy spectrogram images are then created using the specgram function in the matplotlib library employing shorttime fourier transform stft to generate threedimensional plots with time frequency and amplitude represented by color scale spectrogram images of dna sequences extracted using the vit module and obtaining 100 features these 100 features are classified using svm and obtain an accuracy of 99
Analisis Sentimen Masyarakat Indonesia Mengenai Vaksin COVID-19 Pada Media Sosial Twitter Menggunakan Metode Naïve Bayes Classifier dan Support Vector Machine.,"Permatasari, Rizka Widya",http://repository.its.ac.id/91280/,"World Health Organization (WHO) mendeklarasi-kan virus COVID-19 sebagai pandemi global pada 11 Maret 2020. Kondisi tersebut memberikan dampak langsung kepada seluruh masyarakat di dunia, dengan mulai diberlakukannya protokol ke-sehatan yang harus diterapkan pada seluruh aspek kegiatan, mulai dari pembatasan sosial hingga lockdown total yang menghambat seluruh kegiatan masyarakat. Salah satu cara yang dilakukan untuk mencegah penyebaran virus ini adalah dengan pemberian vaksin. Kegiatan vaksinasi mulai diberikan kepada masyarakat Indonesia pada bulan Januari 2021. Pada media sosial twitter, pro kontra vaksin COVID-19 sempat menjadi trending topic sehingga dirasa perlu untuk dilakukan penelitian tentang sentimen publik terhadap adanya kegiatan vaksinasi dalam memutus rantai penyebaran COVID-19 di Indonesia. Pada penelitian ini digunakan analisis klasifikasi teks yaitu Naïve Bayes Classifier (NBC) dan Support Vector Machine (SVM). NBC telah banyak digunakan dalam penelitian mengenai Text Mining karena memiliki algoritma yang sederhana namun dapat menghasilkan akurasi yang tinggi, sedangkan SVM memiliki kemampuan yang baik dalam mengolah data berdimensi besar dengan hasil yang efektif. Perbandingan kedua metode menggunakan 10 fold-stratified cross validation dengan kriteria kebaikan klasifikasi AUC dan akurasi menunjukkan bahwa SVM memiliki kinerja klasifikasi yang lebih baik dibanding NBC dan SVM kernel menghasilkan ketepatan klasifikasi lebih tinggi dibanding SVM kernel RBF.====================================================================================================The World Health Organization (WHO) declared the COVID-19 virus as a global pandemic on March 11, 2020. These conditions had a direct impact on all people in the world, with the introduction of health protocols that must be applied to all aspects of activities, starting from from social restrictions to total lockdowns that hinder all community activities. One way to prevent the spread of this virus is by giving vaccines. Vaccination activities began to be given to the people of Indonesia in January 2021. On social media Twitter, the pros and cons of the COVID-19 vaccine had become a trending topic, so it was deemed necessary to conduct research on public sentiment towards vaccination activities in breaking the chain of spread of COVID-19. 19 in Indonesia. This research uses text classification analysis, namely Naïve Bayes Classifier (NBC) and Support Vector Machine (SVM). NBC has been widely used in research on Text Mining because it has a simple algorithm but can produce high accuracy, while SVM has a good ability to process large-dimensional data with effective results. Comparison of the two methods using 10 fold-stratified cross validation with AUC classification goodness criteria and accuracy shows that SVM has better classification performance than NBC and SVM kernel produces higher classification accuracy than SVM kernel RBF.",analisis sentimen masyarakat indonesia vaksin covid19 media sosial twitter metode na ve bayes classifier support vector machine,world health organization who deklarasi virus covid19 pandemi global 11 maret 2020 kondisi dampak langsung masyarakat dunia laku protokol sehat terap aspek giat batas sosial lockdown total hambat giat masyarakat salah cegah sebar virus beri vaksin giat vaksinasi masyarakat indonesia januari 2021 media sosial twitter pro kontra vaksin covid19 trending topic rasa teliti sentimen publik giat vaksinasi putus rantai sebar covid19 indonesia teliti analisis klasifikasi teks na ve bayes classifier nbc support vector machine svm nbc teliti text mining milik algoritma sederhana hasil akurasi svm milik mampu olah data mens hasil efektif banding metode 10 foldstratified cross validation kriteria baik klasifikasi auc akurasi svm milik kerja klasifikasi banding nbc svm kernel hasil tepat klasifikasi banding svm kernel rbfthe world health organization who declared the covid19 virus as a global pandemic on march 11 2020 these conditions had a direct impact on all people in the world with the introduction of health protocols that must be applied to all aspects of activities starting from from social restrictions to total lockdowns that hinder all community activities one way to prevent the spread of this virus is by giving vaccines vaccination activities began to be given to the people of indonesia in january 2021 on social media twitter the pros and cons of the covid19 vaccine had become a trending topic so it was deemed necessary to conduct research on public sentiment towards vaccination activities in breaking the chain of spread of covid19 19 in indonesia this research uses text classification analysis namely na ve bayes classifier nbc and support vector machine svm nbc has been widely used in research on text mining because it has a simple algorithm but can produce high accuracy while svm has a good ability to process largedimensional data with effective results comparison of the two methods using 10 foldstratified cross validation with auc classification goodness criteria and accuracy shows that svm has better classification performance than nbc and svm kernel produces higher classification accuracy than svm kernel rbf
Pengembangan Sistem Deteksi dan Lokalisasi Kebocoran Pipa Berbasis Deep Learning Residual-Network pada Jaringan Distribusi Air di Perumda Air Minum Tugu Tirta Malang.,"Prabowo, Zhiya Ulhaq",http://repository.its.ac.id/109409/,"Berdasarkan ringkasan SDGs 6.2 tahun 2021, bahwa 46% dari populasi dunia kekurangan air yang tersanitasi. PERUMDA Air Minum Tugu Tirta merupakan salah perusahaan yang berkontribusi dalam penyediaan dan distribusi air bersih. Kehilangan air fisik merupakan tantangan dalam distribusi air bersih yang dialami perusahaan. Demi mengatasi tantangan, diperlukan metode deteksi lokasi kebocoran pada jaringan distribusi air. Penelitian kali ini akan diajukan metode berbasis deep learning residual-network (ResNet) untuk mendeteksi ukuran dan lokasi kebocoran yang terjadi. Pertama, dilakukan pemilihan DMA sebagai objek penelitian. Spesifikasi DMA diambil untuk dilakukan pemodelan dengan software WaterCAD dan kemudian divalidasi serta dilakukan pemodelan kebocoran dengan mengatur Emitter Coefficient serta lokasi kebocorannya. Ukuran kebocoran adalah rendah 0,3 l/s, sedang 0,6 l/s, dan tinggi 1,2 l/s. Ketika kebocoran disimulasikan, data tekanan diambil pada empat titik sensor yang telah ditentukan pada DMA. Kemudian, dilakukan variasi lokasi dengan variasi ukuran yang sama. Data tekanan aktual dari DMA juga diambil dengan menggunakan sensor tekanan yang dipasang pada pressure point dari jaringan. Sistem deteksi dan lokalisasi berbasis ResNet dikembangkan dengan menggunakan data simulasi dalam proses pelatihan sistem. Dari proses pelatihan tersebut didapatkan hasil performa akurasi deteksi ukuran sebesar 98.62% dan lokalisasi sebesar 98.16%, serta F1-Score deteksi ukuran sebesar 98.97% dan lokalisasi sebesar 98.17%. Akan tetapi, pada percobaan dengan data aktual, performa dapat disebut kurang baik, dimana akurasi deteksi ukuran dan lokalisasi sebesar 75%, serta F1-Score deteksi ukuran sebesar 85.71%. dan lokalisasi sebesar 85.71%. =================================================================================================================================According to the 2021 SDGs 6.2 summary, 46% of the world's population lacks access to sanitized water. PERUMDA Air Minum Tugu Tirta is one of the companies contributing to the provision and distribution of clean water. Physical water loss is a significant challenge in the distribution of clean water faced by the company. To address this challenge, a method for detecting leak locations in the water distribution network is necessary. This study proposes a deep learning residual-network (ResNet)-based method to detect the size and location of leaks. First, a District Metered Area (DMA) was selected as the research object. The DMA specifications were used for modeling with WaterCAD software. The model was validated, and leak modeling was performed by adjusting the Emitter Coefficient and the location of the leaks. The leak sizes were categorized as low (0.3 l/s), medium (0.6 l/s), and high (1.2 l/s). During the leak simulation, pressure data was collected at four predetermined sensor points within the DMA. Various locations with the same size variations were tested. Actual pressure data from the DMA was also collected using pressure sensors installed at pressure points in the network. The ResNet-based detection and localization system was developed using simulation data for the system training process. The training process yielded a detection size accuracy is 98.62% and a localization accuracy is 98.16%, with an F1-Score for detection size is 98.97% and for localization is 98.17%. However, when tested with actual data, the performance was less satisfactory, with a detection size and localization accuracy of 75%, and the F1-Score for detection size and localization is 85.71%.",kembang sistem deteksi lokalisasi bocor pipa bas deep learning residualnetwork jaring distribusi air perumda air minum tugu tirta malang,dasar ringkas sdgs 62 2021 46 populasi dunia kurang air sanitasi perumda air minum tugu tirta salah usaha kontribusi sedia distribusi air bersih hilang air fisik tantang distribusi air bersih alami usaha atas tantang metode deteksi lokasi bocor jaring distribusi air teliti kali aju metode bas deep learning residualnetwork resnet deteksi ukur lokasi bocor pilih dma objek teliti spesifikasi dma ambil model software watercad divalidasi model bocor atur emitter coefficient lokasi bocor ukur bocor rendah 03 ls 06 ls 12 ls bocor simulasi data tekan ambil titik sensor tentu dma variasi lokasi variasi ukur data tekan aktual dma ambil sensor tekan pasang pressure point jaring sistem deteksi lokalisasi bas resnet kembang data simulasi proses latih sistem proses latih dapat hasil performa akurasi deteksi ukur 9862 lokalisasi 9816 f1score deteksi ukur 9897 lokalisasi 9817 coba data aktual performa mana akurasi deteksi ukur lokalisasi 75 f1score deteksi ukur 8571 lokalisasi 8571 according to the 2021 sdgs 62 summary 46 of the worlds population lacks access to sanitized water perumda air minum tugu tirta is one of the companies contributing to the provision and distribution of clean water physical water loss is a significant challenge in the distribution of clean water faced by the company to address this challenge a method for detecting leak locations in the water distribution network is necessary this study proposes a deep learning residualnetwork resnetbased method to detect the size and location of leaks first a district metered area dma was selected as the research object the dma specifications were used for modeling with watercad software the model was validated and leak modeling was performed by adjusting the emitter coefficient and the location of the leaks the leak sizes were categorized as low 03 ls medium 06 ls and high 12 ls during the leak simulation pressure data was collected at four predetermined sensor points within the dma various locations with the same size variations were tested actual pressure data from the dma was also collected using pressure sensors installed at pressure points in the network the resnetbased detection and localization system was developed using simulation data for the system training process the training process yielded a detection size accuracy is 9862 and a localization accuracy is 9816 with an f1score for detection size is 9897 and for localization is 9817 however when tested with actual data the performance was less satisfactory with a detection size and localization accuracy of 75 and the f1score for detection size and localization is 8571
Klasterisasi Kasus Kemiskinan di Indonesia pada Hasil Peramalan Backpropagation Neural Network.,"Pradnyandari, Ni Putu Putri Marinda",http://repository.its.ac.id/99719/,"Kemiskinan merupakan permasalahan sosial yang cukup kompleks dan sulit untuk hilang. Banyak negara sudah memfokuskan tujuan kenegaraan mereka untuk menanggulangi kemiskinan. Hal ini dibuktikan dengan lahirnya Sustainable Development Goals (SDGs) yang disusun oleh Perserikatan Bangsa-Bangsa (PBB) dan mengharuskan Indonesia turut andil dalam penanggulangan kemiskinan. Namun, jika kita lihat berdasarkan data, menurut data Badan Pusat Statistik, angka kemiskinan di Indonesia masih mengalami peningkatan di bulan September 2022 dibandingkan dengan periode sebelumnya, Maret 2022. Berdasarkan permasalahan tersebut, solusi yang dapat ditawarkan untuk membantu pemerintah dan masyarakat dalam menanggulangi kemiskinan adalah dengan melakukan peramalan sebagai landasan dalam mengambil kebijakan. Peramalan ini menggunakan metode Backpropagation Neural Network dan hasil data peramalan dilakukan clustering menggunakan metode K-Means. Objek penelitian yang digunakan adalah data kemiskinan 34 provinsi di Indonesia dari tahun 2015 sampai 2022 yang terdiri dari variabel tingkat kemiskinan, PDRB harga konstan, tingkat pengangguran terbuka, dan rasio gini. Data berupa data semester dengan total jumlah data di setiap variabelnya sebanyak 544 data. Dalam pemodelan BPNN, didapatkan model terbaik dengan jaringan BPNN (4-6-1) dengan hasil MAPE dan MSE sebesar 7,14% dan 0,00000492. Hasil peramalan berdasarkan model BPNN terbaik kemudian dilakukan klasterisasi. Clustering K-Means menghasilkan 3 klaster dengan karakteristik yang berbeda. Jumlah provinsi yang masuk ke dalam klaster 1 sebanyak 8 provinsi, klaster 2 sebanyak 5 provinsi, dan klaster 3 sebanyak 21 provinsi.================================================================================================================================Poverty is a complex social problem that is difficult to eliminate. Many countries have focused their state goals on tackling poverty. This is evidenced by the birth of the Sustainable Development Goals (SDGs) compiled by the United Nations (UN) and requires Indonesia to take part in poverty reduction. However, if we look at the data, according to the Central Bureau of Statistics, the poverty rate in Indonesia still increased in September 2022 compared to the previous period, March 2022. Based on these problems, a solution that can be offered to help the government and society in reducing poverty is to conduct forecasting as a basis for making policies. This forecasting uses the Backpropagation Neural Network method and the results of the forecasting data are clustering using the K-Means method. The research object used is poverty data for 34 provinces in Indonesia from 2015 to 2022 which consists of variables of poverty rate, GRDP at constant prices, open unemployment rate, and Gini ratio. The data is in the form of semester data with a total of 544 data in each variable. In BPNN modeling, the best model is obtained with the BPNN network (4-6-1) with MAPE and MSE results of 7.14% and 0.00000492. Forecasting results based on the best BPNN model are then clusterized. K-Means clustering produces 3 clusters with different characteristics. The number of provinces included in cluster 1 is eight provinces, cluster 2 is five provinces, and cluster 3 is 21 provinces.",klasterisasi miskin indonesia hasil amal backpropagation neural network,miskin masalah sosial kompleks sulit hilang negara fokus tuju negara tanggulang miskin bukti lahir sustainable development goals sdgs susun serikat bangsabangsa pbb harus indonesia andil tanggulang miskin lihat dasar data data badan pusat statistik angka miskin indonesia alami tingkat september 2022 banding periode maret 2022 dasar masalah solusi tawar bantu perintah masyarakat tanggulang miskin amal landas ambil bijak amal metode backpropagation neural network hasil data amal clustering metode kmeans objek teliti data miskin 34 provinsi indonesia 2015 2022 variabel tingkat miskin pdrb harga konstan tingkat anggur buka rasio gin data data semester total data variabel 544 data model bpnn dapat model baik jaring bpnn 461 hasil mape mse 714 000000492 hasil amal dasar model bpnn baik klasterisasi clustering kmeans hasil 3 klaster karakteristik beda provinsi masuk klaster 1 8 provinsi klaster 2 5 provinsi klaster 3 21 provinsipoverty is a complex social problem that is difficult to eliminate many countries have focused their state goals on tackling poverty this is evidenced by the birth of the sustainable development goals sdgs compiled by the united nations un and requires indonesia to take part in poverty reduction however if we look at the data according to the central bureau of statistics the poverty rate in indonesia still increased in september 2022 compared to the previous period march 2022 based on these problems a solution that can be offered to help the government and society in reducing poverty is to conduct forecasting as a basis for making policies this forecasting uses the backpropagation neural network method and the results of the forecasting data are clustering using the kmeans method the research object used is poverty data for 34 provinces in indonesia from 2015 to 2022 which consists of variables of poverty rate grdp at constant prices open unemployment rate and gin ratio the data is in the form of semester data with a total of 544 data in each variable in bpnn modeling the best model is obtained with the bpnn network 461 with mape and mse results of 714 and 000000492 forecasting results based on the best bpnn model are then clusterized kmeans clustering produces 3 clusters with different characteristics the number of provinces included in cluster 1 is eight provinces cluster 2 is five provinces and cluster 3 is 21 provinces
Deteksi Dini Financial Distress Pada Perusahaan Sektor Teknologi di Bursa Efek Indonesia Menggunakan Artificial Neural Network dan Support Vector Machine.,"Pradnyaningsih, Ni Luh Eva",http://repository.its.ac.id/118576/,"Kondisi ekonomi dan geopolitik di Indonesia diperkirakan akan memburuk pada beberapa tahun kedepan yang disebabkan oleh beberapa faktor diantaranya inflasi dan biaya operasional yang tinggi. Hal ini berdampak pada minat investor dalam berinvestasi pada perusahaan. Salah satu perusahaan yang paling berdampak besar adalah perusahaan sektor teknologi. Industri teknologi di Indonesia menghadapi tantangan pada pangsa pasar yang relatif rendah dibandingkan pasar global dimana banyak saham teknologi di Indonesia masih tertinggal jauh dibandingkan negara-negara maju. Akibat hal tersebut investor lebih memilih berinvestasi pada emiten yang minim risiko. Penurunan ini memengaruhi kemampuan perusahaan-perusahaan teknologi untuk menarik investasi yang dibutuhkan untuk bertahan dan berkembang. Beberapa perusahaan di sektor teknologi telah mengalami perubahan signifikan dalam kinerja keuangan mereka, menunjukkan adanya potensi kesulitan keuangan. Kesulitan keuangan terjadi ketika kinerja keuangan perusahaan menurun dari waktu ke waktu, yang pada gilirannya memengaruhi stabilitas sistem keuangan dan sumber daya manusia perusahaan. Oleh karena itu, penelitian ini bertujuan untuk memprediksi apakah perusahaan-perusahaan di sektor teknologi di Indonesia akan mengalami kesulitan keuangan di masa depan atau tidak dengan menggunakan metode Artificial Neural Network dan Support Vector Machine. Hasil penelitian menunjukkan bahwa ANN lebih unggul dalam memprediksi kinerja keuangan perusahaan, dengan rasio PER memiliki pengaruh besar dalam memprediksi risiko ini. Selain itu, aplikasi berbasis web yang dikembangkan menggunakan Streamlit memungkinkan pengguna untuk mendeteksi dini kondisi keuangan perusahaan.===================================================================================================================================The economic and geopolitical conditions in Indonesia are expected to deteriorate in the coming years due to several factors, including inflation and high operational costs. This affects investor interest in investing in companies. One of the most significantly impacted sectors is technology companies. The technology industry in Indonesia faces challenges with a relatively low market share compared to the global market, where many technology stocks in Indonesia lag significantly behind those in developed countries. As a result, investors prefer to invest in issuers with minimal risk. This decline affects the ability of technology companies to attract the investment needed to survive and grow. Some companies in the technology sector have experienced significant changes in their financial performance, indicating potential financial difficulties. Financial difficulties occur when a company's financial performance declines over time, which in turn affects the stability of the financial system and the company's human resources. Therefore, this study aims to predict whether technology companies in Indonesia will experience financial distress in the future using Artificial Neural Network and Support Vector Machine methods. The results of the study indicate that ANN outperforms other models in predicting the financial performance of companies, with the PER ratio having a significant impact on forecasting this risk. Additionaly, the web-based application developed using Streamlit enables users to detect companies financial conditions early.",deteksi financial distress usaha sektor teknologi bursa efek indonesia artificial neural network support vector machine,kondisi ekonomi geopolitik indonesia buruk depan sebab faktor inflasi biaya operasional dampak minat investor investasi usaha salah usaha dampak usaha sektor teknologi industri teknologi indonesia hadap tantang pangsa pasar relatif rendah banding pasar global mana saham teknologi indonesia tinggal banding negaranegara maju akibat investor pilih investasi emiten minim risiko turun pengaruh mampu perusahaanperusahaan teknologi tarik investasi butuh tahan kembang usaha sektor teknologi alami ubah signifikan kerja uang potensi sulit uang sulit uang kerja uang usaha turun gilir pengaruh stabilitas sistem uang sumber daya manusia usaha teliti tuju prediksi perusahaanperusahaan sektor teknologi indonesia alami sulit uang metode artificial neural network support vector machine hasil teliti ann unggul prediksi kerja uang usaha rasio milik pengaruh prediksi risiko aplikasi bas web kembang streamlit guna deteksi kondisi uang perusahaanthe economic and geopolitical conditions in indonesia are expected to deteriorate in the coming years due to several factors including inflation and high operational costs this affects investor interest in investing in companies one of the most significantly impacted sectors is technology companies the technology industry in indonesia faces challenges with a relatively low market share compared to the global market where many technology stocks in indonesia lag significantly behind those in developed countries as a result investors prefer to invest in issuers with minimal risk this decline affects the ability of technology companies to attract the investment needed to survive and grow some companies in the technology sector have experienced significant changes in their financial performance indicating potential financial difficulties financial difficulties occur when a companys financial performance declines over time which in turn affects the stability of the financial system and the companys human resources therefore this study aims to predict whether technology companies in indonesia will experience financial distress in the future using artificial neural network and support vector machine methods the results of the study indicate that ann outperforms other models in predicting the financial performance of companies with the ratio having a significant impact on forecasting this risk additionaly the webbased application developed using streamlit enables users to detect companies financial conditions early
Analisis Faktor Yang Mempengaruhi Penjualan Produk B2B Dengan Menggunakan Metode Support Vector Machine Di PT XYZ.,"Pradnyawati, Ni Kadek Dewi",http://repository.its.ac.id/96203/,"Indonesia merupakan salah satu negara dengan pengguna internet terbesar di seluruh dunia yang menduduki posisi keenam pada tahun 2021 dengan menggunakan berbagai media seperti handphone, laptop, personal computer ataupun alat lainnya yang membutuhkan koneksi internet. PT XYZ adalah suatu perusahaan telekomunikasi yang menyediakan layanan internet di Indonesia dengan berbagai produk yang ditujukan untuk segmen Business to Business (B2B) dan juga Business to Consumer (B2C). Produk B2B yang dihasilkan oleh PT XYZ yaitu IaaS, CPaaS, SaaS, dan Analytics yang kemudian ditawarkan oleh salesperson ke pelanggan atau perusahaan yang membutuhkan dengan melakukan assessment awal yang bertujuan untuk melihat kebutuhannya dan kemudian melakukan mapping produk yang sesuai. PT XYZ memiliki lebih dari 50 salesperson yang ada di Indonesia dengan latar belakang dan profil yang berbeda-beda seperti umur, lokasi, jabatan, status, hingga kondisi keluarga dan juga ekonomi yang dapat mempengaruhi performa dari seorang salesperson. PT XYZ ingin meningkatkan performansi penjualan produk B2B dengan mengetahui faktor-faktor yang berpengaruh berdasarkan karakteristik dari salesperson dengan membandingkan antara status proyek win dan lose. Regresi logistic dan scoring feature digunakan untuk mengetahui korelasi antara variabel sehingga dapat mengetahui faktor-faktor yang berpengaruh terhadap penjualan. Support vector machine (SVM) merupakan salah satu metode dari data mining yang dapat digunakan untuk mengklasifikasikan dan memprediksi dari suatu data (Arifin, 2018). Berdasarkan hasil analisis, faktor yang mempengaruhi penjualan dari salesperson yaitu lama bekerja di PT XYZ, sisa waktu pelunasan KPR, jumlah training, usia pernikahan, dan pendidikan terakhir. Nilai akurasi pada hasil klasifikasi SVM sebesar 81% dengan derajat optimalnya yaitu sebesar 2. Rekomendasi bisnis yang dapat diberikan untuk meningkatkan performansi salesperson PT XYZ adalah dengan memberikan training yang sesuai dengan kebutuhan dan pekerjaan untuk salesperson.==============================================================================================================================PT XYZ is a telecommunication company that provides internet services in Indonesia with various products aimed at the Business to Business (B2B) and also Business to Consumer (B2C) segments. B2B products produced by PT XYZ namely IaaS, CPaaS, SaaS, and Analytics which are then offered by salespersons to customers or companies that need them by conducting an initial assessment which aims to see their needs and then mapping the appropriate products. PT XYZ has more than 50 salespersons in Indonesia with different backgrounds and profiles such as age, location, position, status, to family and economic conditions that can affect the performance of a salesperson. PT XYZ wants to improve the sales performance of B2B products by knowing the influencing factors based on the characteristics of the salesperson by comparing the win and lose project statuses. Logistic regression and scoring features are used to determine the correlation between variabels so that they can determine the factors that influence sales. Support vector machine (SVM) is a method of data mining that can be used to classify and predict data (Arifin, 2018). Based on the results of the analysis, The characteristics that influence sales from salespersons are time spent working, remaining KPR repayment time, number of trainings, marriage age, educational status. Advice that offered to PT XYZ by providing training tailored to the demands of the salesperson and also in accordance with the job is intended to boost salesperson performance, allowing them to win more products. The SVM classification results have an accuracy score of 81% with an ideal degree of 2.",analisis faktor pengaruh jual produk b2b metode support vector machine pt xyz,indonesia salah negara guna internet besar dunia duduk posisi enam 2021 media handphone laptop personal computer alat butuh koneksi internet pt xyz usaha telekomunikasi sedia layan internet indonesia produk segmen business to business b2b business to consumer b2c produk b2b hasil pt xyz iaas cpaas saas analytics tawar salesperson langgan usaha butuh assessment tuju butuh mapping produk sesuai pt xyz milik 50 salesperson indonesia latar profil berbedabeda umur lokasi jabat status kondisi keluarga ekonomi pengaruh performa salesperson pt xyz tingkat performansi jual produk b2b faktorfaktor pengaruh dasar karakteristik salesperson banding status proyek win lose regresi logistic scoring feature korelasi variabel faktorfaktor pengaruh jual support vector machine svm salah metode data mining klasifikasi prediksi data arifin 2018 dasar hasil analisis faktor pengaruh jual salesperson pt xyz sisa lunas kpr training usia nikah didik nilai akurasi hasil klasifikasi svm 81 derajat optimal 2 rekomendasi bisnis tingkat performansi salesperson pt xyz training sesuai butuh kerja salespersonpt xyz is a telecommunication company that provides internet services in indonesia with various products aimed at the business to business b2b and also business to consumer b2c segments b2b products produced by pt xyz namely iaas cpaas saas and analytics which are then offered by salespersons to customers or companies that need them by conducting an initial assessment which aims to see their needs and then mapping the appropriate products pt xyz has more than 50 salespersons in indonesia with different backgrounds and profiles such as age location position status to family and economic conditions that can affect the performance of a salesperson pt xyz wants to improve the sales performance of b2b products by knowing the influencing factors based on the characteristics of the salesperson by comparing the win and lose project statuses logistic regression and scoring features are used to determine the correlation between variabels so that they can determine the factors that influence sales support vector machine svm is a method of data mining that can be used to classify and predict data arifin 2018 based on the results of the analysis the characteristics that influence sales from salespersons are time spent working remaining kpr repayment time number of trainings marriage age educational status advice that offered to pt xyz by providing training tailored to the demands of the salesperson and also in accordance with the job is intended to boost salesperson performance allowing them to win more products the svm classification results have an accuracy score of 81 with an ideal degree of 2
Klasifikasi Tumor Glioma dengan Modalitas Magnetic Resonance Imaging (MRI) berbasis Convolutional Neural Network (CNN) untuk Diagnosis Tingkat Keganasan Tumor Otak.,"Prakosa, Nadhira Anindyafitri",http://repository.its.ac.id/111213/,"Glioma mendominasi 80% dari kasus tumor otak ganas pada pasien, menyebabkan tingginya tingkat mortalitas, disabilitas serta penurunan kualitas hidup yang signifikan. Tumor glioma diklasifikasikan menjadi Low-Grade Glioma (LGG) dan High-Grade Glioma (HGG) berdasarkan tingkat keganasannya. Klasifikasi ini sangat penting karena berdampak signifikan terhadap prognosis, keputusan pengobatan, dan perencanaan bedah. Diagnosis yang akurat oleh para ahli medis sangat penting untuk menentukan tindakan yang tepat. Computer Aided Diagnosis (CAD) dapat digunakan dalam mempermudah dokter menghasilkan diagnosis yang persisi. Metode CAD tradisional mengandalkan teknik machine learning (ML) yang memerlukan pemilihan fitur secara manual, seperti analisis tekstur. Namun, pendekatan ini dapat menyebabkan hilangnya fitur data yang esensial, yang berpotensi mengurangi akurasi diagnosis. Convolutional Neural Networks (CNN) telah merevolusi pencitraan medis dengan kemampuan luar biasa dalam mengenali dan mengidentifikasi tumor otak. Berbeda dengan metode tradisional, CNN mengintegrasikan ekstraksi fitur dalam arsitekturnya, menghilangkan kebutuhan pemilihan fitur manual. Kemampuan ini memungkinkan CNN mencapai akurasi tinggi dalam klasifikasi tumor. Untuk klasifikasi glioma, sangat penting untuk memanfaatkan informasi dari berbagai sequence MRI guna memungkinkan model CNN mengekstraksi fitur representatif secara efektif. Studi ini menggunakan pendekatan multi-sequence fusion, menggabungkan sequence MRI Flair, T1, T1ce, dan T2 dengan fine-tuned model VGG16 untuk mengklasifikasikan tingkat keganasan glioma. Model ini memanfaatkan data dari dataset BraTS 2017, 2018, 2019, dan 2020. Model yang diusulkan mencapai hasil yang luar biasa, meliputi akurasi 100%, presisi 99,04%, recall 100%, skor F1 99,52%, dan spesifisitas 99,03%. Evaluasi metrik yang luar biasa ini menunjukkan efektivitas model dalam mengklasifikasikan tingkat keganasan glioma dengan akurat. Studi ini menunjukkan kemajuan signifikan dalam mendiagnosis tingkat keganasan tumor otak, serta memperlihatkan potensi untuk mempermudah pembuatan prognosis pasien melalui klasifikasi yang akurat dan andal.========================================================================================================================Gliomas dominate 80% of malignant brain tumor cases in patients, presenting a significant challenge in neuro-oncology. These tumors are classified into Low-Grade Glioma (LGG) and High-Grade Glioma (HGG) based on their malignancy levels. This classification is crucial as it significantly impacts prognosis, treatment decisions, and surgical planning. Accurate diagnosis by medical experts is essential for determining the appropriate course of action. Computer-aided diagnosis (CAD) systems have emerged as valuable tools in assisting doctors with precise diagnoses. Traditional CAD methods have often relied on machine learning techniques that require manual feature selection, such as texture analysis. However, this approach can lead to the loss of essential data features, potentially compromising the accuracy of the diagnosis. Convolutional Neural Networks (CNNs) have revolutionized medical imaging by excelling in recognizing and identifying brain tumors. Unlike traditional methods, CNNs integrate feature extraction within their architecture, eliminating the need for manual feature selection. This capability allows CNNs to achieve high accuracy in tumor classification. For glioma classification, it is essential to utilize information from different MRI sequences to enable the CNN model to extract representative features effectively. This study employs a multi-sequence fusion approach, combining Flair, T1, T1ce, and T2 MRI sequences with a fine-tuned VGG16 model to classify glioma malignancy levels. The model leverages data from the BraTS 2017, 2018, 2019, and 2020 datasets. The proposed model achieves remarkable results, including 100% accuracy, 99.04% precision, 100% recall, a 99.52% F1 score, and 99.03% specificity. These exceptional performance metrics highlight the model's effectiveness in accurately classifying glioma malignancy levels. The study demonstrates significant advancements in diagnosing brain tumor malignancy levels, showcasing the potential to facilitate accurate and reliable patient prognoses through precise classification.",klasifikasi tumor glioma modalitas magnetic resonance imaging mri bas convolutional neural network cnn diagnosis tingkat ganas tumor otak,glioma dominasi 80 tumor otak ganas pasien sebab tinggi tingkat mortalitas disabilitas turun kualitas hidup signifikan tumor glioma klasifikasi lowgrade glioma lgg highgrade glioma hgg dasar tingkat ganas klasifikasi dampak signifikan prognosis putus obat rencana bedah diagnosis akurat ahli medis tentu tindak computer aided diagnosis cad mudah dokter hasil diagnosis persisi metode cad tradisional andal teknik machine learning ml pilih fitur manual analisis tekstur dekat sebab hilang fitur data esensial potensi kurang akurasi diagnosis convolutional neural networks cnn revolusi citra medis mampu nali identifikasi tumor otak beda metode tradisional cnn integrasi ekstraksi fitur arsitektur hilang butuh pilih fitur manual mampu cnn capai akurasi klasifikasi tumor klasifikasi glioma manfaat informasi sequence mri model cnn ekstraksi fitur representatif efektif studi dekat multisequence fusion gabung sequence mri flair t1 t1ce t2 finetuned model vgg16 klasifikasi tingkat ganas glioma model manfaat data dataset brats 2017 2018 2019 2020 model usul capai hasil liput akurasi 100 presisi 9904 recall 100 skor f1 9952 spesifisitas 9903 evaluasi metrik efektivitas model klasifikasi tingkat ganas glioma akurat studi maju signifikan diagnosis tingkat ganas tumor otak potensi mudah buat prognosis pasien klasifikasi akurat andalgliomas dominate 80 of malignant brain tumor cases in patients presenting a significant challenge in neurooncology these tumors are classified into lowgrade glioma lgg and highgrade glioma hgg based on their malignancy levels this classification is crucial as it significantly impacts prognosis treatment decisions and surgical planning accurate diagnosis by medical experts is essential for determining the appropriate course of action computeraided diagnosis cad systems have emerged as valuable tools in assisting doctors with precise diagnoses traditional cad methods have often relied on machine learning techniques that require manual feature selection such as texture analysis however this approach can lead to the loss of essential data features potentially compromising the accuracy of the diagnosis convolutional neural networks cnns have revolutionized medical imaging by excelling in recognizing and identifying brain tumors unlike traditional methods cnns integrate feature extraction within their architecture eliminating the need for manual feature selection this capability allows cnns to achieve high accuracy in tumor classification for glioma classification it is essential to utilize information from different mri sequences to enable the cnn model to extract representative features effectively this study employs a multisequence fusion approach combining flair t1 t1ce and t2 mri sequences with a finetuned vgg16 model to classify glioma malignancy levels the model leverages data from the brats 2017 2018 2019 and 2020 datasets the proposed model achieves remarkable results including 100 accuracy 9904 precision 100 recall a 9952 f1 score and 9903 specificity these exceptional performance metrics highlight the models effectiveness in accurately classifying glioma malignancy levels the study demonstrates significant advancements in diagnosing brain tumor malignancy levels showcasing the potential to facilitate accurate and reliable patient prognoses through precise classification
Engine Predictive Maintenance Schedule Optimization on Sumbagut-2 Gas Engine Power Plant Using Mixed Integer Nonlinear Programming.,"Pranata, Muhammad Kahari",http://repository.its.ac.id/110691/,"Engine maintenance scheduling is crucial for power plants, particularly those using multiple engines. For example, the Sumbagut-2 Gas Engine Power Plant in Lhokseumawe, Aceh, employs 13 engines to produce 240 MW of power for northern Sumatera, including North Sumatera and Aceh. This project designs an optimized maintenance schedule based on engine usability and the type of maintenance required according to each generator's accumulated operation hours. The goal is to maximize system reliability using a mixed integer nonlinear programming optimization approach. Constraints include maximum duration and maintenance status, while the objective function focuses on reliability. Engine reliability is determined by calculating the components’ respective reliability functions in series, and system reliability is assessed by placing the engines in parallel. The optimized schedule shows that the first maintenance occurs on the 27th day. Most engines are maintained in pairs, with at least one engine undergoing maintenance alone.",engine predictive maintenance schedule optimization on sumbagut2 gas engine power plant using mixed integer nonlinear programming,engine maintenance scheduling is crucial for power plants particularly those using multiple engines for example the sumbagut2 gas engine power plant in lhokseumawe aceh employs 13 engines to produce 240 mw of power for northern sumatera including north sumatera and aceh this project designs an optimized maintenance schedule based on engine usability and the type of maintenance required according to each generators accumulated operation hours the goal is to maximize system reliability using a mixed integer nonlinear programming optimization approach constraints include maximum duration and maintenance status while the objective function focuses on reliability engine reliability is determined by calculating the components  respective reliability functions in series and system reliability is assessed by placing the engines in parallel the optimized schedule shows that the first maintenance occurs on the 27th day most engines are maintained in pairs with at least one engine undergoing maintenance alone
Boosting Support Vector Machine pada Data Microarray yang Imbalance.,"Pratama, Risky Frasetio Wahyu",http://repository.its.ac.id/55389/,"Data microarray memainkan peran penting dalam pengklasifikasian hampir semua jenis jaringan kanker. Permasalahan yang seringkali dihadapi dalam klasifikasi menggunakan data microarray adalah high dimensional data dan kelas imbalance. Masalah high dimensional data dapat diatasi dengan menggunakan seleksi fitur Fast Correlated Based Filter. Metode klasifikasi yang digunakan dalam penelitian ini yaitu Support Vector Machines (SVM) karena beberapa kelebihannya, namun SVM sangat sensitif terhadap kelas imbalance. SMOTE merupakan salah satu dalam penanganan data imbalance dengan cara mereplikasi pengamatan pada kelas minoritas. Metode ini seringkali bekerja baik namun terkadang juga terjadi masalah overfitting. Salah satu alternatif lain dalam meningkatkan performansi klasifikasi pada data imbalance yaitu boosting. Metode ini membangun suatu classifier akhir yang kuat dengan menggabungkan sekumpulan SVM sebagai base classifier selama proses iterasi, sehingga dapat meningkatkan performansi klasifikasi. Penelitian ini, bertujuan untuk mengkaji performansi dari SMOTEBoost-SVM jika dibandingkan dengan AdaBoost-SVM dalam melakukan klasifikasi pada data microarray dengan beberapa tingkatan rasio imbalance yang didesain dalam studi simulasi dan penerapan pada data publik microarray. Data publik yang digunakan yaitu data kanker colon dan data myeloma. Hasil analisis yang diperoleh yaitu secara umum, pada studi simulasi, semua classifier mengalami penurunan performansi g-mean seiring bertambahnya rasio kelas imbalance, namun SMOTEBoost-SVM cenderung unggul dan mengalami penurunan performansi lebih kecil (lebih stabil) dibandingkan AdaBoost-SVM, SMOTE-SVM dan SVM. Pada Penerapan data publik, SMOTEBoost SVM juga  mengungguli ketiga metode lain berdasarkan ukuran g-mean dan sensitivity. Efek dari seleksi fitur juga dilihat dalam analisis dimana menggunakan fitur-fitur informatif hasil seleksi fitur, menghasilkan performansi yang lebih baik dibandingkan menggunakan seluruh fitur dalam klasifikasi.========================================================================================================Microarray data plays an important role in the classification of almost all types of cancer tissue. The problems that often appear in the classification using microarray data are high-dimensional data and imbalanced class. The problem of high-dimensional data can be solved by using Fast Correlated Based Filter (FCBF) feature selection. In this paper, Support Vector Machine (SVM) classifier is used because of its advantages. However, SVM are sensitive with respect to imbalanced class. SMOTE is one of the prepocessing data methods in handling imbalanced class based on sampling approach by increasing the number of samples from the minority class. This method often works well but sometimes it might suffer from over-fitting problem. One other alternative approach in improving the performance of imbalanced data classification is boosting. This method constructs a powerful final classifier by combining a set of SVMs as base classifier during the iteration process. So, it can improve the classification performance. This study aims to see the performance of SMOTEBoost-SVM compared with AdaBoost-SVM in classifying microarray data with several levels of imbalance ratio designed in the simulation study and to apply classification process on public microarray datasets. Colon cancer and myeloma data are used in this study. The result showed that in the simulation study, all classifiers get the g-mean performance deacreasing as the ratio of the imbalanced class is increased, but SMOTEBoost-SVM tend to be superior. Its performance is decrease smaller (more stable) than AdaBoost-SVM, SMOTE-SVM and SVM. In the real data classification, SMOTEBoost-SVM outperforms the others with respect to g-mean and sensitivity metrics.The effect of feature selection is also checked in the analysis. Using informative features obtained in feature selection process gave the better performance than using all feature in the classification process by SVM.",boosting support vector machine data microarray imbalance,data microarray main peran klasifikasi jenis jaring kanker masalah seringkali hadap klasifikasi data microarray high dimensional data kelas imbalance high dimensional data atas seleksi fitur fast correlated based filter metode klasifikasi teliti support vector machines svm lebih svm sensitif kelas imbalance smote salah tangan data imbalance mereplikasi amat kelas minoritas metode seringkali terkadang overfitting salah alternatif tingkat performansi klasifikasi data imbalance boosting metode bangun classifier kuat gabung kumpul svm base classifier proses iterasi tingkat performansi klasifikasi teliti tuju kaji performansi smoteboostsvm banding adaboostsvm klasifikasi data microarray tingkat rasio imbalance desain studi simulasi terap data publik microarray data publik data kanker colon data myeloma hasil analisis oleh studi simulasi classifier alami turun performansi gmean iring tambah rasio kelas imbalance smoteboostsvm cenderung unggul alami turun performansi stabil banding adaboostsvm smotesvm svm terap data publik smoteboost svm unggul tiga metode dasar ukur gmean sensitivity efek seleksi fitur analisis mana fiturfitur informatif hasil seleksi fitur hasil performansi banding fitur klasifikasimicroarray data plays an important role in the classification of almost all types of cancer tissue the problems that often appear in the classification using microarray data are highdimensional data and imbalanced class the problem of highdimensional data can be solved by using fast correlated based filter fcbf feature selection in this paper support vector machine svm classifier is used because of its advantages however svm are sensitive with respect to imbalanced class smote is one of the prepocessing data methods in handling imbalanced class based on sampling approach by increasing the number of samples from the minority class this method often works well but sometimes it might suffer from overfitting problem one other alternative approach in improving the performance of imbalanced data classification is boosting this method constructs a powerful final classifier by combining a set of svms as base classifier during the iteration process so it can improve the classification performance this study aims to see the performance of smoteboostsvm compared with adaboostsvm in classifying microarray data with several levels of imbalance ratio designed in the simulation study and to apply classification process on public microarray datasets colon cancer and myeloma data are used in this study the result showed that in the simulation study all classifiers get the gmean performance deacreasing as the ratio of the imbalanced class is increased but smoteboostsvm tend to be superior its performance is decrease smaller more stable than adaboostsvm smotesvm and svm in the real data classification smoteboostsvm outperforms the others with respect to gmean and sensitivity metricsthe effect of feature selection is also checked in the analysis using informative features obtained in feature selection process gave the better performance than using all feature in the classification process by svm
Trajectory Tracking Pada Mobil Autonomous Menggunakan Prediction Control Dengan Referensi Waktu.,"Priambudi, Renardi Adryantoro",http://repository.its.ac.id/99705/,"Pengaturan pada kendaraan self-driving khusus nya pada topic trajectory tracking sangat banyak dikembangkan oleh civitas akademisi. Pada kasus ini penulis coba menyelesaikan permasalahan trajectory tracking menggunakan pendekatan non-linear yang memiliki batasan waktu tempuh. Pada penelitan ini akan dibentuk time mission control diaman didalamnya terdapat kontrol lateral dan kontrol longitudinal. Kontrol longitudinal dibentuk menggunakan Bezier curve yang akan membentuk local path baru pada saat ingin mendahului mobil lain.Kontrol lateral dibentuk dari gabungan velocity profile dan adaptive cruise control yang akan mengatur kecepatan mobil. Mobil autonomous juga harus memenuhi time mission, dimana mobil akan bergerak dengan kecepatan dinamis dengan menyesuaikan waktu yang telah ditentukan serta kondisi lalu lintas yang ada. Kontrol trejektori menggunakan PID, Mobil akan diamati hanya terhadap jalan yang dilaluinya. Hasil yang diamati adalah visual path yang dibentuk dari mobilautonomous pada saat bergerak dengan referensi global path dan error waktu tempuhnya.======================================================================================================================================The development of self-driving vehicles, particularly in the field of trajectory tracking, has been extensively explored by academia. In this case, the author attempts to address the trajectory tracking issue using a nonlinear approach with a time constraint. This research focuses on implementing a time mission control system that incorporates both lateral and longitudinal control. The longitudinal control is established using a Bezier curve, which creates a new local path when overtaking other vehicles. The lateral control is a combination of a velocity profile and adaptive cruise control, which regulates the vehicle's speed.The autonomous vehicle must also adhere to the time mission, meaning it moves at a dynamic speed, adjusting to the predetermined time and traffic conditions. Trajectory control is achieved using a PID controller, with the vehicle's observations limited to the road it is traveling on. The observed results include the visual path formed by the autonomous vehicle in relation to the global path reference and the corresponding travel time error.",trajectory tracking mobil autonomous prediction control referensi,atur kendara selfdriving khusus nya topic trajectory tracking kembang civitas akademisi tulis coba selesai masalah trajectory tracking dekat nonlinear milik batas tempuh penelitan bentuk time mission control diam dalam kontrol lateral kontrol longitudinal kontrol longitudinal bentuk bezier curve bentuk local path dahulu mobil lainkontrol lateral bentuk gabung velocity profile adaptive cruise control atur cepat mobil mobil autonomous penuh time mission mana mobil gerak cepat dinamis sesuai tentu kondisi lintas kontrol trejektori pid mobil amat jalan lalu hasil amat visual path bentuk mobilautonomous gerak referensi global path error tempuhnyathe development of selfdriving vehicles particularly in the field of trajectory tracking has been extensively explored by academia in this case the author attempts to address the trajectory tracking issue using a nonlinear approach with a time constraint this research focuses on implementing a time mission control system that incorporates both lateral and longitudinal control the longitudinal control is established using a bezier curve which creates a new local path when overtaking other vehicles the lateral control is a combination of a velocity profile and adaptive cruise control which regulates the vehicles speedthe autonomous vehicle must also adhere to the time mission meaning it moves at a dynamic speed adjusting to the predetermined time and traffic conditions trajectory control is achieved using a pid controller with the vehicles observations limited to the road it is traveling on the observed results include the visual path formed by the autonomous vehicle in relation to the global path reference and the corresponding travel time error
Optimizing The Pricing of Egrek Merah Putih's Blade with Different Materials Qualities Using Responsive Pricing Strategy.,"Pribadi, Riski Puteri",http://repository.its.ac.id/108309/,"Indonesia's palm oil production significantly contributes to the country's GDP, with a volume of 46.50 million tons and an area of 15.380.981 ha in 2022, making it the world's top producer. However, Indonesia faces challenges in palm oil agriculture, particularly during harvesting. These challenges include difficulty determining fruit ripeness and quality material preferences, leading to a tendency to import harvesting sickle blades from abroad. To overcome these issues, innovative solution like the development of Egrek Merah Putih's blade from Institut Teknologi Sepuluh Nopember offers two quality materials: regular (Japanese Spring Steel) and premium (High-Speed Steel). To compete in the market, strategic pricing decisions based on a responsive pricing strategy are critical, balancing quality differences against market uncertainties influenced by quality valuation and reservation value. The research constructs a profit maximization model for Egrek Merah Putih's blades, considering reservation value and quality valuation in a responsive pricing strategy. The model includes demand, profitability, and constraint functions for regular and premium blades. Parameters include market demand, overall quality valuation, reservation value, customer Willingness to Pay (WTP), production costs, and percentage multiplier of customer Willingness to Pay (WTP). In the obtained data of 6245 demands, the optimal regular blade’s selling price is Rp225.000 with a profit of Rp27.231.105. The optimal premium blade’s selling price is Rp450.000 with a profit of Rp461.113.372. Quality valuation measures customer satisfaction with quality, while reservation value is the minimum price for a basic product. As quality valuation increases, premium blade demand and profit rise while regular blade demand and profit decline. As reservation value increases, regular blade demand and profit increase proportionally. With both increasing, overall demand and profit for both blades improve, with premium blade contributing more profit due to higher prices and quality preferences. The highest profit occurs at maximum quality valuation and maximum reservation value.=================================================================================================================================Produksi minyak sawit Indonesia memberikan kontribusi signifikan terhadap PDB negara, dengan volume sebesar 46,50 juta ton dan luas wilayah 15.380.981 ha pada tahun 2022, menjadikannya produsen terbesar dunia. Namun, Indonesia menghadapi tantangan dalam pertanian kelapa sawit, khususnya pada saat panen. Tantangan tersebut antara lain sulitnya menentukan kematangan buah dan preferensi kualitas bahan sehingga menimbulkan kecenderungan untuk mengimpor bilah dari luar negeri. Untuk mengatasi permasalahan tersebut, solusi inovatif seperti pengembangan bilah Egrek Merah Putih dari Institut Teknologi Sepuluh Nopember menawarkan dua material berkualitas: reguler (Japanese Spring Steel) dan premium (High-Speed Steel). Untuk bersaing di pasar, keputusan penetapan harga strategis berdasarkan strategi penetapan harga yang responsif sangat penting, menyeimbangkan perbedaan kualitas dengan ketidakpastian pasar yang dipengaruhi oleh penilaian kualitas dan nilai reservasi. Penelitian ini membangun model memaksimalkan keuntungan bilah Egrek Merah Putih dengan mempertimbangkan nilai reservasi dan penilaian kualitas dalam strategi penetapan harga yang responsif. Model ini mencakup fungsi permintaan, profitabilitas, dan kendala untuk bilah reguler dan premium. Parameternya meliputi permintaan pasar, penilaian kualitas secara keseluruhan, nilai reservasi, Willingness to Pay (WTP) pelanggan, biaya produksi, dan persentase pengali Willingness to Pay (WTP) pelanggan. Pada data permintaan 6245 yang diperoleh, harga jual bilah reguler optimal adalah Rp225.000 dengan keuntungan Rp27.231.105. Harga jual bilah premium optimal sebesar Rp450.000 dengan keuntungan sebesar Rp461.113.372. Penilaian kualitas mengukur kepuasan pelanggan terhadap kualitas, sedangkan nilai reservasi adalah harga minimum untuk suatu produk dasar. Ketika penilaian kualitas meningkat, permintaan dan keuntungan bilah premium meningkat sementara permintaan dan keuntungan bilah reguler menurun. Ketika nilai reservasi meningkat, permintaan dan keuntungan bilah reguler meningkat secara proporsional. Dengan meningkatkan keduanya, keseluruhan permintaan dan keuntungan untuk kedua bilah meningkat dengan bilah premium memberikan kontribusi keuntungan lebih besar karena harga dan preferensi kualitas yang lebih tinggi. Keuntungan tertinggi terjadi pada penilaian kualitas maksimum dan nilai reservasi maksimum.",optimizing the pricing of egrek merah putihs blade with different materials qualities using responsive pricing strategy,indonesias palm oil production significantly contributes to the countrys gdp with a volume of 4650 million tons and an area of 15380981 ha in 2022 making it the worlds top producer however indonesia faces challenges in palm oil agriculture particularly during harvesting these challenges include difficulty determining fruit ripeness and quality material preferences leading to a tendency to import harvesting sickle blades from abroad to overcome these issues innovative solution like the development of egrek merah putihs blade from institut teknologi puluh nopember offers two quality materials regular japanese spring steel and premium highspeed steel to compete in the market strategic pricing decisions based on a responsive pricing strategy are critical balancing quality differences against market uncertainties influenced by quality valuation and reservation value the research constructs a profit maximization model for egrek merah putihs blades considering reservation value and quality valuation in a responsive pricing strategy the model includes demand profitability and constraint functions for regular and premium blades parameters include market demand overall quality valuation reservation value customer willingness to pay wtp production costs and percentage multiplier of customer willingness to pay wtp in the obtained data of 6245 demands the optimal regular blade  s selling price is rp225000 with a profit of rp27231105 the optimal premium blade  s selling price is rp450000 with a profit of rp461113372 quality valuation measures customer satisfaction with quality while reservation value is the minimum price for a basic product as quality valuation increases premium blade demand and profit rise while regular blade demand and profit decline as reservation value increases regular blade demand and profit increase proportionally with both increasing overall demand and profit for both blades improve with premium blade contributing more profit due to higher prices and quality preferences the highest profit occurs at maximum quality valuation and maximum reservation valueproduksi minyak sawit indonesia kontribusi signifikan pdb negara volume 4650 juta ton luas wilayah 15380981 ha 2022 jadi produsen besar dunia indonesia hadap tantang tani kelapa sawit panen tantang sulit tentu matang buah preferensi kualitas bahan timbul cenderung impor bilah negeri atas masalah solusi inovatif kembang bilah egrek merah putih institut teknologi puluh nopember tawar material kualitas reguler japanese spring steel premium highspeed steel saing pasar putus tetap harga strategis dasar strategi tetap harga responsif imbang beda kualitas ketidakpastian pasar pengaruh nilai kualitas nilai reservasi teliti bangun model maksimal untung bilah egrek merah putih timbang nilai reservasi nilai kualitas strategi tetap harga responsif model cakup fungsi minta profitabilitas kendala bilah reguler premium parameter liput minta pasar nilai kualitas nilai reservasi willingness to pay wtp langgan biaya produksi persentase ali willingness to pay wtp langgan data minta 6245 oleh harga jual bilah reguler optimal rp225000 untung rp27231105 harga jual bilah premium optimal rp450000 untung rp461113372 nilai kualitas ukur puas langgan kualitas nilai reservasi harga minimum produk dasar nilai kualitas tingkat minta untung bilah premium tingkat minta untung bilah reguler turun nilai reservasi tingkat minta untung bilah reguler tingkat proporsional tingkat minta untung bilah tingkat bilah premium kontribusi untung harga preferensi kualitas untung tinggi nilai kualitas maksimum nilai reservasi maksimum
Reidentifikasi Orang Pada Data Visible-Infrared Yang Terkorupsi Menggunakan Klasifier Vision Transformer.,"Pusaka, Nathanael Tenno Phileo Wong",http://repository.its.ac.id/111951/,"Teknik Reidentifikasi orang, yaitu mengidentifikasi kembali individu berdasarkan data gambar atau video yang telah ada. Dalam era modern, Reidentifikasi menjadi penting di bidang keamanan dan pemantauan. Dataset RegDB-C berisi gambar tampak dan infrared dari berba gai individu. Vision Transformer (ViT) merupakan arsitektur jaringan saraf yang efektif dalam memproses data visual-infrared, terutama saat data tersebut terkorupsi.Penilitian ini berfokus untuk mengidentifikasi orang pada berbagai kondisi pencahayaan, perubahan cahaya yang ek strim, perubahan suhu, data yang terkena noise pada data Visible-infrred dengan menggunakan dataset RegDB-C yang terdiri dari 2.060 citra visible dan 2.060 cintra infrared.Meskipun terda pat permasalahan berupa dataset yang mengalami korupsi, Vision Transformer dapat mengiden tifikasi individu secara akurat.Penilitian ini menggunakan berbagai konfigurasi model Vision Transformer, dengan pengujian menggunakan batchsize 16, 32, 64, dan modifikasi hyperpa rameter seperti learning rate dan loss function.Hasil yang didapatkan tertinggi pada Vision Transformer yang telah dimodifikasi hyperparameter dengan nilai MAP (mean Average Pre cision) yang didapatkan yaitu senilai 0,436899, dengan Rank@1 senilai :0.396440 , Rank@5 senilai 0.601942,dan Rank@10 senilai 0.702265.Penilitian ini diharapkan dapat berkontribusi dalam mengembangkan sistem reidentifikasi pada data visible-infrared yang terkorupsi meng gunakan klasifer Vision Transformer.====================================================================================================Person Reidentification techniques involve re-identifying individuals based on existing image or video data. In the modern era, reidentification has become crucial in the fields of security and monitoring. The RegDB-C dataset contains visible and infrared images of various individ uals. Vision Transformer (ViT) is a neural network architecture that is effective in processing visual-infrared data, especially when the data is corrupted. This research focuses on identifying people under various lighting conditions, extreme light changes, temperature variations, and noise in the visible-infrared data using the RegDB-C dataset, which consists of 2,060 visible images and 2,060 infrared images. Despite issues such as data corruption, Vision Transformer can accurately identify individuals. This study employs various configurations of the Vision Transformer model, testing with batch sizes of 16, 32, and 64, and modifying hyperparameters such as learning rate and loss function. The highest results were obtained with the Vision Trans former model that had modified hyperparameters, achieving a mean Average Precision (MAP) of 0.436899, with Rank@1 of 0.396440, Rank@5 of 0.601942, and Rank@10 of 0.702265. This research is expected to contribute to the development of reidentification systems for corrupted visible-infrared data using Vision Transformer classifiers.",reidentifikasi orang data visibleinfrared korupsi klasifier vision transformer,teknik reidentifikasi orang identifikasi individu dasar data gambar video era modern reidentifikasi bidang aman pantau dataset regdbc isi gambar infrared berba gai individu vision transformer vit arsitektur jaring saraf efektif proses data visualinfrared data terkorupsipenilitian fokus identifikasi orang kondisi cahaya ubah cahaya ek strim ubah suhu data kena noise data visibleinfrred dataset regdbc 2060 citra visible 2060 cintra infraredmeskipun terda pat masalah dataset alami korupsi vision transformer mengiden tifikasi individu akuratpenilitian konfigurasi model vision transformer uji batchsize 16 32 64 modifikasi hyperpa rameter learning rate loss functionhasil dapat tinggi vision transformer modifikasi hyperparameter nilai map mean average pre cision dapat nila 0436899 rank1 nila 0396440 rank5 nila 0601942dan rank10 nila 0702265penilitian harap kontribusi kembang sistem reidentifikasi data visibleinfrared korupsi meng klasifer vision transformerperson reidentification techniques involve reidentifying individuals based on existing image or video data in the modern era reidentification has become crucial in the fields of security and monitoring the regdbc dataset contains visible and infrared images of various individ uals vision transformer vit is a neural network architecture that is effective in processing visualinfrared data especially when the data is corrupted this research focuses on identifying people under various lighting conditions extreme light changes temperature variations and noise in the visibleinfrared data using the regdbc dataset which consists of 2060 visible images and 2060 infrared images despite issues such as data corruption vision transformer can accurately identify individuals this study employs various configurations of the vision transformer model testing with batch sizes of 16 32 and 64 and modifying hyperparameters such as learning rate and loss function the highest results were obtained with the vision trans former model that had modified hyperparameters achieving a mean average precision map of 0436899 with rank1 of 0396440 rank5 of 0601942 and rank10 of 0702265 this research is expected to contribute to the development of reidentification systems for corrupted visibleinfrared data using vision transformer classifiers
Analisis Sentimen Pengguna Aplikasi Shopee Pada Situs Google Play Store Menggunakan Metode Support Vector Machine.,"Putra, Fahmi Maulutfi Dwi",http://repository.its.ac.id/103742/,"Marketplace adalah tempat jual beli online dimana penjual baru menerima uangnya jika barang sudah sampai ke pembeli, sedangkan E-Commerce adalah transaksi jual beli atau perdagangan secara online. Salah satu marketplace yang sangat diminati saat ini dikalangan remaja hingga dewasa adalah Shopee. Shopee resmi diperkenalkan di Indonesia pada Desember 2015 dibawah naungan PT Shopee International Indonesia. Shopee adalah sebuah aplikasi yang bergerak dibidang jual beli secara online dan dapat diakses secara mudah dengan menggunakan smartphone. Shopee merupakan aplikasi jual beli elektronik yang dapat diunduh di situs Google Play. Google Play Store memiliki berbagai macam fitur, salah satunya adalah ulasan atau opini. Ulasan atau opini ini digunakan untuk para pengguna menilai sebuah aplikasi. Pengguna aplikasi Shopee dapat memberikan opini yang berisi tanggapan, apresiasi, kritik dan masukan pada aplikasi Shopee yang tersedia di Google Play Store. Opini pada aplikasi Shopee dapat digunakan untuk mendapatkan informasi sebagai bahan perbaikan atau pengembangan aplikasi sehingga pengguna mendapatkan kepuasan. Proses pengembangan membutuhkan opini dari pengguna, hal tersebut bisa didapat dari data opini pada Google Play Store dalam bentuk data teskstual. Data tekstual tersebut bisa dianalisis menggunakan text mining. Banyak metode yang dapat digunakan untuk memudahkan proses klasifikasi sentiment data, setiap metode memiliki karakteristik berbeda sehingga tingkat keefektifan setiap metode berbeda-beda. Dalam menganalisis opini dibutuhkan metode yang cepat dan akurat yaitu analisis sentimen dengan metode Support Vector Machine (SVM). Hasil penelitian menunjukkan bahwa untuk analisis sentimen dengan kategori sentimen positif yaitu sebesar sebesar 53,13%, sedangkan untuk opini pengguna aplikasi Shopee berdasarkan kategori sentimen negatif sebesar 46,87% dengan hasil nilai accuracy sebesar 64,5%, nilai sensitivity sebesar 60,1%, dan nilai specificity sebesar 69,5%.=================================================================================================================================Marketplace is a place for buying and selling online where sellers only receive money if the goods have reached the buyer, while E-Commerce is buying and selling or trading transactions online. One of the marketplaces that is in great demand today among teenagers to adults is Shopee. Shopee was officially introduced in Indonesia in December 2015 under the auspices of PT Shopee International Indonesia. Shopee is an application engaged in buying and selling online and can be accessed easily using a smartphone. Shopee is an electronic buying and selling application that can be downloaded on the Google Play site. The Google Play Store has various features, one of which is reviews or opinions. These reviews or opinions are used for users to rate an application. Shopee application users can provide opinions that contain responses, appreciation, criticism and input on the Shopee application which is available on the Google Play Store. Opinions on the Shopee application can be used to obtain information as material for improvement or application development so that users get satisfaction. The development process requires opinions from users, this can be obtained from opinion data on the Google Play Store in the form of textual data. The textual data can be analyzed using text mining. Many methods can be used to facilitate the sentiment data classification process, each method has different characteristics so that the level of effectiveness of each method varies. In analyzing opinions, a fast and accurate method is needed, namely sentiment analysis using the Support Vector Machine (SVM) method. The results showed that for sentiment analysis the positive sentiment category was 53.13%, while for the opinion of Shopee application users based on the negative sentiment category it was 46.87% with an accuracy value of 64.5%, a sensitivity value of 60.1%, and a specificity value of 69.5%.",analisis sentimen guna aplikasi shopee situs google play store metode support vector machine,marketplace jual beli online mana jual terima uang barang beli ecommerce transaksi jual beli dagang online salah marketplace mati kalang remaja dewasa shopee shopee resmi kenal indonesia desember 2015 bawah naung pt shopee international indonesia shopee aplikasi gerak bidang jual beli online akses mudah smartphone shopee aplikasi jual beli elektronik unduh situs google play google play store milik fitur salah satu ulas opini ulas opini guna nilai aplikasi guna aplikasi shopee opini isi tanggap apresiasi kritik masuk aplikasi shopee sedia google play store opini aplikasi shopee informasi bahan baik kembang aplikasi guna puas proses kembang butuh opini guna data opini google play store bentuk data teskstual data tekstual analis text mining metode mudah proses klasifikasi sentiment data metode milik karakteristik beda tingkat efektif metode berbedabeda analis opini butuh metode cepat akurat analisis sentimen metode support vector machine svm hasil teliti analisis sentimen kategori sentimen positif 5313 opini guna aplikasi shopee dasar kategori sentimen negatif 4687 hasil nilai accuracy 645 nilai sensitivity 601 nilai specificity 695marketplace is a place for buying and selling online where sellers only receive money if the goods have reached the buyer while ecommerce is buying and selling or trading transactions online one of the marketplaces that is in great demand today among teenagers to adults is shopee shopee was officially introduced in indonesia in december 2015 under the auspices of pt shopee international indonesia shopee is an application engaged in buying and selling online and can be accessed easily using a smartphone shopee is an electronic buying and selling application that can be downloaded on the google play site the google play store has various features one of which is reviews or opinions these reviews or opinions are used for users to rate an application shopee application users can provide opinions that contain responses appreciation criticism and input on the shopee application which is available on the google play store opinions on the shopee application can be used to obtain information as material for improvement or application development so that users get satisfaction the development process requires opinions from users this can be obtained from opinion data on the google play store in the form of textual data the textual data can be analyzed using text mining many methods can be used to facilitate the sentiment data classification process each method has different characteristics so that the level of effectiveness of each method varies in analyzing opinions a fast and accurate method is needed namely sentiment analysis using the support vector machine svm method the results showed that for sentiment analysis the positive sentiment category was 5313 while for the opinion of shopee application users based on the negative sentiment category it was 4687 with an accuracy value of 645 a sensitivity value of 601 and a specificity value of 695
Implementasi IndoBERT Dalam Analisis Sentimen Berita Untuk Prediksi Harga Saham PT. Bank Rakyat Indonesia Tbk. Menggunakan Pendekatan Support Vector Regression.,"Putra, Ferdyansyah Permana",http://repository.its.ac.id/105901/,"Fluktuasi harga saham sering dipengaruhi oleh berbagai faktor, dan salah satunya adalah sentimen, yang dapat berasal dari masyarakat umum atau berita terkait saham. Harga saham PT. Bank Rakyat Indonesia Tbk. (BBRI), sebagai salah satu dari ""big four"" bank terbesar di Indonesia, juga dapat dipengaruhi oleh sentimen ini. Dalam usaha untuk meramalkan harga penutupan saham BBRI berdasarkan sentimen berita, penelitian ini mengadopsi pendekatan machine learning dengan menggunakan metode Support Vector Regression (SVR) dan mengoptimalkan fungsi dengan algoritma Fruit Fly Optimization Algorithm (FOA). Sentimen dievaluasi terlebih dahulu dengan metode IndoBERT. Penelitian ini mengusulkan beberapa model, termasuk model tanpa memperhitungkan sentimen, model dengan mempertimbangkan sentimen pada periode ke t, model dengan mempertimbangkan sentimen pada periode ke t-1, dan model dengan mempertimbangkan sentimen pada periode ke t dan periode ke t-1. Analisis hasil sentimen menggunakan IndoBERT menunjukkan tingkat akurasi sentimen secara keseluruhan di atas 90%. Selain itu, hasil pemodelan menunjukkan bahwa model terbaik menggunakan SVR adalah model yang tidak mempertimbangkan sentimen, dengan nilai error peramalan yaitu Mean Average Percentage Error (MAPE) lebih rendah dibandingkan dengan model lain. Hasil peramalan dengan dari model terbaik menunjukkan bahwa data aktual masih berada dalam interval kepercayaan 95% dari hasil ramalan, sehingga menunjukkan relevansi ramalan dengan data aktual.=================================================================================================================================Fluctuations in stock prices are often influenced by various factors, and one of them is sentiment, which can originate from the general public or stock-related news. The stock price of PT. Bank Rakyat Indonesia Tbk. (BBRI), as one of the ""big four"" largest banks in Indonesia, can also be influenced by this sentiment. In an effort to forecast the closing price of BBRI stock based on news sentiment, this research adopts a machine learning approach using the Support Vector Regression (SVR) method and optimizes the function with the Fruit Fly Optimization Algorithm (FOA). Sentiment is first evaluated using the IndoBERT method. This research proposes several models, including a model without considering sentiment, a model considering sentiment on the day of the event, a model considering sentiment on the previous day, and a model considering sentiment on both the day of the event and the previous day. Sentiment analysis results using IndoBERT show an overall accuracy rate above 90%. Furthermore, modelling results indicate that the best-performing SVR model is the one that does not consider sentiment, with a lower Mean Average Percentage Error (MAPE) compared to other models. The forecasting results from the best model show that the actual data still falls within the 95% confidence interval of the forecast, demonstrating the relevance of the forecast to the actual data.",implementasi indobert analisis sentimen berita prediksi harga saham pt bank rakyat indonesia tbk dekat support vector regression,fluktuasi harga saham pengaruh faktor salah satu sentimen asal masyarakat berita kait saham harga saham pt bank rakyat indonesia tbk bbri salah big four bank besar indonesia pengaruh sentimen usaha ramal harga tutup saham bbri dasar sentimen berita teliti adopsi dekat machine learning metode support vector regression svr optimal fungsi algoritma fruit fly optimization algorithm foa sentimen evaluasi metode indobert teliti usul model model hitung sentimen model timbang sentimen periode t model timbang sentimen periode t1 model timbang sentimen periode t periode t1 analisis hasil sentimen indobert tingkat akurasi sentimen 90 hasil model model baik svr model timbang sentimen nilai error amal mean average percentage error mape rendah banding model hasil amal model baik data aktual interval percaya 95 hasil ramal relevansi ramal data aktualfluctuations in stock prices are often influenced by various factors and one of them is sentiment which can originate from the general public or stockrelated news the stock price of pt bank rakyat indonesia tbk bbri as one of the big four largest banks in indonesia can also be influenced by this sentiment in an effort to forecast the closing price of bbri stock based on news sentiment this research adopts a machine learning approach using the support vector regression svr method and optimizes the function with the fruit fly optimization algorithm foa sentiment is first evaluated using the indobert method this research proposes several models including a model without considering sentiment a model considering sentiment on the day of the event a model considering sentiment on the previous day and a model considering sentiment on both the day of the event and the previous day sentiment analysis results using indobert show an overall accuracy rate above 90 furthermore modelling results indicate that the bestperforming svr model is the one that does not consider sentiment with a lower mean average percentage error mape compared to other models the forecasting results from the best model show that the actual data still falls within the 95 confidence interval of the forecast demonstrating the relevance of the forecast to the actual data
Optimasi Model Klasifikasi Multi-Label Berbahasa Indonesia: Penerapan dan Perbandingan Metode Bi-LSTM dan BERT pada Teks Berita Berbahasa Indonesia.,"Putra, Marsyavero Charisyah",http://repository.its.ac.id/111093/,"Pengguna internet di Indonesia terus meningkat setiap tahunnya. Pada tahun 2023, survei APJII mencatat 78,19% populasi Indonesia menggunakan internet, meningkat 2,67% dari tahun sebelumnya. Peningkatan ini mendorong pertumbuhan media online dan mengubah cara masyarakat mengakses berita dari media cetak ke online. Dengan bertambahnya pengguna internet, volume berita online juga meningkat signifikan. Diperlukan teknik efisien untuk mengelola dan mengklasifikasikan berita agar memudahkan pengguna memahami informasi yang relevan. Penelitian ini mengembangkan model multilabel classification menggunakan Bi-LSTM dan BERT serta membandingkan performanya dengan model dari penelitian sebelumnya. Dataset berasal dari scraping teks berita dari detik.com dan Petakabar, dijadikan satu dataset bernama Topic Mining. Dataset dilabeli secara manual dengan 39 label. Empat model dikembangkan: Bi-LSTM, Bi-LSTM dengan Attention, BERT, dan Hybrid (kombinasi BERT dan Bi-LSTM dengan Attention). Evaluasi kinerja model menggunakan metrik F1-Score, akurasi, recall, dan hamming loss. Model Hybrid menunjukkan performa terbaik dengan mean recall 0,864, mean F1-score 0,893, mean accuracy 0,981, dan mean Hamming Loss 0,019. Label yang berperforma terbaik adalah ""bencana"" dengan F1-score 0,973, sedangkan label yang berperforma terburuk adalah ""politik"" dengan F1-score 0,279.==============================================================================================================================The number of internet users in Indonesia continues to increase every year. In 2023, a survey by APJII recorded that 78.19% of Indonesia's population uses the internet, an increase of 2.67% from the previous year. This growth has driven the rapid expansion of online media and changed the way people access news from print to online. With more internet users, the volume of online news has also increased significantly. Efficient techniques are needed to manage and classify news to help users understand relevant information. This study developed a multi-label classification model using Bi-LSTM and BERT and compared its performance with the previous model from the previous research. The dataset, named Topic Mining, was created by scraping news texts from detik.com and Petakabar. The dataset was manually labeled with 39 labels. Four models were developed: Bi-LSTM, Bi-LSTM with Attention, BERT, and Hybrid (a combination of BERT and Bi-LSTM with Attention). Model performance was evaluated using F1-Score, accuracy, recall, and hamming loss. The Hybrid model showed the best performance with a mean recall of 0,864, a mean F1-score of 0,893, a mean accuracy of 0,981, and a mean hamming loss of 0,019. With the best-performing label is ""disaster"" with an F1-score of 0,973, while the worst performing label is ""politics"" with an F1-score of 0,279.",optimasi model klasifikasi multilabel bahasa indonesia terap banding metode bilstm bert teks berita bahasa indonesia,guna internet indonesia tingkat tahun 2023 survei apjii catat 7819 populasi indonesia internet tingkat 267 tingkat dorong tumbuh media online ubah masyarakat akses berita media cetak online tambah guna internet volume berita online tingkat signifikan teknik efisien kelola klasifikasi berita mudah guna paham informasi relevan teliti kembang model multilabel classification bilstm bert banding performa model teliti dataset asal scraping teks berita detikcom petakabar jadi dataset nama topic mining dataset label manual 39 label model kembang bilstm bilstm attention bert hybrid kombinasi bert bilstm attention evaluasi kerja model metrik f1score akurasi recall hamming loss model hybrid performa baik mean recall 0864 mean f1score 0893 mean accuracy 0981 mean hamming loss 0019 label performa baik bencana f1score 0973 label performa buruk politik f1score 0279the number of internet users in indonesia continues to increase every year in 2023 a survey by apjii recorded that 7819 of indonesias population uses the internet an increase of 267 from the previous year this growth has driven the rapid expansion of online media and changed the way people access news from print to online with more internet users the volume of online news has also increased significantly efficient techniques are needed to manage and classify news to help users understand relevant information this study developed a multilabel classification model using bilstm and bert and compared its performance with the previous model from the previous research the dataset named topic mining was created by scraping news texts from detikcom and petakabar the dataset was manually labeled with 39 labels four models were developed bilstm bilstm with attention bert and hybrid a combination of bert and bilstm with attention model performance was evaluated using f1score accuracy recall and hamming loss the hybrid model showed the best performance with a mean recall of 0864 a mean f1score of 0893 a mean accuracy of 0981 and a mean hamming loss of 0019 with the bestperforming label is disaster with an f1score of 0973 while the worst performing label is politics with an f1score of 0279
Sistem Informasi Geografis Berbasis Google Earth API Menggunakan Algoritma K-Nearest Neighbors.,"Putra, Nicky Permana",http://repository.its.ac.id/81664/,"Sistem Informasi Geografis merupakan sistem komputer yang memiliki kemampuan untuk membangun, menyimpan, mengelola dan menampilkan informasi berupa peta geografis suatu daerah. Sistem Informasi Geogafis ini akan digunakan untuk melakukan pengelompokan statistik – statistik daerah dan dikelompokkan pada kategori yang ada untuk kemudian ditampilkan dalam bentuk peta tematik atau peta digital menggunakan algoritma K-Nearest Neighbor. Data – data statistik yang nantinya akan dimasukkan dapat berupa data tingkat kemiskinan, data tingkat pengangguran dari suatu daerah, dll. Algoritma K-NN akan mengelompokkan data sesuai kategori dan saat data-data tersebut sudah terkelompokkan maka peta akan muncul dengan daerah yang sudah diberi warna dimana daerah-daerah tersebut sudah tergolongkan sesuai dengan kategorinya. Hal ini dapat diterapkan di pemerintahan guna untuk mempermudah dalam pengambilan kebijakan dalam suatu daerah",sistem informasi geografis bas google earth api algoritma knearest neighbors,sistem informasi geografis sistem komputer milik mampu bangun simpan kelola tampil informasi peta geografis daerah sistem informasi geogafis kelompok statistik  statistik daerah kelompok kategori tampil bentuk peta tematik peta digital algoritma knearest neighbor data  data statistik masuk data tingkat miskin data tingkat anggur daerah dll algoritma knn kelompok data sesuai kategori datadata kelompok peta muncul daerah warna mana daerahdaerah golong sesuai kategori terap perintah mudah ambil bijak daerah
"Analysis of Bittern Recovery Scenario Using Mixed-Integer Nonlinear Programming: Centralized, Decentralized, and Hybrid Case Study.","Putra, Furqon Sandiva Utomo",http://repository.its.ac.id/89066/,"In the desalination process to produce salts, it left a wastewater with a high concentration of salts, magnesium, and other kinds of mineral called bittern. For some salt producer, these bitterns are considered as waste that are dumped and never be used again. This can be problematic because although bittern water contains similar compounds as seawater, it is much more concentrated. When bittern is directly dumped into the ecosystem, the increase in salinity can pollute and harm the life around the area. Furthermore, it is also a waste in potential since bittern still contains mineral that can be extracted and have selling value. To combat this, bittern recovery has become an increasingly used practice in the salt industry. This is done not only to reduce the environmental impact of salt production, but also create a circular economy. However, there is a strong requirement in determining how the process is carried out. In that, one needs to know the optimal type and number of recovery stations that can meets the supply and demand constrains, cost effective, and beneficial for the environment and economy. This research proposes a mixed-integer nonlinear programming (MINLP) model for analyzing the supply and demand of the bittern recovery to achieve circular economy and environmental sustainability. The research considers the supply and demand structure of bittern and the constrains from the recovery process. The MINLP model is used to optimize the trade-off between the cost of waste transportation, recovery, and station installation, with the benefit from the selling value of the recovered minerals and the environmental sustainability. The objective of the research is to create a model that can determine the best bittern recovery scenario between a centralized, decentralized, or hybrid types of recovery stations based on profit optimization. The proposed system optimizations are tested and analyzed upon its sensitivity.=================================================Dalam proses desalinasi untuk menghasilkan garam, akan meninggalkan limbah cair dengan garam, magnesium, dan jenis mineral lain dengan konsentrasi tinggi yang disebut air tua atau bittern. Bagi produsen garam pada umumnya, bittern ini dianggap sebagai limbah yang dibuang dan tidak akan pernah digunakan lagi. Ini bisa menjadi masalah karena meskipun air bittern mengandung senyawa yang mirip dengan air laut, air tua memiliki kandungan yang jauh lebih pekat sehingga dapat menjadi polusi untuk lingkungan sekitar. Ketika bittern langsung dibuang ke ekosistem, peningkatan salinitas dalam air dapat membahayakan kehidupan di sekitar area tersebut. Selain itu, hal ini juga merupakan penyia-nyiaan potensi, karena bittern masih mengandung mineral yang dapat diekstraksi dan memiliki nilai jual. Untuk mengatasi hal ini, pengolahan bittern telah menjadi praktik yang semakin sering digunakan di industri garam. Hal ini dilakukan tidak hanya untuk mengurangi dampak lingkungan dari produksi garam, tetapi juga menciptakan ekonomi sirkuler. Namun, ada beberapa pertimbangan penting yang menentukan bagaimana proses tersebut dilakukan. Hal ini penting untuk menentukan jenis dan jumlah stasiun pemulihan yang optimal yang dapat memenuhi faktor supply dan demand, kehematan biaya, dan manfaatnya bagi lingkungan serta perekonomian. Penelitian ini mengusulkan model Mixed-Integer Nonlinear programming (MINLP) untuk menganalisis pasok dan permintaan pengolahan bittern untuk mencapai ekonomi sirkuler dan kelestarian lingkungan. Penelitian ini mempertimbangkan struktur supply dan demand bittern dan kendala dan batasan dari proses pemulihan. Model MINLP digunakan untuk mengoptimalkan trade-off antara biaya pengangkutan limbah, pengolahan, dan instalasi stasiun pengolahan, dengan pertimbangan keuntungan yakni nilai jual mineral yang dipulihkan dan kelestarian lingkungan. Tujuan dari penelitian ini adalah untuk memilih skenario pemulihan bittern terbaik antara tipe stasiun pengolahan terpusat, terdesentralisasi, atau hibrid berdasarkan pengoptimalan keuntungan. Optimasi sistem yang diusulkan kemudian diuji dan dianalisis berdasarkan sensitivitasnya======================================================================================================Dalam proses desalinasi untuk menghasilkan garam, akan meninggalkan limbah cair dengan garam, magnesium, dan jenis mineral lain dengan konsentrasi tinggi yang disebut air tua atau bittern. Bagi produsen garam pada umumnya, bittern ini dianggap sebagai limbah yang dibuang dan tidak akan pernah digunakan lagi. Ini bisa menjadi masalah karena meskipun air bittern mengandung senyawa yang mirip dengan air laut, air tua memiliki kandungan yang jauh lebih pekat sehingga dapat menjadi polusi untuk lingkungan sekitar. Ketika bittern langsung dibuang ke ekosistem, peningkatan salinitas dalam air dapat membahayakan kehidupan di sekitar area tersebut. Selain itu, hal ini juga merupakan penyia-nyiaan potensi, karena bittern masih mengandung mineral yang dapat diekstraksi dan memiliki nilai jual. Untuk mengatasi hal ini, pengolahan bittern telah menjadi praktik yang semakin sering digunakan di industri garam. Hal ini dilakukan tidak hanya untuk mengurangi dampak lingkungan dari produksi garam, tetapi juga menciptakan ekonomi sirkuler. Namun, ada beberapa pertimbangan penting yang menentukan bagaimana proses tersebut dilakukan. Hal ini penting untuk menentukan jenis dan jumlah stasiun pemulihan yang optimal yang dapat memenuhi faktor supply dan demand, kehematan biaya, dan manfaatnya bagi lingkungan serta perekonomian. Penelitian ini mengusulkan model Mixed-Integer Nonlinear programming (MINLP) untuk menganalisis pasok dan permintaan pengolahan bittern untuk mencapai ekonomi sirkuler dan kelestarian lingkungan. Penelitian ini mempertimbangkan struktur supply dan demand bittern dan kendala dan batasan dari proses pemulihan. Model MINLP digunakan untuk mengoptimalkan trade-off antara biaya pengangkutan limbah, pengolahan, dan instalasi stasiun pengolahan, dengan pertimbangan keuntungan yakni nilai jual mineral yang dipulihkan dan kelestarian lingkungan. Tujuan dari penelitian ini adalah untuk memilih skenario pemulihan bittern terbaik antara tipe stasiun pengolahan terpusat, terdesentralisasi, atau hibrid berdasarkan pengoptimalan keuntungan. Optimasi sistem yang diusulkan kemudian diuji dan dianalisis berdasarkan sensitivitasnya.",analysis of bittern recovery scenario using mixedinteger nonlinear programming centralized decentralized and hybrid case study,in the desalination process to produce salts it left a wastewater with a high concentration of salts magnesium and other kinds of mineral called bittern for some salt producer these bitterns are considered as waste that are dumped and never be used again this can be problematic because although bittern water contains similar compounds as seawater it is much more concentrated when bittern is directly dumped into the ecosystem the increase in salinity can pollute and harm the life around the area furthermore it is also a waste in potential since bittern still contains mineral that can be extracted and have selling value to combat this bittern recovery has become an increasingly used practice in the salt industry this is done not only to reduce the environmental impact of salt production but also create a circular economy however there is a strong requirement in determining how the process is carried out in that one needs to know the optimal type and number of recovery stations that can meets the supply and demand constrains cost effective and beneficial for the environment and economy this research proposes a mixedinteger nonlinear programming minlp model for analyzing the supply and demand of the bittern recovery to achieve circular economy and environmental sustainability the research considers the supply and demand structure of bittern and the constrains from the recovery process the minlp model is used to optimize the tradeoff between the cost of waste transportation recovery and station installation with the benefit from the selling value of the recovered minerals and the environmental sustainability the objective of the research is to create a model that can determine the best bittern recovery scenario between a centralized decentralized or hybrid types of recovery stations based on profit optimization the proposed system optimizations are tested and analyzed upon its sensitivitydalam proses desalinasi hasil garam tinggal limbah cair garam magnesium jenis mineral konsentrasi air tua bittern produsen garam bittern anggap limbah buang air bittern kandung senyawa air laut air tua milik kandung pekat polusi lingkung bittern langsung buang ekosistem tingkat salinitas air bahaya hidup area penyianyiaan potensi bittern kandung mineral ekstraksi milik nilai jual atas olah bittern praktik industri garam kurang dampak lingkung produksi garam cipta ekonomi sirkuler timbang tentu proses tentu jenis stasiun pulih optimal penuh faktor supply demand hemat biaya manfaat lingkung ekonomi teliti usul model mixedinteger nonlinear programming minlp analis pasok minta olah bittern capai ekonomi sirkuler lestari lingkung teliti timbang struktur supply demand bittern kendala batas proses pulih model minlp optimal tradeoff biaya angkut limbah olah instalasi stasiun olah timbang untung nilai jual mineral pulih lestari lingkung tuju teliti pilih skenario pulih bittern baik tipe stasiun olah pusat desentralisasi hibrid dasar optimal untung optimasi sistem usul uji analis dasar sensitivitasnyadalam proses desalinasi hasil garam tinggal limbah cair garam magnesium jenis mineral konsentrasi air tua bittern produsen garam bittern anggap limbah buang air bittern kandung senyawa air laut air tua milik kandung pekat polusi lingkung bittern langsung buang ekosistem tingkat salinitas air bahaya hidup area penyianyiaan potensi bittern kandung mineral ekstraksi milik nilai jual atas olah bittern praktik industri garam kurang dampak lingkung produksi garam cipta ekonomi sirkuler timbang tentu proses tentu jenis stasiun pulih optimal penuh faktor supply demand hemat biaya manfaat lingkung ekonomi teliti usul model mixedinteger nonlinear programming minlp analis pasok minta olah bittern capai ekonomi sirkuler lestari lingkung teliti timbang struktur supply demand bittern kendala batas proses pulih model minlp optimal tradeoff biaya angkut limbah olah instalasi stasiun olah timbang untung nilai jual mineral pulih lestari lingkung tuju teliti pilih skenario pulih bittern baik tipe stasiun olah pusat desentralisasi hibrid dasar optimal untung optimasi sistem usul uji analis dasar sensitivitas
Klasifikasi Electroencephalogram (EEG) Motor Imagery Dengan Fitur Differential Asymmetry Pada Support Vector Machine (SVM).,"Putranto, Yulianto Tejo",http://repository.its.ac.id/97190/,"Selama bertahun-tahun penelitian bidang Brain-Computer Interface (BCI) telah difokuskan pada keinginan untuk menyediakan para penyandang disabilitas kemudahan dan kemampuan untuk berinteraksi dengan lingkungannya. Dalam beberapa tahun terakhir, penelitian BCI telah merambah ke aplikasi yang diperuntukkan bagi orang normal untuk meningkatkan kualitas hidup atau mendapatkan keuntungan komersial bagi suatu komunitas atau target group. Pada penelitian ini dirancang sistem BCI berbasis EEG, khususnya untuk mengenali aktivitas motor imagery untuk diterapkan dalam perangkat keras atau perangkat lunak yang bersifat interaktif. Sistem BCI menuntut akurasi dan kecepatan respon yang tinggi. Permasalahan ini dicoba dipecahkan dengan mengembangkan ekstraksi fitur yaitu differential asymmetry berdasarkan nilai selisih antara hasil pengukuran sinyal otak belahan kiri dan kanan. Fitur-fitur statistik dari hasil dekomposisi sinyal EEG motor imagery menggunakan transformasi wavelet diskrit dan dekomposisi mode empiris dimodifikasi dengan mengambil nilai selisihnya untuk dijadikan fitur baru. Sebagai pengklasifikasi digunakan Support Vector Machine (SVM).Hasil penelitian menunjukkan peningkatan nilai akurasi dari pengklasifikasi dengan menerapkan fitur differential asymmetry dibandingkan tanpa menerapkan fitur differential asymmetri. Dari tiga dataset yang diteliti, dataset I mengalami kenaikan nilai akurasi rata-rata sebesar 30,33%, dataset II sebesar 6,54% dan dataset III sebesar 23,17%. Hasil akurasi dengan menggunakan SVM untuk dataset I, dataset II dan dataset III berturut-turut: 91,70%, 66,91% dan 93,16%.=================================================================================================================================Through the years, research in Brain-Computer Interface (BCI) has focused on providing convenience and ability for disabilities people to interact with the environment. In recent years, BCI research has been enlarge into applications intended for normal people to improve life quality or obtain commercial advantage for a community or group target. In this study, an EEG-based BCI system was designed, especially for recognizing motor imagery activity to be applied in games.The BCI system demands accuracy and response speed. This problem will be solved by developing a feature extraction, namely differential asymmetry based on the value of the difference between the measurement results of the left and right brain hemisphere signals. Statistical features from the decomposition of motor imagery EEG signals using discrete wavelet transform (DWT) and empirical mode decomposition (EMD) are modified by taking those difference values was as a new feature. As a classifier, Support Vector Machine (SVM) is used.The results showed an increase in the accuracy value of the classifier by applying the differential asymmetry feature compared to without applying the differential asymmetry feature. Of the three datasets studied, dataset I experienced an average increase in accuracy by 30.33%, dataset II by 6.54% and dataset III by 23.17%. Accuracy results using SVM for dataset I, dataset II and dataset III are respectively: 91.70%, 66.91% and 93.16%.",klasifikasi electroencephalogram eeg motor imagery fitur differential asymmetry support vector machine svm,bertahuntahun teliti bidang braincomputer interface bci fokus sedia sandang disabilitas mudah mampu interaksi lingkung teliti bci rambah aplikasi untuk orang normal tingkat kualitas hidup untung komersial komunitas target group teliti rancang sistem bci bas eeg nali aktivitas motor imagery terap perangkat keras perangkat lunak sifat interaktif sistem bci tuntut akurasi cepat respon masalah coba pecah kembang ekstraksi fitur differential asymmetry dasar nilai selisih hasil ukur sinyal otak bahan kiri kanan fiturfitur statistik hasil dekomposisi sinyal eeg motor imagery transformasi wavelet diskrit dekomposisi mode empiris modifikasi ambil nilai selisih jadi fitur klasifikasi support vector machine svmhasil teliti tingkat nilai akurasi klasifikasi terap fitur differential asymmetry banding terap fitur differential asymmetri dataset teliti dataset i alami naik nilai akurasi ratarata 3033 dataset ii 654 dataset iii 2317 hasil akurasi svm dataset i dataset ii dataset iii berturutturut 9170 6691 9316through the years research in braincomputer interface bci has focused on providing convenience and ability for disabilities people to interact with the environment in recent years bci research has been enlarge into applications intended for normal people to improve life quality or obtain commercial advantage for a community or group target in this study an eegbased bci system was designed especially for recognizing motor imagery activity to be applied in gamesthe bci system demands accuracy and response speed this problem will be solved by developing a feature extraction namely differential asymmetry based on the value of the difference between the measurement results of the left and right brain hemisphere signals statistical features from the decomposition of motor imagery eeg signals using discrete wavelet transform dwt and empirical mode decomposition emd are modified by taking those difference values was as a new feature as a classifier support vector machine svm is usedthe results showed an increase in the accuracy value of the classifier by applying the differential asymmetry feature compared to without applying the differential asymmetry feature of the three datasets studied dataset i experienced an average increase in accuracy by 3033 dataset ii by 654 and dataset iii by 2317 accuracy results using svm for dataset i dataset ii and dataset iii are respectively 9170 6691 and 9316
Optimization Model for Vehicle Parking Space Unit Proportion And Zoning On Conventional And Digital Parking System Using Mixed Integer Non-Linear Programming And Response Surface Methodology.,"Qisthauzan, Avenzoar Zufar",http://repository.its.ac.id/87645/,"Pemerintah setempat menemukan bahwa pungutan liar masih terjadi pada area parkir di bahu jalan. Tindakan ini mengurangi pendapatan dari retribusi parkir daerah sebesar 72,5% pada tahun 2018. Untuk mengatasi masalah tersebut, pemerintah bekerjasama dengan pihak ketiga untuk mengembangkan aplikasi parkir digital. Studi sebelumnya menyimpulkan bahwa program parkir digital layak secara finansial untuk diterapkan di beberapa lokasi di Indonesia. Namun, studi tersebut berdasar pada asumsi bahwa 100% masyarakat siap menerima perubahan sistem parkir dari konvensional ke digital. Studi lebih lanjut menemukan bahwa hanya 59,3% masyarakat lokal yang siap dengan perubahan sistem; dengan demikian, perlu dilakukan proses transisi sistem secara bertahap. Penelitian ini akan menentukan proporsi optimal satuan ruang parkir (SRP) antara mobil dan sepeda motor yang dikombinasikan dengan proporsi optimal sistem digital dan konvensional yang diterapkan pada suatu area parkir. Tujuan sistem ini untuk memaksimalkan manfaat yang diterima oleh penyedia tempat parkir dan pengguna parkir. Model optimasi dilakukan dengan software LINGO. Response Surface Methodology (RSM) juga digunakan untuk pengambilan keputusan. Dari hasil keputusan optimasi, SRP yang optimum untuk Jalan Gajah Mada di Kabupaten Sidoarjo adalah 188 SRP mobil untuk area parkir digital, 323 SRP sepeda motor untuk area parkir digital, 133 SRP mobil untuk area parkir konvensional, dan 251 SRP sepeda motor untuk area parkir konvensional. Komposisi tersebut diharapkan akan memberikan retribusi yang kepada penyedia jasa parkir sebesar Rp75.798.856 dengan tingkat kepadatan tempat parkir sebesar 68,07%. Dari sisi pengguna parkir, total biaya pengguna parkir sebesar Rp57.358.168.====================================================================================================The Indonesian government imposed a subscription parking policy to improve the on-street parking system, but the execution did not go well. The local government found that illegal levies were still happening. This action negatively impacted the local government by reducing revenue from parking fees by 72.5% in 2018. To overcome this problem, the government collaborates with third parties to develop a digital parking application. A previous study has concluded that the digital parking program is financially feasible to be implemented in several locations in Indonesia. However, the study assumes that 100% of the people are ready to accept the change in the parking system from conventional to digital. A further study found that only 59.3% of the local community is ready for the system changes; thus, a gradual transition is needed. This research will determine the optimal proportion of parking space units between cars and motorcycles combined with the optimal proportion of digital and conventional system proportion applied to the parking area. The objective is to maximize benefits from parking space providers and parking users. The optimization model were carried out with a model built on the LINGO software. Response Surface Methodology will be performed for final decision making. The model found that the optimum SRP arrangement for Gajah Mada Street is 188 car SRP for digital parking area, 323 motorcycle SRP for digital parking area, 133 car SRP for conventional parking area, and 251 motorcycle SRP for conventional parking area. The arrangement will give parking service providers expected retribution of Rp75,798,856 with a parking area utilization rate of 68.07%. From the parking user perspective, the total parking user cost is Rp57,358,168.",optimization model for vehicle parking space unit proportion and zoning on conventional and digital parking system using mixed integer nonlinear programming and response surface methodology,perintah temu pungut liar area parkir bahu jalan tindak kurang dapat retribusi parkir daerah 725 2018 atas perintah bekerjasama tiga kembang aplikasi parkir digital studi simpul program parkir digital layak finansial terap lokasi indonesia studi dasar asumsi 100 masyarakat terima ubah sistem parkir konvensional digital studi temu 593 masyarakat lokal ubah sistem proses transisi sistem tahap teliti tentu proporsi optimal satu ruang parkir srp mobil sepeda motor kombinasi proporsi optimal sistem digital konvensional terap area parkir tuju sistem maksimal manfaat terima sedia parkir guna parkir model optimasi software lingo response surface methodology rsm ambil putus hasil putus optimasi srp optimum jalan gajah mada kabupaten sidoarjo 188 srp mobil area parkir digital 323 srp sepeda motor area parkir digital 133 srp mobil area parkir konvensional 251 srp sepeda motor area parkir konvensional komposisi harap retribusi sedia jasa parkir rp75798856 tingkat padat parkir 6807 sisi guna parkir total biaya guna parkir rp57358168the indonesian government imposed a subscription parking policy to improve the onstreet parking system but the execution did not go well the local government found that illegal levies were still happening this action negatively impacted the local government by reducing revenue from parking fees by 725 in 2018 to overcome this problem the government collaborates with third parties to develop a digital parking application a previous study has concluded that the digital parking program is financially feasible to be implemented in several locations in indonesia however the study assumes that 100 of the people are ready to accept the change in the parking system from conventional to digital a further study found that only 593 of the local community is ready for the system changes thus a gradual transition is needed this research will determine the optimal proportion of parking space units between cars and motorcycles combined with the optimal proportion of digital and conventional system proportion applied to the parking area the objective is to maximize benefits from parking space providers and parking users the optimization model were carried out with a model built on the lingo software response surface methodology will be performed for final decision making the model found that the optimum srp arrangement for gajah mada street is 188 car srp for digital parking area 323 motorcycle srp for digital parking area 133 car srp for conventional parking area and 251 motorcycle srp for conventional parking area the arrangement will give parking service providers expected retribution of rp75798856 with a parking area utilization rate of 6807 from the parking user perspective the total parking user cost is rp57358168
"STUDI KINERJA METODE SELEKSI FITUR BERBASIS 
UNCERTAINTY PADA DETEKSI CHRONIC KIDNEY DISEASE
DENGAN KLASIFIKASI SVM.","Qolby, Lailly Syifa`ul",http://repository.its.ac.id/88100/,"Chronic Kidney Disease (CKD) merupakan sebuah kelainan yang merusak fungsi ginjal. Tanda awal penderita CKD sangat sulit untuk diketahui hingga penderita kehilangan 25% dari fungsi ginjalnya. Oleh karena itu dibutuhkan pendeteksian dini dan treatment yang efektif untuk mengurangi tingkat kematian penderita CKD.Dalam penelitian ini penulis melakukan diagnosa pada dataset CKD menggunakan metode klasifikasi Support Vector Machine (SVM) untuk mendapatkan hasil diagnosa yang akurat. Untuk memperoleh hasil klasifikasi yang terbaik, maka penulis mengusulkan perbandingan hasil pada penerapan metodeseleksi fitur agar mendapatkan kandidat fitur terbaik dalam meningkatkan hasil klasifikasi.Proses pengujian dilakukan dengan membandingkan metode seleksi fiturSymmetrical Uncertainty (SU) dan Multivariate Symmetrical Uncertainty (MSU)serta metode SVM sebagai metode klasifikasi. Dengan menggunakan dataset CKD, dilakukan beberapa skenario percobaan baik dengan menggunakan metode seleksi fitur SU maupun MSU. Dari hasil ujicoba yang dilakukan menunjukkan bahwa dengan menggunakan metode seleksi fitur MSU dengan split data 80% : 20% menghasilkan jumlah fitur penting sebanyak 9 fitur dengan nilai akurasi 0.9, sensitivy 0.8400, dan specification 1 serta jika dilihat pada grafik ROC grafik metode MSU menunjukkan nilai true positive lebih tinggi daripada nilai false positive. Sehingga klasifikasi dengan menggunakan metode seleksi fitur MSU lebih baik daripada metode seleksi fitur SU.=====================================================================================================Chronic Kidney Disease (CKD) is a disorder that impairs kidney function. Early signs of CKD patients are very difficult to know until the patient loses 25% of their kidney function. Therefore, early detection and effective treatment are needed to reduce the mortality rate of CKD sufferers.In this study, the authors diagnose the CKD dataset using the Support Vector Machine (SVM) classification method to obtain accurate diagnostic results. The authors propose a comparison of the result on the application of the feature selection method in order to get the best feature candidates in improving the classification result.Testing process is carried out by comparing the Symmetrical Uncertainty (SU) and Multivariate Symmetrical Uncertainty (MSU) feature selection method as well as the SVM method as a classification method. By using the CKD dataset, several experimental scenarios were carried out using both the SU and MSU feature selection methods. From the results of the tests carried out, it shows that using the MSU feature selection method with 80% : 20% data split produces 9 important features with an accuracy value of 0.9, sensitivity 0.8400, specification 1 and when viewed on the ROC graph, the MSU method graph shows the true positive value is higher than the false positive value. So the classification using the MSU feature selection method is better than the SU feature selection method.",studi kerja metode seleksi fitur bas uncertainty deteksi chronic kidney disease klasifikasi svm,chronic kidney disease ckd lain rusak fungsi ginjal tanda derita ckd sulit derita hilang 25 fungsi ginjal butuh deteksi treatment efektif kurang tingkat mati derita ckddalam teliti tulis diagnosa dataset ckd metode klasifikasi support vector machine svm hasil diagnosa akurat oleh hasil klasifikasi baik tulis usul banding hasil terap metodeseleksi fitur kandidat fitur baik tingkat hasil klasifikasiproses uji banding metode seleksi fitursymmetrical uncertainty su multivariate symmetrical uncertainty msuserta metode svm metode klasifikasi dataset ckd skenario coba metode seleksi fitur su msu hasil ujicoba metode seleksi fitur msu split data 80 20 hasil fitur 9 fitur nilai akurasi 09 sensitivy 08400 specification 1 grafik roc grafik metode msu nilai true positive nilai false positive klasifikasi metode seleksi fitur msu metode seleksi fitur suchronic kidney disease ckd is a disorder that impairs kidney function early signs of ckd patients are very difficult to know until the patient loses 25 of their kidney function therefore early detection and effective treatment are needed to reduce the mortality rate of ckd sufferersin this study the authors diagnose the ckd dataset using the support vector machine svm classification method to obtain accurate diagnostic results the authors propose a comparison of the result on the application of the feature selection method in order to get the best feature candidates in improving the classification resulttesting process is carried out by comparing the symmetrical uncertainty su and multivariate symmetrical uncertainty msu feature selection method as well as the svm method as a classification method by using the ckd dataset several experimental scenarios were carried out using both the su and msu feature selection methods from the results of the tests carried out it shows that using the msu feature selection method with 80 20 data split produces 9 important features with an accuracy value of 09 sensitivity 08400 specification 1 and when viewed on the roc graph the msu method graph shows the true positive value is higher than the false positive value so the classification using the msu feature selection method is better than the su feature selection method
Sistem Deteksi Gangguan Spektrum Autisme pada Anak Melalui Metode Facial Landmarks dan Machine Learning pada Citra Respons Emosional.,"Rachmah, Indah Nabila",http://repository.its.ac.id/113008/,"Meskipun prevalensi Autism Spectrum Disorder (ASD) terus meningkat secara global, metode skrining saat ini untuk deteksi dini tetap memakan waktu dan mahal, yang menyoroti kesenjangan penelitian yang kritis. Penelitian ini bertujuan untuk mengembangkan sistem deteksi baru untuk ASD pada anak-anak, memanfaatkan landmark wajah dan metode pembelajaran mesin untuk menganalisis gambar respons emosional. Pendekatan kami melibatkan penangkapan ekspresi wajah spontan menggunakan sensor pencitraan non-invasif, diikuti dengan ekstraksi landmark wajah kunci. Dua model klasifikasi, Support Vector Machine (SVM) dan Convolutional Neural Network (CNN), diimplementasikan untuk menganalisis dan mengklasifikasikan landmark wajah ini. Model SVM mencapai akurasi 92.54%, presisi 93.43%, recall 92.56%, dan skor F1 92.42%, sementara model CNN mencapai akurasi 84.16%, presisi 83.06%, recall 85.83%, dan skor F1 84.42%. Studi ini menunjukkan potensi integrasi teknik pembelajaran mesin lanjutan dengan ekstraksi landmark wajah untuk deteksi dini ASD yang andal dan non-invasi. Kinerja menjanjikan dari model SVM dan CNN menunjukkan bahwa pendekatan kami dapat secara signifikan meningkatkan strategi diagnosis dan intervensi dini untuk anak-anak dengan ASD. Selain itu, penggunaan dataset yang beragam dan real-time serta langkah-langkah pra-pemrosesan yang efektif memastikan akurasi, keandalan, dan generalisasi sistem deteksi ini. Potensi sistem yang diusulkan untuk aplikasi praktis dalam diagnosis dini ASD ditingkatkan oleh integrasi teknik pencitraan non-invasi yang berhasil dan pengembangan GUI yang ramah pengguna, membuka jalan untuk deteksi real-time dan pelaporan otomatis, yang pada akhirnya berkontribusi pada hasil perkembangan yang lebih baik dan kualitas hidup anak-anak yang terkena ASD.",sistem deteksi ganggu spektrum autisme anak metode facial landmarks machine learning citra respons emosional,prevalensi autism spectrum disorder asd tingkat global metode skrining deteksi makan mahal sorot senjang teliti kritis teliti tuju kembang sistem deteksi asd anakanak manfaat landmark wajah metode ajar mesin analis gambar respons emosional dekat libat tangkap ekspresi wajah spontan sensor citra noninvasif ikut ekstraksi landmark wajah kunci model klasifikasi support vector machine svm convolutional neural network cnn implementasi analis klasifikasi landmark wajah model svm capai akurasi 9254 presisi 9343 recall 9256 skor f1 9242 model cnn capai akurasi 8416 presisi 8306 recall 8583 skor f1 8442 studi potensi integrasi teknik ajar mesin lanjut ekstraksi landmark wajah deteksi asd andal noninvasi kerja janji model svm cnn dekat signifikan tingkat strategi diagnosis intervensi anakanak asd guna dataset agam realtime langkahlangkah prapemrosesan efektif akurasi andal generalisasi sistem deteksi potensi sistem usul aplikasi praktis diagnosis asd tingkat integrasi teknik citra noninvasi hasil kembang gui ramah guna buka jalan deteksi realtime lapor otomatis kontribusi hasil kembang kualitas hidup anakanak kena asd
Analisis Hubungan Sentimen Publik di Media Sosial X dan SPI Terhadap Pemerintah Provinsi di Indonesia Menggunakan Algoritma GRU dan LSTM.,"Rafli, Andi Muhammad",http://repository.its.ac.id/111297/,"Media sosial, khususnya Twitter, telah menjadi platform utama bagi masyarakat untuk mengekspresikan pandangan dan opini mereka terhadap berbagai isu, termasuk kinerja pemerintah provinsi di Indonesia. Penelitian ini bertujuan untuk menganalisis sentimen publik di media sosial X (Twitter) terkait pemerintah provinsi dengan menggunakan algoritma Gated Recurrent Unit (GRU) dan Long Short-Term Memory   (LSTM). Tahap pertama penelitian melibatkan pengumpulan dan pra-pemrosesan data teks, termasuk case folding, penghapusan tautan, dan lainnya. Setelah itu, data dilabeli secara manual dan dengan model pra-terlatih IndoBERT untuk klasifikasi ke dalam label positif, negatif, dan netral. Metode oversampling dan parameter tuning diterapkan untuk menghasilkan model LSTM dengan akurasi 0,9313, F1-Score 0,9352, dan loss 0,3269.Analisis topik dengan metode LDA menunjukkan dominasi sentimen negatif pada topik seperti ""Persepsi Publik tentang Program dan Kebijakan Anies Baswedan,"" ""Proyek Infrastruktur dan Pengelolaan Lahan,"" dan ""Kinerja Pemerintah Provinsi dalam Sektor Transportasi."" Ini menunjukkan kecenderungan negatif masyarakat terhadap isu-isu pemerintah provinsi.Penelitian ini juga membandingkan analisis sentimen di lima provinsi dengan hasil Survei Penilaian Integritas (SPI). Perhitungan korelasi Pearson menunjukkan nilai sentimen negatif dan positif terhadap SPI masing-masing sebesar 0,53 dan -0,53. Hasil ini mengindikasikan bahwa tingginya nilai SPI tidak selalu berhubungan langsung dengan tingginya atau rendahnya sentimen positif dan negatif, menunjukkan bahwa faktor lain mungkin mempengaruhi bagaimana masyarakat memandang kinerja pemerintah provinsi.============================================================Social media, especially Twitter, has become a major platform for people to express their views and opinions on various issues, including the performance of provincial governments in Indonesia. This study aims to analyze public sentiment on social media X (Twitter) regarding provincial governments using Gated Recurrent Unit (GRU) and Long Short-Term Memory   (LSTM) algorithms. The first stage of the research involved collecting and preprocessing text data, including case folding, removing links, usernames, punctuation, stopwords, double spaces, duplicate data, emoticons, and tweets with fewer than four words. After that, the data was manually labeled and classified using a pre-trained IndoBERT model into positive, negative, and neutral labels. Data imbalance was addressed using oversampling and parameter tuning methods, resulting in an LSTM model with an accuracy of 0.9313, an F1-Score of 0.9352, and a loss of 0.3269.Topic analysis using the Latent Dirichlet Allocation (LDA) method shows a dominance of negative sentiment on topics such as ""Public Perception of Anies Baswedan's Programs and Policies,"" ""Infrastructure Projects and Land Management by the Provincial Government,"" and ""Public Perception of the Provincial Government's Performance in the Transportation Sector."" This indicates a negative tendency in public sentiment towards provincial government issues.The study also compares sentiment analysis across five provinces with the Integrity Assessment Survey (SPI). Pearson correlation calculations show that the correlations between negative and positive sentiment scores and SPI are 0.53 and -0.53, respectively. This suggests that a high SPI value does not necessarily correlate with high or low positive and negative sentiment, indicating that other factors may influence public perceptions of provincial government performance.",analisis hubung sentimen publik media sosial x spi perintah provinsi indonesia algoritma gru lstm,media sosial twitter platform utama masyarakat ekspresi pandang opini isu kerja perintah provinsi indonesia teliti tuju analis sentimen publik media sosial x twitter kait perintah provinsi algoritma gated recurrent unit gru long shortterm memory lstm tahap teliti libat kumpul prapemrosesan data teks case folding hapus taut data label manual model praterlatih indobert klasifikasi label positif negatif netral metode oversampling parameter tuning terap hasil model lstm akurasi 09313 f1score 09352 loss 03269analisis topik metode lda dominasi sentimen negatif topik persepsi publik program bijak anies baswedan proyek infrastruktur kelola lahan kerja perintah provinsi sektor transportasi cenderung negatif masyarakat isuisu perintah provinsipenelitian banding analisis sentimen provinsi hasil survei nilai integritas spi hitung korelasi pearson nilai sentimen negatif positif spi masingmasing 053 053 hasil indikasi tinggi nilai spi hubung langsung tinggi rendah sentimen positif negatif faktor pengaruh masyarakat pandang kerja perintah provinsisocial media especially twitter has become a major platform for people to express their views and opinions on various issues including the performance of provincial governments in indonesia this study aims to analyze public sentiment on social media x twitter regarding provincial governments using gated recurrent unit gru and long shortterm memory lstm algorithms the first stage of the research involved collecting and preprocessing text data including case folding removing links usernames punctuation stopwords double spaces duplicate data emoticons and tweets with fewer than four words after that the data was manually labeled and classified using a pretrained indobert model into positive negative and neutral labels data imbalance was addressed using oversampling and parameter tuning methods resulting in an lstm model with an accuracy of 09313 an f1score of 09352 and a loss of 03269topic analysis using the latent dirichlet allocation lda method shows a dominance of negative sentiment on topics such as public perception of anies baswedans programs and policies infrastructure projects and land management by the provincial government and public perception of the provincial governments performance in the transportation sector this indicates a negative tendency in public sentiment towards provincial government issuesthe study also compares sentiment analysis across five provinces with the integrity assessment survey spi pearson correlation calculations show that the correlations between negative and positive sentiment scores and spi are 053 and 053 respectively this suggests that a high spi value does not necessarily correlate with high or low positive and negative sentiment indicating that other factors may influence public perceptions of provincial government performance
"Tutorial Pemodelan, Perhitungan Volume, dan Biaya Menggunakan Revit 2018.","Rahaditya, Verdi Arya",http://repository.its.ac.id/82609/,"Autodesk Revit adalah software Building Information Modeling (BIM) oleh Autodesk untuk desain arsitektur, struktur serta mekanikal, elektrikal dan plumbing (MEP). Dengan software ini pengguna dapat merancang bangunan dan struktur dengan pemodelan komponen dalam 3D dan sekaligus menyajikan gambar kerja dalam 2D. Data yang digunakan dalam tutorial pemodelan ini adalah data sekunder berupa gambar CAD dengan sumber yang telah dilampirkan. Tugas KP ini memberikan tutorial permodelan untuk komponen struktur sekaligus menghitung Rencana Anggaran Biaya (RAB) secara otomatis. Tujuan dari tugas pengganti KP ini adalah untuk: 1) Memberikan cara pemodelan rumah dua lantai menggunakan Autodesk Revit 2018. 2) Memberikan cara perhitungan volume, dan biaya menggunakan Autodesk Revit 2018. 3) Untuk mengetahui hasil perhitungan biaya total perencanaan rumah dua lantai sederhana yang dihitung menggunakan Autodesk Revit 2018. Tugas pengganti KP diharapkan dapat memberi tutorial mengenai pemodelan dalam Autodesk Revit yang jelas dan mudah dipahami untuk pembaca.=====================================================================================================Autodesk Revit is Autodesk's Building Information Modeling (BIM) software, for architectural, structural, mechanical, electrical and plumbing (MEP) design. With this software users can design buildings and structures with component modeling in 3D and simultaneously present work drawings in 2D. The data used in this modeling tutorial is secondary data in the form of CAD drawings with the attached source. This internship report provides modeling tutorials for structural components as well as calculating the Budget Plan (RAB) automatically. The objectives of this internship report replacement task are to: 1) Provide a two-story house modeling method using Autodesk Revit 2018. 2) Provide a method of calculating volume and costs using Autodesk Revit 2018.3) To find out the results of calculating the total cost of planning a simple two-story house calculated using Autodesk Revit 2018. The task of replacing the internship program is expected to provide a tutorial on modeling in Autodesk Revit that is clear and easy to understand for readers.",tutorial model hitung volume biaya revit 2018,autodesk revit software building information modeling bim autodesk desain arsitektur struktur mekanikal elektrikal plumbing mep software guna rancang bangun struktur model komponen 3d saji gambar kerja 2d data tutorial model data sekunder gambar cad sumber lampir tugas kp tutorial model komponen struktur hitung rencana anggar biaya rab otomatis tuju tugas ganti kp 1 model rumah lantai autodesk revit 2018 2 hitung volume biaya autodesk revit 2018 3 hasil hitung biaya total rencana rumah lantai sederhana hitung autodesk revit 2018 tugas ganti kp harap tutorial model autodesk revit mudah paham pembacaautodesk revit is autodesks building information modeling bim software for architectural structural mechanical electrical and plumbing mep design with this software users can design buildings and structures with component modeling in 3d and simultaneously present work drawings in 2d the data used in this modeling tutorial is secondary data in the form of cad drawings with the attached source this internship report provides modeling tutorials for structural components as well as calculating the budget plan rab automatically the objectives of this internship report replacement task are to 1 provide a twostory house modeling method using autodesk revit 2018 2 provide a method of calculating volume and costs using autodesk revit 20183 to find out the results of calculating the total cost of planning a simple twostory house calculated using autodesk revit 2018 the task of replacing the internship program is expected to provide a tutorial on modeling in autodesk revit that is clear and easy to understand for readers
Desain Trajektori Kapal Patrol Menggunakan  Deep Reinforcement Learning dalam Operasi  Pengejaran Kapal dengan Losses Data AIS.,"Rahmania, Amanda Caesa",http://repository.its.ac.id/109525/,"Indonesia, sebagai negara kepulauan terbesar, menghadapi tantangan dalam menjaga keamanan maritimnya yang luas. Kehilangan data AIS (Automatic Identification System) pada kapal, seperti yang terjadi di Selat Malaka dan Laut Natuna Utara, mengindikasikan adanya aktivitas ilegal di perairan Indonesia. Penelitian ini bertujuan merancang rute patroli kapal yang optimal menggunakan deep reinforcement learning untuk mengatasi masalah kehilangan data AIS dengan mempertimbangkan faktor lingkungan kapal. Data kapal yang diteliti berada di Selat Malaka terutama Pulau Bengkalis, dengan spesifikasi kapal patrol yaitu KN Ular Laut 406. Penelitian ini dimulai dengan mendeteksi kapal yang mengalami kehilangan data selama lebih dari 1 jam, kemudian dilajutkan dengan deteksi tindakan illegal, setelah mendapatkan data kapal yang mengalami losses data kemudian dilakukan pembuatan trajektori dengan diakhiri dengan pembuatan trajektori dengan berbagai variasi. Hasil dari model yang telah dibuat didapatkan metrik performansi MAE untuk subsistem identifikasi losses data sebesar 0.01312 dan untuk subsistem selektor sebesar 0.12. Pada Deep Reinforcement Learning didapatkan grafik loss dibandingkan dengan 8000episode menunjukkan tren turun dan grafik reward dibandingkan dengan 8000episode menunjukkan tren naik. RMSE juga digunakan untuk perhitungan error dari model visualisasi trajektori dengan nilai terkecil yaitu 0.8104575756222229. Kesimpulan dari penelitian ini antara lain, metode DRL dapat dijadikan sebagai metode dalam pembuatan trajektori kapal patrol, dan model yang digunakan memunculkan grafik loss function dengan tren naik dan reward dengan tren turun maka dapat dikatakan bahwa model bagus.============================================================================================================================================Indonesia, as the largest archipelagic country, faces challenges in maintaining the security of its vast maritime territory. The loss of AIS (Automatic Identification System) data on ships, as observed in the Malacca Strait and the North Natuna Sea, indicates illegal activities in Indonesian waters. This research aims to design an optimal patrol route for ships using deep reinforcement learning to address the problem of AIS data loss and accelerate the capture of illegal vessels by considering the ship's environmental factors. The studied ship data is from the Malacca Strait, particularly around Bengkalis Island, with the patrol vessel specifications being KN Ular Laut 406. The research begins by detecting ships that have experienced data loss for more than 1 hour, followed by the detection of illegal activities. After obtaining data on ships experiencing data loss, trajectory planning is carried out, concluding with the creation of various trajectory variations. The performance metrics of the developed model showed a Mean Absolute Error (MAE) of 0.04 for the data loss identification subsystem and 0.12 for the selector subsystem. In the Deep Reinforcement Learning model, the loss graph over 8000 episodes showed a downward trend, and the reward graph over 8000 episodes showed an upward trend, indicating that the deep reinforcement learning model developed is effective. RMSE was also used to calculate the error of the trajectory visualization model, with the smallest value being 0.8104575756222229.",desain trajektori kapal patrol deep reinforcement learning operasi kejar kapal losses data ais,indonesia negara pulau besar hadap tantang jaga aman maritim luas hilang data ais automatic identification system kapal selat malaka laut natuna utara indikasi aktivitas ilegal air indonesia teliti tuju rancang rute patroli kapal optimal deep reinforcement learning atas hilang data ais timbang faktor lingkung kapal data kapal teliti selat malaka pulau bengkal spesifikasi kapal patrol kn ular laut 406 teliti deteksi kapal alami hilang data 1 jam dilajutkan deteksi tindak illegal data kapal alami losses data buat trajektori buat trajektori variasi hasil model dapat metrik performansi mae subsistem identifikasi losses data 001312 subsistem lektor 012 deep reinforcement learning dapat grafik loss banding 8000episode tren turun grafik reward banding 8000episode tren rmse hitung error model visualisasi trajektori nilai kecil 08104575756222229 simpul teliti metode drl jadi metode buat trajektori kapal patrol model muncul grafik loss function tren reward tren turun model bagusindonesia as the largest archipelagic country faces challenges in maintaining the security of its vast maritime territory the loss of ais automatic identification system data on ships as observed in the malacca strait and the north natuna sea indicates illegal activities in indonesian waters this research aims to design an optimal patrol route for ships using deep reinforcement learning to address the problem of ais data loss and accelerate the capture of illegal vessels by considering the ships environmental factors the studied ship data is from the malacca strait particularly around bengkal island with the patrol vessel specifications being kn ular laut 406 the research begins by detecting ships that have experienced data loss for more than 1 hour followed by the detection of illegal activities after obtaining data on ships experiencing data loss trajectory planning is carried out concluding with the creation of various trajectory variations the performance metrics of the developed model showed a mean absolute error mae of 004 for the data loss identification subsystem and 012 for the selector subsystem in the deep reinforcement learning model the loss graph over 8000 episodes showed a downward trend and the reward graph over 8000 episodes showed an upward trend indicating that the deep reinforcement learning model developed is effective rmse was also used to calculate the error of the trajectory visualization model with the smallest value being 08104575756222229
Klasifikasi Gerakan Pencak Silat Menggunakan Convolutional Neural Network Berbasis Body Pose.,"Rahmawati, Vira Nur",http://repository.its.ac.id/99417/,"Pencak silat selain bermanfaat untuk perlindungan diri, juga memiliki banyak manfaat lainnya, seperti meningkatkan kekuatan fisik, menjaga postur tubuh, dan menjaga kesehatan jantung. Karena pandemi yang belakangan terjadi ini, latihan pencak silat sulit dilakukan secara bersama-sama. Selain itu, jika ada materi pelajaran pencak silat di sekolah, guru olahraga kesulitan untuk mengajarkan gerak secara langsung. Tetapi latihan pencak silat yang dilakukan sendiri tanpa pelatih dapat menyebabkan cedera jika gerakannya tidak benar. Oleh karena itu, penelitian ini membangun sistem pengenalan gerakan pencak silat. Sistem dibangun menggunakan metode CNN berbasis bodypose. Bodypose extraction digunakan untuk mendeteksi keypoint tubuh manusia, kemudian keypoint tersebut digunakan sebagai fitur input ke CNN untuk mengenali gerakan pada setiap frame. Sistem ini menggunakan CNN karena membutuhkan parameter yang lebih sedikit dan daya komputasi yang lebih sedikit sehingga dapat lebih mudah diterapkan untuk studi selanjutnya. Akurasi yang diperoleh mencapai 77% saat diuji pada data yang belum pernah digunakan. Model ini dapat digunakan sebagai titik awal untuk membuat sistem yang mudah digunakan untuk membantu orang berlatih pencak silat dengan gerakan yang lebih banyak.================================================================================================================================Pencak silat, besides from being useful for self-protection, also has many other benefits, such as increasing physical strength, maintaining posture, and maintaining heart health. Due to the recent pandemic, practicing pencak silat is difficult to do together. Even when there is study material on pencak silat at school, it is difficult for the sports teacher to teach the movements directly. Pencak silat exercises that are practiced alone without a coach can cause injury if the movements are not correct. Therefore, this study builds a system to recognize pencak silat movements. The system was built using the bodypose-based CNN method. Bodypose estimation is used to detect human body keypoints, then these keypoints are used as a feature for input to CNN to recognize movement in each frame. This system uses CNN because it requires fewer parameters and less computing power so that it can be more easily applied for further studies. The accuracy obtained reaches 77% when tested on data that has never been used. This model can be used as a starting point for creating an easy-to-use system to help people practice pencak silat with more recognizable moves.",klasifikasi gera pencak silat convolutional neural network bas body pose,pencak silat manfaat lindung milik manfaat tingkat kuat fisik jaga postur tubuh jaga sehat jantung pandemi latih pencak silat sulit bersamasama materi ajar pencak silat sekolah guru olahraga sulit ajar gerak langsung latih pencak silat latih sebab cedera gera teliti bangun sistem kenal gera pencak silat sistem bangun metode cnn bas bodypose bodypose extraction deteksi keypoint tubuh manusia keypoint fitur input cnn nali gera frame sistem cnn butuh parameter daya komputasi mudah terap studi akurasi oleh capai 77 uji data model titik sistem mudah bantu orang latih pencak silat gera banyakpencak silat besides from being useful for selfprotection also has many other benefits such as increasing physical strength maintaining posture and maintaining heart health due to the recent pandemic practicing pencak silat is difficult to do together even when there is study material on pencak silat at school it is difficult for the sports teacher to teach the movements directly pencak silat exercises that are practiced alone without a coach can cause injury if the movements are not correct therefore this study builds a system to recognize pencak silat movements the system was built using the bodyposebased cnn method bodypose estimation is used to detect human body keypoints then these keypoints are used as a feature for input to cnn to recognize movement in each frame this system uses cnn because it requires fewer parameters and less computing power so that it can be more easily applied for further studies the accuracy obtained reaches 77 when tested on data that has never been used this model can be used as a starting point for creating an easytouse system to help people practice pencak silat with more recognizable moves
Integrasi Data Multisensor Untuk Peningkatan Lokalisasi Pada Navigasi Mobile Robot Menggunakan Extended Kalman Filter.,"Ramadhan, Fadhly",http://repository.its.ac.id/117061/,"Sistem navigasi robot tidak terlepas dari penggunaan sensor yang digunakan sebagai masukan untuk menentukan persepsi robot baik secara internal maupun eksternal. Setiap sensor memiliki kelebihan dan kekurangannya masing – masing, seperti penggunaan sensor INS menawarkan keunggulan dalam menyediakan data posisi dan orientasi dengan laju tinggi, sementara rotary encoder menyediakan data posisi yang lebih akurat namun rotary encoder yangsensitif terhadap slip. Mengandalkan satu jenis sensor sering kali tidak cukup untuk mencapai estimasi posisi yang akurat dan andal, terutama dalam lingkungan yang kompleks dan dinamis. Kombinasi kedua sistem ini melalui EKF memungkinkan pemanfaatan keunggulan masing-masing sistem, menghasilkan data navigasi yang lebih stabil dan akurat. Dalam penelitian ini, Sensor yang digunakan meliputi Inertial Measurement Unit (IMU) untuk memperoleh orientasi, Rotary Encoder untuk posisi translasi, dan RPLidar A1 untuk deteksi lingkungan. Proses integrasi data melibatkan mekanisasi IMU, filtering menggunakan Kalman Filter, dan pemetaan lingkungan SLAM. Mobile robot yang digunakan memiliki konfigurasi roda omni-directional 4WD yang memungkinkan gerakan bebas dalam ruang dua dimensi. Hasil pengujian menunjukkan bahwa integrasi multisensor dengan EKF signifikan meningkatkan akurasi estimasi posisi dan orientasi dibandingkan metode sensor tunggal.====================================================================================================================================The robot navigation system cannot be separated from the use of sensors which are used as input to determine the robot's perception both internally and externally. Each sensor has its own advantages and disadvantages, such as the use of the INS sensor offers the advantage of providing position and orientation data at a high rate, while the rotary encoder provides more accurate position data but the rotary encoder is sensitive to slip. Relying on one type of sensor is often insufficient to achieve accurate and reliable position estimation, especially in complex and dynamic environments. The combination of these two systems via EKF allows exploiting the advantages of each system, producing more stable and accurate navigation data. In this research, the sensors used include the Inertial Measurement Unit (IMU) to obtain orientation, the Rotary Encoder for translation position, and the RPLidar A1 for environmental detection. The data integration process involves IMU mechanization, filtering using the Kalman Filter, and SLAM environment mapping. The mobile robot used has a 4WD omni-directional wheel configuration which allows free movement in two-dimensional space. Test results show that multisensor integration with EKF significantly increases the accuracy of position and orientation estimation compared to single sensor methods.",integrasi data multisensor tingkat lokalisasi navigasi mobile robot extended kalman filter,sistem navigasi robot lepas guna sensor masuk tentu persepsi robot internal eksternal sensor milik lebih kurang  guna sensor ins tawar unggul sedia data posisi orientasi laju rotary encoder sedia data posisi akurat rotary encoder yangsensitif slip andal jenis sensor kali capai estimasi posisi akurat andal lingkung kompleks dinamis kombinasi sistem ekf manfaat unggul masingmasing sistem hasil data navigasi stabil akurat teliti sensor liput inertial measurement unit imu oleh orientasi rotary encoder posisi translasi rplidar a1 deteksi lingkung proses integrasi data libat mekanisasi imu filtering kalman filter meta lingkung slam mobile robot milik konfigurasi roda omnidirectional 4wd gera bebas ruang dimensi hasil uji integrasi multisensor ekf signifikan tingkat akurasi estimasi posisi orientasi banding metode sensor tunggalthe robot navigation system can not be separated from the use of sensors which are used as input to determine the robots perception both internally and externally each sensor has its own advantages and disadvantages such as the use of the ins sensor offers the advantage of providing position and orientation data at a high rate while the rotary encoder provides more accurate position data but the rotary encoder is sensitive to slip relying on one type of sensor is often insufficient to achieve accurate and reliable position estimation especially in complex and dynamic environments the combination of these two systems via ekf allows exploiting the advantages of each system producing more stable and accurate navigation data in this research the sensors used include the inertial measurement unit imu to obtain orientation the rotary encoder for translation position and the rplidar a1 for environmental detection the data integration process involves imu mechanization filtering using the kalman filter and slam environment mapping the mobile robot used has a 4wd omnidirectional wheel configuration which allows free movement in twodimensional space test results show that multisensor integration with ekf significantly increases the accuracy of position and orientation estimation compared to single sensor methods
Prototipe Sistem Deteksi Maling Menggunakan Wi-Fi Based Secure Indoor Positioning System.,"Ramadhan, Naufal",http://repository.its.ac.id/106170/,"Sistem pemosisian dalam ruangan sudah mulai berkembang dalam beberapa tahun belakangan ini. Berbeda dengan sistem pemosisian yang sudah sangat dikenal oleh masyarakat yakni Global Positioning System (GPS), pada penelitian kali ini akan berfokus melakukan pemosisian di dalam ruangan atau biasa disebut dengan Indoor Positioning System (IPS). Indoor Positiong System (IPS) pada era digitalisasi sangat berpengaruh mengingat seluruh perkembangan infrastruktur sangat maju serta dengan sektor digitalisasi. Pada perkembangan di banyak sektor ini pula maka akan menimbulkan banyak masalah baru seperti contohnya apabila terdapat gedung pencakar langit maka terdapat banyak halangan atau masalah untuk memastikan lokasi dari orang atau pun benda. Masalah tidak berhenti sampai disitu, dimana ancaman juga dapat datang dari manusia baik masuk melalui sistem maupun secara fisik. Pada penelitian kali ini akan digunakan untuk mencari tau perbandingan model terbaik berdasarkan dataset yang sudah ada dengan dataset yang diambil secara langsung dalam salah satu ruangan yang dianggap steril. Kemudian dibandingkan menggunakan beberapa algoritma machine learning sebagai bahan perbandingan algoritma mana yang memiliki akurasi terbaik. Serta dibuat salah satu ujicoba metode serangan yang kemudian dibuat model yang robust. Kemudian dari perbandingan tersebut akan dipilih salah satu model dari dataset yang memiliki akurasi terbaik untuk dibuat prototipe sistem deteksi dimana apabila terdeteksi sebuah anomali di dalam model maka akan mengirimkan pesan warning melalui email dengan harapan sistem ini dapat berguna di ruang atau tempat restricted. Penelitian ini memanfaatkan dataset berbentuk Channel State Information (CSI). Dari beberapa model yang diuji diperoleh akurasi senilai 74,02% menggunakan algoritma random forest. Dimana implementasi serangan menggunakan Decision Tree Attack berhasil dilakukan hingga akurasi turun di angka 52%. Uji coba penerapan metode pertahanan menggunakan featuresqueezing berhasil membuat model lebig tahan dibuktikan dengan akurasi menjadi 68%. Serta implementasi Anomaly Detector dapat mengirimkan pesan bahaya melalui email.=================================================================================================================================Indoor positioning systems have begun to develop in recent years. Different from the positioning system that is well known to the public, namely the Global Positioning System (GPS), this research will focus on indoor positioning or what is usually called the Indoor Positioning System (IPS). The Indoor Positioning System (IPS) in the digitalization era is very influential considering that all infrastructure developments are very advanced as well as the digitalization sector. Development in many of these sectors will also give rise to many new problems, for example if there are skyscrapers then there will be many obstacles or problems in determining the location of people or objects. The problem doesn't stop there, where threats can also come from humans, either through the system or physically. In this research, it will be used to find out the comparison of the best model based on an existing dataset with a dataset taken directly in a room that is considered sterile. Then it is compared using several machine learning algorithms as a comparison which algorithm has the best accuracy. And a test method of attack was made which was then made into a sturdy model. Then, from this comparison, one of the models from the dataset that has the best accuracy will be selected to create a detection system prototype, where if an anomaly is detected in the model, it will send a warning message via email in the hope that this system can be useful in limited spaces or places. This research utilizes a dataset in the form of Channel State Information (CSI). Several models tested obtained an accuracy of 74.02% using the random forest algorithm. Where the implementation of the attack using Decision Tree Attack was successfully carried out until the accuracy fell to 52%. The trial application of the maintenance method using featurequeezing succeeded in making the model more durable, proven by an accuracy of 68%. And the Anomaly Detector implementation can send danger messages via email.",prototipe sistem deteksi maling wifi based secure indoor positioning system,sistem posisi ruang kembang beda sistem posisi kenal masyarakat global positioning system gps teliti kali fokus posisi ruang indoor positioning system ips indoor positiong system ips era digitalisasi pengaruh kembang infrastruktur maju sektor digitalisasi kembang sektor timbul contoh gedung cakar langit halang lokasi orang benda henti situ mana ancam manusia masuk sistem fisik teliti kali cari tau banding model baik dasar dataset dataset ambil langsung salah ruang anggap steril banding algoritma machine learning bahan banding algoritma milik akurasi baik salah ujicoba metode serang model robust banding pilih salah model dataset milik akurasi baik prototipe sistem deteksi mana deteksi anomali model kirim pesan warning email harap sistem guna ruang restricted teliti manfaat dataset bentuk channel state information csi model uji oleh akurasi nila 7402 algoritma random forest mana implementasi serang decision tree attack hasil akurasi turun angka 52 uji coba terap metode tahan featuresqueezing hasil model lebig tahan bukti akurasi 68 implementasi anomaly detector kirim pesan bahaya emailindoor positioning systems have begun to develop in recent years different from the positioning system that is well known to the public namely the global positioning system gps this research will focus on indoor positioning or what is usually called the indoor positioning system ips the indoor positioning system ips in the digitalization era is very influential considering that all infrastructure developments are very advanced as well as the digitalization sector development in many of these sectors will also give rise to many new problems for example if there are skyscrapers then there will be many obstacles or problems in determining the location of people or objects the problem doesnt stop there where threats can also come from humans either through the system or physically in this research it will be used to find out the comparison of the best model based on an existing dataset with a dataset taken directly in a room that is considered sterile then it is compared using several machine learning algorithms as a comparison which algorithm has the best accuracy and a test method of attack was made which was then made into a sturdy model then from this comparison one of the models from the dataset that has the best accuracy will be selected to create a detection system prototype where if an anomaly is detected in the model it will send a warning message via email in the hope that this system can be useful in limited spaces or places this research utilizes a dataset in the form of channel state information csi several models tested obtained an accuracy of 7402 using the random forest algorithm where the implementation of the attack using decision tree attack was successfully carried out until the accuracy fell to 52 the trial application of the maintenance method using featurequeezing succeeded in making the model more durable proven by an accuracy of 68 and the anomaly detector implementation can send danger messages via email
Analisis Gangguan (Noise) Heart Rate Sensor Pada Wearable Device Berdasarkan Artefak Tangan Menggunakan Polar Oh1.,"Ramadhan, Rizqi",http://repository.its.ac.id/110335/,"Penelitian ini bertujuan untuk mengidentifikasi dan menganalisis tingkat noise yang dihasilkan oleh perangkat wearable OH1 selama berbagai gerakan tangan, yang dapat mempengaruhi keakuratan pengukuran detak jantung (HR). Masalah umum yang dihadapi adalah ketidakakuratan data HR yang disebabkan oleh noise saat perangkat digunakan selama aktivitas fisik. Masalah khususnya adalah menentukan gerakan tangan mana yang menghasilkan noise tertinggi dan terendah, serta bagaimana variabilitas data BPM dalam kondisi gerakan tangan yang berbeda-beda. Untuk mengatasi masalah ini, penelitian ini mengumpulkan data HR dari 10 jenis gerakan tangan, yaitu Menekan Tangan Lurus, Horizontal Shoulder Extension, Siku ke Hidung, Menyentuh Bahu, Mengangkat Bahu 90°, Supinate, Pronate, Melenturkan Bahu 180°, Tangan ke Dahi, dan Siku Menekuk 90°. Data tersebut kemudian dianalisis menggunakan metode Support Vector Machine (SVM) untuk mengklasifikasikan tingkat noise yang dihasilkan oleh setiap gerakan.Dengan meenggunakan 11 partisipan yang dalam kondisi sehat. Hasil analisis menunjukkan bahwa gerakan Melenturkan Bahu 180° menghasilkan tingkat noise tertinggi, sementara gerakan Siku Menekuk 90° menghasilkan noise terendah. Variabilitas data BPM menunjukkan perbedaan signifikan dalam stabilitas pengukuran HR yang dipengaruhi oleh jenis gerakan tangan. Dengan menggunakan metode SVM, akurasi klasifikasi mencapai 67%, yang menunjukkan efektivitas metode ini dalam mengidentifikasi dan mengklasifikasikan noise dari berbagai gerakan tangan. Kesimpulannya, penelitian ini memberikan wawasan penting tentang pengaruh gerakan tangan terhadap akurasi pengukuran HR oleh perangkat wearable OH1. Dengan mengetahui gerakan yang menghasilkan noise tinggi, pengguna dapat menghindari gerakan tersebut untuk memperoleh data HR yang lebih akurat dan andal.=================================================================================================================================This study aims to identify and analyze the level of noise produced by the OH1 wearable device during various hand movements, which can affect the accuracy of heart rate (HR) measurements. The general issue addressed is the inaccuracy of HR data caused by noise when the device is used during physical activities. The specific issues include determining which hand movements produce the highest and lowest noise levels and understanding the variability of BPM data under different hand movement conditions. To address these issues, HR data was collected from 10 types of hand movements, including Pressing Straight Hand, Horizontal Shoulder Extension, Elbow to Nose, Touching Shoulder, Lifting Shoulder 90°, Supinate, Pronate, Shoulder Flexion 180°, Hand to Forehead, and Elbow Bent 90°. The data was analyzed using the Support Vector Machine (SVM) method to classify the noise levels generated by each movement. The study involved 11 healthy participants. The analysis results show that the Shoulder Flexion 180° movement produces the highest noise level, while the Elbow Bent 90° movement produces the lowest noise. The variability in BPM data indicates significant differences in the stability of HR measurements influenced by the type of hand movement. Using the SVM method, the classification accuracy reached 67%, demonstrating the effectiveness of this method in identifying and classifying noise from various hand movements. In conclusion, this study provides important insights into the impact of hand movements on the accuracy of HR measurements by the OH1 wearable device. By identifying movements that generate high noise levels, users can avoid these movements to obtain more accurate and reliable HR data.",analisis ganggu noise heart rate sensor wearable device dasar artefak tangan polar oh1,teliti tuju identifikasi analis tingkat noise hasil perangkat wearable oh1 gera tangan pengaruh akurat ukur detak jantung hr hadap ketidakakuratan data hr sebab noise perangkat aktivitas fisik tentu gera tangan hasil noise tinggi rendah variabilitas data bpm kondisi gera tangan berbedabeda atas teliti kumpul data hr 10 jenis gera tangan tekan tangan lurus horizontal shoulder extension siku hidung sentuh bahu angkat bahu 90 supinate pronate lentur bahu 180 tangan dahi siku tekuk 90 data analis metode support vector machine svm klasifikasi tingkat noise hasil gerakandengan meenggunakan 11 partisipan kondisi sehat hasil analisis gera lentur bahu 180 hasil tingkat noise tinggi gera siku tekuk 90 hasil noise rendah variabilitas data bpm beda signifikan stabilitas ukur hr pengaruh jenis gera tangan metode svm akurasi klasifikasi capai 67 efektivitas metode identifikasi klasifikasi noise gera tangan simpul teliti wawas pengaruh gera tangan akurasi ukur hr perangkat wearable oh1 gera hasil noise guna hindar gera oleh data hr akurat andalthis study aims to identify and analyze the level of noise produced by the oh1 wearable device during various hand movements which can affect the accuracy of heart rate hr measurements the general issue addressed is the inaccuracy of hr data caused by noise when the device is used during physical activities the specific issues include determining which hand movements produce the highest and lowest noise levels and understanding the variability of bpm data under different hand movement conditions to address these issues hr data was collected from 10 types of hand movements including pressing straight hand horizontal shoulder extension elbow to nose touching shoulder lifting shoulder 90 supinate pronate shoulder flexion 180 hand to forehead and elbow bent 90 the data was analyzed using the support vector machine svm method to classify the noise levels generated by each movement the study involved 11 healthy participants the analysis results show that the shoulder flexion 180 movement produces the highest noise level while the elbow bent 90 movement produces the lowest noise the variability in bpm data indicates significant differences in the stability of hr measurements influenced by the type of hand movement using the svm method the classification accuracy reached 67 demonstrating the effectiveness of this method in identifying and classifying noise from various hand movements in conclusion this study provides important insights into the impact of hand movements on the accuracy of hr measurements by the oh1 wearable device by identifying movements that generate high noise levels users can avoid these movements to obtain more accurate and reliable hr data
Peringkasan Pertanyaan Stack Overflow Pada Atribut Kualitas Perangkat Lunak Menggunakan Teknik Penggalian Informasi Dan Klasifikasi Support Vector Machine (SVM).,"Rausanfita, Alqis",http://repository.its.ac.id/92791/,"Stack Overflow merupakan forum diskusi informal yang dapat menjadi bahan untuk evaluasi kualitas suatu perangkat lunak dengan cara penambangan teks. Evaluasi dapat dilakukan dengan menggunakan hasil peringkasan pertanyaan pada Stack Overflow, peringkasan tersebut dapat mengandung persyaratan kebutuhan pelanggan yang dapat dilakukan pemrosesan lebih lanjut. Selain itu, developer juga dapat mengelompokkan kendala yang dialami pengguna berdasarkan kualitas perangkat lunak sehingga dapat memudahkan dalam melakukan maintenance. Metode peringkasan sebelumnya menggunakan 2 jenis bobot, yang mana antara frasa pada sub aspek dengan frasa pada extend domain memiliki bobot yang sama, seharusnya bobot  sub domain lebih besar daripada frasa hasil extend.  Oleh karena itu penelitian ini bertujuan untuk meringkas kebutuhan pengguna pada atribut kualitas perangkat lunak dengan menggunakan informasi retrieval dan klasifikasi kualitas perangkat lunak sehingga diharapkan dapat membantu developer dalam mengevaluasi kualitas perangkat lunak secara otomatis. Ada beberapa tahapan yang dilakukan, yaitu: melakukan klasifikasi. Kemudian hasil klasifikasi tiap atribut kualitas dilakukan peringkasan. Pada penelitian ini, didapatkan hasil akurasi terbaikk dengan menggunakan metode SVM dengan nilai akurasi sebesar 86,63 persen. Hasil akurasi terbaik ini didapatkan dengan membandingkan 5 metode lainnya, yaitu Random Forest, Decision Tree, Logistic Regression, Naïve Bayes, dan Neural Network. Setelah didapatkan hasil klasifikasi kemudian dilakukan proses peringkasan dan mendapatkan nilai akurasi sebesar 73,08 persen. Hal tersebut mengindikasikan bahwa penelitian ini cukup baik dalam menghasilkan ringkasan kebutuhan pengguna pada atribut kualitas perangkat lunak dengan menggunakan information retrieval dan klasifikasi kualitas perangkat lunak. ================================================================================================Stack Overflow is an informal discussion platform that can be used as source for quality evaluation of a software through text mining. Evaluation can be done using the results of the questions summary on the Stack Overflow, the summary can contain the requirements of customer needs that can be processed further. Besides, developer can also group the constraints experienced by users based on the quality of the software so that it can be easier to carry out maintenance. The previous summary method used 2 types of weights with the phrases in the sub-aspects and the phrases in the extend domain had the same weight, in which sub domain should be larger than the extended result phrase. Therefore, this study aims to summarize the user needs on software quality by using retrieval information and software quality classification so that it can help developers in evaluating the software quality automatically. There are several stages that carried out, the first one is classifying. Then the results of the classification of each quality attribute are summarized. In this study, the best accuracy result was obtained using the SVM method with the accuracy value of 86.63 percent. The best accuracy results is obtained by comparing 5 other methods, that are Random Forest, Decision Tree, Logistic Regression, Naïve Bayes, and Neural Network. After obtaining the classification, a summary process was carried out and obtained the accuracy value of 73.08 percent. This indicates that this research is quite good at producing a summary of user needs on software quality attributes using information retrieval and classification of software quality.",ringkas stack overflow atribut kualitas perangkat lunak teknik gali informasi klasifikasi support vector machine svm,stack overflow forum diskusi informal bahan evaluasi kualitas perangkat lunak tambang teks evaluasi hasil ringkas stack overflow ringkas kandung syarat butuh langgan pemrosesan developer kelompok kendala alami guna dasar kualitas perangkat lunak mudah maintenance metode ringkas 2 jenis bobot frasa sub aspek frasa extend domain milik bobot bobot sub domain frasa hasil extend teliti tuju ringkas butuh guna atribut kualitas perangkat lunak informasi retrieval klasifikasi kualitas perangkat lunak harap bantu developer evaluasi kualitas perangkat lunak otomatis tahap klasifikasi hasil klasifikasi atribut kualitas ringkas teliti dapat hasil akurasi terbaikk metode svm nilai akurasi 8663 persen hasil akurasi baik dapat banding 5 metode random forest decision tree logistic regression na ve bayes neural network dapat hasil klasifikasi proses ringkas nilai akurasi 7308 persen indikasi teliti hasil ringkas butuh guna atribut kualitas perangkat lunak information retrieval klasifikasi kualitas perangkat lunak stack overflow is an informal discussion platform that can be used as source for quality evaluation of a software through text mining evaluation can be done using the results of the questions summary on the stack overflow the summary can contain the requirements of customer needs that can be processed further besides developer can also group the constraints experienced by users based on the quality of the software so that it can be easier to carry out maintenance the previous summary method used 2 types of weights with the phrases in the subaspects and the phrases in the extend domain had the same weight in which sub domain should be larger than the extended result phrase therefore this study aims to summarize the user needs on software quality by using retrieval information and software quality classification so that it can help developers in evaluating the software quality automatically there are several stages that carried out the first one is classifying then the results of the classification of each quality attribute are summarized in this study the best accuracy result was obtained using the svm method with the accuracy value of 8663 percent the best accuracy results is obtained by comparing 5 other methods that are random forest decision tree logistic regression na ve bayes and neural network after obtaining the classification a summary process was carried out and obtained the accuracy value of 7308 percent this indicates that this research is quite good at producing a summary of user needs on software quality attributes using information retrieval and classification of software quality
Prediksi Curah Hujan Memanfaatkan Statistical Downscaling Data Global Forecast System Menggunakan Support Vector Regression dan Long Short-Term Memory Sebagai Penunjang Keputusan Top Management.,"Rohman, Priya Setiawan A.",http://repository.its.ac.id/116288/,"Wilayah Sungai (WS) Brantas sering mengalami kejadian banjir akibat dari curah hujan yang tinggi, sehingga diperlukan prediksi cuaca yang akurat untuk mendukung keputusan manajemen dalam mitigasi banjir. Data Global Forecast System (GFS) digunakan dalam memprediksi cuaca khususnya prediksi curah hujan, namun resolusinya yang rendah tidak cukup memadai untuk skala lokal di WS Brantas. Masalah yang dihadapi adalah bagaimana cara untuk meningkatkan ketepatan prediksi curah hujan dengan mengintegrasikan data GFS yang memiliki resolusi rendah dengan data curah hujan lokal. Penelitian ini bertujuan untuk meningkatkan akurasi prediksi curah hujan di WS Brantas dengan teknik Statistical downscaling menggunakan metode Support Vector Regression (SVR) yang baik dalam menangani data non-linear dan Long Short-Term Memory (LSTM), sebuah jenis jaringan saraf tiruan yang dapat menangkap hubungan temporal dalam data deret waktu. Data yang diperlukan adalah prediksi curah hujan dari GFS dan data curah hujan lokal hasil pengukuran di WS Brantas. Hasil penelitian menunjukkan bahwa tingkat akurasi prediksi dengan SVR dan LSTM lebih tinggi daripada akurasi data prediksi GFS, sehingga dapat diusulkan untuk diimplementasikan sebagai data penunjang top management.==================================================================================================================================The Brantas River Basin (Brantas RB) often experiences flooding events due to high rainfall, so accurate weather predictions are needed to support management decisions in flood mitigation. Global Forecast System (GFS) data is used in predicting weather, especially rainfall prediction, but its low resolution is not sufficient for the local scale in the Brantas RB. The problem faced is how to improve the accuracy of rainfall prediction by integrating low-resolution GFS data with local rainfall data. This study aims to improve the accuracy of rainfall prediction in Brantas RB with statistical downscaling technique using Support Vector Regression (SVR) method which is good in handling non-linear data and Long Short-Term Memory (LSTM), a type of artificial neural network that can capture temporal relationships in time series data. The data required are rainfall predictions from GFS and local rainfall data measured in Brantas RB. The results show that the accuracy of prediction with SVR and LSTM is higher than the accuracy of GFS prediction data, so it can be proposed to be implemented as top management support data.",prediksi curah hujan manfaat statistical downscaling data global forecast system support vector regression long shortterm memory tunjang putus top management,wilayah sungai ws brantas alami jadi banjir akibat curah hujan prediksi cuaca akurat dukung putus manajemen mitigasi banjir data global forecast system gfs prediksi cuaca prediksi curah hujan resolusi rendah pada skala lokal ws brantas hadap tingkat tepat prediksi curah hujan integrasi data gfs milik resolusi rendah data curah hujan lokal teliti tuju tingkat akurasi prediksi curah hujan ws brantas teknik statistical downscaling metode support vector regression svr tangan data nonlinear long shortterm memory lstm jenis jaring saraf tiru tangkap hubung temporal data deret data prediksi curah hujan gfs data curah hujan lokal hasil ukur ws brantas hasil teliti tingkat akurasi prediksi svr lstm akurasi data prediksi gfs usul implementasi data tunjang top managementthe brantas river basin brantas rb often experiences flooding events due to high rainfall so accurate weather predictions are needed to support management decisions in flood mitigation global forecast system gfs data is used in predicting weather especially rainfall prediction but its low resolution is not sufficient for the local scale in the brantas rb the problem faced is how to improve the accuracy of rainfall prediction by integrating lowresolution gfs data with local rainfall data this study aims to improve the accuracy of rainfall prediction in brantas rb with statistical downscaling technique using support vector regression svr method which is good in handling nonlinear data and long shortterm memory lstm a type of artificial neural network that can capture temporal relationships in time series data the data required are rainfall predictions from gfs and local rainfall data measured in brantas rb the results show that the accuracy of prediction with svr and lstm is higher than the accuracy of gfs prediction data so it can be proposed to be implemented as top management support data
Perencanaan Model Distribusi Bahan Baku Baterai Kendaraan Listrik.,"Roihan, Imam Farhannabil",http://repository.its.ac.id/106836/,"Pemerintah Republik Indonesia telah melarang ekspor bijih nikel agar bijih nikel diolah lebih  lanjut di dalam negeri. Kebijakan ini guna meningkatkan nilai tambah dari ekspor nikel  Indonesia. Nikel merupakan salah satu mineral yang melimpah di Indonesia dan merupakan  salah satu bahan baku utama dalam memproduksi baterai kendaraan listrik di samping bahan  baku lainnya seperti mangan, kobalt, dan litium. Indonesia memiliki peluang untuk menjadi  lokasi produksi baterai kendaraan listrik. Untuk menjadi produsen baterai kendaraan listrik,  Indonesia harus membangun industri produksi baterai kendaraan listrik di dalam negeri serta  ngimpor bahan baku lainnya yang tidak melimpah di Indonesia. Industri baterai kendaraan  listrik merupakan industri yang masih tergolong baru di Indonesi sehingga penelitian ini adalah  untuk mencari model distribusi bahan baku baterai kendaraan listrik yang optimum  menggunakan metode optimisasi. Optimisasi dilakukan dengan membagi model distribusi  menjadi beberapa skenario berdasarkan model transportasi laut yang digunakan. Transportasi  laut yang terpilih akan mempengaruhi model distribusi secara keseluruhan. Model distribusi  yang terpilih didapatkan unit cost distribusi bijih nikel Rp22.205/ton, nikel sulfat  Rp2.751.791/ton, kobalt sulfat Rp2.751.791/ton, litium hidroksida Rp1.253.788/ton, mangan  sulfat Rp1.253.788/ton, dan katoda Rp878.723/ton==================================================================================================================================The Government of the Republic of Indonesia has banned the export of nickel ore so that nickel ore can be further processed domestically. This policy is to increase the added value of Indonesian nickel exports. Nickel is one of the minerals that is abundant in Indonesia and is one of the main raw materials for producing electric vehicle batteries alongside other raw materials such as manganese, cobalt and lithium. Indonesia has the opportunity to become a production location for electric vehicle batteries. To become an electric vehicle battery producer, Indonesia must build a domestic electric vehicle battery production industry and import other raw materials that are not abundant in Indonesia. The electric vehicle battery industry is an industry that is still relatively new in Indonesia, so this research is to find an optimum distribution model for electric vehicle battery raw materials using optimization methods. Optimization is carried out by dividing the distribution model into several scenarios based on the sea transportation model used. The selected sea transportation will influence the overall distribution model. The selected distribution model obtained unit distribution costs for nickel ore IDR 22,205/ton, nickel sulfate IDR 2,751,791/ton, cobalt sulfate IDR 2,751,791/ton, lithium hydroxide IDR 1,253,788/ton, manganese sulfate IDR 1,253,788/ton, and cathode IDR 878,723/ton",rencana model distribusi bahan baku baterai kendara listrik,perintah republik indonesia larang ekspor bijih nikel bijih nikel olah negeri bijak tingkat nilai ekspor nikel indonesia nikel salah mineral limpah indonesia salah bahan baku utama produksi baterai kendara listrik samping bahan baku mangan kobalt litium indonesia milik peluang lokasi produksi baterai kendara listrik produsen baterai kendara listrik indonesia bangun industri produksi baterai kendara listrik negeri ngimpor bahan baku limpah indonesia industri baterai kendara listrik industri golong indonesi teliti cari model distribusi bahan baku baterai kendara listrik optimum metode optimisasi optimisasi bagi model distribusi skenario dasar model transportasi laut transportasi laut pilih pengaruh model distribusi model distribusi pilih dapat unit cost distribusi bijih nikel rp22205ton nikel sulfat rp2751791ton kobalt sulfat rp2751791ton litium hidroksida rp1253788ton mangan sulfat rp1253788ton katoda rp878723tonthe government of the republic of indonesia has banned the export of nickel ore so that nickel ore can be further processed domestically this policy is to increase the added value of indonesian nickel exports nickel is one of the minerals that is abundant in indonesia and is one of the main raw materials for producing electric vehicle batteries alongside other raw materials such as manganese cobalt and lithium indonesia has the opportunity to become a production location for electric vehicle batteries to become an electric vehicle battery producer indonesia must build a domestic electric vehicle battery production industry and import other raw materials that are not abundant in indonesia the electric vehicle battery industry is an industry that is still relatively new in indonesia so this research is to find an optimum distribution model for electric vehicle battery raw materials using optimization methods optimization is carried out by dividing the distribution model into several scenarios based on the sea transportation model used the selected sea transportation will influence the overall distribution model the selected distribution model obtained unit distribution costs for nickel ore idr 22205ton nickel sulfate idr 2751791ton cobalt sulfate idr 2751791ton lithium hydroxide idr 1253788ton manganese sulfate idr 1253788ton and cathode idr 878723ton
DETEKSI PENYAKIT CABAI MERAH BESAR BERDASARKAN CITRA DAUN MENGGUNAKAN METODE SUPPORT VECTOR MACHINE (SVM) DAN LEARNING VECTOR QUANTIZATION (LVQ).,"Rossa, Shevia",http://repository.its.ac.id/114982/,"Salah satu tantangan utama yang menyebabkan rendahnya produksi cabai merah besar adalah gangguan penyakit yang dapat menyerang tanaman mulai dari tahap persemian hingga hasil panen. Gejala visual kunci suatu penyakit menjadi petunjuk kritis dalam menentukan patogen penyebabnya. Beberapa penyakit yang secara signifikan mempengaruhi produksi cabai merah besar di Indonesia meliputi penyakit kuning, embun tepung, mosaik keriting, dan kuning keriting. Penyebaran cepat penyakit ini terjadi karena kurangnya perhatian khusus dari petani, yang mengakibatkan kurangnya pemahaman mereka tentang karakteristik dan penanganan penyakit ini. Oleh karena itu, sangat penting untuk mengembangkan sistem deteksi yang akurat, cepat, dan efisien dalam mengidentifikasi penyakit pada tanaman cabai. Salah satu cara pendeteksian adalah dengan mengklasifikasikan citra daun. Data penelitian bersumber dari pertanian di Kabupaten Bener Meriah Provinsi Aceh pada 21 September hingga 1 Oktober tahun 2023. Teknologi rekognisi citra dilakukan untuk mengenali jenis hama dan penyakit pada tanaman cabai merah besar. Langkah pertama dalam penelitian adalah mengumpulkan citra daun, kemudilan melakukan preprocessing dan dilanjutkan tahap proses ekstraksi fitur warna, fitur tekstur dan fitur bentuk, hasil ekstraksi citra digunakan sebagai input dalam proses klasifikasi menggunakan algoritma Support Vector Machine (SVM) dan Learning Vector Quantization (LVQ). Accuracy hasil prediksi data training dan testing dengan metode SVM kernel polynolial adalah 95% dan 97%, sedangkan accuracy data training dan testing menggunakan metode LVQ adalah 53% dan 57%. Model terbaik dalam memprediksi penyakit cabai adalah model SVM dengan kernel polynomial.========================================================================================================================One of the primary challenges contributing to the low production of large red chili peppers is the prevalence of diseases that can affect plants from the seedling stage to the harvest. Key visual symptoms of a disease serve as critical indicators in determining the causative pathogen. Several diseases significantly impact the production of large red chili peppers in Indonesia, including yellowing disease, powdery mildew, mosaic curl, and yellow curl. The rapid spread of these diseases is attributed to the insufficient specific attention from farmers, resulting in a lack of understanding regarding the characteristics and management of these diseases. Therefore, it is crucial to develop an accurate, rapid, and efficient detection system to identify diseases in chili plants. One method of detection involves classifying leaf images. The research data is sourced from agricultural activities in the Bener Meriah Regency, Aceh Province, from September 21 to October 1, 2023. Image recognition technology is employed to identify types of pests and diseases affecting large red chili plants. The first step in the research involves collecting leaf images, followed by preprocessing and subsequent stages of color feature extraction, texture feature extraction, and shape feature extraction. The extracted image features serve as parameters in the classification process using the Support Vector Machine (SVM) and Learning Vector Quantization (LVQ) algorithms. The accuracy of the prediction results for the training and testing data using the SVM with a polynomial kernel method is 95% and 97%, respectively. In contrast, the accuracy of the training and testing data using the LVQ method is 53% and 57%, respectively. Therefore, the best model for predicting chili plant diseases is the SVM model with a polynomial kernel.",deteksi sakit cabai merah dasar citra daun metode support vector machine svm learning vector quantization lvq,salah tantang utama sebab rendah produksi cabai merah ganggu sakit serang tanam tahap semi hasil panen gejala visual kunci sakit tunjuk kritis tentu patogen sebab sakit signifikan pengaruh produksi cabai merah indonesia liput sakit kuning embun tepung mosaik keriting kuning keriting sebar cepat sakit kurang perhati khusus tani akibat kurang paham karakteristik tangan sakit kembang sistem deteksi akurat cepat efisien identifikasi sakit tanam cabai salah deteksi klasifikasi citra daun data teliti sumber tani kabupaten bener riah provinsi aceh 21 september 1 oktober 2023 teknologi rekognisi citra nali jenis hama sakit tanam cabai merah langkah teliti kumpul citra daun kemudilan preprocessing lanjut tahap proses ekstraksi fitur warna fitur tekstur fitur bentuk hasil ekstraksi citra input proses klasifikasi algoritma support vector machine svm learning vector quantization lvq accuracy hasil prediksi data training testing metode svm kernel polynolial 95 97 accuracy data training testing metode lvq 53 57 model baik prediksi sakit cabai model svm kernel polynomialone of the primary challenges contributing to the low production of large red chili peppers is the prevalence of diseases that can affect plants from the seedling stage to the harvest key visual symptoms of a disease serve as critical indicators in determining the causative pathogen several diseases significantly impact the production of large red chili peppers in indonesia including yellowing disease powdery mildew mosaic curl and yellow curl the rapid spread of these diseases is attributed to the insufficient specific attention from farmers resulting in a lack of understanding regarding the characteristics and management of these diseases therefore it is crucial to develop an accurate rapid and efficient detection system to identify diseases in chili plants one method of detection involves classifying leaf images the research data is sourced from agricultural activities in the bener riah regency aceh province from september 21 to october 1 2023 image recognition technology is employed to identify types of pests and diseases affecting large red chili plants the first step in the research involves collecting leaf images followed by preprocessing and subsequent stages of color feature extraction texture feature extraction and shape feature extraction the extracted image features serve as parameters in the classification process using the support vector machine svm and learning vector quantization lvq algorithms the accuracy of the prediction results for the training and testing data using the svm with a polynomial kernel method is 95 and 97 respectively in contrast the accuracy of the training and testing data using the lvq method is 53 and 57 respectively therefore the best model for predicting chili plant diseases is the svm model with a polynomial kernel
PREDIKSI PENGELUARAN PERKAPITA YANG DISESUAIKAN BERDASARKAN CITRA DIGITAL GOOGLE EARTH MENGGUNAKAN KOMBINASI CONVOLUTIONAL NEURAL NETWORK (CNN) DAN SUPPORT VECTOR REGRESSION(SVR).,"Rouhan, Asva Abadila",http://repository.its.ac.id/81193/,"Kemiskinan dapat didefinisikan sebagai ketidakmampuan seseorang atau rumah tangga dalam memenuhi kebutuhan pokoknya. Kebanyakan negara menggunakan pendapatan atau konsumsi rumah tangga sebagai standar pengukuran kesejahteraan penduduk. Namun, pengumpulan data secara mendetail dari pintu ke pintu merupakan hal banyak memakan waktu dan biaya. Belakangan ini muncul sumber data alternatif pengganti survei, yaitu citra digital satelit. Citra digital umumnya diolah menggunakan Convolutional Neural Network (CNN). Salah satu arsitektur CNN yang dianggap paling baik adalah VGG16. VGG16 dalam tugas akhir ini digunakan sebagai fixed feature extraction sedangkan pemodelan estimasi kemiskinan di Pulau Jawa menggunakan Support Vector Regression (SVR). Kombinasi kedua metode menghasilkan model dengan performa 0,703 pada tahap testing. Terdapat hampir 80% kesesuaian pada 25% golongan pengeluaran perkapita terendah antara hasil estimasi dan data aktual.",prediksi keluar kapita sesuai dasar citra digital google earth kombinasi convolutional neural network cnn support vector regressionsvr,miskin definisi ketidakmampuan rumah tangga penuh butuh pokok banyak negara dapat konsumsi rumah tangga standar ukur sejahtera duduk kumpul data detail pintu pintu makan biaya muncul sumber data alternatif ganti survei citra digital satelit citra digital olah convolutional neural network cnn salah arsitektur cnn anggap vgg16 vgg16 tugas fixed feature extraction model estimasi miskin pulau jawa support vector regression svr kombinasi metode hasil model performa 0703 tahap testing 80 sesuai 25 golong keluar kapita rendah hasil estimasi data aktual
Bayisehatkita: Aplikasi Berbasis Web Untuk Klasifikasi Stunting Pada Aud.,"Ruslan, Bima Triadi",http://repository.its.ac.id/88038/,"Malnutrisi merupakan permasalahan umum yang masih banyak terjadi di seluruh dunia, salah satu bentuk dari malnutrisi yang paling banyak diderita oleh anak dibawah 5 tahun adalah stunting. Indonesia masuk ke dalam region Asia Selatan dengan nilai persentase stunting yang masih berada di kategori sangat tinggi. Pada tahun 2019 stunting masih dianggap sebagai permasalahan utama dalam kesehatan masyarakat Indonesia dengan angka prevalensi sebesar 27,67%. Stunting dapat mengakibatkan penurunan kemampuan kognitif dan akademik dari anak, penurunan produktivitas, peningkatan risiko naik berat badan yang eksesif dan penyakit kronis terkait nutrisi pada saat kehidupan dewasa. Dengan angka prevalensi yang masih tinggi dan dampak yang memiliki pengaruh besar pada kehidupan anak, maka perlu diteliti lebih lanjut langkah atau cara apa yang perlu dilakukan untuk menurunkan angka prevalensi stunting di Indonesia.Dalam tugas akhir ini metode yang akan digunakan adalah Binary Logistic Regression. Metode tersebut digunakan karena dapat membandingkan beberapa independent variabel berjenis continuous dan categorical dengan variabel dependent yang terdiri dari dua kemungkinan atau dichotomous. Selain itu dengan menggunakan metode ini maka dapat diperhitungkan probabilitas dari suatu kejadian yang akan terjadi, dalam kasus ini proabilitias anak akan stunting atau probabilitas anak tidak akan stunting. Lalu untuk mengukur kinerja dari metode tersebut akan digunakan confusion matrix untuk memperhitungkan tingkat accuracy, precision, dan recall. Dataset yang akan digunakan dalam tugas akhir ini merupakan dataset Indonesian Family Life Surveys 4 (IFLS 4) dari tahun 2007 dan Indonesian Family Life Survey 5 (IFLS 5) dari tahun 2014-2015 yang diselenggarakan oleh RAND Corporation dan Surveymeter.Hasil analisis dari tugas akhir ini telah diketahui bahwa faktor yang memiliki pengaruh signifikan terhadap perubahan status stunting anak terdiri dari tinggi ayah, tinggi ibu, berat badan ibu, pendidikan ibu, area rumah, dan gender anak. Lalu dalam pengembangan model telah didapatkan bahwa model menggunakan binary logistic regression dengan parameter C bernilai 1, penalty L2 dan solver newton-cg dapat melakukan prediksi status stunting anak dengan cukup baik dengan nilai accuracy sebesar 75,05% dan f1-score sebesar 74,89%.==================================================================================================Malnutrition is a common problem that still occurs throughout the world, one of the most common forms of malnutrition that is suffered by children under years old is stunting. Indonesia is part of the Sout Asia region with a stunting percentage value that is still in the very high category. In 2019 stunting was still considered a major problem in the Indonesian public healthwith a prevalence rate of 27.67%. Stunting can lead to decreased cognitive and academic abilities of children, decreased productivity, increased risk of excessive weight gain and chronic nutrition-related disease when they grow older. With a prevalence rate that is still considered as high and the impact that has a big influence on children’s lives, it is necessary to further investigate what steps or ways that needs to be done to reduce the prevalence of stunting in Indonesia.In this final project the method that is used is binary logistic regression. This method is used based on it’s capabilities to compare several independent variable of continuous and categorical type with a dependent variable which consists of two possibilities or is dichotomous. In addition, by using this method, the probability of an event that will occur can be calculated. In this case the probability of the child being stunted or the probability that the child will not be stunted. To calculate the performance of the model, a confusion matrix will be used to calculate the level of accuracy, precision, and recall. The dataset that is used in this final project is the Indonesian Family Life Surveys 4 (IFLS 4) dataset from 2007 and the Indonesian Family Life Survey 5 (IFLS 5) from 2014-2015 organized by RAND Corporation and Surveymeter. The results of the analysis that is conducted in this final project have shown that the factors that have a significant influence on changes in a child stunting status consist of father’s height, mother’s height, mother’s weight, mother’s education, house area, and child’s gender. Then in the development of the model, it was found that the model using binary logistic regression with a parameter C with a value of 1, penalty of L2, and with the newton-cg solver can predict the stunting status quite well with an accuracy value of 75.05% and f1-score of 74.89%.",bayisehatkita aplikasi bas web klasifikasi stunting aud,malnutrisi masalah dunia salah bentuk malnutrisi derita anak bawah 5 stunting indonesia masuk region asia selatan nilai persentase stunting kategori 2019 stunting anggap masalah utama sehat masyarakat indonesia angka prevalensi 2767 stunting akibat turun mampu kognitif akademik anak turun produktivitas tingkat risiko berat badan eksesif sakit kronis kait nutrisi hidup dewasa angka prevalensi dampak milik pengaruh hidup anak teliti langkah turun angka prevalensi stunting indonesiadalam tugas metode binary logistic regression metode banding independent variabel jenis continuous categorical variabel dependent dichotomous metode hitung probabilitas jadi proabilitias anak stunting probabilitas anak stunting ukur kerja metode confusion matrix hitung tingkat accuracy precision recall dataset tugas dataset indonesian family life surveys 4 ifls 4 2007 indonesian family life survey 5 ifls 5 20142015 selenggara rand corporation surveymeterhasil analisis tugas faktor milik pengaruh signifikan ubah status stunting anak ayah berat badan didik area rumah gender anak kembang model dapat model binary logistic regression parameter c nila 1 penalty l2 solver newtoncg prediksi status stunting anak nilai accuracy 7505 f1score 7489malnutrition is a common problem that still occurs throughout the world one of the most common forms of malnutrition that is suffered by children under years old is stunting indonesia is part of the sout asia region with a stunting percentage value that is still in the very high category in 2019 stunting was still considered a major problem in the indonesian public healthwith a prevalence rate of 2767 stunting can lead to decreased cognitive and academic abilities of children decreased productivity increased risk of excessive weight gain and chronic nutritionrelated disease when they grow older with a prevalence rate that is still considered as high and the impact that has a big influence on children  s lives it is necessary to further investigate what steps or ways that needs to be done to reduce the prevalence of stunting in indonesiain this final project the method that is used is binary logistic regression this method is used based on it  s capabilities to compare several independent variable of continuous and categorical type with a dependent variable which consists of two possibilities or is dichotomous in addition by using this method the probability of an event that will occur can be calculated in this case the probability of the child being stunted or the probability that the child will not be stunted to calculate the performance of the model a confusion matrix will be used to calculate the level of accuracy precision and recall the dataset that is used in this final project is the indonesian family life surveys 4 ifls 4 dataset from 2007 and the indonesian family life survey 5 ifls 5 from 20142015 organized by rand corporation and surveymeter the results of the analysis that is conducted in this final project have shown that the factors that have a significant influence on changes in a child stunting status consist of father  s height mother  s height mother  s weight mother  s education house area and child  s gender then in the development of the model it was found that the model using binary logistic regression with a parameter c with a value of 1 penalty of l2 and with the newtoncg solver can predict the stunting status quite well with an accuracy value of 7505 and f1score of 7489
Model Optimasi (Mixed Integer Nonlinear Programming) Untuk Menentukan Struktur Rantai Pasok Pengolahan Bittern Dengan Konsolidasi.,"Ryanto, Zido Fairuz",http://repository.its.ac.id/89061/,"Garam merupakan salah satu komoditas dengan tingkat permintaan yang tinggi di Indonesia. Produksi garam terdiri dari beberapa tahap, salah satunya adalah pemisahan air dari garam. Selama proses pemisahan air dari garam, terdapat air sisa yang menjadi limbah. Air tersebut disebut sebagai air tua atau bittern. Bittern merupakan cairan pekat sebagai limbah hasil dari proses produksi garam. Bittern dibuang ke lingkungan sekitar sehingga dapat mencemari lingkungan, terutama sungai dan laut. Namun, bittern dapat diolah dan dijual kembali karena memiliki beberapa kandungan mineral yang dapat dimanfaatkan. Pengolahan bittern membutuhkan fasilitas pengolahan untuk mengolah bittern berupa bahan mentah menjadi bittern yang siap digunakan dan sebagai perantara antara produsen dan konsumen dengan fungsi sebagai fasilitas pengolahan atau gudang. Skenario yang dapat diimplementasikan adalah sentralisasi, desentralisasi dengan konsolidasi, dan campuran dengan konsolidasi. Permasalahan digambarkan melalui model mixed integer nonlinear programming (MINLP) dan penyelesaian dilakukan dengan metode GRG Nonlinear. Berdasarkan penelitian yang telah dilakukan, skenario desentralisasi dengan konsolidasi lebih layak untuk digunakan pada rantai pasok pengolahan bittern. Perubahan keputusan penggunaan skenario dipengaruhi oleh tingkat permintaan konsumen, biaya pengolahan bittern, dan biaya pembangunan fasilitas pengolahan atau gudang sebagai parameter yang paling berpengaruh.=========================================================================================================Salt is one of the commodities with a high level of demand in Indonesia. Salt production consists of several stages, one of them is the separation of water from salt. During the process, there is residual water that becomes waste. This water is known as old water or bittern. Bittern is a concentrated liquid come from the salt production process. Bitterns are thrown into the environment so it can pollute the environment, especially rivers and seas. However, bittern can be processed and resold because it has some mineral that can be used. Bittern processing requires processing facilities to process bittern in the form of raw materials to be ready to use and as intermediaries between producers and consumers with the function as processing facilities or warehouses. The scenarios that can be implemented are centralized, decentralized with consolidation, and mixed with consolidation. Problems in the bittern processing supply chain are described through a mixed integer nonlinear programming (MINLP) model and the solution is solved with GRG Nonlinear method. Based on the research that has been done, decentralized with consolidation scenario is more suitable to use in the bittern processing supply chain. Changes in decision to use scenarios are influenced by the level of consumer demand, bittern processing cost, and the cost to build processing facilities or warehouses as the most influential parameter.",model optimasi mixed integer nonlinear programming tentu struktur rantai pasok olah bittern konsolidasi,garam salah komoditas tingkat minta indonesia produksi garam tahap salah satu pisah air garam proses pisah air garam air sisa limbah air air tua bittern bittern cair pekat limbah hasil proses produksi garam bittern buang lingkung cari lingkung sungai laut bittern olah jual milik kandung mineral manfaat olah bittern butuh fasilitas olah olah bittern bahan mentah bittern antara produsen konsumen fungsi fasilitas olah gudang skenario implementasi sentralisasi desentralisasi konsolidasi campur konsolidasi masalah gambar model mixed integer nonlinear programming minlp selesai metode grg nonlinear dasar teliti skenario desentralisasi konsolidasi layak rantai pasok olah bittern ubah putus guna skenario pengaruh tingkat minta konsumen biaya olah bittern biaya bangun fasilitas olah gudang parameter berpengaruhsalt is one of the commodities with a high level of demand in indonesia salt production consists of several stages one of them is the separation of water from salt during the process there is residual water that becomes waste this water is known as old water or bittern bittern is a concentrated liquid come from the salt production process bitterns are thrown into the environment so it can pollute the environment especially rivers and seas however bittern can be processed and resold because it has some mineral that can be used bittern processing requires processing facilities to process bittern in the form of raw materials to be ready to use and as intermediaries between producers and consumers with the function as processing facilities or warehouses the scenarios that can be implemented are centralized decentralized with consolidation and mixed with consolidation problems in the bittern processing supply chain are described through a mixed integer nonlinear programming minlp model and the solution is solved with grg nonlinear method based on the research that has been done decentralized with consolidation scenario is more suitable to use in the bittern processing supply chain changes in decision to use scenarios are influenced by the level of consumer demand bittern processing cost and the cost to build processing facilities or warehouses as the most influential parameter
Semi-Kuantifikasi Electronic Nose Berdasarkan HS-SPME/GC-MS Untuk Klasifikasi Jenis Daging.,"Sabilla, Shoffi Izza",http://repository.its.ac.id/91759/,"Masyarakat membedakan jenis daging secara tradisional dengan cara melihat warna, tekstur, dan mencium aromanya. Namun, untuk membedakan potongan jenis daging menggunakan cara tradisional kurang akurat jika dilakukan oleh manusia karena warna, tekstur, dan aroma memiliki beberapa kesamaan antara jenis daging satu dengan jenis daging yang lainnya sehingga butuh keahlian khusus dan pengalaman. Selain itu, hasil yang didapat berbeda antara satu orang dengan orang yang lainnya.Saat ini, electronic nose (e-nose) telah banyak dikembangkan untuk mengidentifikasi berbagai jenis daging dengan cepat dan akurat dengan biaya produksi yang terjangkau. Namun, hasil dari e-nose tidak dapat digunakan sebagai analisis kuantitatif karena tidak dapat memberikan informasi gas atau volatile organic compound (VOC) dan jumlah kadar dari setiap VOC yang dapat membedakan antara jenis daging. Beberapa penelitian sebelumnya telah mengusulkan semi-kuantifikasi e-nose berdasarkan HS-SPME/GC-MS. Namun, hasil dari semi-kuantifikasi pada penelitian tersebut memiliki nilai eror yang tinggi dan tidak dilakukan klasifikasi kembali dari hasil semi-kuantifikasi.Penelitian ini mengusulkan untuk mengembangkan semi-kuantifikasi e- nose berdasarkan Headspace Solid-Phase Microextraction/Gas Chromatography- Mass Spectrometer (HS-SPME/GC-MS) untuk klasifikasi jenis daging. Metode optimasi hyperparameter klasifikasi berbasis Single-Objective Modified Grey Wolf Optimization Deep Neural Network (SOM-GWO-DNN) dan Multi-Objective M- GWO-DNN (MOM-GWO-DNN) yang diusulkan dapat menemukan hyperparameter klasifikasi yang optimal dan dapat digunakan untuk analisis kualitatif jenis daging pada e-nose dengan akurasi 94,03% dan 95,52%. Metode Ensemble MOM-GWO-DNN strategi one versus one (OVO) berhasil meningkatkan akurasi analisis kualitatif pada e-nose sebesar 97,02%.E-nose yang dikembangkan dapat melakukan semi-kuantifikasi dengan mengestimasi kadar %TIC dari VOC berdasarkan hasil HS-SPME/GC-MS menggunakan metode yang diusulkan yaitu Stacking MOM-GWO-DNNR dengan R2 mendekati sempurna yaitu 0,9845. Hasil estimasi kadar %TIC dari metode Stacking MOM-GWO-DNNR digunakan untuk klasifikasi jenis daging menggunakan metode MOM-GWO-DNN dengan akurasi 100% sehingga masyarakat dapat menggunakan aplikasi semi-kuantifikasi e-nose untuk klasifikasi empat jenis daging dengan efektif, efisien, portabel dan murah.",semikuantifikasi electronic nose dasar hsspmegcms klasifikasi jenis daging,masyarakat beda jenis daging tradisional warna tekstur cium aroma beda potong jenis daging tradisional akurat manusia warna tekstur aroma milik sama jenis daging jenis daging butuh ahli khusus alam hasil beda orang orang lainnyasaat electronic nose enose kembang identifikasi jenis daging cepat akurat biaya produksi jangkau hasil enose analisis kuantitatif informasi gas volatile organic compound voc kadar voc beda jenis daging teliti usul semikuantifikasi enose dasar hsspmegcms hasil semikuantifikasi teliti milik nilai eror klasifikasi hasil semikuantifikasipenelitian usul kembang semikuantifikasi e nose dasar headspace solidphase microextractiongas chromatography mass spectrometer hsspmegcms klasifikasi jenis daging metode optimasi hyperparameter klasifikasi bas singleobjective modified grey wolf optimization deep neural network somgwodnn multiobjective m gwodnn momgwodnn usul temu hyperparameter klasifikasi optimal analisis kualitatif jenis daging enose akurasi 9403 9552 metode ensemble momgwodnn strategi one versus one ovo hasil tingkat akurasi analisis kualitatif enose 9702enose kembang semikuantifikasi estimasi kadar tic voc dasar hasil hsspmegcms metode usul stacking momgwodnnr r2 dekat sempurna 09845 hasil estimasi kadar tic metode stacking momgwodnnr klasifikasi jenis daging metode momgwodnn akurasi 100 masyarakat aplikasi semikuantifikasi enose klasifikasi jenis daging efektif efisien portabel murah
Perencanaan Jalur Quadcopter dan Penghindaran Rintangan Menggunakan Algoritma Fuzzy RRT.,"Sadida, Tiara Asa",http://repository.its.ac.id/110426/,"Sistem kontrol UAV (Unmanned Aerial Vehicle) merupakan topik penelitian yang sering dikembangkan di bidang penerbangan terutama mengenai perencanaan jalur dan penghindaran rintangan di berbagai sektor, sehingga berbagai metode sering diuji untuk memperoleh hasil optimal. Berdasarkan hal tersebut, diperlukan algoritma yang efektif dan efisien untuk eksplorasi ruang pada UAV. Pada tugas akhir ini, dikembangkan dua metode Rapidly exploring Random Tree (RRT) untuk global path planning dan Fuzzy Control Logic untuk local planning refinement. Kedua metode ini dipilih karena keefektifannya dalam optimalisasi jalur pada ruang tiga dimensi dan kemampuan menyesuaikan jalur dengan keadaan sekitar. Pada tugas akhir ini dirancang simulasi dalam MATLAB yang memungkinkan quadcopter merencanakan jalur, menghindari rintangan, dan mencapai tujuan. Dengan mengombinasikan RRT dan Fuzzy Control Logic, proses eksplorasi ruang tiga dimensi dapat ditingkatkan serta menghasilkan jalur yang lebih baik, sehingga lebih efisien dan mudah diikuti oleh quadcopter. Hasil simulasi menunjukkan bahwa kombinasi RRT dan Fuzzy Control Logic mampu memperbaiki perencanaan jalur untuk quadcopter dengan pengurangan panjang jalur total sebesar 9.73% hingga 14.74% setelah fuzzy refinement, pengurangan nilai kesalahan RMSE sebesar 24.44%, MedAE sebesar 20.81%, dan pengurangan curvature serta deviasi jalurnya. ======================================================================================================================================The UAV (Unmanned Aerial Vehicle) control system is a frequently developed research topic in aviation, especially regarding path planning and obstacle avoidance in various sectors. Effective and efficient algorithms are needed for UAV space exploration. In this final project, two methods are developed: Rapidly exploring Random Tree (RRT) for global path planning and Fuzzy Control for local planning refinement. These methods were chosen for their effectiveness in optimizing paths in three dimensional space and adapting to surroundings. Therefore, a MATLAB simulation will be designed, enabling the quadcopter to plan paths, avoid obstacles, and reach destinations. Combining RRT and Fuzzy Control Logic aims to enhance three-dimensional space exploration and produce a better path, making it more efficient and easier for the quadcopter to follow. Simulation results show that the combination of RRT and Fuzzy Control Logic improves path planning for the quadcopter, with a reduction in total path length of 9.73% to 14.74% after fuzzy refinement, a reduction in RMSE error value by 24.44%, MedAE of 20.81%, and a reduction in curvature and path deviation.",rencana jalur quadcopter hindar rintang algoritma fuzzy rrt,sistem kontrol uav unmanned aerial vehicle topik teliti kembang bidang terbang rencana jalur hindar rintang sektor metode uji oleh hasil optimal dasar algoritma efektif efisien eksplorasi ruang uav tugas kembang metode rapidly exploring random tree rrt global path planning fuzzy control logic local planning refinement metode pilih efektif optimalisasi jalur ruang dimensi mampu sesuai jalur tugas rancang simulasi matlab quadcopter rencana jalur hindar rintang capai tuju kombinasi rrt fuzzy control logic proses eksplorasi ruang dimensi tingkat hasil jalur efisien mudah ikut quadcopter hasil simulasi kombinasi rrt fuzzy control logic baik rencana jalur quadcopter kurang jalur total 973 1474 fuzzy refinement kurang nilai salah rmse 2444 medae 2081 kurang curvature deviasi jalur the uav unmanned aerial vehicle control system is a frequently developed research topic in aviation especially regarding path planning and obstacle avoidance in various sectors effective and efficient algorithms are needed for uav space exploration in this final project two methods are developed rapidly exploring random tree rrt for global path planning and fuzzy control for local planning refinement these methods were chosen for their effectiveness in optimizing paths in three dimensional space and adapting to surroundings therefore a matlab simulation will be designed enabling the quadcopter to plan paths avoid obstacles and reach destinations combining rrt and fuzzy control logic aims to enhance threedimensional space exploration and produce a better path making it more efficient and easier for the quadcopter to follow simulation results show that the combination of rrt and fuzzy control logic improves path planning for the quadcopter with a reduction in total path length of 973 to 1474 after fuzzy refinement a reduction in rmse error value by 2444 medae of 2081 and a reduction in curvature and path deviation
Pelabelan dan Pembuatan Model Image Captioning Menggunakan Deep Learning.,"Safitri, Wardatul Amalia",http://repository.its.ac.id/118175/,"Kerja praktik ini dilakukan di Laboratorium Komputasi Cerdas dan Visi (KCV) Departemen Teknik Informatika Institut Teknologi Sepuluh Nopember (ITS). Kegiatan yang dilakukan memiliki tujuan untuk menghasilkan model image captioning dengan memanfaatkan deep learning. Kegiatan kerja praktik dimulai dengan membuat dataset citra trotoar dan lingkungan ITS beserta pelabelan atau pemberian deskripsi di setiap citra. Selanjutnya, dataset citra yang sudah diberi label akan diolah menjadi model image captioning dengan beberapa skenario implementasi deep learning. Metode deep learning yang diimplementasikan dalam kerja praktik ini meliputi LSTM, CNN, dan GRU. Hasil pengembangan model akan dibandingkan performanya menggunakan parameter BLEU Score dan ROUGE. Hasil evaluasi menunjukkan bahwa Dataset 1 menghasilkan performa terbaik dengan BLEU-1 51.49% dan ROUGE-1 40.05%. Metode CNN memberikan hasil terbaik dengan BLEU-1 25.56% dan ROUGE-1 23.44%. Sementara itu, fungsi aktivasi Relu memberikan performa terbaik pada hyperparameter tuning dengan BLEU-1 23.61% dan ROUGE-1 22.37%.============================================================================================================================This project was carried out at the Komputasi Cerdas dan Visi (KCV) Laboratory, Department of Informatics Engineering, Institut Teknologi Sepuluh Nopember (ITS). The activities carried out have the aim of producing an image captioning model by utilizing deep learning. This project begin with creating a dataset of images of ITS pavements and environments along with labeling or giving descriptions in each image. Furthermore, the labeled image dataset will be processed into an image captioning model with several deep learning implementation scenarios. The deep learning methods implemented in this practical work include LSTM, CNN, and GRU. The results of the model development will be compared using the BLEU Score and ROUGE parameters. The evaluation results show that Dataset 1 produces the best performance with BLEU-1 51.49% and ROUGE-1 40.05%. CNN method gives the best result with BLEU-1 25.56% and ROUGE-1 23.44%. Meanwhile, the Relu activation function gives the best performance in hyperparameter tuning with BLEU-1 23.61% and ROUGE-1 22.37%.",label buat model image captioning deep learning,kerja praktik laboratorium komputasi cerdas visi kcv departemen teknik informatika institut teknologi puluh nopember its giat milik tuju hasil model image captioning manfaat deep learning giat kerja praktik dataset citra trotoar lingkung its serta label beri deskripsi citra dataset citra label olah model image captioning skenario implementasi deep learning metode deep learning implementasi kerja praktik liput lstm cnn gru hasil kembang model banding performa parameter bleu score rouge hasil evaluasi dataset 1 hasil performa baik bleu1 5149 rouge1 4005 metode cnn hasil baik bleu1 2556 rouge1 2344 fungsi aktivasi relu performa baik hyperparameter tuning bleu1 2361 rouge1 2237this project was carried out at the komputasi cerdas visi kcv laboratory department of informatics engineering institut teknologi puluh nopember its the activities carried out have the aim of producing an image captioning model by utilizing deep learning this project begin with creating a dataset of images of its pavements and environments along with labeling or giving descriptions in each image furthermore the labeled image dataset will be processed into an image captioning model with several deep learning implementation scenarios the deep learning methods implemented in this practical work include lstm cnn and gru the results of the model development will be compared using the bleu score and rouge parameters the evaluation results show that dataset 1 produces the best performance with bleu1 5149 and rouge1 4005 cnn method gives the best result with bleu1 2556 and rouge1 2344 meanwhile the relu activation function gives the best performance in hyperparameter tuning with bleu1 2361 and rouge1 2237
Penerapan Artificial Neural Network Untuk Prediksi Energi Listrik Jangka Menengah Menggunakan Backpropagation.,"Sakhis, Badri Ainur",http://repository.its.ac.id/119006/,"Peningkatan kebutuhan energi listrik yang terus berkembang menuntut adanya sistem prediksi untuk mendukung perencanaan dan pengelolaan sumber daya energi. Penelitian ini bertujuan untuk menerapkan metode Artificial Neural Network (ANN) dengan algoritma backpropagation dalam memprediksi konsumsi energi listrik jangka menengah. Metode ini dipilih karena kemampuannya dalam menangkap pola kompleks dan hubungan non-linear dalam data historis konsumsi listrik. Oleh karena itu, penting untuk memilih metode yang tepat untuk melakukan prediksi. Untuk menguji tingkat akurasi hasil peramalan konsumsi energi listrik menggunakan perhitungan nilai Mean Absolute Error (MAE). Tujuan penelitian ini adalah menganalisis akurasi hasil peramalan dengan algoritma backpropagation. Arsitektur ANN pada penelitian ini menggunakan 36 input layer, 2 hidden layer dimana masing masing hidden layer sebanyak 10 neuron, dan 1 output layer yang merupakan total energi yang dikonsumsi. Pada penelitian ini, melakukan beberapa pengujian model dan mengatur parameter-parameter ANN setiap pengujian. Parameter tersebut meliputi banyaknya hidden layer yang digunakan, learning rate, dan epoch. Optimizer yang digunakan untuk membangun model yaitu Adaptive Moment Estimation (Adam). Hasil penelitian menyatakan bahwa dari beberapa pengujian model terdapat nilai persentase error terendah dan persentase akurasi atau valid tertinggi. Pengujian terbaik menghasilkan error sebesar 5,6%, dengan tingkat akurasi atau validasi sebesar 94,4%. Percobaan prediksi kedepannya berdasarkan input tanggal yang ditentukan menghasilkan persentase error sebesar 43% dan persentase valid sebesar 57%.=================================================================================================================================The growing demand for electrical energy requires a prediction system to support the planning and management of energy resources. This research aims to apply the Artificial Neural Network (ANN) method with the backpropagation algorithm in predicting medium-term electrical energy consumption. This method was chosen due to its ability to capture complex patterns and non-linear relationships in historical electricity consumption data. Therefore, it is important to choose the right method for prediction. To test the accuracy of electric energy consumption forecasting results using the calculation of the Mean Absolute Error (MAE) value. The purpose of this research is to analyze the accuracy of forecasting results with the backpropagation algorithm. The ANN architecture in this study uses 36 input layers, 2 hidden layers where each hidden layer is 10 neurons, and 1 output layer which is the total energy consumed. In this research, several model tests were conducted and ANN parameters were set for each test. These parameters include the number of hidden layers used, learning rate, and epoch. The optimizer used to build the model is Adaptive Moment Estimation (Adam). The results state that from several model tests there is the lowest percentage error value and the highest percentage of accuracy or validity. The best test produces an error of 5,6%, with an accuracy or validation rate of 94,4%. Future prediction experiments based on the specified date input resulted in an error percentage of 43% and a valid percentage of 57%.",terap artificial neural network prediksi energi listrik jangka tengah backpropagation,tingkat butuh energi listrik kembang tuntut sistem prediksi dukung rencana kelola sumber daya energi teliti tuju terap metode artificial neural network ann algoritma backpropagation prediksi konsumsi energi listrik jangka tengah metode pilih mampu tangkap pola kompleks hubung nonlinear data historis konsumsi listrik pilih metode prediksi uji tingkat akurasi hasil amal konsumsi energi listrik hitung nilai mean absolute error mae tuju teliti analis akurasi hasil amal algoritma backpropagation arsitektur ann teliti 36 input layer 2 hidden layer mana hidden layer 10 neuron 1 output layer total energi konsumsi teliti uji model atur parameterparameter ann uji parameter liput banyak hidden layer learning rate epoch optimizer bangun model adaptive moment estimation adam hasil teliti uji model nilai persentase error rendah persentase akurasi valid tinggi uji baik hasil error 56 tingkat akurasi validasi 944 coba prediksi depan dasar input tanggal tentu hasil persentase error 43 persentase valid 57the growing demand for electrical energy requires a prediction system to support the planning and management of energy resources this research aims to apply the artificial neural network ann method with the backpropagation algorithm in predicting mediumterm electrical energy consumption this method was chosen due to its ability to capture complex patterns and nonlinear relationships in historical electricity consumption data therefore it is important to choose the right method for prediction to test the accuracy of electric energy consumption forecasting results using the calculation of the mean absolute error mae value the purpose of this research is to analyze the accuracy of forecasting results with the backpropagation algorithm the ann architecture in this study uses 36 input layers 2 hidden layers where each hidden layer is 10 neurons and 1 output layer which is the total energy consumed in this research several model tests were conducted and ann parameters were set for each test these parameters include the number of hidden layers used learning rate and epoch the optimizer used to build the model is adaptive moment estimation adam the results state that from several model tests there is the lowest percentage error value and the highest percentage of accuracy or validity the best test produces an error of 56 with an accuracy or validation rate of 944 future prediction experiments based on the specified date input resulted in an error percentage of 43 and a valid percentage of 57
Model Optimasi Gabungan Pada Manajemen Persediaan Suku Cadang Dan Perencanaan Perawatan Dengan Mempertimbangkan Ketidakpastian Kegagalan.,"Salsabila, Nabila Yuraisyah",http://repository.its.ac.id/79796/,"Suku cadang pada umumnya termasuk dalam kelompok barang kelas C, hal ini disebabkan karena biaya dan permintaan yang rendah dibandingkan dengan barang-barang lainnya. Tetapi, ketersediaan suku cadang sangat penting untukmendukung perawatan. Salah satu masalah utama dalam manajemen persediaan suku cadang adalah meminimalkan jumlah barang yang tersimpan dalam gudang dengan mengoptimalkan parameter persediaan. Teknik optimasi pada umumnya digunakan untuk menyeimbangkan biaya persediaan dan ketersediaan suku cadang. Penelitian ini mengusulkan model optimasi gabungan dari manajemen persediaan suku cadang multi-periode multi-item dan perencanaan perawatan dengan mempertimbangkan ketidakpastian kegagalan. Pertama, model Mixed Integer Nonlinear Programing (MINLP) persediaan suku cadang diformulasikan dengan kebijakan (s, S) dengan tinjauan berkala setiap T periode. Kedua, model persediaan suku cadang ini kemudian digabungkan dengan model perencanaan pemeliharaan berkala. Ketidakpastian kegagalan dimodelkan berdasarkan distribusi probabilitas normal. Pendekatan optimasi eksak akan membutuhkan waktu komputasi yang lama untuk menyelesaikan model gabungan ini dalam skala besar. Sehingga, pendekatan metaheuristik dengan Genetic Algorithm (GA) dikembangkan untuk menyelesaikan permasalahan ini dalam skala besar. Ketiga, analisis komputasi dilakukan pada beberapa contoh dan studi kasus untuk mengevaluasi efektivitas dan efisiensi pendekatan GA yang diusulkan. Berdasarkan hasil simulasi, GA dapat menyelesaikan permasalahan berskala besar. Total biaya pada contoh studi kasus dapat menurun hingga 17,9% dibandingkan dengan kebijakan awal.============================================================================================Spare parts are often considered as Class C items, because of their low cost and low demand among the stocked items, but the availability of spare parts is essential to support maintenance requirements. Optimizing inventory parameters is the main problem of spare parts management to maintain a small number of SKUs kept in a store, and optimization techniques are commonly used to balance inventory cost and spare parts availability. Thus, this research proposes a joint optimization model of single-item multi-period spare parts inventory management and planned maintenance under uncertain failures. We present a Mixed Integer Nonlinear Programming (MINLP) formulation of the inventory optimization model under (s, S) policy with T periods of the order interval. Second, we combine this formulation with the predictive maintenance interval, representing the uncertain failures under predefined distribution. Since the model is nonlinear and stochastic, it is difficult to use exact methods to tackle it. Therefore, we combine the previously introduced MINLP formulation with a metaheuristic approach to solve the problem. Lastly, we perform a computational study on some instances and a real case study to demonstrate the proposed approach’s effectiveness and efficiency. Based on the numerical experiment results, the proposed GA performs efficiently in large scale problem and the total cost of the real case study decreased by 17.9% compared to the current policy.",model optimasi gabung manajemen sedia suku cadang rencana awat timbang ketidakpastian gagal,suku cadang kelompok barang kelas c sebab biaya minta rendah banding barangbarang sedia suku cadang untukmendukung awat salah utama manajemen sedia suku cadang minimal barang simpan gudang optimal parameter sedia teknik optimasi imbang biaya sedia sedia suku cadang teliti usul model optimasi gabung manajemen sedia suku cadang multiperiode multiitem rencana awat timbang ketidakpastian gagal model mixed integer nonlinear programing minlp sedia suku cadang formulasi bijak s s tinjau kala t periode model sedia suku cadang gabung model rencana pelihara kala ketidakpastian gagal model dasar distribusi probabilitas normal dekat optimasi eksak butuh komputasi selesai model gabung skala dekat metaheuristik genetic algorithm ga kembang selesai masalah skala tiga analisis komputasi contoh studi evaluasi efektivitas efisiensi dekat ga usul dasar hasil simulasi ga selesai masalah skala total biaya contoh studi turun 179 banding bijak awalspare parts are often considered as class c items because of their low cost and low demand among the stocked items but the availability of spare parts is essential to support maintenance requirements optimizing inventory parameters is the main problem of spare parts management to maintain a small number of skus kept in a store and optimization techniques are commonly used to balance inventory cost and spare parts availability thus this research proposes a joint optimization model of singleitem multiperiod spare parts inventory management and planned maintenance under uncertain failures we present a mixed integer nonlinear programming minlp formulation of the inventory optimization model under s s policy with t periods of the order interval second we combine this formulation with the predictive maintenance interval representing the uncertain failures under predefined distribution since the model is nonlinear and stochastic it is difficult to use exact methods to tackle it therefore we combine the previously introduced minlp formulation with a metaheuristic approach to solve the problem lastly we perform a computational study on some instances and a real case study to demonstrate the proposed approach  s effectiveness and efficiency based on the numerical experiment results the proposed ga performs efficiently in large scale problem and the total cost of the real case study decreased by 179 compared to the current policy
Sistem Deteksi Ekspresi Toileting Pada Anak Penyandang Multidisabilitas Berdasarkan Ekstraksi Fitur Menggunakan Support Vector Machine.,"Siregar, Salsabiela Khairunnisa",http://repository.its.ac.id/113488/,"Anak-anak dengan disabilitas sering menghadapi kesulitan dalam mengekspresikan keinginan mereka, termasuk saat ingin menggunakan fasilitas toilet. Hambatan ini dapat menyebabkan terjadinya masalah kesehatan ataupun masalah lainnya pada anak, seperti perilaku buang air tidak pada tempatnya. Melalui toilet training, anak akan belajar bagaimana mereka mengendalikan keinginan untuk buang air. Keberhasilan toilet training tergantung pada cara pengajaran bertahap sesuai dengan kemampuan anak. Oleh karena itu, penelitian ini bertujuan untuk menemukan parameter toileting berdasarkan ekspresi wajah anak disabilitas dengan menggunakan kamera. Kamera diposisikan di depan subjek selama kegiatan sekolah berlangsung untuk merekam perubahan ekspresi. Hasil citra akuisisi akan dipilih untuk dibuat dataset berdasarkan perubahan ekspresi yang muncul pada saat kondisi toileting. Ekstraksi fitur dilakukan dari 51 titik landmark wajah untuk mendapatkan nilai sudut, jarak, kemiringan antar titik landmark elemen wajah. Dataset TOP5 dan TOP10 dibuat menggunakan fitur-fitur dengan nilai korelasi pearson tertinggi. Proses klasifikasi menggunakan Support Vector Machine (SVM) menunjukkan bahwa model dengan dataset TOP5 mencapai akurasi tertinggi sebesar 96% dengan kombinasi parameter C=25 dan γ=0.001, menggunakan cross validation 5-folds. Model ini menunjukkan kinerja yang baik dengan nilai precision, recall, dan F1-score yang tinggi. Sistem deteksi ekspresi toileting ini memiliki beberapa kendala pada proses pengambilan data yang membutuhkan banyak pengondisian subjek. Selain itu, terdapat beberapa kesalahan klasifikasi yang perlu diatasi untuk mendapatkan hasil yang lebih baik. Untuk meningkatkan kemampuan dan generalisasi sistem dalam mendeteksi ekspresi toileting, diperlukan dilakukan penambahan jumlah dan variasi dataset dengan melibatkan subjek dari berbagai jenis disabilitas.=========================================================================================Children with disabilities often face challenges in expressing their needs, including when they wish to use toilet facilities. These barriers can lead to health issues or other problems, such as inappropriate toileting behaviors. Toilet training helps children learn to control their urges to urinate or defecate, and its success relies on gradual teaching methods tailored to the child`s abilities. Therefore, this study aims to identify toileting parameters based on the facial expressions of children with disabilities using a camera system. The camera is positioned in front of the subjects during school activities to capture expression changes. The acquired images are selected to create a dataset based on the expression changes observed during toileting events. Feature extraction is performed using 51 facial landmark points to obtain angles, distances, and inclinations between these points. TOP5 and TOP10 datasets are generated using features with the highest Pearson correlation values. The classification process using Support Vector Machine (SVM) demonstrated that the model with the TOP5 dataset achieved the highest accuracy of 96%, with parameter settings of C=25 and γ=0.001, utilizing 5-fold cross validation. This model exhibits robust performance with high precision, recall, and F1-score metrics. Despite this, the toileting expression detection system faces challenges in data collection, such as the extensive conditioning required for data collection and some misclassification errors that need to be addressed for improved results. To enhance the system`s capability and generalization in detecting toileting expressions, it is essential to increase the number and diversity of datasets by involving subjects with various types of disabilities.",sistem deteksi ekspresi toileting anak sandang multidisabilitas dasar ekstraksi fitur support vector machine,anakanak disabilitas hadap sulit ekspresi fasilitas toilet hambat sebab sehat anak perilaku buang air tempat toilet training anak ajar kendali buang air hasil toilet training gantung ajar tahap sesuai mampu anak teliti tuju temu parameter toileting dasar ekspresi wajah anak disabilitas kamera kamera posisi subjek giat sekolah rekam ubah ekspresi hasil citra akuisisi pilih dataset dasar ubah ekspresi muncul kondisi toileting ekstraksi fitur 51 titik landmark wajah nilai sudut jarak miring titik landmark elemen wajah dataset top5 top10 fiturfitur nilai korelasi pearson tinggi proses klasifikasi support vector machine svm model dataset top5 capai akurasi tinggi 96 kombinasi parameter c25 0001 cross validation 5folds model kerja nilai precision recall f1score sistem deteksi ekspresi toileting milik kendala proses ambil data butuh kondisi subjek salah klasifikasi atas hasil tingkat mampu generalisasi sistem deteksi ekspresi toileting tambah variasi dataset libat subjek jenis disabilitaschildren with disabilities often face challenges in expressing their needs including when they wish to use toilet facilities these barriers can lead to health issues or other problems such as inappropriate toileting behaviors toilet training helps children learn to control their urges to urinate or defecate and its success relies on gradual teaching methods tailored to the childs abilities therefore this study aims to identify toileting parameters based on the facial expressions of children with disabilities using a camera system the camera is positioned in front of the subjects during school activities to capture expression changes the acquired images are selected to create a dataset based on the expression changes observed during toileting events feature extraction is performed using 51 facial landmark points to obtain angles distances and inclinations between these points top5 and top10 datasets are generated using features with the highest pearson correlation values the classification process using support vector machine svm demonstrated that the model with the top5 dataset achieved the highest accuracy of 96 with parameter settings of c25 and 0001 utilizing 5fold cross validation this model exhibits robust performance with high precision recall and f1score metrics despite this the toileting expression detection system faces challenges in data collection such as the extensive conditioning required for data collection and some misclassification errors that need to be addressed for improved results to enhance the systems capability and generalization in detecting toileting expressions it is essential to increase the number and diversity of datasets by involving subjects with various types of disabilities
Deteksi Kecacatan Perangkat Lunak Menggunakan Support Vector Machine Teroptimasi Berbasis Grey Wolf Optimizer dan Random Walk.,"Siswantoro, Muhammad Zain Fawwaz Nuruddin",http://repository.its.ac.id/118354/,"Deteksi kecacatan perangkat lunak merupakan proses penting dalam pengembangan perangkat lunak untuk mengidentifikasi sebagai bug sehingga aplikasi dapat berfungsi tanpa kesalahan. Namun, proses ini sering memakan biaya dan waktu. Penelitian ini mengusulkan penggunaan Support Vector Machine (SVM) yang hyperparameter-nya dioptimasi menggunakan Grey Wolf Optimizer (GWO) yang dipadukan dengan Random Walk (RW). Selain itu penelitian ini juga menggunakan Principal Component Analysis (PCA) sebagai pengurangan dimensi fitur dan juga oversampling dengan Synthetic Minority Over-sampling Technique (SMOTE) untuk menyeimbangkan dataset. Hasil dari penelitian ini menunjukan bahwa GWO yang dipadukan dengan RW mampu meningkatkan akurasi SVM dalam mengklasifikasi deteksi kecacatan perangkat lunak dibandingkan dengan optimasi lain, dengan akurasi berkisar antara 76,26% - 98,21% dan rata-rata akurasi 87,03% pada berbagai dataset, sehingga membuktikan efektivitasnya dalam deteksi kecacatan perangkat lunak.=================================================================================================================================Software defect detection is an important process in software development to identify as a bug so that the application can function without errors. However, this process is often costly and time consuming. This study proposes the use of Support Vector Machine (SVM) whose hyperparameters are optimized using Grey Wolf Optimizer (GWO) combined with Random Walk (RW). In addition, this study also uses Principal Component Analysis (PCA) as a feature dimension reduction and also oversampling with Synthetic Minority Over-sampling Technique (SMOTE) to balance the dataset. The results of this study show that GWO combined with RW is able to increase the accuracy of SVM in classifying software defect detection compared to other optimizations, with an accuracy ranging from 76.26% - 98.21% and an average accuracy of 87.03% on various datasets, thus proving its effectiveness in software defect detection.",deteksi cacat perangkat lunak support vector machine teroptimasi bas grey wolf optimizer random walk,deteksi cacat perangkat lunak proses kembang perangkat lunak identifikasi bug aplikasi fungsi salah proses makan biaya teliti usul guna support vector machine svm hyperparameternya dioptimasi grey wolf optimizer gwo padu random walk rw teliti principal component analysis pca kurang dimensi fitur oversampling synthetic minority oversampling technique smote imbang dataset hasil teliti tunjuk gwo padu rw tingkat akurasi svm klasifikasi deteksi cacat perangkat lunak banding optimasi akurasi kisar 7626 9821 ratarata akurasi 8703 dataset bukti efektivitas deteksi cacat perangkat lunaksoftware defect detection is an important process in software development to identify as a bug so that the application can function without errors however this process is often costly and time consuming this study proposes the use of support vector machine svm whose hyperparameters are optimized using grey wolf optimizer gwo combined with random walk rw in addition this study also uses principal component analysis pca as a feature dimension reduction and also oversampling with synthetic minority oversampling technique smote to balance the dataset the results of this study show that gwo combined with rw is able to increase the accuracy of svm in classifying software defect detection compared to other optimizations with an accuracy ranging from 7626 9821 and an average accuracy of 8703 on various datasets thus proving its effectiveness in software defect detection
SEGMENTASI DAN EKSTRAKSI CIRI CITRA SEL DARAH PUTIH UNTUK KLASIFIKASI LEUKEMIA AKUT.,"Siti Fatonah, Nenden",http://repository.its.ac.id/77972/,"Penyakit leukemia adalah penyakit yang sangat berbahaya dan mematikan. Penyakit leukemia disebabkan oleh gagalnya kematangan sel-sel yang dihasilkan oleh sumsum tulang dan menyebar keseluruh tubuh. Perhitungan dan analisa sel darah putih saat ini hanya bisa dilakukan oleh ahli hematologi atau dokter di laboratorium dan hasil diagnosa bersifat subyektif berdasarkan pengalaman dokter. Perhitungan dan analisa sel darah putih secara otomatis sangat diperlukan agar lebih mudah dalam membantu dokter melakukan diagnosa penyakit misalnya leukemia. Leukemia akut merupakan penyakit leukemia yang paling banyak diderita pasien. Pengembangan sistem deteksi jenis leukemia akut secara otomatis berdasarkan citra mikroskopis dibagi menjadi tiga tahapan yaitu segmentasi sel darah putih, ekstraksi ciri sel darah putih, dan klasifikasi. Kendala pertama pada segmentasi sel darah putih adalah variasi staining (pewarnaan) pada citra mikroskopis sel darah sehingga perlu metode segmentasi yang bisa menangani permasalahan tersebut. Kendala kedua adalah segmentasi multi sel darah putih yaitu adanya sel-sel yang bersentuhan sehingga perlu dikembangkan metode pemisahan sel yang lebih baik agar perhitungan jumlah sel serta hasil ekstraksi ciri lebih akurat untuk proses klasifikasi. Metode pemisahan sel-sel bersentuhan yang sudah dilakukan penelitian-penelitian sebelumnya masih terkendala adanya oversegmen, undersegmen, dan estimasi kontur sel darah putih yang kurang akurat.Penelitian ini mengusulkan perbaikan metode segmentasi sel darah putih dan melakukan ekstraksi ciri pada citra mikroskopik sel darah untuk klasifikasi jenis leukemia akut. Untuk mendapatkan hasil klasifikasi yang akurat, metode segmentasi sel darah putih yang dikembangkan harus mendapatkan area sel darah putih dengan baik khususnya sel-sel yang bersentuhan sehingga pada tahapan ekstraksi ciri dapat menghasilkan ciri yang merepresentasikan karakteristik sel darah putih dengan baik. Tahapan segmentasi sel darah putih meliputi segmentasi area sel darah putih yaitu area nukleus dan sitoplasma, deteksi sel bersentuhan dan perhitungan jumlah sel, serta estimasi kontur hasil pemisahan sel yang bersentuhan. Sedangkan tahapan ekstraksi ciri adalah ekstraksi ciri warna, bentuk, dan tekstur pada area nukleus dan sitoplasma sel darah putih. Tahapan terakhir melakukan klasifikasi untuk mendapatkan jenis leukemia akut Acute Lymphocytic Leukemia (ALL) yang mempunyai tiga tipe yaitu L1, L2, dan L3. Dataset yang digunakan adalah data pada citra mikroskopis apusan darah tepi ALL yang disediakan oleh Labati, dkk dan dikumpulkan oleh pakar di Pusat Penelitian Tettamanti, Tettamanti Research. Serta menggunakan data citra bone marrow jenis Acute Lymphocytic Leukemia (ALL) dan Acute Myelotic Leukemia (AML) dari RSUD Dr. Soetomo Surabaya. Dari hasil ujicoba yang sudah dilakukan menunjukkan metode segmentasi sel darah putih yang diusulkan meliputi deteksi sel bersentuhan dan estimasi kontur single sel lebih baik dibandingkan metode sebelumnya. Metode segmentasi sel darah putih yang diusulkan kemudian digunakan untuk klasifikasi jenis ALL menghasilkan sensitivitas yang lebih tinggi dibandingkan metode lainnya.",segmentasi ekstraksi ciri citra sel darah putih klasifikasi leukemia akut,sakit leukemia sakit bahaya mati sakit leukemia sebab gagal matang selsel hasil sumsum tulang sebar seluruh tubuh hitung analisa sel darah putih ahli hematologi dokter laboratorium hasil diagnosa sifat subyektif dasar alam dokter hitung analisa sel darah putih otomatis mudah bantu dokter diagnosa sakit leukemia leukemia akut sakit leukemia derita pasien kembang sistem deteksi jenis leukemia akut otomatis dasar citra mikroskopis bagi tahap segmentasi sel darah putih ekstraksi ciri sel darah putih klasifikasi kendala segmentasi sel darah putih variasi staining warna citra mikroskopis sel darah metode segmentasi tangan masalah kendala segmentasi multi sel darah putih selsel sentuh kembang metode pisah sel hitung sel hasil ekstraksi ciri akurat proses klasifikasi metode pisah selsel sentuh penelitianpenelitian kendala oversegmen undersegmen estimasi kontur sel darah putih akuratpenelitian usul baik metode segmentasi sel darah putih ekstraksi ciri citra mikroskopik sel darah klasifikasi jenis leukemia akut hasil klasifikasi akurat metode segmentasi sel darah putih kembang area sel darah putih selsel sentuh tahap ekstraksi ciri hasil ciri representasi karakteristik sel darah putih tahap segmentasi sel darah putih liput segmentasi area sel darah putih area nukleus sitoplasma deteksi sel sentuh hitung sel estimasi kontur hasil pisah sel sentuh tahap ekstraksi ciri ekstraksi ciri warna bentuk tekstur area nukleus sitoplasma sel darah putih tahap klasifikasi jenis leukemia akut acute lymphocytic leukemia all tipe l1 l2 l3 dataset data citra mikroskopis apusan darah tepi all sedia labati dkk kumpul pakar pusat teliti tettamanti tettamanti research data citra bone marrow jenis acute lymphocytic leukemia all acute myelotic leukemia aml rsud dr soetomo surabaya hasil ujicoba metode segmentasi sel darah putih usul liput deteksi sel sentuh estimasi kontur single sel banding metode metode segmentasi sel darah putih usul klasifikasi jenis all hasil sensitivitas banding metode
Prediksi Drop Pressure Dan Over Pressure Pada Jaringan Pipa Distribusi Gas Bumi Menggunakan Machine Learning.,"Supriatna, Reza Yudistira",http://repository.its.ac.id/117602/,"Menjaga stabilitas distribusi gas bumi sangat penting untuk memastikan pasokan energi yang dapat diandalkan dan mendukung tujuan energi yang berkelanjutan. Pemantauan dan simulasi secara real time sangat penting untuk mengelola gangguan pasokan sehingga menyebabkan fluktuasi tekanan yang dapat membahayakan jika tidak segera ditangani, serta dapat menyebabkan penurunan produksi sehingga berdampak kepada revenue perusahaan dan risiko keselamatan pada peralatan. Kondisi tekanan over pressure dapat mendorong sistem untuk melampaui batas operasional yang aman, sehingga mengancam infrastruktur dan personel yang berada di sekitar peralatan. Menstabilkan jaringan distribusi tidak hanya mengatasi masalah keselamatan tetapi juga meningkatkan efisiensi energi, mengurangi limbah, dan mendukung upaya keberlanjutan. Studi ini mengevaluasi empat model prediktif ARIMAX, SARIMAX, random forest regression, dan linear regression untuk mengurangi risiko dan meningkatkan pengambilan keputusan operasional dalam distribusi gas alam. Model-model tersebut dinilai dengan menggunakan metrik kinerja utama, termasuk Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), dan Mean Absolute Percentage Error (MAPE), untuk mengidentifikasi metode yang paling akurat dan dapat diandalkan untuk prediksi waktu nyata. Mengingat risiko operasional dan keuangan yang terkait dengan ketidakseimbangan pasokan, memilih model prediksi yang tepat sangat penting untuk menjaga stabilitas jaringan dan meminimalkan potensi kerugian. Temuan ini menunjukkan bahwa random forest regression memberikan akurasi tertinggi dalam pengujian di dunia nyata dimana memiliki nilai MAPE 2.264, menjadikannya model yang paling cocok untuk memprediksi fluktuasi tekanan yang kompleks. Sebaliknya, linear regression kurang efektif karena variabilitasnya yang lebih tinggi ketika menangani kompleksitas manajemen tekanan memiliki nilai MAPE sebesar 31.714. Pada akhirnya, memilih model prediktif yang tepat adalah kunci untuk memastikan stabilitas jaringan, mengurangi risiko, dan mempromosikan praktik energi yang berkelanjutan.",prediksi drop pressure over pressure jaring pipa distribusi gas bumi machine learning,jaga stabilitas distribusi gas bumi pasok energi andal dukung tuju energi lanjut pantau simulasi real time kelola ganggu pasok sebab fluktuasi tekan bahaya tangan sebab turun produksi dampak revenue usaha risiko selamat alat kondisi tekan over pressure dorong sistem lampau batas operasional aman ancam infrastruktur personel alat stabil jaring distribusi atas selamat tingkat efisiensi energi kurang limbah dukung upaya lanjut studi evaluasi model prediktif arimax sarimax random forest regression linear regression kurang risiko tingkat ambil putus operasional distribusi gas alam modelmodel nilai metrik kerja utama mean squared error mse root mean squared error rmse mean absolute error mae mean absolute percentage error mape identifikasi metode akurat andal prediksi nyata risiko operasional uang kait ketidakseimbangan pasok pilih model prediksi jaga stabilitas jaring minimal potensi rugi temu random forest regression akurasi tinggi uji dunia nyata mana milik nilai mape 2264 jadi model cocok prediksi fluktuasi tekan kompleks linear regression efektif variabilitas tangan kompleksitas manajemen tekan milik nilai mape 31714 pilih model prediktif kunci stabilitas jaring kurang risiko promosi praktik energi lanjut
Entity Matching Menggunakan Large Language Model dan Knowledge Graph untuk Mencari Redundansi Fitur dalam Software Specification.,"Syaifudin, Mohamad Fahmi",http://repository.its.ac.id/117535/,"Dalam Software Development Lifecycle (SDLC), berbagai dokumentasi software pendukung dihasilkan, salah satunya adalah dokumen software specification, yang berisi deskripsi fitur yang dibangun. Permasalahan umum dalam pengembangan software adalah munculnya requirement baru yang mirip dengan fungsionalitas modul yang sudah ada. Masalah ini dapat diatasi dengan memanfaatkan entity matching (EM) untuk mendeteksi redundansi antar fitur dalam software atau modul yang berbeda. EM bertujuan untuk menentukan apakah dua entitas yang berbeda mengacu pada entitas yang sama. Pendekatan EM tradisional umumnya menggunakan rule-based, deep learning, atau machine learning. Penelitian ini mengusulkan pendekatan entity matching menggunakan Large Language Model (LLM) dan Knowledge Graph (KG). Dataset yang digunakan dalam penelitian ini antara lain dari dokumen panduan user Odoo, dokumen panduan Zoho Commerce, dan dokumen public user requirement. Entitas dan relasi diekstrak dan dirubah kedalam dimensi vector melalui proses knowledge embedding. Neo4j digunakan untuk menyimpan KG dan memanfaatkan vektor index mencari entitas atau relasi yang relevan untuk EM. Penelitian ini menggunakan metode sentence-based dan graph-based dalam EM. Sentence-based matching memiliki F1-score 0.762, lebih tinggi dibandingkan metode graph-based dengan F1-score maksimum 0.471. Namun, graph-based matching unggul pada Mean Reciprocal Rank dengan nilai 0.660 dibandingkan sentence-based yang hanya 0.477. Keunggulan lain dari graph-based adalah ketidakbergantungannya pada jenis word embedding, yang ditunjukkan oleh konsistensi F1-score dalam rentang 0.4 sampai 0.5 untuk berbagai variasi model embedding.==============================================================================================================================In the Software Development Lifecycle (SDLC), various supporting software documentation is produced, one of which is the software specification document that contains a description of the features being developed. A common issue in software development is the emergence of new requirements that are similar to the functionalities of existing modules. This can be addressed by leveraging entity matching (EM) to identify redundancies between features in different software or modules. EM aims to determine whether two different entities refer to the same entity. Traditional EM approaches generally use rule-based, deep learning, or machine learning methods. This study proposes an entity matching approach using a Large Language Model (LLM) and a Knowledge Graph (KG). The datasets used in this research include user guide documents from Odoo, Zoho Commerce user guide documents, and public user requirement documents. Entities and relationships are extracted and transformed into vector dimensions through a knowledge embedding process. Neo4j is used to store the KG and to utilize vector indexing for finding relevant entities or relationships for EM. This research employs both sentence-based and graph-based methods in EM. Sentence-based matching achieved an F1-score of 0.762, which is higher than the graph-based method with a maximum F1-score of 0.471. However, graph-based matching outperformed in Mean Reciprocal Rank (MRR) with a score of 0.660 compared to 0.477 for the sentence-based approach. Another advantage of the graph-based method is its independence from the type of word embedding, as indicated by the consistent F1-score range of 0.4 to 0.5 across various embedding model variations.",entity matching large language model knowledge graph cari redundansi fitur software specification,software development lifecycle sdlc dokumentasi software dukung hasil salah satu dokumen software specification isi deskripsi fitur bangun masalah kembang software muncul requirement fungsionalitas modul atas manfaat entity matching em deteksi redundansi fitur software modul beda em tuju tentu entitas beda acu entitas dekat em tradisional rulebased deep learning machine learning teliti usul dekat entity matching large language model llm knowledge graph kg dataset teliti dokumen pandu user odoo dokumen pandu zoho commerce dokumen public user requirement entitas relasi ekstrak rubah dalam dimensi vector proses knowledge embedding neo4j simpan kg manfaat vektor index cari entitas relasi relevan em teliti metode sentencebased graphbased em sentencebased matching milik f1score 0762 banding metode graphbased f1score maksimum 0471 graphbased matching unggul mean reciprocal rank nilai 0660 banding sentencebased 0477 unggul graphbased ketidakbergantungannya jenis word embedding konsistensi f1score rentang 04 05 variasi model embeddingin the software development lifecycle sdlc various supporting software documentation is produced one of which is the software specification document that contains a description of the features being developed a common issue in software development is the emergence of new requirements that are similar to the functionalities of existing modules this can be addressed by leveraging entity matching em to identify redundancies between features in different software or modules em aims to determine whether two different entities refer to the same entity traditional em approaches generally use rulebased deep learning or machine learning methods this study proposes an entity matching approach using a large language model llm and a knowledge graph kg the datasets used in this research include user guide documents from odoo zoho commerce user guide documents and public user requirement documents entities and relationships are extracted and transformed into vector dimensions through a knowledge embedding process neo4j is used to store the kg and to utilize vector indexing for finding relevant entities or relationships for em this research employs both sentencebased and graphbased methods in em sentencebased matching achieved an f1score of 0762 which is higher than the graphbased method with a maximum f1score of 0471 however graphbased matching outperformed in mean reciprocal rank mrr with a score of 0660 compared to 0477 for the sentencebased approach another advantage of the graphbased method is its independence from the type of word embedding as indicated by the consistent f1score range of 04 to 05 across various embedding model variations
Prediksi Tipe Kepribadian Berdasaran Myers-Briggs Type Indicator Menggunakan Metode Klasifikasi Kolmogorov-Arnold Networks.,"Syamsudin, Afifah Nur Sabrina",http://repository.its.ac.id/117237/,"Pembahasan mengenai prediksi tipe kepribadian di media sosial telah meningkat pesat dalam beberapa tahun terakhir. Salah satu tes kepribadian yang ramai diperbincangkan adalah Myers-Briggs Type Indicator (MBTI). MBTI merupakan sebuah metode penilaian kepribadian yang mengklasifikasikan individu ke dalam salah satu dari 16 tipe kepribadian berdasarkan empat dimensi utama: Ekstroversi-Introversi, Sensing-Intuition, Thinking-Feeling, dan Judging-Perceiving. Terdapat banyak cara dalam memprediksi kepribadian seseorang salah satunya melalui analisis tipe kepribadian berdasarkan tulisan di media sosial, metode yang umum digunakan melibatkan beberapa tahapan analisis teks dan pemrosesan bahasa. Pada penelitian ini akan dipelajari proses dan kinerja dari model klasifikasi KAN. Metode klasifikasi baru ini diharapkan dapat digunakan sebagai cara untuk mengkategorikan teks ke dalam tipe kepribadian yang sesuai. Hasil dari penelitian ini nantinya diharapkan dapat mengetahui penggunaan kata pada unggahan media sosial terhadap tipe kepribadian seseorang serta kinerja model klasifikasi dalam mengenali tipe kepribadian berdasarkan aktivitas media sosial. Hasil dari uji coba pada implementasi metode KAN mendapatkan akurasi data uji senilai 0,2545.===================================================================================================================================Discussions about personality type prediction on social media have increased rapidly in recent years. One of the most discussed personality tests is the Myers-Briggs Type Indicator (MBTI). MBTI is a personality assessment method that classifies individuals into one of 16 personality types based on four main dimensions: Extroversion-Introversion, Sensing-Intuition, Thinking-Feeling, and Judging-Perceiving. There are many ways to predict a person's personality, one of which is through analyzing personality types based on social media posts, a commonly used method involving several stages of text analysis and language processing. In this research, the process and performance of the KAN classification model will be explained. This new classification method is expected to be used to categorize text into the appropriate personality type. The results of this research are expected to determine the use of words in social media posts on a person's personality type and the performance of the classification model in recognizing personality types based on social media activities. The results of the trial on the KAN method show that the implementation gets a test data metric accuracy of 0.2545.",prediksi tipe pribadi dasar myersbriggs type indicator metode klasifikasi kolmogorovarnold networks,bahas prediksi tipe pribadi media sosial tingkat pesat salah tes pribadi ramai bincang myersbriggs type indicator mbti mbti metode nilai pribadi klasifikasi individu salah 16 tipe pribadi dasar dimensi utama ekstroversiintroversi sensingintuition thinkingfeeling judgingperceiving prediksi pribadi salah satu analisis tipe pribadi dasar tulis media sosial metode libat tahap analisis teks pemrosesan bahasa teliti ajar proses kerja model klasifikasi metode klasifikasi harap kategori teks tipe pribadi sesuai hasil teliti harap guna unggah media sosial tipe pribadi kerja model klasifikasi nali tipe pribadi dasar aktivitas media sosial hasil uji coba implementasi metode akurasi data uji nila 02545discussions about personality type prediction on social media have increased rapidly in recent years one of the most discussed personality tests is the myersbriggs type indicator mbti mbti is a personality assessment method that classifies individuals into one of 16 personality types based on four main dimensions extroversionintroversion sensingintuition thinkingfeeling and judgingperceiving there are many ways to predict a persons personality one of which is through analyzing personality types based on social media posts a commonly used method involving several stages of text analysis and language processing in this research the process and performance of the classification model will be explained this new classification method is expected to be used to categorize text into the appropriate personality type the results of this research are expected to determine the use of words in social media posts on a persons personality type and the performance of the classification model in recognizing personality types based on social media activities the results of the trial on the method show that the implementation gets a test data metric accuracy of 02545
Perancangan Penyelesaian Kinematika Balik Pada Posisi Dan Orientasi End Effector Robot Open Manipulator-X Dengan Metode Neural Network.,"Syauqi, Muhammad Yavi Marsa",http://repository.its.ac.id/98932/,"Robot manipulator merupakan bukti dari perkembangan teknologi otomasi di era 4.0 saat ini, Robot yang memiliki 4 degree of freedom (DoF) dalam pergerakannya merupakan salah satu sistem yang biasa digunakan untuk mengefisiensi dan mengurangi resiko kecelakaan pada dunia Industri. Namun, pada penyelesaian kinematika balik robot manipulator terdapat permasalahan dimana terdapat multi solution dalam mendapatkan nilai sudut keluaran pada setiap joint. Oleh sebab itu, Penelitian ini bertujuan untuk menyelesaikan permasalahan kinematika balik tersebut menggunakan metode neural network menggunakan Robot Open Manipulator-X. Penelitian ini dilakukan dengan pengambilan dataset dengan kinematika maju, perancangan model neural network dengan melakukan pengujian pada jumlah neuron, hidden layer, dan learning rate, serta pembuktian dengan pengujian titik dari hasil neural network pada robot melalui simulasi pada gazebo dan real plant. Hasil dari peneletian ini yaitu metode neural network dapat menemukan single solution sebagai penyelesaian kinematika balik untuk Robot Open Manipulator-X dengan rata-rata error posisi dan orientasi sebesar (0.36 ± 0.06) cm dan (3.224±2.942)° pada simulasi, serta (0.37 ± 0.06) cm dan (3.224±2.942)° pada real plant.====================================================================================================================================Manipulator robot is evidence of the technological advancement in automation in the current era of Industry 4.0. A robot with 4 degrees of freedom (DoF) in its movement is commonly used to improve efficiency and reduce the risk of accidents in the industrial world. However, there is a problem in solving the inverse kinematics of robot manipulators where multiple solutions exist in obtaining the angle values for each joint. Therefore, this research aims to solve the inverse kinematics problem using a neural network method with the Robot Open Manipulator-X. The research involves collecting a dataset with forward kinematics, designing a neural network model by testing various configurations such as the number of neurons, hidden layers, and learning rate, and validating the results through point testing of the neural network's output on the robot using simulations in Gazebo and real plant environments. The result of this research is that the neural network method can find a single solution as the inverse kinematics solution for the Robot Open Manipulator-X with an average position error of (0.36 ± 0.06) cm and orientation error of (3.224±2.942)° in simulation, as well as (0.37 ± 0.06) cm and (3.224±2.942)° in the real plant.",ancang selesai kinematika posisi orientasi end effector robot open manipulatorx metode neural network,robot manipulator bukti kembang teknologi otomasi era 40 robot milik 4 degree of freedom dof gera salah sistem efisiensi kurang resiko celaka dunia industri selesai kinematika robot manipulator masalah mana multi solution nilai sudut keluar joint teliti tuju selesai masalah kinematika metode neural network robot open manipulatorx teliti ambil dataset kinematika maju ancang model neural network uji neuron hidden layer learning rate bukti uji titik hasil neural network robot simulasi gazebo real plant hasil peneletian metode neural network temu single solution selesai kinematika robot open manipulatorx ratarata error posisi orientasi 036  006 cm 3224 2942 simulasi 037  006 cm 3224 2942 real plantmanipulator robot is evidence of the technological advancement in automation in the current era of industry 40 a robot with 4 degrees of freedom dof in its movement is commonly used to improve efficiency and reduce the risk of accidents in the industrial world however there is a problem in solving the inverse kinematics of robot manipulators where multiple solutions exist in obtaining the angle values for each joint therefore this research aims to solve the inverse kinematics problem using a neural network method with the robot open manipulatorx the research involves collecting a dataset with forward kinematics designing a neural network model by testing various configurations such as the number of neurons hidden layers and learning rate and validating the results through point testing of the neural networks output on the robot using simulations in gazebo and real plant environments the result of this research is that the neural network method can find a single solution as the inverse kinematics solution for the robot open manipulatorx with an average position error of 036  006 cm and orientation error of 3224 2942 in simulation as well as 037  006 cm and 3224 2942 in the real plant
Identifikasi Normality Shift dalam Deteksi Anomali dengan Pendekatan Uji Distribusi.,"Talasari, Resky Ayu Dewi",http://repository.its.ac.id/116720/,"Seiring dengan pesatnya perkembangan teknologi jaringan dan internet, serta meningkatnya ancaman yang beragam dan sulit dideteksi, deteksi anomali menjadi sangat penting, event logs dapat digunakan untuk mencatat setiap aktivitas yang terjadi dan digunakan untuk mendeteksi anomali. Salah satu pendekatan untuk mendeteksi anomali pada event logs adalah berbasis rekonstruksi menggunakan deep learning dengan mempelajari pola normal data, namun tantangannya terletak pada normality shift, yaitu perubahan pola normal data yang dipelajari model. Penelitian ini berfokus pada deteksi normality shift dalam data Windows Event Logs dan Sysmon, menggunakan uji distribusi Jensen Shannon Divergence (JSD) dan Hellinger Distance (HD), hasil penelitian menunjukkan bahwa HD mampu mendeteksi distribution shift dengan baik pada skenario distribution shift kecil dan besar. Proses filtering data dapat mempengaruhi kinerja model deteksi anomali pada skenario distribution shift kecil dengan peningkatan 66% pada precision, 63% pada recall, 40% pada f1-Score dan AUC Score. Namun, model deteksi anomali tidak mampu menghadapi skenario distribution shift besar dengan penurunan performa pada precision, recall, f1-score, dan AUC score. Karena proses filtering data yaitu proses mengidentifikasi data treatment yang berada dalam rentang batas atas dan bawah data control sebagai normal sehingga membuat model deteksi anomali bergantung pada pola normalitas awal pada data control (data training).=================================================================================================================================Along with the rapid development of network and internet technology, as well as the increase in diverse and difficult-to-detect threats, anomaly detection is very important, event logs can be used to record every activity that occurs and used to detect anomalies. One approach to detect anomalies in event logs is reconstruction-based using deep learning by learning the normal pattern of the data, but the challenge lies in normality shift, which is the change in the normal pattern of the data that the model learns. This research focuses on normality shift detection in Windows Event Logs and Sysmon data, using Jensen Shannon Divergence (JSD) and Hellinger Distance (HD) distribution tests, the results show that HD is able to detect distribution shifts well in small and large distribution shift scenarios. The data filtering process can affect the performance of the anomaly detection model in the small distribution shift scenario with an increase of 66% in precision, 63% in recall, 40% in f1-Score and AUC Score.However, the anomaly detection model is not able to deal with large distribution shift scenarios with decreased performance in precision, recall, f1-score, and AUC score. Due to the data filtering process, which is the process of identifying treatment data that is within the upper and lower limits of the control data as normal, the anomaly detection model depends on the initial normality pattern in the control data (training data).",identifikasi normality shift deteksi anomali dekat uji distribusi,iring pesat kembang teknologi jaring internet tingkat ancam agam sulit deteksi deteksi anomali event logs catat aktivitas deteksi anomali salah dekat deteksi anomali event logs bas rekonstruksi deep learning ajar pola normal data tantang letak normality shift ubah pola normal data ajar model teliti fokus deteksi normality shift data windows event logs sysmon uji distribusi jensen shannon divergence jsd hellinger distance hd hasil teliti hd deteksi distribution shift skenario distribution shift proses filtering data pengaruh kerja model deteksi anomali skenario distribution shift tingkat 66 precision 63 recall 40 f1score auc score model deteksi anomali hadap skenario distribution shift turun performa precision recall f1score auc score proses filtering data proses identifikasi data treatment rentang batas data control normal model deteksi anomali gantung pola normalitas data control data trainingalong with the rapid development of network and internet technology as well as the increase in diverse and difficulttodetect threats anomaly detection is very important event logs can be used to record every activity that occurs and used to detect anomalies one approach to detect anomalies in event logs is reconstructionbased using deep learning by learning the normal pattern of the data but the challenge lies in normality shift which is the change in the normal pattern of the data that the model learns this research focuses on normality shift detection in windows event logs and sysmon data using jensen shannon divergence jsd and hellinger distance hd distribution tests the results show that hd is able to detect distribution shifts well in small and large distribution shift scenarios the data filtering process can affect the performance of the anomaly detection model in the small distribution shift scenario with an increase of 66 in precision 63 in recall 40 in f1score and auc scorehowever the anomaly detection model is not able to deal with large distribution shift scenarios with decreased performance in precision recall f1score and auc score due to the data filtering process which is the process of identifying treatment data that is within the upper and lower limits of the control data as normal the anomaly detection model depends on the initial normality pattern in the control data training data
Klasifikasi Citra Hasil Endoskopi Pada Sistem Gastrointestinal Bagian Bawah Menggunakan Metode Transfer Learning dengan Convolutional Neural Network.,"Tambunan, Rivaldo Panangian",http://repository.its.ac.id/117621/,"Sistem gastrointestinal sering menjadi perhatian utama dalam penelitian medis karena berbagai gangguan, seperti polip dan kolitis ulseratif, yang jika tidak segera ditangani dapat berkembang menjadi kondisi yang serius. Endoskopi merupakan metode utama yang digunakan untuk mendeteksi penyakit ini, meskipun prosesnya sering memakan waktu dan membutuhkan tenaga ahli yang signifikan. Penelitian ini bertujuan untuk klasifikasi citra hasil endoskopi dengan memanfaatkan metode Transfer Learning berbasis Convolutional Neural Network (CNN). Dataset HyperKvasir dan GastroVision digunakan sebagai dataset citra, terdapat tiga kelas : polip, kolitis ulseratif, dan mukosa normal. Model pre-trained seperti VGG19, ResNet101V2, dan InceptionV3 akan digunakan sebagai ekstraksi fitur dan menambahkan fully connected layer untuk melakukan klasifikasi kelas polip, kolitis ulseratif, dan mukosa normal. Dalam penggunaan model pre-trained tersebut akan menggunakan teknik finetuning pada layer awal setiap model pre-trained. Hasil eksperimen menunjukkan bahwa model pre-trained ResNet101V2 memberikan hasil terbaik dengan tingkat akurasi, recall, dan F1-score yang tinggi. Dengan Hasil akurasi sebesar 0.9881, loss 0.0687, Recall 0.9881, Presicion 0.9882, dan F1-Score 0.9881. Penelitian ini diharapkan dapat berkontribusi dalam mendukung deteksi dini penyakit gastrointestinal secara lebih cepat dan efisien, sekaligus mempermudah proses diagnosis di bidang medis.==============================================================================================================================The gastrointestinal system is a major focus in medical research due to various disorders, such as polyps and ulcerative colitis, which, if left untreated, can develop into severe conditions. Endoscopy is the primary method used to detect these diseases, although the process often requires significant time and specialized expertise. This study aims to classify endoscopic images using a Transfer Learning approach based on Convolutional Neural Networks (CNN). The HyperKvasir and GastroVision datasets were utilized, consisting of three main classes: polyps, ulcerative colitis, and normal mucosa. Pre-trained models such as VGG19, ResNet101V2, and InceptionV3 were employed for feature extraction, with the addition of fully connected layers for classifying the three aforementioned categories. Fine-tuning techniques were applied to the initial layers of each pre-trained model to optimize performance. Experimental results demonstrated that the ResNet101V2 pre-trained model achieved the best performance, with high accuracy, recall, and F1-score. The final results include an accuracy of 0.9881, loss of 0.0687, recall of 0.9881, precision of 0.9882, and F1-score of 0.9881.This research is expected to contribute to the early detection of gastrointestinal diseases more efficiently and effectively, thereby facilitating the diagnostic process in the medical field.",klasifikasi citra hasil endoskopi sistem gastrointestinal metode transfer learning convolutional neural network,sistem gastrointestinal perhati utama teliti medis ganggu polip kolitis ulseratif tangan kembang kondisi serius endoskopi metode utama deteksi sakit proses makan butuh tenaga ahli signifikan teliti tuju klasifikasi citra hasil endoskopi manfaat metode transfer learning bas convolutional neural network cnn dataset hyperkvasir gastrovision dataset citra kelas polip kolitis ulseratif mukosa normal model pretrained vgg19 resnet101v2 inceptionv3 ekstraksi fitur fully connected layer klasifikasi kelas polip kolitis ulseratif mukosa normal guna model pretrained teknik finetuning layer model pretrained hasil eksperimen model pretrained resnet101v2 hasil baik tingkat akurasi recall f1score hasil akurasi 09881 loss 00687 recall 09881 presicion 09882 f1score 09881 teliti harap kontribusi dukung deteksi sakit gastrointestinal cepat efisien mudah proses diagnosis bidang medisthe gastrointestinal system is a major focus in medical research due to various disorders such as polyps and ulcerative colitis which if left untreated can develop into severe conditions endoscopy is the primary method used to detect these diseases although the process often requires significant time and specialized expertise this study aims to classify endoscopic images using a transfer learning approach based on convolutional neural networks cnn the hyperkvasir and gastrovision datasets were utilized consisting of three main classes polyps ulcerative colitis and normal mucosa pretrained models such as vgg19 resnet101v2 and inceptionv3 were employed for feature extraction with the addition of fully connected layers for classifying the three aforementioned categories finetuning techniques were applied to the initial layers of each pretrained model to optimize performance experimental results demonstrated that the resnet101v2 pretrained model achieved the best performance with high accuracy recall and f1score the final results include an accuracy of 09881 loss of 00687 recall of 09881 precision of 09882 and f1score of 09881this research is expected to contribute to the early detection of gastrointestinal diseases more efficiently and effectively thereby facilitating the diagnostic process in the medical field
Prediksi Kejadian Luar Biasa Pada Kasus Demam Berdarah Dengue Di Kabupaten Malang Menggunakan Support Vector Machines - Flower Pollination Algorithm.,"Tendio, Yusnardo",http://repository.its.ac.id/78859/,"Penyakit demam berdarah dengue (DBD) merupakan salah satu penyakit berbahaya yang menjadi sumber masalah kesehatan bagi masyarakat Indonesia. Jumlah penderita DBD mengalami peningkatan seiring berjalannya waktu. KLB pada kasus DBD dapat diprediksi dengan membuat model prediksi menggunakan keterkaitan antar variabel. Beberapa variabel yang mempengaruhi hasil prediksi antara lain adalah curah hujan, suhu, kecepatan angin, dan kelembaban. Dalam tugas akhir ini, data jumlah kasus DBD per kecamatan diperoleh dari Dinas Kesehatan Kabupaten Malang, sedangkan data curah hujan, suhu, kecepatan angin, dan kelembaban diperoleh dari Badan Meteorologi, Klimatologi, dan Geofisika (BMKG). Dalam Tugas Akhir ini, sebuah model prediksi KLB untuk kasus DBD dibangun menggunakan gabungan metode Support Vector Machine dan Flower Pollination Algorithm (SVM-FPA). Metode SVM digunakan untuk memisahkan kasus yang termasuk dalam kelas KLB dan kelas non-KLB, sedang FPA digunakan untuk memperoleh nilai parameter yang optimal dalam SVM. Hasil uji coba menunjukkan bahwa nilai parameter opti-mal yang dihasilkan oleh FPA berupa kombinasi nilai cost dan gamma berturut-turut sebesar 2.829,0587 dan 0,002801. Kombinasi kedua nilai paremeter ini mem-berikan hasil prediksi SVM terbaik untuk data validasi, di mana berturut-turut diperoleh nilai akurasi, recall, dan presisi sebesar 90,34%, 89,11%, dan 91,32%. Dengan menggunakan nilai parameter yang sama, hasil prediksi untuk data tes berturut-turut diperoleh nilai akurasi, recall, dan presisi sebesar 59,65%, 88,37%, dan 36,53%. Kata Kunci: demam berdarah, prediksi kejadian luar biasa, support vector machines, algoritma penyerbukan bunga.======================================================================================================Dengue fever (DF) is a dangerous disease that causes health problems for the people. The number of DF cases increases as time goes by. DF Outbreak can be predicted by making prediction models using interrelationships among variables. Some relevant variables that influence the results of predictions are rainfall, temperature, wind speed, and humidity. In this final project, the number of dengue cases per district data are obtained from the Public Health Office of Malang Region, while rainfall, temperature, wind speed, and humidity data are obtained from the Meteorology, Climatology and Geophysics Agency. In this Final Project, an outbreak prediction model for DF cases is built using a combination of Support Vector Machine and Flower Pollination Algorithm (SVM-FPA). The SVM method is used to classify cases that are included in the outbreak class or not outbreak class, while the FPA is used to obtain optimal parameter values in the SVM.. The experimental results show that the optimal parameter values produced by the FPA consists of a combination of cost and gamma values respectively of 2,829.0587 and 0.002801. The combination of these two parameter values gives the best SVM prediction results for validation data, where successively obtained values of accuracy, recall, and precision of 90.34%, 89.11%, and 91.32%. By using the same parameter values, the prediction results for test data in terms of accuracy, recall, and precision values of 59.65%, 88.37%, and 36.53% are obtained, respectively. Keywords: dengue fever, outbreak prediction, support vector machines, flower pollination algorithm.",prediksi jadi demam darah dengue kabupaten malang support vector machines flower pollination algorithm,sakit demam darah dengue dbd salah sakit bahaya sumber sehat masyarakat indonesia derita dbd alami tingkat iring jalan klb dbd prediksi model prediksi kait variabel variabel pengaruh hasil prediksi curah hujan suhu cepat angin kelembaban tugas data dbd camat oleh dinas sehat kabupaten malang data curah hujan suhu cepat angin kelembaban oleh badan meteorologi klimatologi geofisika bmkg tugas model prediksi klb dbd bangun gabung metode support vector machine flower pollination algorithm svmfpa metode svm pisah kelas klb kelas nonklb fpa oleh nilai parameter optimal svm hasil uji coba nilai parameter optimal hasil fpa kombinasi nilai cost gamma berturutturut 28290587 0002801 kombinasi nilai paremeter hasil prediksi svm baik data validasi berturutturut oleh nilai akurasi recall presisi 9034 8911 9132 nilai parameter hasil prediksi data tes berturutturut oleh nilai akurasi recall presisi 5965 8837 3653 kunci demam darah prediksi jadi support vector machines algoritma serbu bungadengue fever df is a dangerous disease that causes health problems for the people the number of df cases increases as time goes by df outbreak can be predicted by making prediction models using interrelationships among variables some relevant variables that influence the results of predictions are rainfall temperature wind speed and humidity in this final project the number of dengue cases district data are obtained from the public health office of malang region while rainfall temperature wind speed and humidity data are obtained from the meteorology climatology and geophysics agency in this final project an outbreak prediction model for df cases is built using a combination of support vector machine and flower pollination algorithm svmfpa the svm method is used to classify cases that are included in the outbreak class or not outbreak class while the fpa is used to obtain optimal parameter values in the svm the experimental results show that the optimal parameter values produced by the fpa consists of a combination of cost and gamma values respectively of 28290587 and 0002801 the combination of these two parameter values gives the best svm prediction results for validation data where successively obtained values of accuracy recall and precision of 9034 8911 and 9132 by using the same parameter values the prediction results for test data in terms of accuracy recall and precision values of 5965 8837 and 3653 are obtained respectively keywords dengue fever outbreak prediction support vector machines flower pollination algorithm
Klasifikasi Tumor Otak Pada Citra MRI Menggunakan en-CNN.,"Tjahyaningtijas, Hapsari Peni Agustin",http://repository.its.ac.id/87168/,"Tumor otak adalah salah satu penyakit yang paling umum terjadi pada sistem saraf pusat dan sifatnya berbahaya. Diagnosis dini sangat penting untuk perawatan pasien yang tepat. Klasifikasi biner tumor otak yang sering dicirikan dengan tumor otak ganas dan jinak yang melibatkan multi-sekuen MRI (T1, T2, T1CE, dan FLAIR), membuat pekerjaan ahli radiologi membosankan dan rawan terjadinya kesalahan. Pada penelitian ini, dikembangkan metode klasifikasi melalui tahap segmentasi dan metode klasifikasi langsung tanpa mealui tahap segmentasi untuk membantu proses klasifikasi tumor otak oleh ahli. Untuk metode klasifikasi melalui segmentasi, fokus penelitian terdapat pada pengembangan metode segmentasi otomatis untuk segmentasi tumor otak ganas yaitu Glioblastoma (GBM) dan tumor otak jinak yaitu Low Grade Glioma (LGG). Metode segmentasi dikembangkan menggunakan modifikasi U-Net. Arsitektur U-Net dievaluasi berdasarkan jumlah epoch dan nilai drop-out untuk mencapai arsitektur yang paling sesuai. Dari hasil eksperimen, model arsitektur yang paling sesuai untuk segmentasi tumor otak  adalah arsitektur modifikasi U-Net atau mU-Net dengan jumlah epoch 90 dan nilai lapisan drop out 0,5. Hasil kinerja segmentasi ditunjukkan dengan nilai dice score sebesar 0,909 yang lebih besar dari penelitian sebelumnya. Metode segmentasi yang diusulkan mampu meningkatkan akurasi klasifikasi tumor otak sebesar 95,65% menggunakan DNN. Nilai akurasi tersebut 2,7% lebih tinggi dari pada jika menggunakan metode SVM yaitu sebesar 92,9%. Dilain pihak, beberapa metode klasifikasi berdasarkan deep learning  digunakan untuk mengklasifikasikan tumor otak. Performa masing-masing model sangat bergantung pada arsitektur CNN yang digunakan. Karena kompleksitas arsitektur CNN yang ada, penyetelan hyperparameter menjadi masalah dalam penerapannya. Pada penelitian ini diusulkan metode CNN yang disebut dengan en-CNN untuk mengatasi masalah ini. Metode ini didasarkan pada VGG-16 yang terdiri dari tujuh jaringan konvolusi, empat ReLU, dan empat max-pooling. Metode yang diusulkan digunakan untuk memfasilitasi penyetelan hyperparameter. Metode ini merupakan pendekatan dimana klasifikasi tumor otak dilakukan secara langsung tanpa terlebih dahulu melakukan proses segmentasi. Pendekatan baru terdiri dari tahapan berikut: preproses, augmentasi citra, dan penerapan metode en-CNN. Klasifikasi tumor otak dilakukan  menggunakan empat sekuen MRI T1, T1CE, T2, dan FLAIR. Metode yang diusulkan memberikan akurasi pada dataset MRI multi-sekuen BraTS 2018 dengan akurasi 95,5% untuk T1, 95,5% untuk T1CE, 94% untuk T2, dan 97% untuk FLAIR dengan ukuran mini-batch 128 dan epoch 200 menggunakan fungsi optimasi ADAM. Akurasinya 4% lebih tinggi dari penelitian sebelumnya dalam dataset yang sama.=====================================================================================================Brain tumors are one of the most common diseases of the central nervous system and are dangerous in nature. Early diagnosis is essential for proper patient care. Radiologists need an automated system to identify brain tumor images. The tumor identification process is a tedious and error-prone task. In addition, the binary classification of brain tumors which are often characterized by malignant and benign brain tumors involving multi-sequence MRI (T1, T2, T1CE, and FLAIR), makes the work of radiologists quite challenging. In this study, a classification method was developed through the segmentation stage. and the direct classification method without going through the segmentation stage. For the classification method through segmentation, the research focus is on the development of automatic segmentation methods using U-Net modifications. The U-Net architecture was evaluated based on the number of epochs and drop-out values to achieve the most suitable architecture for automatic segmentation of glioblastoma brain tumors. From the experimental results, the most suitable architectural model for brain tumor segmentation is the mU-Net architecture with 90 epochs and a dropout layer value of 0.5. The results of segmentation performance are indicated by a dice score of 0.909, which is greater than the previous study. Using DNN, the proposed segmentation method can improve the accuracy of brain tumor classification by 95.65%. The accuracy value is 2.7 % higher than 92.9 % when using the SVM method.On the other hand, several classification methods based on deep learning are used to classify brain tumors. The performance of each model is highly dependent on the CNN architecture used. Due to the complexity of the existing CNN architecture, hyperparameter tuning is a problem in its implementation. In this study, a CNN method called en-CNN is proposed to overcome this problem. This method is based on VGG-16 which consists of seven convolution networks, four ReLUs, and four max-poolings. The proposed method is used to facilitate hyperparameter tuning. This method is an approach where the classification of brain tumors is done directly without first doing the segmentation process. The new approach consists of the following stages: preprocessing, image augmentation, and application of the en-CNN method. Brain tumor classification was performed using four MRI sequences T1, T1CE, T2, and FLAIR. The proposed method provides an accuracy of the 2018 BraTS multi-sequence MRI dataset with an accuracy of 95.5% for T1, 95.5% for T1CE, 94% for T2, and 97% for FLAIR with mini-batch sizes of 128 and epoch 200 using the function ADAM optimization. The accuracy is 4% higher than previous studies in the same dataset",klasifikasi tumor otak citra mri encnn,tumor otak salah sakit sistem saraf pusat sifat bahaya diagnosis awat pasien klasifikasi biner tumor otak ciri tumor otak ganas jinak libat multisekuen mri t1 t2 t1ce flair kerja ahli radiologi bosan rawan salah teliti kembang metode klasifikasi tahap segmentasi metode klasifikasi langsung mealui tahap segmentasi bantu proses klasifikasi tumor otak ahli metode klasifikasi segmentasi fokus teliti kembang metode segmentasi otomatis segmentasi tumor otak ganas glioblastoma gbm tumor otak jinak low grade glioma lgg metode segmentasi kembang modifikasi unet arsitektur unet evaluasi dasar epoch nilai dropout capai arsitektur sesuai hasil eksperimen model arsitektur sesuai segmentasi tumor otak arsitektur modifikasi unet munet epoch 90 nilai lapis drop out 05 hasil kerja segmentasi nilai dice score 0909 teliti metode segmentasi usul tingkat akurasi klasifikasi tumor otak 9565 dnn nilai akurasi 27 metode svm 929 lain metode klasifikasi dasar deep learning klasifikasi tumor otak performa masingmasing model gantung arsitektur cnn kompleksitas arsitektur cnn setel hyperparameter terap teliti usul metode cnn encnn atas metode dasar vgg16 tujuh jaring konvolusi relu maxpooling metode usul fasilitas setel hyperparameter metode dekat mana klasifikasi tumor otak langsung proses segmentasi dekat tahap preproses augmentasi citra terap metode encnn klasifikasi tumor otak sekuen mri t1 t1ce t2 flair metode usul akurasi dataset mri multisekuen brats 2018 akurasi 955 t1 955 t1ce 94 t2 97 flair ukur minibatch 128 epoch 200 fungsi optimasi adam akurasi 4 teliti dataset samabrain tumors are one of the most common diseases of the central nervous system and are dangerous in nature early diagnosis is essential for proper patient care radiologists need an automated system to identify brain tumor images the tumor identification process is a tedious and errorprone task in addition the binary classification of brain tumors which are often characterized by malignant and benign brain tumors involving multisequence mri t1 t2 t1ce and flair makes the work of radiologists quite challenging in this study a classification method was developed through the segmentation stage and the direct classification method without going through the segmentation stage for the classification method through segmentation the research focus is on the development of automatic segmentation methods using unet modifications the unet architecture was evaluated based on the number of epochs and dropout values to achieve the most suitable architecture for automatic segmentation of glioblastoma brain tumors from the experimental results the most suitable architectural model for brain tumor segmentation is the munet architecture with 90 epochs and a dropout layer value of 05 the results of segmentation performance are indicated by a dice score of 0909 which is greater than the previous study using dnn the proposed segmentation method can improve the accuracy of brain tumor classification by 9565 the accuracy value is 27 higher than 929 when using the svm methodon the other hand several classification methods based on deep learning are used to classify brain tumors the performance of each model is highly dependent on the cnn architecture used due to the complexity of the existing cnn architecture hyperparameter tuning is a problem in its implementation in this study a cnn method called encnn is proposed to overcome this problem this method is based on vgg16 which consists of seven convolution networks four relus and four maxpoolings the proposed method is used to facilitate hyperparameter tuning this method is an approach where the classification of brain tumors is done directly without first doing the segmentation process the new approach consists of the following stages preprocessing image augmentation and application of the encnn method brain tumor classification was performed using four mri sequences t1 t1ce t2 and flair the proposed method provides an accuracy of the 2018 brats multisequence mri dataset with an accuracy of 955 for t1 955 for t1ce 94 for t2 and 97 for flair with minibatch sizes of 128 and epoch 200 using the function adam optimization the accuracy is 4 higher than previous studies in the same dataset
Analisis Sentimen Terhadap Tweets Samsung Indonesia Menggunakan Metode Support Vector Machine.,"Triantoro, Aris Rendyansyah",http://repository.its.ac.id/90797/,"Samsung as the world's leading smartphone company is a company that produces various types of technological devices. Technology as the driving force of human civilization is very important. However, in the course of time it is necessary to improve and evaluate gradually in order to satisfy needs properly and avoid undesirable things.Social media Twitter is an application that allows users to write about various topics and discuss current issues. Services are available to send tweets or re-tweets messages that have been shared. With the existence of Twitter this makes it easier for people to have an opinion. The opinion expressed by the public is a very valuable input and can be an instrument for evaluating. These opinions can be analyzed so that information can be obtained, but in practice, processing a text data requires an appropriate method so that the information generated can help many parties to support a decision or choice.Sentiment analysis is the classification of text documents into sentiment classes, such as positive and negative. This study aims to classify the community's tweets against the Samsung Indonesia company on Twitter social media using the Support Vector Machine method by using the data source from crawling tweets with samsungidas the reference keyword using the Twitter API. This research results that the number of tweets with negative sentiment is 13.37%, positive sentiment is 26.01%, and neutral sentiment is 60.60% tweets and the best model for classifying tweet data with SVM is to use data sharing by sharing training data by 80% and testing data by 20% and using value C = 1.",analisis sentimen tweets samsung indonesia metode support vector machine,samsung as the worlds leading smartphone company is a company that produces various types of technological devices technology as the driving force of human civilization is very important however in the course of time it is necessary to improve and evaluate gradually in order to satisfy needs properly and avoid undesirable thingssocial media twitter is an application that allows users to write about various topics and discuss current issues services are available to send tweets or retweets messages that have been shared with the existence of twitter this makes it easier for people to have an opinion the opinion expressed by the public is a very valuable input and can be an instrument for evaluating these opinions can be analyzed so that information can be obtained but in practice processing a text data requires an appropriate method so that the information generated can help many parties to support a decision or choicesentiment analysis is the classification of text documents into sentiment classes such as positive and negative this study aims to classify the communitys tweets against the samsung indonesia company on twitter social media using the support vector machine method by using the data source from crawling tweets with samsungidas the reference keyword using the twitter api this research results that the number of tweets with negative sentiment is 1337 positive sentiment is 2601 and neutral sentiment is 6060 tweets and the best model for classifying tweet data with svm is to use data sharing by sharing training data by 80 and testing data by 20 and using value c 1
Sentiment Analysis of Public Figure News using Sentiment Lexicon and Machine Learning.,"Tsabit, Fitriana Zahirah",http://repository.its.ac.id/100969/,"Dalam dunia politik maupun dunia bisnis penilaian yang dibentuk media dapat menjadi sebuah citra dari seseorang. Citra seseorang merupakan komponen penting bagi seorang publik figur untuk mendapatkan popularitas dan keuntungan secara finansial. Saat ini dunia informasi berkembang dengan cepat sehingga lebih mudah mendapatkan informasi melalui situs berita online. Di Indonesia salah satu situs beritaonline terbesar yaitu Detik.com. Situs berita online menyediakan informasi dalam berbagai bentuk (teks, video atau gambar) dengan membaginya sesuai dengan topik-topik tertentu. Sehingga, dapat dilakukan sentimen analisis untuk mengetahui citra publik figur dari situs berita online melalui penerapan metode machine learning yaitu klasifikasi. Data yang digunakan berasal dari situs berita online yang diambil dengan cara scraping. Tahapan yang dilakukan preprocessing, gabungan score feature extraction menggunakan kamus lexicon, InSet, SentIl, Emolex dan juga terhadap gabungan kamus EmoTil (Emolex dan SentIl), EmoSet (Emotil dan InSet) dan SenSet (InSet dan SentIl) dengan TFIDF. Hasil dari penggabungan ini digunakan untuk klasifikasi machine learning dengan algoritma SVM dan Logistic Regression. Model yang telah dibangun akan dievaluasi dengan membandingkan nilai akurasi dari cross validation. Hasil akurasi terbesar dan terkecil akan dilakukan penembahan parameter untuk meningkatkan hasil dari rata-rata cross validation. Hasil dari akurasi terbesar adalah SVM dengan selisih 1.2% dengan Logistic Regression=================================================================================================================================In the world of politics and business, the judgment formed by the media can become an image of a person. A person's image is essential for a public figure to gain popularity and financial benefits. The world of information is developing rapidly, making it easier to get information through online news sites. In Indonesia, one of the largest online news sites is Detik.com. Online news sites provide information in various forms (text, video, or images) by dividing it according to specific topics. Thus, an analysis of sentiment can be carried out to determine the image of public figures from online news sites through machine learning methods, namely classification. The data used comes from online news sites taken by scraping. The stages carried out are preprocessing, combined score feature extraction using lexicon dictionaries, InSet, SentIl, and Emolex and also against the combined dictionaries EmoTil (Emolex and SentIl), EmoSet (Emotil and InSet) and SenSet (InSet and SentIl) with TFIDF. The result of this combination is used for machine learning classification with SVM and Logistic Regression algorithms. The model that has been built will be evaluated by comparing the accuracy value of cross validation. The largest and smallest accuracy results will be parameterised to improve the results of the average cross validation. The result of the greatest accuracy is SVM with a difference of 1.2% with Logistic Regression.",sentiment analysis of public figure news using sentiment lexicon and machine learning,dunia politik dunia bisnis nilai bentuk media citra citra komponen publik figur popularitas untung finansial dunia informasi kembang cepat mudah informasi situs berita online indonesia salah situs beritaonline besar detikcom situs berita online sedia informasi bentuk teks video gambar bagi sesuai topiktopik sentimen analisis citra publik figur situs berita online terap metode machine learning klasifikasi data asal situs berita online ambil scraping tahap preprocessing gabung score feature extraction kamus lexicon inset sentil emolex gabung kamus emotil emolex sentil emoset emotil inset senset inset sentil tfidf hasil gabung klasifikasi machine learning algoritma svm logistic regression model bangun evaluasi banding nilai akurasi cross validation hasil akurasi besar kecil penembahan parameter tingkat hasil ratarata cross validation hasil akurasi besar svm selisih 12 logistic regressionin the world of politics and business the judgment formed by the media can become an image of a person a persons image is essential for a public figure to gain popularity and financial benefits the world of information is developing rapidly making it easier to get information through online news sites in indonesia one of the largest online news sites is detikcom online news sites provide information in various forms text video or images by dividing it according to specific topics thus an analysis of sentiment can be carried out to determine the image of public figures from online news sites through machine learning methods namely classification the data used comes from online news sites taken by scraping the stages carried out are preprocessing combined score feature extraction using lexicon dictionaries inset sentil and emolex and also against the combined dictionaries emotil emolex and sentil emoset emotil and inset and senset inset and sentil with tfidf the result of this combination is used for machine learning classification with svm and logistic regression algorithms the model that has been built will be evaluated by comparing the accuracy value of cross validation the largest and smallest accuracy results will be parameterised to improve the results of the average cross validation the result of the greatest accuracy is svm with a difference of 12 with logistic regression
Penerapan Algoritma Blocplan Sebagai Metode Desain Terminal Regasifikasi Gas Alam Cair (LNG).,"Ulfauzi, Zaki",http://repository.its.ac.id/80801/,"Dalam perancangan tata letak fasilitas yang menggunakan aplikasi, seperti dalam bidang teknik sipil, perkapalan, arsitektur, banyak sistem algoritma perancangan yang telah dikembangkan. Algoritma perancangan merupakan salah satu metode pendekatan dalam perancangan dimana sistem komputer telah diolah dengan beberapa rumus untuk menghasilkan rancangan secara otomatis dan efisien. Peneliti mencoba menggunakan salah satu algoritma perancangan untuk mendesain layout terminal LNG yang disebut algoritma BLOCPLAN. Algoritma BLOCPLAN digunakan untuk meningkatkan efisiensi pemanfaatan ruang dan penempatan fasilitas. BLOCPLAN bekerja dengan menghasilkan beberapa tata letak terminal dengan sistem penilaian langsung. Desain yang paling efisien akan dipilih dari desain yang dihasilkan setelah proses analisis ulang. Dalam menentukan fasilitas terminal utama, Excel Solver juga digunakan untuk memilih skenario terbaik dengan parameter modal investasi yang rendah. Dalam penelitian ini, 15 layout dihasilkan oleh algoritma. Untuk proses perankingan, metode AHP digunakan untuk mengubah karakter skor dari cost criteria menjadi benefit criteria. Nilai bobot untuk masing-masing skor adalah 0.1 untuk Adj.Score, 0.3 untuk R.Score, dan 0.6 untuk Rel-Dist Score. Dari hasil pemeringkatan, layout nomor 14 menjadi rekomendasi terbaik dengan total skor 0.14987.======================================================================================================================================================================In the layout design of buildings using applications, such as in the fields of civil engineering, shipping, architecture, many design algorithm systems have been developed. Design algorithm is an approaching method in design where the computer system has been processed with several formulas to produce designs automatically and efficiently. The researcher tries to use one of the design algorithms for designing the LNG terminal layout, called the BLOCPLAN algorithm. The BLOCPLAN algorithm is used to improve the efficiency of space utilization and facility placement. BLOCPLAN works by generating several terminal layouts with a direct appraisal system. A most efficient design will be selected from generated designs after the re-analysis process. In determining the main terminal facilities, Excel Solver is also used to choose the best scenario with low investment capital. In this research, 15 layouts are generated by the algorithm. For the ranking process, the AHP method is used to change the character of the score from the cost criteria to the benefit criteria. The weighted value of each score is 0.1 for Adj.Score, 0.3 for R.Score, and 0.6 for the Rel-Dist Score. From the ranking results, layout number 14 is the best recommendation with a total score of 0.14987.",terap algoritma blocplan metode desain terminal regasifikasi gas alam cair lng,ancang tata letak fasilitas aplikasi bidang teknik sipil kapal arsitektur sistem algoritma ancang kembang algoritma ancang salah metode dekat ancang mana sistem komputer olah rumus hasil rancang otomatis efisien teliti coba salah algoritma ancang desain layout terminal lng algoritma blocplan algoritma blocplan tingkat efisiensi manfaat ruang tempat fasilitas blocplan hasil tata letak terminal sistem nilai langsung desain efisien pilih desain hasil proses analisis ulang tentu fasilitas terminal utama excel solver pilih skenario baik parameter modal investasi rendah teliti 15 layout hasil algoritma proses perankingan metode ahp ubah karakter skor cost criteria benefit criteria nilai bobot masingmasing skor 01 adjscore 03 rscore 06 reldist score hasil peringkat layout nomor 14 rekomendasi baik total skor 014987in the layout design of buildings using applications such as in the fields of civil engineering shipping architecture many design algorithm systems have been developed design algorithm is an approaching method in design where the computer system has been processed with several formulas to produce designs automatically and efficiently the researcher tries to use one of the design algorithms for designing the lng terminal layout called the blocplan algorithm the blocplan algorithm is used to improve the efficiency of space utilization and facility placement blocplan works by generating several terminal layouts with a direct appraisal system a most efficient design will be selected from generated designs after the reanalysis process in determining the main terminal facilities excel solver is also used to choose the best scenario with low investment capital in this research 15 layouts are generated by the algorithm for the ranking process the ahp method is used to change the character of the score from the cost criteria to the benefit criteria the weighted value of each score is 01 for adjscore 03 for rscore and 06 for the reldist score from the ranking results layout number 14 is the best recommendation with a total score of 014987
Model Traffic Forecasting dengan RNN-Based Deep Learning dan Explainable Artificial Intelligence.,"Ulhaq, Naufal Dhiya",http://repository.its.ac.id/106242/,"Peningkatan konsep smart city yang didorong oleh kemajuan Internet of Things (IoT), telah mengubah lanskap perkotaan modern. Salah satu pilar utama dari hal ini adalah Intelligent Transportation System (ITS), di mana model traffic forecasting menjadi perangkat kunci dari sistem ini. Penelitian ini bertujuan untuk mengembangkan model forecasting yang tidak hanya akurat tetapi juga mudah dipahami, dengan menggunakan pendekatan Recurrent Neural Network (RNN) dan menerapkan Explainable Artificial Intelligence (XAI). Hasil pengujian menunjukkan bahwa model dengan algoritma Bidirectional Long Short-Term Memory (BiLSTM) yang merupakan pengembangan RNN, mencapai kinerja terbaik. Model tersebut berhasil mencapai nilai Mean Absolute Error (MAE) sebesar 163,13, Root Mean Square Error (RMSE) sebesar 241,62, dan Mean Absolute Percentage Error (MAPE) sebesar 8,03%. Penggunaan XAI, khususnya metode Shapley Additive Explanations (SHAP), mengungkapkan bahwa fitur ""traffic_volume"" dan timestep pada 1 jam terakhir memberikan kontribusi terbesar dalam pengambilan keputusan model. Lebih lanjut, penelitian ini berhasil mengintegrasikan model dan XAI ke dalam aplikasi website berbasis Flask. Integrasi ini memberikan akses untuk melihat riwayat forecasting, nilai shap value, feature importance, dan dataset. Aplikasi tersebut juga menyertakan formulir untuk input data baru dan tabel dataset.====================================================================================================================================The rise of the smart city concept, driven by the advancement of the Internet of Things (IoT), has changed the modern urban landscape. One of its main pillars is the Intelligent Transportation System (ITS), where traffic forecasting models are a key tool of this system. This research aims to develop a forecasting model that is not only accurate but also easy to understand, by using a Recurrent Neural Network (RNN) approach and applying Explainable Artificial Intelligence (XAI). The results showed that the model with the Bidirectional Long Short-Term Memory (BiLSTM) algorithm, which is a development of RNN, achieved the best performance. The model managed to achieve a Mean Absolute Error (MAE) value of 163.13, Root Mean Square Error (RMSE) of 241.62, and Mean Absolute Percentage Error (MAPE) of 8,03%. The use of XAI, specifically the Shapley Additive Explanations (SHAP) method, revealed that the ""traffic_volume"" feature and the timestep of the last 1 hour contributed the most to the model's decision making. Furthermore, this research successfully integrated the model and XAI into a Flask-based website application. This integration provides access to view forecasting history, shap value, feature importance, and datasets. The application also includes a form for new data input and a dataset table.",model traffic forecasting rnnbased deep learning explainable artificial intelligence,tingkat konsep smart city dorong maju internet of things iot ubah lanskap kota modern salah pilar utama intelligent transportation system its model traffic forecasting perangkat kunci sistem teliti tuju kembang model forecasting akurat mudah paham dekat recurrent neural network rnn terap explainable artificial intelligence xai hasil uji model algoritma bidirectional long shortterm memory bilstm kembang rnn capai kerja baik model hasil capai nilai mean absolute error mae 16313 root mean square error rmse 24162 mean absolute percentage error mape 803 guna xai metode shapley additive explanations shap fitur trafficvolume timestep 1 jam kontribusi besar ambil putus model teliti hasil integrasi model xai aplikasi website bas flask integrasi akses riwayat forecasting nilai shap value feature importance dataset aplikasi serta formulir input data tabel datasetthe rise of the smart city concept driven by the advancement of the internet of things iot has changed the modern urban landscape one of its main pillars is the intelligent transportation system its where traffic forecasting models are a key tool of this system this research aims to develop a forecasting model that is not only accurate but also easy to understand by using a recurrent neural network rnn approach and applying explainable artificial intelligence xai the results showed that the model with the bidirectional long shortterm memory bilstm algorithm which is a development of rnn achieved the best performance the model managed to achieve a mean absolute error mae value of 16313 root mean square error rmse of 24162 and mean absolute percentage error mape of 803 the use of xai specifically the shapley additive explanations shap method revealed that the trafficvolume feature and the timestep of the last 1 hour contributed the most to the models decision making furthermore this research successfully integrated the model and xai into a flaskbased website application this integration provides access to view forecasting history shap value feature importance and datasets the application also includes a form for new data input and a dataset table
Peningkatan Akurasi Klasifikasi Kemurnian Daging Sapi Berbasis Electronic Nose Dengan Menggunakan Ensemble Method.,"Ulhaq, Azzam Jihad",http://repository.its.ac.id/84701/,"Daging sapi merupakan salah satu jenis daging yang sering dikonsumsi oleh manusia. Namun, pencampuran jenis daging sapi dengan daging lainnya seperti daging babi dilakukan dalam praktik jual beli dalam rangka mendapatkan keuntungan yang lebih. Hal ini tidak hanya mengurangi kepercayaan publik tentang keaslian daging juga membahayakan kesehatan dan melanggar aturan-aturan agam tertentu. Dalam penelitian ini, kami merancang dan mengusulkan sistem yang lebih akurat dalam melakukan klasifikasi kemurnian daging sapi berdasarkan data sampel aroma yang ditangkap oleh electronic nose.Sistem ini dibangun melalui tujuh tahap: pengambilan sampel data menggunakan electronic nose yang dibuat dari sensor gas dan Arduino; praproses data sensor; ekstraksi fitur statistik; hyperparameter tunning; seleksi fitur menggunakan ANOVA; klasifikasi menggunakan metode SVM, LDA dan MLP; dan peningkatan akurasi menggunakan ensemble method.Hasil penelitian menunjukkan bahwa sistem ini dapat membedakan daging sapi yang dicampur dengan daging babi dengan perbandingan 0%, 10%, 25%, 50%, 75%, 90%, dan 100% dengan akurasi 89,71% menggunakan Bagging MLP.======================================================================================================Beef is a type of meat that is often consumed by humans. However, mixing types of beef with other meats such as pork is carried out in buying and selling to get more profit. The adulteration undermines public belief in meat's authenticity and harms health, and violates specific religious rules. In this study, we designed and proposed a more accurate system for classifying beef purity based on the aroma sample data captured by the electronic nose.This system has seven stages: data sampling using an electronic nose made from the gas sensor and Arduino; preprocessing sensor data; statistical feature extraction; hyperparameter tunning; feature selection using ANOVA; classification using the SVM, LDA, and MLP methods; and improved accuracy using the ensemble method.The results showed that this system could distinguish beef mixed with pork with a ratio of 0%, 10%, 25%, 50%, 75%, 90%, and 100% with an accuracy of 89.71% using Bagging MLP.",tingkat akurasi klasifikasi murni daging sapi bas electronic nose ensemble method,daging sapi salah jenis daging konsumsi manusia campur jenis daging sapi daging daging babi praktik jual beli rangka untung kurang percaya publik asli daging bahaya sehat langgar aturanaturan agam teliti rancang usul sistem akurat klasifikasi murni daging sapi dasar data sampel aroma tangkap electronic nosesistem bangun tujuh tahap ambil sampel data electronic nose sensor gas arduino praproses data sensor ekstraksi fitur statistik hyperparameter tunning seleksi fitur anova klasifikasi metode svm lda mlp tingkat akurasi ensemble methodhasil teliti sistem beda daging sapi campur daging babi banding 0 10 25 50 75 90 100 akurasi 8971 bagging mlpbeef is a type of meat that is often consumed by humans however mixing types of beef with other meats such as pork is carried out in buying and selling to get more profit the adulteration undermines public belief in meats authenticity and harms health and violates specific religious rules in this study we designed and proposed a more accurate system for classifying beef purity based on the aroma sample data captured by the electronic nosethis system has seven stages data sampling using an electronic nose made from the gas sensor and arduino preprocessing sensor data statistical feature extraction hyperparameter tunning feature selection using anova classification using the svm lda and mlp methods and improved accuracy using the ensemble methodthe results showed that this system could distinguish beef mixed with pork with a ratio of 0 10 25 50 75 90 and 100 with an accuracy of 8971 using bagging mlp
News Classification Using Ensemble Learning Approach.,"Utomo, Erlangga Wahyu",http://repository.its.ac.id/117829/,"The amount of information published online every day can be overwhelming, making it difficult to effectively manage and categorize. This research addresses this problem by combining multiple machine learning and deep learning models in a method known as ensemble learning. Using a set of Huffpost News from Kaggle, the study integrates traditional models, such as logistics regression, random forests and Support for Vector Machines (SVM) with advanced approaches deep learning, such as Long Short Term Memory (LSTM), Bidirectional Long Short Term Memory (BiLSTM) with a mechanism for attention, and the introduction of layers. The data preparation process included cleaning the text, removing unnecessary characters and the conversion of text into numerical forms using Word2Vec embedding field These features were then fed into an ensemble model that combined predictions from different classifiers using a method called soft voting, improving the overall accuracy and reliability of the classification process. To confirm the results, the model was tested using various departments of learning data and test data (80-20 reports). The results indicate that the ensemble model achieved an overall accuracy of 60.19%, outperforming individual models. Among the individual models, BiLSTM with Attention achieved the highest accuracy of 63.9%, followed by LSTM at 54.7%, Random Forest at 48.3%, Logistic Regression at 58.2%, and SVM at 57.5%. Among the individual models, BiLSTM with Attention achieved the best performance, demonstrating its effectiveness in understanding sentence structure and capturing complex patterns in news content. Even though it differs not so much from the individual model, the ensemble still has the best accuracy because it combines all the individual models and combines preprocessing data between machine learning and deep learning, However, the training process for the ensemble model required significant computational resources, taking 10 days to complete.",news classification using ensemble learning approach,the amount of information published online every day can be overwhelming making it difficult to effectively manage and categorize this research addresses this problem by combining multiple machine learning and deep learning models in a method known as ensemble learning using a set of huffpost news from kaggle the study integrates traditional models such as logistics regression random forests and support for vector machines svm with advanced approaches deep learning such as long short term memory lstm bidirectional long short term memory bilstm with a mechanism for attention and the introduction of layers the data preparation process included cleaning the text removing unnecessary characters and the conversion of text into numerical forms using word2vec embedding field these features were then fed into an ensemble model that combined predictions from different classifiers using a method called soft voting improving the overall accuracy and reliability of the classification process to confirm the results the model was tested using various departments of learning data and test data 8020 reports the results indicate that the ensemble model achieved an overall accuracy of 6019 outperforming individual models among the individual models bilstm with attention achieved the highest accuracy of 639 followed by lstm at 547 random forest at 483 logistic regression at 582 and svm at 575 among the individual models bilstm with attention achieved the best performance demonstrating its effectiveness in understanding sentence structure and capturing complex patterns in news content even though it differs not so much from the individual model the ensemble still has the best accuracy because it combines all the individual models and combines preprocessing data between machine learning and deep learning however the training process for the ensemble model required significant computational resources taking 10 days to complete
Nowcasting Jumlah Penduduk dengan Metode Support Vector Regression (SVR) dan Multi-Output Support Vector Regression (M-SVR).,"Vinahari, Riyan Zulmaniar",http://repository.its.ac.id/104274/,"Data dan informasi statistik beserta proyeksinya merupakan dasar penting untuk perencanaan dan evaluasi pembangunan nasional di masa mendatang khususnya jangka menengah maupun jangka panjang. Data tersebut tidak dapat dipenuhi melalui sistem registrasi sehingga data-data diperoleh dari sensus dan survei yang dilakukan Badan Pusat Statistik (BPS) untuk digunakan sebagai dasar proyeksi. Metode proyeksi penduduk yang umum digunakan di berbagai negara dan masih menjadi metode proyeksi penduduk Indonesia adalah Cohort Component Model (CCM). Akan tetapi, metode ini mempunyai beberapa kelemahan sehingga diperlukan metode baru yang lebih akurat salah satunya melalui metode nowcasting. Analisis time series tidak hanya dilakukan menggunakan statistika klasik, tetapi juga machine learning (ML). Metode ML mempunyai performa lebih unggul dibandingkan dengan metode statistika klasik. Algoritma ML yang umum digunakan untuk nowcasting adalah Support Vector Regression (SVR) dan Multi-output SVR (M-SVR). SVR juga mampu menghasilkan performa bagus dalam proyeksi di berbagai macam bidang. Akan tetapi SVR hanya mampu menangani single output. Sedangkan M-SVR mampu menangani permasalahan regresi multi-output seperti jumlah penduduk di beberapa provinsi di Pulau Jawa yang saling berkorelasi. Data yang digunakan bersumber dari BPS dengan variabel output jumlah penduduk di Provinsi DKI Jakarta, Jawa Barat, Jawa Tengah, dan Jawa Timur. Variabel input yang digunakan yaitu jumlah pelanggan listrik kelompok rumah tangga, jumlah angkatan kerja, jumlah rumah tangga, kepadatan penduduk (jiwa/km2), PDRB komponen PKRT ADHK (miliar Rp). Periode data yang digunakan merupakan data tahunan dari tahun 1985 sampai 2022. Pemilihan model terbaik dilakukan dengan membandingkan nilai RMSE dan MAPE out sample nowcasting model SVR dan M-SVR. Hasil penelitian menunjukkan bahwa berdasarkan nilai kebaikan model, nowcasting model SVR mempunyai performa yang lebih baik dibandingkan model M-SVR yang ditunjukkan dari nilai MAPE out sample nowcasting model SVR yang lebih kecil dibanding model M-SVR untuk seluruh variabel output. Selain itu, proyeksi penduduk hasil dari metode nowcasting memberikan performa yang lebih baik dibandingkan dengan metode CCM.===================================================================================================================================Statistical data and information, as well as their projections are an important basis for planning and evaluation of future national development, especially in the medium and long term development. These data cannot be provided through the population registration system. Hence, the data obtained from censuses and surveys conducted by Badan Pusat Statistik (BPS- Statistics Indonesia). The common method is Cohort Component Method (CCM). CCM is widely used in many countries including Indonesia, which still be utilized by BPS. Unfortunately, this method has several drawbacks, and therefore, more accurate method is required to outperform CCM. One of these methods is nowcasting. Time series analysis can now be conducted not only using classical statistical but also machine learning (ML). Machine learning is a new method in statistical forecasting that shows an excellent performance compared to classical statistical methods. Machine learning algorithms that are commonly used in sequential analysis are Support Vector Regression (SVR) and Multioutput SVR (MSVR) where both of these algorithms can perform nowcasting. SVR is also capable of producing excellent projections in a variety of disciplines. However, SVR is only able to handle single output. Meanwhile, M-SVR is capable of handling multi-output regression problems such as the number of populations in several provinces in Java Island which are correlated with each other. The data used was obtained from the BPS, and the output variable is the population of DKI Jakarta, West Java, Central Java, and East Java Provinces.  The variables used as inputs are the number of electricity consumers for the household group, the number of workers, the number of households, the population density (people/km2), and the GRDP of the PKRT ADHK component (billion Rp). The data period used spans from 1985 to 2022 with annual data. Comparing the SVR and MSVR models' RMSE and MAPE values enables the selection of the optimal model. The results showed that based on the quality of the model, the SVR nowcasting model outperformed the M-SVR model, as shown by the SVR nowcasting model's out sample MAPE value, which was lower for all output variables than MAPE value from M-SVR. In addition, the efficacy of the population projections derived from the nowcasting method is outperform than CCM method.",nowcasting duduk metode support vector regression svr multioutput support vector regression msvr,data informasi statistik serta proyeksi dasar rencana evaluasi bangun nasional jangka tengah jangka data penuh sistem registrasi datadata oleh sensus survei badan pusat statistik bps dasar proyeksi metode proyeksi duduk negara metode proyeksi duduk indonesia cohort component model ccm metode lemah metode akurat salah satu metode nowcasting analisis time series statistika klasik machine learning ml metode ml performa unggul banding metode statistika klasik algoritma ml nowcasting support vector regression svr multioutput svr msvr svr hasil performa bagus proyeksi bidang svr tangan single output msvr tangan masalah regresi multioutput duduk provinsi pulau jawa korelasi data sumber bps variabel output duduk provinsi dki jakarta jawa barat jawa jawa timur variabel input langgan listrik kelompok rumah tangga angkat kerja rumah tangga padat duduk jiwakm2 pdrb komponen pkrt adhk miliar rp periode data data tahun 1985 2022 pilih model baik banding nilai rmse mape out sample nowcasting model svr msvr hasil teliti dasar nilai baik model nowcasting model svr performa banding model msvr nilai mape out sample nowcasting model svr banding model msvr variabel output proyeksi duduk hasil metode nowcasting performa banding metode ccmstatistical data and information as well as their projections are an important basis for planning and evaluation of future national development especially in the medium and long term development these data can not be provided through the population registration system hence the data obtained from censuses and surveys conducted by badan pusat statistik bps statistics indonesia the common method is cohort component method ccm ccm is widely used in many countries including indonesia which still be utilized by bps unfortunately this method has several drawbacks and therefore more accurate method is required to outperform ccm one of these methods is nowcasting time series analysis can now be conducted not only using classical statistical but also machine learning ml machine learning is a new method in statistical forecasting that shows an excellent performance compared to classical statistical methods machine learning algorithms that are commonly used in sequential analysis are support vector regression svr and multioutput svr msvr where both of these algorithms can perform nowcasting svr is also capable of producing excellent projections in a variety of disciplines however svr is only able to handle single output meanwhile msvr is capable of handling multioutput regression problems such as the number of populations in several provinces in java island which are correlated with each other the data used was obtained from the bps and the output variable is the population of dki jakarta west java central java and east java provinces the variables used as inputs are the number of electricity consumers for the household group the number of workers the number of households the population density peoplekm2 and the grdp of the pkrt adhk component billion rp the data period used spans from 1985 to 2022 with annual data comparing the svr and msvr models rmse and mape values enables the selection of the optimal model the results showed that based on the quality of the model the svr nowcasting model outperformed the msvr model as shown by the svr nowcasting models out sample mape value which was lower for all output variables than mape value from msvr in addition the efficacy of the population projections derived from the nowcasting method is outperform than ccm method
Pengembangan Sistem Deteksi Kebocoran Air Berbasis Support Vector Machine Pada Jaringan Distribusi Air Di Perumda Air Minum Tugu Tirta Malang.,"Wicaksana, Farhan Arief",http://repository.its.ac.id/109411/,"Di Indonesia, PDAM (Perusahaan Daerah Air Minum) mendistribusikan air minum kepada masyarakat melalui jaringan pipa. Pada penggunaan jaringan pipa, seringkali pipa ditempatkan di bawah tanah di area luas, menyulitkan operator untuk memantau aliran air dan kondisi pipa karena keterbatasan peralatan dan tenaga. Oleh karena itu, penelitian ini menggunakan Artificial Intelligence sebagai opsi metode deteksi kebocoran air dengan memprediksi tekanan yang tercatat pada datalogger DMA(District Meter Area). Algoritma SVM (Support Vector Machine)  yang digunakan sendiri untuk memprediksi hasil tekanan pada DMA yang dianalisis. Dalam penelitian tugas akhir ini, setelah melalui studi literatur dan lapangan, kemudian hasil dari software tersebut akan dimasukkan kedalam algoritma SVM. Hasil menunjukkan untuk perfomansi algoritma pada ukuran kebocoran pada DMA TL 2.2I memiliki nilai akurasi sebesar 93.5% dan F1 score sebesar 93.25% dan untuk perfomansi algoritma pada lokalisasi area kebocoran memiliki nilai akurasi sebesar 93.30% dan F1 score sebesar 93.80%. Kemudian untuk perbedaan perfomansi menggunakan data lapangan memiliki perbedaan nilai, untuk nilai akurasi dari pemodelan ukuran kebocoran menggunakan data lapangan yaitu sebesar 82.10% dan F1 score 90% serta untuk pemodelan lokalisasi area kebocoran yaitu memiliki nilai akurasi sebesar 85.71% dan F1 score 92 %. Dengan nilai perfomansi seperti yang ditunjukan pada pemodelan, maka dapat disimpulkan algoritma SVM dapat digunakan untuk mendeteksi adanya kebocoran air pada jaringan distribusi air.====================================================================================================================================In Indonesia, PDAMs (Regional Water Supply Companies) distribute drinking water to the public through pipelines. In the use of pipelines, pipes are often placed underground in large areas, making it difficult for operators to monitor water flow and pipe conditions due to limited equipment and manpower. Therefore, this research uses Artificial Intelligence as an option for water leak detection methods by predicting the pressure recorded in the DMA (District Meter Area) datalogger. The SVM (Support Vector Machine) algorithm is used alone to predict the pressure results on the analyzed DMA. In this final project research, after going through literature and field studies, then the results of the software will be entered into the SVM algorithm. The results show that the algorithm performance on leakage size in DMA TL 2.2I has an accuracy value of 93.5% and F1 score of 93.25% and for the algorithm performance on leakage area localization has an accuracy value of 93.30% and F1 score of 93.80%. Then for the difference in performance using acquisition data has a difference in value, for the accuracy value of the leak size modeling using acquisition data is 82.10% and F1 score 90% and for modeling the leak area localization which has an accuracy value of 85.71% and F1 score 92%. With the performance value as shown in the modeling, it can be concluded that the SVM algorithm can be used to detect water leaks in the water distribution network.",kembang sistem deteksi bocor air bas support vector machine jaring distribusi air perumda air minum tugu tirta malang,indonesia pdam usaha daerah air minum distribusi air minum masyarakat jaring pipa guna jaring pipa seringkali pipa tempat tanah area luas sulit operator pantau alir air kondisi pipa batas alat tenaga teliti artificial intelligence opsi metode deteksi bocor air prediksi tekan catat datalogger dmadistrict meter area algoritma svm support vector machine prediksi hasil tekan dma analis teliti tugas studi literatur lapang hasil software masuk dalam algoritma svm hasil perfomansi algoritma ukur bocor dma tl 22i milik nilai akurasi 935 f1 score 9325 perfomansi algoritma lokalisasi area bocor milik nilai akurasi 9330 f1 score 9380 beda perfomansi data lapang milik beda nilai nilai akurasi model ukur bocor data lapang 8210 f1 score 90 model lokalisasi area bocor milik nilai akurasi 8571 f1 score 92 nilai perfomansi tunjuk model simpul algoritma svm deteksi bocor air jaring distribusi airin indonesia pdams regional water supply companies distribute drinking water to the public through pipelines in the use of pipelines pipes are often placed underground in large areas making it difficult for operators to monitor water flow and pipe conditions due to limited equipment and manpower therefore this research uses artificial intelligence as an option for water leak detection methods by predicting the pressure recorded in the dma district meter area datalogger the svm support vector machine algorithm is used alone to predict the pressure results on the analyzed dma in this final project research after going through literature and field studies then the results of the software will be entered into the svm algorithm the results show that the algorithm performance on leakage size in dma tl 22i has an accuracy value of 935 and f1 score of 9325 and for the algorithm performance on leakage area localization has an accuracy value of 9330 and f1 score of 9380 then for the difference in performance using acquisition data has a difference in value for the accuracy value of the leak size modeling using acquisition data is 8210 and f1 score 90 and for modeling the leak area localization which has an accuracy value of 8571 and f1 score 92 with the performance value as shown in the modeling it can be concluded that the svm algorithm can be used to detect water leaks in the water distribution network
Pemanfaatan Komputasi Awan untuk Pengenalan Ekspresi Wajah menggunakan AWS DeepLens.,"Widojoko, Gregorius Rafael",http://repository.its.ac.id/81986/,"Komunikasi tatap-muka merupakan suatu bentuk interaksi yang sering dilakukan oleh semua orang. Akan tetapi, hal tersebut sulit untuk diimplementasikan bagi penyandang tuna netra, terutama bagi mereka untuk mengenali ekspresi wajah dari lawan bicaranya dan ekspresi wajah dipercayai mempunyai kaitan erat dalam emosi seseorang dan memberikan informasi yang lebih lengkap saat berkomunikasi.  Oleh karena itu, diperlukanlah suatu alat yang bisa membaca ataupun mengenali ekspresi wajah, sehingga para penyandang tuna netra dapat mengenali ekspresi wajah dari lawan bicaranya dengan jelas dan ekspresi itu dikonversikan menjadi informasi non-verbal berupa suara yang mengindikasikan ekspresi dari lawan bicara penyandang tuna netra.Penelitian tentang pengenalan ekspresi wajah kepada penyandang tunanetra telah banyak dilakukan. Akan tetapi, salah satu skenario kendala yang dihadapi dari beberapa penelitian sebelumnya adalah biaya pembuatan dan performa yang kurang sesuai dengan pengguna. Pada penelitian ini akan digunakan perangkat untuk komputasi awan dan pembelajaran mesin AWS DeepLens yang bertujuan untuk mencari performa dari perangkat yang menggunakan layanan komputasi awan AWS dan membandingkannya dengan performa dari alat yang menggunakan pemrograman deep learning tanpa komputasi awan. Semua bentuk keluaran dari perangkat akan menyampaikan informasi pengenalan ekspresi ke pengguna melalui media suara. Keberhasilan algoritma deep learning akan diukur dalam confusion matrix dengan rerata keberhasilan sebesar 73,43 % . Alat yang dikembangkan dari divais AWS DeepLens ini menggunakan sistem komputasi awan dari AWS, dengan harapan alat ini robust secara sistem dan real-time dalam penggunaannya.",manfaat komputasi awan kenal ekspresi wajah aws deeplens,komunikasi tatapmuka bentuk interaksi orang sulit implementasi sandang tuna netra nali ekspresi wajah lawan bicara ekspresi wajah percaya kait erat emosi informasi lengkap komunikasi perlu alat baca nali ekspresi wajah sandang tuna netra nali ekspresi wajah lawan bicara ekspresi konversi informasi nonverbal suara indikasi ekspresi lawan bicara sandang tuna netrapenelitian kenal ekspresi wajah sandang tunanetra salah skenario kendala hadap teliti biaya buat performa sesuai guna teliti perangkat komputasi awan ajar mesin aws deeplens tuju cari performa perangkat layan komputasi awan aws banding performa alat pemrograman deep learning komputasi awan bentuk keluar perangkat informasi kenal ekspresi guna media suara hasil algoritma deep learning ukur confusion matrix rerata hasil 7343 alat kembang divais aws deeplens sistem komputasi awan aws harap alat robust sistem realtime guna
Analisis Sentimen Twitter Pada Initial Public  Offering Saham GOTO Tahun 2022 Dengan  Menggunakan Support Vector Machine.,"Wijaya, Ikhlasul Ikhwan",http://repository.its.ac.id/99758/,"Initial Public Offering atau biasa disingkat IPO merupakan sebuah penarawaran saham kepada  publik dengan penjualan pertama dari suatu perusahaan kepada masyarakat sehingga perusahaan yang  bersangkutan status perusahaanya berubah yang semula berupa perusahaan swasta menjadi perusahaan  publik. Initial Public Offering sendiri biasanya dikelola oleh bank yang membantu investasi yang  fungsinya mencatat saham di bursa efek, tujuan dari IPO sebuah perusahaan sendiri adalah untuk  meningkatkan modal ekuitas baru bagi perusahaan. Kinerja dari perusahaan sendiri sangat berpengaruh  pada penawaran kepada publik, apabila dari masyarakat memiliki banyak sentimen buruk maka akan  sangat berpengaruh terhadap minat beli dan harga saham pada pembukaan saham. Oleh karena itu,  penting untuk mengetahui seberapa besar sentimen dan minat pada saham yang akan IPO. Tujuan  penelitian kali ini adalah untuk mengklasifikasi seberapa besar sentimen masyarakat melalui twitter  terhadap beberapa perusahaan pada kuartal 2 tahun 2022 yang rilis ke publik atau IPO. Metode yang  digunakan pada peneliain kali ini adalah support vector machine dengan menggunakan sumber data dari  crawling tweet dengan menggunakan package scrapping dari Python. Dari penelitian kali ini  didapatkan hasil tweets sebanyak 4873 tweets dengan presentase 22,8% sentimen positif dan  77,2% sentimen negatif dengan menggunakan tiga kali percobaan dengan data testing sebesar  20%, 30%, dan 40% dengan tiga kernel yang dicoba yaitu linear, radial basis function, dan  Sigmoid. Berdasarkan ketiga percobaan dengan menggunakan tiga kernel yang berbeda, dapat  didapatkan skor akurasi yang terbesar yaitu dengan menggunakan kernel linear dengan skor  akurasi sebesar 80% pada data testing 30% dan memiliki nilai sensitivity, precission dan recall sebesar 91%, 38%, 85% dan 89% pada nilai cost 50% dengan akurasi cost sebesar 80%===================================================================================================================================Initial Public Offering or commonly abbreviated as IPO is an offering of shares to the public with  the first sale of a company to the public so that the company concerned changes its company status from  a private company to a public company. Initial Public Offering itself is usually managed by an  investment bank whose function is to list shares on the stock exchange, the purpose of a company's own  IPO is to raise new equity capital for the company. The performance of the company itself is very  influential on the offer to the public, if the public has a lot of bad sentiment, it will greatly affect the  buying interest and share price at the opening of the stock. Therefore, it is important to know how much  sentiment and interest in stocks that will IPO. The purpose of this research is to classify how much  public sentiment through twitter towards several companies in the 2nd quarter of 2022 that are released  to the public or IPO. The method used in this research is support vector machine by using data sources  from crawling tweets using the scrapping package from Python. From this research, 4873 tweets were  obtained with a percentage of 22.8% positive sentiment and 77.2% negative sentiment using three  experiments with testing data of 20%, 30%, and 40% with three kernels tried, namely linear, radial basis  function, and Sigmoid. Based on the three experiments using three different kernels, the largest accuracy  score can be obtained by using a linear kernel with an accuracy score of 80% on 30% testing data and  has sensitivity, precission and recall values of 91%, 38%, 85% and 89% at a cost value of 50% with a  cost accuracy of 80%",analisis sentimen twitter initial public offering saham goto 2022 support vector machine,initial public offering singkat ipo penarawaran saham publik jual usaha masyarakat usaha sangkut status perusahaanya ubah usaha swasta usaha publik initial public offering kelola bank bantu investasi fungsi catat saham bursa efek tuju ipo usaha tingkat modal ekuitas usaha kerja usaha pengaruh tawar publik masyarakat milik sentimen buruk pengaruh minat beli harga saham buka saham sentimen minat saham ipo tuju teliti kali klasifikasi sentimen masyarakat twitter usaha kuartal 2 2022 rilis publik ipo metode peneliain kali support vector machine sumber data crawling tweet package scrapping python teliti kali dapat hasil tweets 4873 tweets presentase 228 sentimen positif 772 sentimen negatif kali coba data testing 20 30 40 kernel coba linear radial basis function sigmoid dasar tiga coba kernel beda dapat skor akurasi besar kernel linear skor akurasi 80 data testing 30 milik nilai sensitivity precission recall 91 38 85 89 nilai cost 50 akurasi cost 80initial public offering or commonly abbreviated as ipo is an offering of shares to the public with the first sale of a company to the public so that the company concerned changes its company status from a private company to a public company initial public offering itself is usually managed by an investment bank whose function is to list shares on the stock exchange the purpose of a companys own ipo is to raise new equity capital for the company the performance of the company itself is very influential on the offer to the public if the public has a lot of bad sentiment it will greatly affect the buying interest and share price at the opening of the stock therefore it is important to know how much sentiment and interest in stocks that will ipo the purpose of this research is to classify how much public sentiment through twitter towards several companies in the 2nd quarter of 2022 that are released to the public or ipo the method used in this research is support vector machine by using data sources from crawling tweets using the scrapping package from python from this research 4873 tweets were obtained with a percentage of 228 positive sentiment and 772 negative sentiment using three experiments with testing data of 20 30 and 40 with three kernels tried namely linear radial basis function and sigmoid based on the three experiments using three different kernels the largest accuracy score can be obtained by using a linear kernel with an accuracy score of 80 on 30 testing data and has sensitivity precission and recall values of 91 38 85 and 89 at a cost value of 50 with a cost accuracy of 80
Prototipe Sistem Rekomendasi Konten Hiburan Anak-Anak Dan Klasifikasi Kelompok Usia Berbasis Suara Pada Perangkat Tinyml (Tiny Machine Learning).,"Wijaya, Rayhan Kurnia Alunantara",http://repository.its.ac.id/106099/,"Era digital menuntut solusi inovatif untuk memastikan anak-anak mengakses konten hiburan yang sesuai usia. Sistem rekomendasi yang digunakan pada berbagai platform konten hiburan tidak dapat mengklasifikasikan usia anak-anak secara akurat dan memberikan konten yang sesuai untuk mereka. Oleh karena itu, penelitian ini bertujuan untuk mengembangkan prototipe sistem rekomendasi dan klasifikasi usia anak-anak berbasis suara menggunakan perangkat Tiny Machine Learning yang dapat menentukan kelompok usia anak-anak secara akurat. Model kunci dalam penelitian ini adalah Hybrid MLP (Hybrid Multilayer Perceptron), dimana digunakan teknik ekstraksi fitur MFCC (Mel-Frequency Cepstral Coefficients) untuk mengolah data suara. Dalam penelitian ini, dataset utama berasal dari Mozilla Common Voice dan dataset suara anak-anak Indonesia yang dikumpulkan secara mandiri. Dilakukan juga perbandingan dengan model-model yang telah dikembangkan sebelumnya pada dataset yang sama dimana model Hybrid MLP berhasil melebihi akurasi model pembanding tersebut. Pengembangan model klasifikasi usia dilakukan pada platform Edge Impulse dengan menggunakan Arduino Nano BLE 33 Sense Lite. Pengujian model dilakukan dengan memanfaatkan kata kunci 'oke' yang bertujuan untuk mengaktivasi dan mengevaluasi respons sistem. Dalam uji coba untuk mengklasifikasikan kelompok usia anak SD dan SMP dengan skenario optimasi paling optimal, Hybrid MLP berhasil menunjukkan tingkat akurasi pelatihan sebesar 97.6% serta akurasi validasi 87.72%. Hasil ini mengindikasikan efektivitas model dalam proses klasifikasi usia dalam kondisi sumber daya komputasi yang terbatas.==================================================================================================================================The digital age demands innovative solutions to ensure children access age-appropriate entertainment content. Recommendation systems used on various entertainment content platforms are unable to accurately classify children's age and provide appropriate content for them. Therefore, this research aims to develop a prototype of a voice-based children's age classification and recommendation system using Tiny Machine Learning tools that can accurately determine children's age groups. The key model in this research is Hybrid MLP (Hybrid Multilayer Perceptron), where MFCC (Mel-Frequency Cepstral Coefficients) feature extraction technique is used to process voice data. In this research, the main dataset comes from Mozilla Common Voice and Indonesian children's voice dataset collected independently. Comparisons were also made with previously developed models on the same dataset where the Hybrid MLP model successfully exceeded the accuracy of the comparison model. The age classification model development was conducted on the Edge Impulse platform using Arduino Nano BLE 33 Sense Lite. Model testing was conducted by utilizing the keyword 'oke' which aims to activate and evaluate the system response. In the test to classify the age groups of elementary and junior high school children with the most optimal optimization scenario, Hybrid MLP successfully showed a training accuracy rate of 97.6% and a validation accuracy of 87.72%. These results indicate the effectiveness of the model in the age classification process under conditions of limited computational resources.",prototipe sistem rekomendasi konten hibur anakanak klasifikasi kelompok usia bas suara perangkat tinyml tiny machine learning,era digital tuntut solusi inovatif anakanak akses konten hibur sesuai usia sistem rekomendasi platform konten hibur klasifikasi usia anakanak akurat konten sesuai teliti tuju kembang prototipe sistem rekomendasi klasifikasi usia anakanak bas suara perangkat tiny machine learning tentu kelompok usia anakanak akurat model kunci teliti hybrid mlp hybrid multilayer perceptron mana teknik ekstraksi fitur mfcc melfrequency cepstral coefficients olah data suara teliti dataset utama asal mozilla common voice dataset suara anakanak indonesia kumpul mandiri banding modelmodel kembang dataset mana model hybrid mlp hasil lebih akurasi model banding kembang model klasifikasi usia platform edge impulse arduino nano ble 33 sense lite uji model manfaat kunci oke tuju mengaktivasi evaluasi respons sistem uji coba klasifikasi kelompok usia anak sd smp skenario optimasi optimal hybrid mlp hasil tingkat akurasi latih 976 akurasi validasi 8772 hasil indikasi efektivitas model proses klasifikasi usia kondisi sumber daya komputasi terbatasthe digital age demands innovative solutions to ensure children access ageappropriate entertainment content recommendation systems used on various entertainment content platforms are unable to accurately classify childrens age and provide appropriate content for them therefore this research aims to develop a prototype of a voicebased childrens age classification and recommendation system using tiny machine learning tools that can accurately determine childrens age groups the key model in this research is hybrid mlp hybrid multilayer perceptron where mfcc melfrequency cepstral coefficients feature extraction technique is used to process voice data in this research the main dataset comes from mozilla common voice and indonesian childrens voice dataset collected independently comparisons were also made with previously developed models on the same dataset where the hybrid mlp model successfully exceeded the accuracy of the comparison model the age classification model development was conducted on the edge impulse platform using arduino nano ble 33 sense lite model testing was conducted by utilizing the keyword oke which aims to activate and evaluate the system response in the test to classify the age groups of elementary and junior high school children with the most optimal optimization scenario hybrid mlp successfully showed a training accuracy rate of 976 and a validation accuracy of 8772 these results indicate the effectiveness of the model in the age classification process under conditions of limited computational resources
Inversi Data Magnetotellurik (MT) 1-D Menggunakan Algoritma Ensemble Kalman Inversion (EKI).,"Wijdannysa, Jasinda",http://repository.its.ac.id/115180/,"Metode magnetotellurik (MT) merupakan metode eksplorasi geofisika pasif yang dapat menjangkau kedalaman lapisan batuan yang sangat dalam, sehingga cocok digunakan untuk penentuan kedalaman basemen. Untuk menentukan kedalaman basemen, data MT diinversikan agar mendapatkan estimasi parameter model (resistivitas dan ketebalan lapisan batuan). Pada penelitian ini, algoritma Ensemble Kalman Inversion (EKI) digunakan untuk melakukan inversi data MT 1-D. Algoritma EKI dilakukan uji coba pada data sintetik tipe kurva sounding (A, K, H, Q, D, Q) serta data sintetik kasus cekungan sedimen. Setelahnya, hasil inversi pada setiap data sintetik tersebut dianalisis posterior distribution model (PDM) dan principal component analysis (PCA). Analisis PDM dilakukan untuk mengestimasi ketidakpastian parameter model terbaik hasil inversi, sedangkan analisis PCA digunakan untuk mengkorelasikan parameter model sebenarnya pada data sintetik dengan parameter model hasil inversi. Hasil analisis PDM pada data sintetik A, K, H, Q, D, dan Q menunjukkan estimasi model parameter yang sesuai dengan model sebenarnya, sedangkan hasil analisis PCA menunjukkan model sebenarnya dan model terbaik yang berhimpit untuk setiap tipe kurva dan berada pada nilai fungsi objektif yang minimum. Hal ini mengindikasikan bahwa algoritma EKI terbukti robust dalam uji coba data sintetik tipe kurva sounding. Analisis yang sama juga dilakukan pada data MT sintetik untuk kasus cekungan sedimen. Namun, untuk data ini model terbaik pada analisis PDM menunjukkan hasil yang berbeda dari model sebenarnya, serta jarak model sebenarnya dengan model terbaik hasil inversi yang berjauhan pada ruang PCA. Hal ini menunjukkan bahwa algoritma EKI belum akurat dalam menentukan estimasi model parameter pada kasus cekungan sedimen sintetik, khususnya dalam penentuan parameter model resistivitas lapisan basemen.=================================================================================================================================The magnetotelluric (MT) method is a passive geophysical exploration technique that can probe deep rock layers, making it ideal for determining basement depths. To achieve this, inversion modeling of MT data is performed to estimate model parameters such as resistivity and rock layer thickness. This research utilizes the Ensemble Kalman Inversion (EKI) algorithm for 1-D MT data inversion. The EKI algorithm was tested on synthetic sounding curve data types (A, K, H, Q, D, Q) and synthetic data in the case of sedimentary basins. The inversion results for each synthetic dataset were analyzed using posterior distribution model (PDM) and principal component analysis (PCA). PDM analysis estimates the uncertainty of the best model parameters from the inversion, while PCA correlates the actual model parameters of synthetic data with the inversion results. For synthetic sounding curve data, PDM analysis indicated that the estimated model parameters matched the actual model, and PCA analysis showed the actual and best models coinciding at the minimum objective function value. This demonstrates the robustness of the EKI algorithm for synthetic sounding curve data. For synthetic MT data representing sedimentary basins, the PDM analysis showed discrepancies between the best model and the actual model, with a significant distance between them in PCA space. This suggests that the EKI algorithm is less accurate in estimating model parameters for synthetic sedimentary basin cases, particularly in determining basement layer resistivity model.",inversi data magnetotellurik mt 1d algoritma ensemble kalman inversion eki,metode magnetotellurik mt metode eksplorasi geofisika pasif jangkau dalam lapis batu cocok tentu dalam basemen tentu dalam basemen data mt inversi estimasi parameter model resistivitas tebal lapis batu teliti algoritma ensemble kalman inversion eki inversi data mt 1d algoritma eki uji coba data sintetik tipe kurva sounding a k h q d q data sintetik cekung sedimen telah hasil inversi data sintetik analis posterior distribution model pdm principal component analysis pca analisis pdm estimasi ketidakpastian parameter model baik hasil inversi analisis pca korelasi parameter model data sintetik parameter model hasil inversi hasil analisis pdm data sintetik a k h q d q estimasi model parameter sesuai model hasil analisis pca model model baik berhimpit tipe kurva nilai fungsi objektif minimum indikasi algoritma eki bukti robust uji coba data sintetik tipe kurva sounding analisis data mt sintetik cekung sedimen data model baik analisis pdm hasil beda model jarak model model baik hasil inversi jauh ruang pca algoritma eki akurat tentu estimasi model parameter cekung sedimen sintetik tentu parameter model resistivitas lapis basementhe magnetotelluric mt method is a passive geophysical exploration technique that can probe deep rock layers making it ideal for determining basement depths to achieve this inversion modeling of mt data is performed to estimate model parameters such as resistivity and rock layer thickness this research utilizes the ensemble kalman inversion eki algorithm for 1d mt data inversion the eki algorithm was tested on synthetic sounding curve data types a k h q d q and synthetic data in the case of sedimentary basins the inversion results for each synthetic dataset were analyzed using posterior distribution model pdm and principal component analysis pca pdm analysis estimates the uncertainty of the best model parameters from the inversion while pca correlates the actual model parameters of synthetic data with the inversion results for synthetic sounding curve data pdm analysis indicated that the estimated model parameters matched the actual model and pca analysis showed the actual and best models coinciding at the minimum objective function value this demonstrates the robustness of the eki algorithm for synthetic sounding curve data for synthetic mt data representing sedimentary basins the pdm analysis showed discrepancies between the best model and the actual model with a significant distance between them in pca space this suggests that the eki algorithm is less accurate in estimating model parameters for synthetic sedimentary basin cases particularly in determining basement layer resistivity model
Prediksi Mahasiswa Drop Out Institut Teknologi Sepuluh Nopember Menggunakan XGBoost dan SHAP Values Berbasis Dashboard Interaktif.,"Winarso, Raihan Adam Handoyo",http://repository.its.ac.id/105897/,"Peran mahasiswa menjadi aspek penting dalam menentukan keberhasilan penyelenggaraan pendidikan. Namun, tidak semua mahasiswa dapat menyelesaikan studi tepat waktu sesuai dengan yang direncanakan, hingga terancam drop out. Drop out atau pemberhentian status mahasiswa adalah proses pencabutan status kemahasiswaan, yang disebabkan oleh hal-hal tertentu atau sudah ditentukan oleh perguruan tinggi yang bersangkutan. Fenomena ini menjadi tantangan bagi institusi, yang harus ditemukan solusinya, karena drop out menimbulkan kerugian signifikan baik pada mahasiswa maupun institusi. Langkah preventif untuk memprediksi mahasiswa yang berpotensi drop out dilakukan dengan menggunakan teknik klasifikasi menggunakan XGBoost dan SHAP Values. XGBoost adalah algoritma klasifikasi yang menggunakan teknik boosting, yaitu langkah berulang untuk memperkuat performa model klasifikasi lemah hingga akhirnya menjadi model yang lebih kuat. Setelah model XGBoost terbentuk, interpretasi dilakukan dengan melihat rata-rata kontribusi setiap variabel menggunakan SHAP Values. Hasil penelitian ini menunjukkan bahwa semester yang sudah dijalani, IPK persiapan, dan IPK mahasiswa memiliki kontribusi besar dalam menentukan status mahasiswa sebagai drop out atau tidak drop out. Model XGBoost yang terbentuk memberikan kebaikan model dengan akurasi sebesar 100%, sensitivitas sebesar 100%, dan spesifisitas sebesar 100%. Dashboard prediksi mahasiswa drop out atau tidak drop out memiliki 4 menu yaitu menu dashboard untuk melihat karakteristik dari mahasiswa ketika data imbalance dan balance, menu kedua yaitu data mahasiswa untuk menampilkan data mahasiswa secara keseluruhan, menu ketiga yaitu prediksi untuk melakukan prediksi dengan cara input variabel yang diduga memengaruhi status mahasiswa, dan yang terakhir adalah kontribusi variabel untuk melihat besar kontribusi variabel yang digunakan dalam memprediksi status mahasiswa.=================================================================================================================================The role of students is an important aspect in determining the success of educational provision. However, not all students can complete their studies on time as planned, so they are threatened with dropping out. Drop out or termination of student status is the process of revoking student status, which is caused by certain reasons or has been determined by the university concerned. This phenomenon is a challenge for institutions, which must find a solution, because dropping out causes significant losses to both students and institutions. Preventive steps to predict students who have the potential to drop out are carried out using classification techniques using XGBoost and SHAP Values. XGBoost is a classification algorithm that uses a boosting technique, namely repeated steps to strengthen the performance of a weak classification model until it finally becomes a stronger model. After the XGBoost model is formed, interpretation is carried out by looking at the average contribution of each variable using SHAP Values. The results of this research show that the semester that has been completed, the preparatory GPA, and the student's GPA have a major contribution in determining a student's status as a dropout or not. The XGBoost model formed provides a good model with an accuracy of 100%, sensitivity of 100%, and specificity of 100%. The dashboard predicting whether students will drop out or not drop out has 4 menus, namely the dashboard menu to see the characteristics of students when the data is imbalanced and balanced, the second menu is student data to display overall student data, the third menu is prediction to make predictions by inputting the specified variables. is thought to influence student status, and the last is variable contribution to see the contribution of the variables used in predicting student status.",prediksi mahasiswa drop out institut teknologi puluh nopember xgboost shap values bas dashboard interaktif,peran mahasiswa aspek tentu hasil selenggara didik mahasiswa selesai studi sesuai rencana ancam drop out drop out henti status mahasiswa proses cabut status mahasiswa sebab halhal tentu guru sangkut fenomena tantang institusi temu solusi drop out timbul rugi signifikan mahasiswa institusi langkah preventif prediksi mahasiswa potensi drop out teknik klasifikasi xgboost shap values xgboost algoritma klasifikasi teknik boosting langkah ulang kuat performa model klasifikasi lemah model kuat model xgboost bentuk interpretasi ratarata kontribusi variabel shap values hasil teliti semester jalan ipk siap ipk mahasiswa milik kontribusi tentu status mahasiswa drop out drop out model xgboost bentuk baik model akurasi 100 sensitivitas 100 spesifisitas 100 dashboard prediksi mahasiswa drop out drop out milik 4 menu menu dashboard karakteristik mahasiswa data imbalance balance menu data mahasiswa tampil data mahasiswa menu tiga prediksi prediksi input variabel duga pengaruh status mahasiswa kontribusi variabel kontribusi variabel prediksi status mahasiswathe role of students is an important aspect in determining the success of educational provision however not all students can complete their studies on time as planned so they are threatened with dropping out drop out or termination of student status is the process of revoking student status which is caused by certain reasons or has been determined by the university concerned this phenomenon is a challenge for institutions which must find a solution because dropping out causes significant losses to both students and institutions preventive steps to predict students who have the potential to drop out are carried out using classification techniques using xgboost and shap values xgboost is a classification algorithm that uses a boosting technique namely repeated steps to strengthen the performance of a weak classification model until it finally becomes a stronger model after the xgboost model is formed interpretation is carried out by looking at the average contribution of each variable using shap values the results of this research show that the semester that has been completed the preparatory gpa and the students gpa have a major contribution in determining a students status as a dropout or not the xgboost model formed provides a good model with an accuracy of 100 sensitivity of 100 and specificity of 100 the dashboard predicting whether students will drop out or not drop out has 4 nus namely the dashboard menu to see the characteristics of students when the data is imbalanced and balanced the second menu is student data to display overall student data the third menu is prediction to make predictions by inputting the specified variables is thought to influence student status and the last is variable contribution to see the contribution of the variables used in predicting student status
Sistem Klasifikasi Kondisi Motor Dust Collector Menggunakan Model Support Vector Machine (SVM) Guna Menunjang Condition-Based Maintenance.,"Winata, Nurdiwansyah Bagus",http://repository.its.ac.id/115583/,"Perusahaan Pestisida MSI merupakan salah satu perusahaan yang bergerak di bidang formulasi pestisida. Pada proses produksi, terdapat satu mesin penting yang menggunakan motor induksi 3 fasa sebagai penggerak utama, yaitu mesin dust collector. Namun, dalam dua tahun terakhir, terjadi sembilan kali kasus kerusakan pada mesin dust collector di MSI. Kerusakan tersebut terbagi menjadi beberapa jenis kerusakan, seperti kerusakan bearing, shaft misalignment, dan motor terbakar. Untuk mencegah kerusakan pada motor diperlukan penerapan metode maintenance yang efektif. Dengan data historis yang terbatas, metode Condition-Based Maintenance (CBM) adalah metode yang efektif. Dengan melakukan pemeliharaan hanya saat diperlukan berdasarkan kondisi aktual peralatan, CBM dapat mengurangi biaya yang tidak perlu dan mengurangi downtime yang tidak direncanakan. Dibantu dengan model Support Vector Machine (SVM), CBM pada proyek ini bertujuan untuk mengklasifikasikan kondisi motor secara aktual. Motor dengan kondisi normal, shaft miasalignment, dan bearing damage menjadi target klasifikasi pada proyek ini. Klasifikasi kondisi motor tersebut mengacu kepada data historis getaran dan suhu permukaan motor secara aktual. Dari penelitian yang telah dilakukan, pembacaan sensor HVT100 pada nilai getaran memiliki error sebesar 2,16% dan nilai suhu permukaan motor memiliki galat sebesar 3,89% dari 20 kali percobaan. Metode Support Vector Machine (SVM) menggunakan multiclass strategy OneVsOne (OVO) dan OneVsRest (OVR) dapat mengklasifikasikan kondisi motor normal, shaft misalignment, dan bearing damage secara aktual dengan akurasi dari 66% hingga 100%.==================================================================================================================================Pesticide company MSI is one of the companies active in the field of pesticide formulation. In the production process, there's one important engine that uses a three-phase induction motor as its primary driver, a dust collector. However, in the last two years, there have been nine cases of damage to the dust collection machine at MSI. Such damage is divided into several types of damage, such as bearing damage, shaft misalignment, and motorcycle burning. To prevent damage to the motorcycle, effective maintenance methods are required. With limited historical data, the Condition-Based Maintenance (CBM) method is an effective method. By performing maintenance only when necessary based on the actual condition of the equipment, CBM can reduce unnecessary costs and reduce unplanned downtime. Assisted by the Support Vector Machine (SVM) model, the CBM in this project aims to classify the motor condition in actual terms. Motorcycles in normal condition, shaft misalignment, and bearing damage are classified targets on this project. The classification of the condition of the motor refers to the historical data of the vibration and surface temperature of the actual motor. From the research that has been carried out the HVT100 sensor readings on the vibration value had an error of 2.16% and the surface temperature value of the motor had a error of 3.89% of 20 trials. Support Vector Machine (SVM) methods using multiclass strategies OneVsOne (OVO) and OneVsRest (OVR) can classify normal motor conditions, shaft misalignment, and bearing damage effectively with accuracy from 66% up to 100%.",sistem klasifikasi kondisi motor dust collector model support vector machine svm tunjang conditionbased maintenance,usaha pestisida msi salah usaha gerak bidang formulasi pestisida proses produksi mesin motor induksi 3 fasa gerak utama mesin dust collector sembilan kali rusa mesin dust collector msi rusa bagi jenis rusa rusa bearing shaft misalignment motor bakar cegah rusa motor terap metode maintenance efektif data historis batas metode conditionbased maintenance cbm metode efektif pelihara dasar kondisi aktual alat cbm kurang biaya kurang downtime rencana bantu model support vector machine svm cbm proyek tuju klasifikasi kondisi motor aktual motor kondisi normal shaft miasalignment bearing damage target klasifikasi proyek klasifikasi kondisi motor acu data historis getar suhu muka motor aktual teliti baca sensor hvt100 nilai getar milik error 216 nilai suhu muka motor milik galat 389 20 kali coba metode support vector machine svm multiclass strategy onevsone ovo onevsrest ovr klasifikasi kondisi motor normal shaft misalignment bearing damage aktual akurasi 66 100pesticide company msi is one of the companies active in the field of pesticide formulation in the production process theres one important engine that uses a threephase induction motor as its primary driver a dust collector however in the last two years there have been nine cases of damage to the dust collection machine at msi such damage is divided into several types of damage such as bearing damage shaft misalignment and motorcycle burning to prevent damage to the motorcycle effective maintenance methods are required with limited historical data the conditionbased maintenance cbm method is an effective method by performing maintenance only when necessary based on the actual condition of the equipment cbm can reduce unnecessary costs and reduce unplanned downtime assisted by the support vector machine svm model the cbm in this project aims to classify the motor condition in actual terms motorcycles in normal condition shaft misalignment and bearing damage are classified targets on this project the classification of the condition of the motor refers to the historical data of the vibration and surface temperature of the actual motor from the research that has been carried out the hvt100 sensor readings on the vibration value had an error of 216 and the surface temperature value of the motor had a error of 389 of 20 trials support vector machine svm methods using multiclass strategies onevsone ovo and onevsrest ovr can classify normal motor conditions shaft misalignment and bearing damage effectively with accuracy from 66 up to 100
Simulasi Performa Sistem Suspensi Semi Aktif Dengan Kendali PID Pada Kendaraan Roda Dua.,"Yahya, Nur Muhammad Adi",http://repository.its.ac.id/107805/,"Seiring dengan perkembangan sepeda motor dalam masyarakat, spesifikasi kendaraan roda dua masih terbatas pada suspensi standar yang menggunakan sistem pasif. Dimana sistem suspensi ini belum mampu secara optimal mengatasi getaran yang timbul akibat berbagai kondisi jalan. Ketidakmampuan mengisolasi getaran mengakibatkan ketidaknyamanan bagi pengendara. Pada proyek akhir ini, dilakukan perancangan simulasi sistem suspensi semi aktif yang dapat menghasilkan respon keseluruhan dari model kendaraan roda dua yang sesuai dengan standar kenyamanan ISO 2631 dengan menggunakan kendali PID. Metode autotuning digunakan untuk menentukan nilai parameter pengendali PID. Hasil autotuning menghasilkan nilai Kp = 36836, Ki = 212093, dan Kd = 17587. Perancangan simulasi dilakukan dengan variasi kecepatan yang berbeda yaitu 15 km/jam, 30 km/jam, dan 45 km/jam. Terdapat tiga jenis lintasan pengganggu jalan yang digunakan, yaitu step, impulse, dan sinusoidal. Perancangan ini bertujuan untuk mendapatkan hasil respon percepatan dan simpangan yang dialami  bodi kendaraan dari sistem suspensi semi aktif yang dibantu oleh gaya aktuator, dan membandingkannya dengan sistem suspensi pasif. Dari hasil simulasi yang dilakukan, sistem suspensi semi aktif yang dirancang dapat menghasilkan respon percepatan pada bodi kendaraan yang sesuai dengan ISO 2631. Seluruh parameter dari sistem suspensi semi aktif yang dirancang menghasilkan rentang nilai displacement 0.0005 – 0.006 m, nilai settling time selama 0.5 – 2s ,serta nilai a_{rms} sebesar 0.050 – 0.28 {m/s}^2,dimana nilai ini sudah sesuai dengan standar kenyamanan yang sudah ditetapkan ISO 2631 yaitu a_{rms}< 0.315 {m/s}^2.=================================================================================================================================Along with the development of motorbikes in society, the specifications of two-wheeled vehicles are still limited to standard suspensions that use passive systems. Where this suspension system has not been able to optimally overcome vibrations arising from various road conditions. The inability to isolate vibrations results in discomfort for the rider. In this final project, a semi-active suspension system simulation design is carried out that can produce an overall response from a two-wheeled vehicle model that complies with ISO 2631 comfort standards using PID control. The autotuning method is used to determine the value of the PID controller parameters. The autotuning results produce values of Kp = 36836, Ki = 212093, and Kd = 17587. The simulation design is carried out with different speed variations of 15 km/h, 30 km/h, and 45 km/h. There are three types of road disturbance trajectories used, namely step, impulse, and sinusoidal. This design aims to get the results of the acceleration and deviation response experienced by the vehicle body of the semi-active suspension system assisted by the actuator force, and compare it with the passive suspension system. From the simulation results, the designed semi-active suspension system can produce an acceleration response on the vehicle body in accordance with ISO 2631. All parameters of the designed semi-active suspension system produce a displacement value range of 0.0005 - 0.006 m, a settling time value of 0.5 - 2s, and a_{rms} value of 0.050 - 0.28 {m/s}^2., where this value is in accordance with the comfort standards set by ISO 2631, namely a_{rms} < 0.315 {m/s}^2.",simulasi performa sistem suspensi semi aktif kendali pid kendara roda,iring kembang sepeda motor masyarakat spesifikasi kendara roda batas suspensi standar sistem pasif mana sistem suspensi optimal atas getar timbul akibat kondisi jalan ketidakmampuan isolasi getar akibat ketidaknyamanan kendara proyek ancang simulasi sistem suspensi semi aktif hasil respon model kendara roda sesuai standar nyaman iso 2631 kendali pid metode autotuning tentu nilai parameter kendali pid hasil autotuning hasil nilai kp 36836 ki 212093 kd 17587 ancang simulasi variasi cepat beda 15 kmjam 30 kmjam 45 kmjam jenis lintas ganggu jalan step impulse sinusoidal ancang tuju hasil respon cepat simpang alami bodi kendara sistem suspensi semi aktif bantu gaya aktuator banding sistem suspensi pasif hasil simulasi sistem suspensi semi aktif rancang hasil respon cepat bodi kendara sesuai iso 2631 parameter sistem suspensi semi aktif rancang hasil rentang nilai displacement 00005  0006 m nilai settling time 05  2s nilai arms 0050  028 ms2dimana nilai sesuai standar nyaman tetap iso 2631 arms 0315 ms2along with the development of motorbikes in society the specifications of twowheeled vehicles are still limited to standard suspensions that use passive systems where this suspension system has not been able to optimally overcome vibrations arising from various road conditions the inability to isolate vibrations results in discomfort for the rider in this final project a semiactive suspension system simulation design is carried out that can produce an overall response from a twowheeled vehicle model that complies with iso 2631 comfort standards using pid control the autotuning method is used to determine the value of the pid controller parameters the autotuning results produce values of kp 36836 ki 212093 and kd 17587 the simulation design is carried out with different speed variations of 15 kmh 30 kmh and 45 kmh there are three types of road disturbance trajectories used namely step impulse and sinusoidal this design aims to get the results of the acceleration and deviation response experienced by the vehicle body of the semiactive suspension system assisted by the actuator force and compare it with the passive suspension system from the simulation results the designed semiactive suspension system can produce an acceleration response on the vehicle body in accordance with iso 2631 all parameters of the designed semiactive suspension system produce a displacement value range of 00005 0006 m a settling time value of 05 2s and arms value of 0050 028 ms2 where this value is in accordance with the comfort standards set by iso 2631 namely arms 0315 ms2
Sistem Rejector Label Kemasan Susu Menggunakan Image processing Dengan Metode Support Vector Machine Pada Industri Pengolahan Susu.,"Yuliyanto, Jefrin",http://repository.its.ac.id/89605/,"Pada pabrik pengolahan susu, terdapat beberapa permasalahan saat pemasangan label kemasan botol susu. Permasalahan tersebut adalah terjadinya gagal pemasangan atau sobeknya label pada saat dilakukan pemasangan label botol. Problem tersebut menjadi jobdesk tersendiri pada suatu pabrik, yang menyebabkan produk belum layak jual. Sehingga memerlukan perbaikan pada label dan produk harus di reject terlebih dahulu. Maka dari itu dirancang sebuah alat yang dapat mendeteksi kerusakan atau gagal pemasangan pada label kemasan susu menggunakan image processing dengan metode Gray Level Co-occurance Matrix (GLCM) sebagai pendeteksi texture dari objek dengan mengeluarkan nilai energy, entropy, homogeneity, dan contrast. Kemudian hasil pembacaan GLCM akan dilakukan klasifikasi menggunakan support vector machine (SVM) untuk memilah kondisi label botol. Jika salah label botol cacat maka botol akan di reject dan jika sempurna atau normal akan lanjut ke proses pengemasan. Hasil dari alat rejector label kemasan susu ini, Ketika mendeteksi label kemasan botol susu secara random menghasilkan nilai accuracy sebesar 85%, precission 90%, dan False Positive Rate 20%, Ketika dilakukan pengujian keseluruhan didapat hasil %error sebesar 20%.=====================================================================================================In milk processing plants, there are several problems when installing milk bottle packaging labels. The problem is the occurrence of failed installation or tearing of the label when the bottle label is installed. The problem becomes a separate job desk in a factory, which causes the product to be unfit for sale. So it requires improvement on the label and the product must be rejected first. Therefore, a tool is designed that can detect damage or failure of installation on milk packaging labels using image processing with the Gray Level Co-occurance Matrix (GLCM) method as a texture detector of objects by issuing energy, entropy, homogeneity, and contrast values. Then the results of the GLCM reading will be classified using a support vector machine (SVM) to sort out the condition of the bottle label. If the wrong bottle label is defective, the bottle will be rejected and if it is perfect or normal, it will continue to the packaging process. The results of this milk packaging label rejector tool, when detecting milk bottle packaging labels randomly produce an accuracy value of 85%, precision 90%, and a False Positive Rate of 20%. When the overall test is carried out, the result is an error of 20%.",sistem rejector label kemas susu image processing metode support vector machine industri olah susu,pabrik olah susu masalah pasang label kemas botol susu masalah gagal pasang sobek label pasang label botol problem jobdesk sendiri pabrik sebab produk layak jual baik label produk reject rancang alat deteksi rusa gagal pasang label kemas susu image processing metode gray level cooccurance matrix glcm deteksi texture objek keluar nilai energy entropy homogeneity contrast hasil baca glcm klasifikasi support vector machine svm mem kondisi label botol salah label botol cacat botol reject sempurna normal proses emas hasil alat rejector label kemas susu deteksi label kemas botol susu random hasil nilai accuracy 85 precission 90 false positive rate 20 uji hasil error 20in milk processing plants there are several problems when installing milk bottle packaging labels the problem is the occurrence of failed installation or tearing of the label when the bottle label is installed the problem becomes a separate job desk in a factory which causes the product to be unfit for sale so it requires improvement on the label and the product must be rejected first therefore a tool is designed that can detect damage or failure of installation on milk packaging labels using image processing with the gray level cooccurance matrix glcm method as a texture detector of objects by issuing energy entropy homogeneity and contrast values then the results of the glcm reading will be classified using a support vector machine svm to sort out the condition of the bottle label if the wrong bottle label is defective the bottle will be rejected and if it is perfect or normal it will continue to the packaging process the results of this milk packaging label rejector tool when detecting milk bottle packaging labels randomly produce an accuracy value of 85 precision 90 and a false positive rate of 20 when the overall test is carried out the result is an error of 20
Analisis Sentimen Dan Clustering Pada Pengguna Tiket.Com Menggunakan Metode Naïve Bayes Classifier Dan Support Vector Machine.,"Yuniar, Iga Amalia",http://repository.its.ac.id/100403/,"Tiket.com adalah perusahaan agen untuk pelayanan perjalanan daring yang berbasis website dan aplikasi untuk mobile phone atau perangkat desktop. Aplikasi tiket.com juga disebut sebagai pionir online travel agent (OTA) terbesar di Indonesia yang selalu memberikan inovasi handal untuk mempermudah pengguna ketika memesan tiket pesawat online, selain itu aplikasi ini melayani pesanan untuk penginapan, sewa mobil maupun menawarkan berbagai macam aktifitas hiburan dan menjadi satu-satunya mitra resmi PT Kereta Api Indonesia. Penelitian ini melakukan penelitian dengan topik analisis sentimen terhadap pengguna tiket.com. Dengan bantuan analisis sentimen, informasi yang sebelumnya tidak terstruktur dapat dirubah menjadi data yang lebih terstruktur. Selain itu sistem analisis sentimen ini dapat membantu perusahaan dalam memahami keinginan pelanggan berdasarkan review atau umpan balik pelanggan yang tulus dan spesifik untuk meningkatkan kualitas produk dan layanan perusahaan. Penelitian ini melakukan perbandingan hasil analisis sentimen pengguna tiket.com dengan menggunakan metode Naïve Bayes Classifier dan Support Vector Machine untuk membandingkan tingkat akurasi yang lebih akurat. dan mengelompokkan review pengguna yang mana memberikan respon positif atau negatif. Akurasi terbaik diperoleh dari klasifikasi dengan menggunakan algoritma Support Vector Machine Kernel RBF dengan indikator kinerja dengan menggunakan akurasi sebesar 93,1%, AUC sebesar 64,3% dan GMean sebesar 53,5%. dan dengan berdasarkan analisis Cluster K-means terdapat 2 kelompok opini yang terbentuk yaitu opini bersentimen positif, negatif.=================================================================================================================================Tiket.com is an online travel agent company which is website based and an application for mobile phone or desktop. Tiket.com is also known as the pioneer of the biggest online travel agent (OTA) in Indonesia which always provides reliable innovation to make users easier when they order a plane online, this application also provides accommodation, rent car or any other entertainment and became the only official partner for PT. Kereta Api Indonesia. This study conducts research on sentiment analysis towards users of tiket.com users. By using sentiment analysis, the unstructured information can be transformed to well-structured data. Besides, this sentiment analysis system can help the company to figure out what users want based on honest and specific reviews to approve quality of the product and company services. Researchers want to compare the result of sentiment analysis of tiket.com users by using the methods of Naive Bayes Classifier and Support Vector Machine. This research is done by comparing the accuracy level of the methods so can get the method with the most accurate analysis result. And cluster user reviews based on their positive, and negative responses using K-Means clustering analysis. The best accuracy is obtained from classification by using Support Vector Machine kernel RBF algorithm with performance indicator by using accuracy as 93,1%, AUC as 64,3% and G-mean as 53,5%. Based on the K-means clustering analysis, two opinion clusters have been formed, namely positive sentiment, negative sentiment.",analisis sentimen clustering guna tiketcom metode na ve bayes classifier support vector machine,tiketcom usaha agen layan jalan daring bas website aplikasi mobile phone perangkat desktop aplikasi tiketcom pionir online travel agent ota besar indonesia inovasi handal mudah guna mes tiket pesawat online aplikasi layan pesan inap sewa mobil tawar aktifitas hibur satusatunya mitra resmi pt kereta api indonesia teliti teliti topik analisis sentimen guna tiketcom bantu analisis sentimen informasi struktur rubah data struktur sistem analisis sentimen bantu usaha paham langgan dasar review umpan langgan tulus spesifik tingkat kualitas produk layan usaha teliti banding hasil analisis sentimen guna tiketcom metode na ve bayes classifier support vector machine banding tingkat akurasi akurat kelompok review guna respon positif negatif akurasi baik oleh klasifikasi algoritma support vector machine kernel rbf indikator kerja akurasi 931 auc 643 gmean 535 dasar analisis cluster kmeans 2 kelompok opini bentuk opini sentimen positif negatiftiketcom is an online travel agent company which is website based and an application for mobile phone or desktop tiketcom is also known as the pioneer of the biggest online travel agent ota in indonesia which always provides reliable innovation to make users easier when they order a plane online this application also provides accommodation rent car or any other entertainment and became the only official partner for pt kereta api indonesia this study conducts research on sentiment analysis towards users of tiketcom users by using sentiment analysis the unstructured information can be transformed to wellstructured data besides this sentiment analysis system can help the company to figure out what users want based on honest and specific reviews to approve quality of the product and company services researchers want to compare the result of sentiment analysis of tiketcom users by using the methods of naive bayes classifier and support vector machine this research is done by comparing the accuracy level of the methods so can get the method with the most accurate analysis result and cluster user reviews based on their positive and negative responses using kmeans clustering analysis the best accuracy is obtained from classification by using support vector machine kernel rbf algorithm with performance indicator by using accuracy as 931 auc as 643 and gmean as 535 based on the kmeans clustering analysis two opinion clusters have been formed namely positive sentiment negative sentiment
Pengembangan Algoritma Support Vector Machine (SVM) Multiclass untuk Prediktor Kategorik dengan Proportional Class Constraint.,"Yustanti, Wiyli",http://repository.its.ac.id/107355/,"Terdapat  tiga prinsip penting dalam pengelompokan Uang Kuliah Tunggal (UKT). Pertama, pengelompokan UKT harus berdasarkan pada tingkat kemampuan sosial ekonomi orang tua mahasiswa. Kedua, perguruan tinggi harus mencapai pendapatan negara bukan pajak (PNBP) melalui penerimaan pembayaran UKT berdasarkan target yang ditetapkan, dan yang ketiga adalah bahwa PTN sebagai lembaga pemerintah memiliki tanggung jawab sosial untuk menerima minimal 20% mahasiswa dari keluarga kurang mampu. Ketiga prinsip ini menjadi latar belakang utama dalam penelitian ini, sehingga dibutuhkan sebuah pengembangan metode klasifikasi UKT dengan memperhitungkan target penerimaan (revenue) PTN dan persyaratan proporsi minimal pada kelompok UKT rendah. Untuk penyelesaian masalah tersebut, perlu dikembangkan algoritma klasifikasi yang dapat mengakomodasi faktor kendala (constraint). Faktor kendala yang wajib ada adalah proporsi  kelas tertentu dari hasil klasifikasi (Proportional Class Constraint) dan jumlah minimal penerimaan UKT (revenue). Tipe variabel prediktor dari studi kasus penelitian ini adalah kategorik. Hasil kajian pustaka mendapatkan bahwa metode klasifikasi untuk prediktor kategorik yang secara langsung dapat digunakan adalah metode berbasis Kernel Density Classification (KDC). Akan tetapi, metode KDC memiliki keterbatasan dalam penambahan constraint pada model klasi-fikasinya, selain itu banyak penelitian yang menunjukkan bahwa kinerjanya masih dapat diungguli oleh metode Support Vector Machine (SVM). Pada metode SVM terdapat keterbatasan yaitu bahwa input algoritma harus bertipe numerik. Dengan demikian penelitian ini memberikan kontribusi, yaitu (1) pemilihan metode encoding prediktor kategorik yang mampu meningkatkan kinerja SVM multiclass pada tahap pre-processing, dan (2) pengembangan algoritma SVM multiclass dengan Proportional Class Constraint (SVM-ProClass). Penelitian ini meng-gunakan ordinal encoding dan menghasilkan algoritma SVM-ProClass dengan dua tahapan utama yaitu fase prediksi kelas dan fase pergeseran kelas (Birth-Death Process). Selanjutnya, algoritma SVM-ProClass diterapkan pada dataset UKT untuk menghasilkan dataset yang besifat separable dan imbalanced berbasis proporsi kelas, dimana kinerja dari dataset hasil SVM-ProClass memiliki nilai akurasi F1-Score rata-rata 99,22% dan berbeda secara signifikan dengan α=5% terhadap kinerja dataset tanpa  SVM-ProClass.===================================================================================================================================There are three important principles in grouping single tuition fees (UKT). First, the UKT grouping must be based on the socio-economic ability level of the student's parents. Second, universities must achieve non-tax state income (PNBP) through receipt of UKT payments based on set targets, and third, the public university as government institutions have a social responsibility to accept a minimum of 20% of students from underprivileged families. These three principles are the main background for this research, so it is necessary to develop a UKT classification method that takes into account university revenue targets and minimum proportion requirements in the low UKT group. To solve this problem, it is necessary to develop a classification algorithm that can accommodate constraint factors. The constraint factors that must be present are the proportion of a certain class from the classification results (proportional class constraint) and the minimum amount of UKT receipts (revenue). The type of predictor variable used in the case study is categorical. The results of the literature review found that the classification method for categorical predictors that can be directly used is the Kernel Density Classification (KDC) based method. However, the KDC method has limitations in adding constraints to the classification model; apart from that, many studies show that its performance can still be superior to the Support Vector Machine (SVM) method. There is a limitation to the SVM method, namely that the algorithm input cannot be of the categorical type. Thus, this research provides contributions, namely (1) selecting a categorical predictor encoding method that is able to improve multiclass SVM performance at the pre-processing stage and (2) developing a multiclass SVM algorithm with proportional class constraints (SVM-ProClass). This research uses ordinal encoding and produces the SVM-ProClass algorithm with two main stages, namely the class prediction phase and the class shift phase (Birth-Death Process). Next, the SVM-ProClass algorithm is applied to the UKT dataset to produce a separable and imbalanced dataset based on class proportions, where the performance of the SVM-ProClass dataset has an average F1-Score accuracy value of 99.22% and it is significantly different from the performance of the dataset without SVM-ProClass with α=5%.",kembang algoritma support vector machine svm multiclass prediktor kategorik proportional class constraint,prinsip kelompok uang kuliah tunggal ukt kelompok ukt dasar tingkat mampu sosial ekonomi orang tua mahasiswa guru capai dapat negara pajak pnbp terima bayar ukt dasar target tetap tiga ptn lembaga perintah milik tanggung sosial terima minimal 20 mahasiswa keluarga tiga prinsip latar utama teliti butuh kembang metode klasifikasi ukt hitung target terima revenue ptn syarat proporsi minimal kelompok ukt rendah selesai kembang algoritma klasifikasi akomodasi faktor kendala constraint faktor kendala wajib proporsi kelas hasil klasifikasi proportional class constraint minimal terima ukt revenue tipe variabel prediktor studi teliti kategorik hasil kaji pustaka metode klasifikasi prediktor kategorik langsung metode bas kernel density classification kdc metode kdc milik batas tambah constraint model klasifikasi teliti kerja unggul metode support vector machine svm metode svm batas input algoritma tipe numerik teliti kontribusi 1 pilih metode encoding prediktor kategorik tingkat kerja svm multiclass tahap preprocessing 2 kembang algoritma svm multiclass proportional class constraint svmproclass teliti ordinal encoding hasil algoritma svmproclass tahap utama fase prediksi kelas fase geser kelas birthdeath process algoritma svmproclass terap dataset ukt hasil dataset besifat separable imbalanced bas proporsi kelas mana kerja dataset hasil svmproclass milik nilai akurasi f1score ratarata 9922 beda signifikan 5 kerja dataset svmproclassthere are three important principles in grouping single tuition fees ukt first the ukt grouping must be based on the socioeconomic ability level of the students parents second universities must achieve nontax state income pnbp through receipt of ukt payments based on set targets and third the public university as government institutions have a social responsibility to accept a minimum of 20 of students from underprivileged families these three principles are the main background for this research so it is necessary to develop a ukt classification method that takes into account university revenue targets and minimum proportion requirements in the low ukt group to solve this problem it is necessary to develop a classification algorithm that can accommodate constraint factors the constraint factors that must be present are the proportion of a certain class from the classification results proportional class constraint and the minimum amount of ukt receipts revenue the type of predictor variable used in the case study is categorical the results of the literature review found that the classification method for categorical predictors that can be directly used is the kernel density classification kdc based method however the kdc method has limitations in adding constraints to the classification model apart from that many studies show that its performance can still be superior to the support vector machine svm method there is a limitation to the svm method namely that the algorithm input can not be of the categorical type thus this research provides contributions namely 1 selecting a categorical predictor encoding method that is able to improve multiclass svm performance at the preprocessing stage and 2 developing a multiclass svm algorithm with proportional class constraints svmproclass this research uses ordinal encoding and produces the svmproclass algorithm with two main stages namely the class prediction phase and the class shift phase birthdeath process next the svmproclass algorithm is applied to the ukt dataset to produce a separable and imbalanced dataset based on class proportions where the performance of the svmproclass dataset has an average f1score accuracy value of 9922 and it is significantly different from the performance of the dataset without svmproclass with 5
Optimisasi Rate of Penetration (ROP) pada Operasi Drilling menggunakan Predictive Modelling dan Particle Swarm Optimization (PSO) untuk Meminimalkan Waktu dan Biaya (Studi Kasus : Sumur X Lapangan Mudi).,"Zahra, Haya Aqilah",http://repository.its.ac.id/109285/,"Operasi pemboran diketahui merepresentasikan 30% dari total biaya produksi pada sumur minyak dan gas. Biaya pemboran memiliki hubungan yang erat dengan waktu pemboran, yang mana semakin singkat waktu pemboran, maka biaya pemboran akan semakin murah, dan begitu juga sebaliknya. Parameter utama yang mempengaruhi secara langsung waktu pemboran adalah Rate of Penetration (ROP). Untuk itu, dalam memecahkan masalah biaya dan waktu pemboran, dilakukan penelitian untuk mengoptimasi ROP dengan mempertimbangan tiga parameter utama, yaitu Weight on Bit (WOB), Rotation per Minute(RPM),dan Flowrate. Metode Predictive Modelling dan Particle Swarm Optimization (PSO) diterapkan untuk mengoptimisasi ROP. Metode Predictive Modelling merupakan metode data-driven based yang menggantikan persamaan tradisional. Penelitian ini menggunakan empat model regresi, memungkinkan model untuk dapat mengidentifikasi hubungan kompleks antara parameter pemboran dengan membaca datahistoris yang diberikan. Empat algoritma predictive modelling yang disimulasikan lalu dievaluasi menggunakan nilai RMSE,R², MAE, dan MAPE. Random Forest Regressor dipilih sebagai model yang paling akurat dengan nilai R² mencapai 0.92. Optimisasi ROP memberikan hasil yang signifikan, yaitu pengurangan waktu pemboran sampai 6.2 hari dan biaya hingga Rp1,812,531.93 atau 16% lebih murah dari biaya aktual.=====================================================================================================================================Drilling operations are known to represent 30% of the total production cost in oil and gas wells. Drilling costs are closely related to drilling time; the shorter the drilling time, the cheaper the drilling costs, and vice versa. The primary parameter that directly influences drilling time is the Rate of Penetration (ROP). Therefore, to address the issues of drilling costs and time, a study was conducted to optimize ROP by considering three main parameters: Weight on Bit (WOB), Revolutions per Minute (RPM), and Flowrate. Predictive Modeling and Particle Swarm Optimization (PSO) methods were applied to optimize ROP. Predictive Modeling is a data-driven method that replaces traditional equations. This study utilized four regression models, allowing the model to identify complex relationships between drilling parameters by reading the provided historical data. Four predictive modeling algorithms were simulated and then evaluated using RMSE, R², MAE, and MAPE values. Random Forest Regressor was selected as the most accurate model with an R² value of 0.92. The ROP optimization yielded significant results, reducing drilling time by up to 6.2 days and costs by Rp1,812,531.93 or 16% cheaper than actual costs.",optimisasi rate of penetration rop operasi drilling predictive modelling particle swarm optimization pso minimal biaya studi sumur x lapang mud,operasi bor representasi 30 total biaya produksi sumur minyak gas biaya bor milik hubung erat bor singkat bor biaya bor murah parameter utama pengaruh langsung bor rate of penetration rop pecah biaya bor teliti mengoptimasi rop timbang parameter utama weight on bit wob rotation minuterpmdan flowrate metode predictive modelling particle swarm optimization pso terap mengoptimisasi rop metode predictive modelling metode datadriven based ganti sama tradisional teliti model regresi model identifikasi hubung kompleks parameter bor baca datahistoris algoritma predictive modelling simulasi evaluasi nilai rmser mae mape random forest regressor pilih model akurat nilai r capai 092 optimisasi rop hasil signifikan kurang bor 62 biaya rp181253193 16 murah biaya aktualdrilling operations are known to represent 30 of the total production cost in oil and gas wells drilling costs are closely related to drilling time the shorter the drilling time the cheaper the drilling costs and vice versa the primary parameter that directly influences drilling time is the rate of penetration rop therefore to address the issues of drilling costs and time a study was conducted to optimize rop by considering three main parameters weight on bit wob revolutions mute rpm and flowrate predictive modeling and particle swarm optimization pso methods were applied to optimize rop predictive modeling is a datadriven method that replaces traditional equations this study utilized four regression models allowing the model to identify complex relationships between drilling parameters by reading the provided historical data four predictive modeling algorithms were simulated and then evaluated using rmse r mae and mape values random forest regressor was selected as the most accurate model with an r value of 092 the rop optimization yielded significant results reducing drilling time by up to 62 days and costs by rp181253193 or 16 cheaper than actual costs
Deteksi Nodul Paru Pada Citra Ct Scan Berbasis Fitur Glcm Dan Rlm Menggunakan Metode Support Vector Machine (SVM).,"Zai'mah, Permatasari",http://repository.its.ac.id/87680/,"Kanker paru-paru merupakan salah satu jenis kanker yang memiliki  tingkat kematian yang tinggi di dunia. Untuk mengurangi angka kematian  tersebut, maka perlu dilakukan pendeteksian secara dini sehingga pasien dapat  diobati secepat mungkin. Salah satu proses pendeteksian yang dilakukan adalah  dengan cara screening yaitu menggunakan Computed Tomography (CT) scan.  Penelitian ini bertujuan untuk mengembangkan metode yang dapat membedakan karakteristik densitas nodul paru normal dan tidak. Tahap ekstraksi fitur tekstur  berbasis histogram dan Gray Level Co-occurrence Matrix (GLCM) dan (Run Length Matrix) RLM. Nilai fitur tekstur kemudian digunakan sebagai masukan  tahap klasifikasi menggunakan metode Support Vector Machine (SVM) dan  Neural Network Backpropagation. Berdasarkan pada hasil eksperimen,didapatkan bahwa metode SVM dapat mengenali nodul paru lebih baik dibandingkan aNN Backpropagation dengan nilai akurasi terbaik 85,3% sedangan nilai akursi aNN Backpropagation 77.7 % .Hasil ini menyediakan informasi bahwa deteksi nodul paru berdasarkan fitur glcm dan rlm yang dapat dideteksi lebih baik. Lebih jauh, memilih parameter C dan γ pada SVM dan nilai learning dan hidden layer pada aNN Backpropagation untuk mendapatkan hasil klasifikasi yang optimal dapat diemplementasikan untuk mendapatkan hasil yang lebih baik. Kata kunci : Kanker paru-paru, glcm, rlm, Klasifikasi fitur, aNN Backpropagation",deteksi nodul paru citra ct scan bas fitur glcm rlm metode support vector machine svm,kanker paruparu salah jenis kanker milik tingkat mati dunia kurang angka mati deteksi pasien obat cepat salah proses deteksi screening computed tomography ct scan teliti tuju kembang metode beda karakteristik densitas nodul paru normal tahap ekstraksi fitur tekstur bas histogram gray level cooccurrence matrix glcm run length matrix rlm nilai fitur tekstur masuk tahap klasifikasi metode support vector machine svm neural network backpropagation dasar hasil eksperimendidapatkan metode svm nali nodul paru banding ann backpropagation nilai akurasi baik 853 sedang nilai akursi ann backpropagation 777 hasil sedia informasi deteksi nodul paru dasar fitur glcm rlm deteksi pilih parameter c  svm nilai learning hidden layer ann backpropagation hasil klasifikasi optimal diemplementasikan hasil kunci kanker paruparu glcm rlm klasifikasi fitur ann backpropagation
