Judul,Penulis,Link,Abstrak
Klasifikasi Aritmia Sinyal ECG Menggunakan Transformasi Wavelet Dan Analisa Statistik.,"Gusnam, Mu'thiana",http://repository.its.ac.id/95953/,"Pengenalan kelainan aritmia seseorang diketahui dengan melakukan rekam aktivitas jantung menggunakan Electrocardiogram (ECG). Rekaman ECG detak jantung dibagi menjadi gelombang P, QRS, dan T yang menunjukkan aktivitas kelistrikan jantung seperti depolarisasi atrium dari gelombang P, depolarisasi ventrikel dari kompleks QRS dan repolarisasi ventrikel maupun atrium dari segmen ST."
"Klasifikasi Jenis Tumor Otak Meningioma, Glioma, Dan Pituitari Berbasis Hybrid Vgg-16 Dan Svm Untuk Diagnosis Praoperasi.","Hajjanto, Ariq  Dreiki",http://repository.its.ac.id/110912/,"Berdasarkan Global Cancer Statistic pada tahun 2020, kasus baru tumor otak dan CNS mencapai 308.102 dengan kematian mencapai 251.329 di seluruh dunia.  Di Indonesia sendiri, estimasi kejadian dan kematian pada tahun 2016 mencapai 6.337 dan 5.405 kasus. Banyak jenis tumor otak dengan variasi lokasi, ukuran, dan tingkat keganasan membuat melokalisasi dan klasifikasi tumor kompleks bagi ahli medis secara konvensional, menyebabkan kesalahan dalam penentuan jenis tumor otak karena perlu membaca hasil citra dalam jumlah yang sangat banyak. Keakuratan klasifikasi konvensional dapat dipengaruhi oleh beberapa faktor, seperti perbedaan subjektivitas individu dalam mengenali lokasi tumor, waktu, ketelitian, kelelahan, dan faktor manusia lainnya. Maka dari itu, dibutuhkan suatu metode dalam menghasilkan diagnosis tumor yang akurat dengan machine learning. Akan tetapi, penelitian yang menggunakan pendekatan machine learning sangat rentan akan overfitting disebabkan kurangnya dataset ataupun model arsitektur yang digunakan dan juga lamanya proses komputasi yang dibutuhkan. Oleh sebab itu, Pada penelitian ini diusulkan sistem klasifikasi hibrida dengan bantuan machine learning, yaitu menggunakan arsitektur/model VGG-16 dan Support Vector Machine (SVM). VGG-16 memiliki keunggulan dalam ekstraksi fitur hierarkis dan invariansi spasial yang memungkinkan identifikasi tumor dengan akurasi lebih tinggi. Output fitur jenis tumor otak dari VGG-16 direduksi menggunakan Principal Component Analysis (PCA), lalu diklasifikasi dengan bantuan SVM serta dioptimalkan dengan pengujian kombinasi kernel dan hyperparameter. Performa arsitektur dievaluasi menggunakan performance metrics dan komparasi model sebelumnya, yang memungkinkan penilaian objektif terhadap hasil yang dicapai. Hasil penelitian memberikan hasil untuk masing-masing metrik akurasi, presisi, recall¸f1-score, dan spesifisitas secara berturut-turut sebesar 96.9%, 97.3%, 96.67%, 96.67%, dan 99.97% dengan menggunakan kernel polynomial dengan hyperparameter C, degree, dan coef0 sebesar 10, 3, dan 0.5.============================================================According to the 2020 Global Cancer Statistics, there were 308,102 new cases of brain and CNS tumors, resulting in 251,329 deaths worldwide. In Indonesia alone, the estimated incidence and mortality in 2016 were 6,337 and 5,405 cases, respectively. The various types of brain tumors, with variations in location, size, and malignancy levels, make localization and classification complex for conventional medical professionals, leading to errors in brain tumor determination due to the need to analyze a vast amount of imaging results. Conventional classification accuracy can be influenced by factors such as individual subjectivity in recognizing tumor locations, timing, precision, fatigue, and other human factors. Therefore, a method is needed to produce accurate tumor diagnoses using machine learning. However, research using machine learning approaches is highly susceptible to overfitting due to the lack of datasets or the architectural models used and the lengthy computational processes required. Hence, this study proposes a hybrid classification system with the assistance of machine learning, utilizing the VGG-16 architecture/model and Support Vector Machine (SVM). VGG-16 excels in hierarchical feature extraction and spatial invariance, enabling higher accuracy in tumor identification. The output features of brain tumor types from VGG-16 are reduced using Principal Component Analysis (PCA) and then classified with the help of SVM, optimized by testing combinations of kernels and hyperparameters. The architecture performance is evaluated using performance metrics and comparison with previous models, allowing for an objective assessment of the achieved results. The study results for each metric of accuracy, precision, recall, f1-score, and specificity were 96.9%, 97.3%, 96.67%, 96.67%, and 99.97%, respectively, using the polynomial kernel with hyperparameters C, degree, and coef0 of 10, 3, and 0.5."
Pembuatan Sistem Visual Question Answering Berbasis Web Untuk Mendukung Pembelajaran Visual Anak TK Berbahasa Indonesia Menggunakan Deep Learning.,"Hanifah, Asiyah",http://repository.its.ac.id/102392/,"Seiring pesatnya perkembangan teknologi, Indonesia semakin gencar melakukan persiapan transformasi digital untuk menghadapi perubahan teknologi. Salah satunya adalah implementasi e-learning di berbagai sektor, termasuk pendidikan. E-learning telah diterapkan dalam pembelajaran taman kanak-kanak, termasuk pembelajaran visual. Bentuk pembelajaran visual pada e-learning dapat dibuat dengan pembangunan sistem visual question answering. Beberapa penelitian telah dibuat untuk pembangunan sistem visual question answering dan berhasil membuat sistem visual question answering dengan ilmu patologi dalam bahasa inggris, dan dataset objek di sekitar monas dalam bahasa indonesia. Oleh karena itu, dilakukan pengajuan pembuatan sistem visual question answering dengan dataset yang lebih umum dan dapat dikenali oleh anak TK berbahasa indonesia. Dadanya penelitian ini akan dapat membantu tenaga pendidik dalam kegiatan belajar mengajar yang lebih interaktif dalam e-learning. Penelitian ini menggunakan model Bootstrapping Language-Image Pre-training (BLIP) untuk proses pembuatan sistem visual question answering dan mengimplementasikan model No Language Left Behind (NLLB) pada input-output pertanyaan untuk menerjemahkan bahasa yang digunakan. Hasil implementasi kedua model BLIP dan NLLB berhasil membangun sistem visual question answering berbahasa indonesia. Berdasarkan hasil pengujiannya, dari beberapa pertanyaan yang mengandung 6 jenis jawaban: ya/tidak, kata benda, kata kerja, kata sifat, kata keterangan, dan numeral, sistem ini berhasil menjawab tepat untuk jenis jawaban ya/tidak, kata benda, kata kerja, dan kata keterangan dengan nilai ketepatan jawaban ya/tidak 100, kata benda 100, kata kerja 100, dan kata keterangan 87.5.===============================================================================================================================Along with the rapid development of technology, Indonesia is increasingly intensifying its digital transformation preparations to face the existing technological advancements. With the rapid development of technology, Indonesia is increasingly intensifying its preparations for digital transformation to face technological changes. One of these preparations involves the implementation of e-learning across various sectors, including education. E-learning has been applied in kindergarten education, including visual learning. Visual learning in e-learning can be achieved through the development of a visual question answering system. Several studies have been conducted on visual question answering systems and have successfully created such systems using pathology images in English and object datasets around Monas (National Monument) in Indonesian. Therefore, the author proposes the creation of a visual question answering system with a more general dataset that can be recognized by Indonesian-speaking kindergarten children. The purpose of this research is to assist educators in conducting more interactive e-learning activities. The research utilizes the Bootstrapping Language-Image Pre-training (BLIP) model for the development of the visual question answering system and implements the No Language Left Behind (NLLB) model for translating the language used in the input-output questions. The implementation results of both the BLIP and NLLB models successfully build a visual question answering system in the Indonesian language. Based on testing, the system can provide accurate answers for yes/no, nouns, verbs, and adverbial questions, with accuracy rates of 100% for yes/no, 100% for nouns, 100% for verbs, and 87.5% for adverbial questions, all of which contain six types of answers: yes/no, nouns, verbs, adjectives, adverbs, and numerals."
Analisis Prediksi Faktor Intensitas Tegangan Pada Sambungan Tubular Jacket Platform Berbasis Surrogate Model.,"Hardian, Muhammad Akbar",http://repository.its.ac.id/98455/,"Berdasarkan data SKK migas pada tahun 2016, 54,65% anjungan lepas pantai di Indonesia telah berumur lebih dari 20 tahun. Struktur yang telah melebihi umur operasinya perlu ditinjau ulang dari segi kekuatan struktur apakah masih mampu untuk beroperasi. Dalam penelitian ini, penulis akan berfokus pada analisis prediksi faktor intensitas tegangan pada struktur jacket berkaki empat berbasis surrogate model. Faktor intensitas tegangan merupakan faktor yang menentukan kelelahan pada sambungan tubular dengan metode fracture mechanics. Dalam rangkat meningkatkan akurasi dan mengoptimalkan waktu analisis dikembangkan surrogate model dari analisis variasi retak yang didapat dengan metode elemen hingga. Metode analisis yang digunakan dalam penelitian ini meliputi analisis statis inplace untuk analisis tegangan struktur secara global, analisis lokal sambungan tubular kritis, analisis retak pada tubular dengan titik tegangan kritis tertinggi, dan pemodelan faktor intensitas tegangan berbasis surrogate model menggunakan machine learning model SVM berdasarkan variasi kedalaman retak dan panjang retak. Analisis retak menggunakan 30 variasi model retak yang berada pada tegangan maksimum di analisis lokal metode elemen hingga. Analisis lokal struktur berdasarkan hasil analisis statis inplace global struktur dengan sambungan kritisnya adalah sambungan tubular multiplanar DKT. Diperoleh tegangan von-mises tertinggi pada brace 5 dengan tegangan sebesar 327 MPa. Hasil surrogate model variasi model retak dengan algoritma RBF memberikan hasil prediksi dengan validasi R2 dengan variabel rasio (a/2c) sebesar 1 lalu dengan algoritma SVM memberikan hasil prediksi dengan validasi R2 dengan variabel rasio (a/2c) sebesar 0,99.=================================================================================================================================Based on SKK Migas data in 2016, 54.65% of offshore platforms in Indonesia were over 20 years old. Structures that have exceeded their operational life need to be reviewed in terms of their structural strength to determine if they are still capable of operating. In this study, the author will focus on predicting the stress intensity factor on a four-legged jacket structure based on a surrogate model. The stress intensity factor is a factor that determines fatigue in tubular connections using fracture mechanics methods. To improve accuracy and optimize analysis time, a surrogate model was developed from the analysis of crack variations obtained using the finite element method. The analysis methods used in this study include static analysis in-place for global structural stress analysis, local critical tubular connection analysis, crack analysis in tubular with the highest critical stress point, and modeling of stress intensity factors based on a surrogate model using a machine learning SVM model based on variations in crack depth and crack length. Crack analysis used 30 crack model variations located at maximum stress in the local analysis of the finite element method. Local structural analysis is based on the results of global in-place static analysis of the structure with its critical connection, which is the DKT multiplanar tubular connection. The highest von-Mises stress was obtained at brace 5 with a stress of 327 MPa. The surrogate model results of crack model variations with the RBF algorithm provided a prediction result with a validation R2 value of 1 for the ratio variable (a/2c), while the SVM algorithm provided a prediction result with a validation R2 value of 0.99 for the ratio variable (a/2c)."
Surrogate-Assisted Model Untuk Prediksi Umur Kelelahan Pada Sambungan Tubular Multiplanar Jacket Platform Berbasis Mekanika Kepecahan.,"Hardian, Muhammad Akbar",http://repository.its.ac.id/108251/,"Berdasarkan informasi yang disampaikan dalam presentasi SKK Migas pada The 3rd Indo Decomm in Oil and Gas Conference, Indonesia telah mengoperasikan 613 unit anjungan lepas pantai terpancang sejak produksi komersial pertama di daerah lepas pantai. Dari total anjungan, sebanyak 54.65% telah berusia lebih dari 20 tahun, sementara 24.63% memiliki usia antara 16-20 tahun. Dengan perpanjangan waktu operasinya, integritas struktur platform tua tentu akan menurun. Salah satu akibatnya potensial terjadi kegagalan struktur karena beban siklis dengan adanya retak yang mayoritas bermula dari bagian las sambungan tubular pada strukturnya. Penelitian ini bertujuan untuk mengembangkan model baru dalam memprediksi umur lelah sambungan tubular multi-planar DKT berbasis Mekanika Kepecahan (Fracture Mechanics) dengan lebih efektif melalui surrogate model. Dengan menganalisis parameter geometri yang dapat mempengaruhi keretakan dan membangkitkan surrogate model yang lebih akurat untuk memprediksi umur kelelahan sambungan tubular multi-planar DKT kritis pada pembebanan aksial, IPB, OPB, dan gabungan. Analisis tersebut berhasil mendapatkan tegangan kritis yang terdapat pada brace 5. Umur lelah hingga kedalaman retak kritis juga didapatkan pada pembebanan aksial, IPB, OPB, dan gabungan untuk digunakan sebagai data training pada pembangkitan surrogate model dengan 2 variasi algoritma machine learning. Penelitian ini menyimpulkan bahwa algoritma radial basis function memberikan hasil yang lebih baik pada pembangkitan surrogate model daripada algoritma kriging. Hasil error yang diberikan pada algoritma radial basis function adalah 0.3%====================================================================================================================================Based on information presented in SKK Migas' presentation at The 3rd Indo Decomm in Oil and Gas Conference, Indonesia has operated 613 units of offshore platforms since the first commercial production in offshore areas. Of the total platforms, 54.65% are more than 20 years old, while 24.63% are between 16-20 years old. With the extension of its operation time, the structural integrity of the old platform will certainly decrease. One of the potential consequences is structural failure due to cyclical loading with cracks, the majority of which originate in the welds of tubular joints in the structure. This research aims to develop a new model to more effectively predict the fatigue life of DKT multi-planar tubular joints based on Fracture Mechanics through a surrogate model. By analysing geometry parameters that can affect cracking and generating a more accurate surrogate model to predict the fatigue life of critical DKT multi-planar tubular joints under axial, IPB, OPB and combined loading. The analysis successfully obtained the critical stress located at brace 5. The fatigue life to critical crack depth was also obtained under axial, IPB, OPB, and combined loading to be used as training data for surrogate model generation with 2 variations of machine learning algorithms. This study concluded that radial basis function algorithm gives better results in surrogate model generation than kriging algorithm. The error result given in the radial basis function algorithm is 0.3%."
"Perancangan Sistem Deteksi Keausan Pahat Pada Mesin Milling Menggunakan ""Cubic SVM"".","Hikmah, Zahra Putri Nurul",http://repository.its.ac.id/100911/,"Kerusakan suatu mesin dapat terjadi begitu saja tanpa timbulnya suatu indikasi tertentu. Sehingga dibutuhkan suatu sistem monitoring yang dapat digunakan untuk mendeteksi suatu anomali dalam proses permesinan. Deteksi anomali merupakan suatu proses untuk mengidentifikasikan suatu error atau peristiwa yang tidak terduga. Penelitian ini bertujuan untuk mengetahui sinyal vibrasi atau sinyal arus, sinyal yang paling tepat digunakan untuk mendeteksi keausan pahat pada mesin milling 3 axis Matsura 510 menggunakan model machine learning cubic SVM dan juga untuk mengetahui pengaruh penggunaan dekomposisi sinyal EMD terhadap hasil klasifikasi data yang dihasilkan. Penelitian dimulai dari pengambilan data untuk mendapatkan sinyal arus dan sinyal vibrasi kemudian masing-masing sinyal di-prepocessing. Lalu setelah itu sinyal diubah menjadi numerical features melalui proses features extraction. Numerical features yang sudah didapatkan kemudian diseleksi menggunakan ANOVA supaya menghasilkan hasil performance metrics yang baik. Sebelum features diklasifikasikan dengan model machine learning, maka diperlukan validasi model untuk menghindari overfitting dan underfitting. Setelah itu features dapat diklasifikasikan dengan menggunakan dua proses yaitu proses training dan proses testing sehingga didapatkan prediksi mengenai kondisi mesin. Berdasarkan penelitian yang telah dilakukan dapat disimpulkan bahwa ternyata sinyal vibrasi dalam domain frekuensi yang diolah tanpa menggunakan EMD dapat digunakan untuk mendeteksi keasuan pahat pada mesin milling 3 axis Matsura 510. Hal tersebut dapat dibuktikan dengan nilai precision dan recall yang dihasilkan dari proses training dan testing. Pada proses training didapatkan nilai precision sebesar 94,7% dan recall sebesar 84,7%. Kemudian pada proses testing didapatkan nilai precision sebesar 90,1% dan recall sebesar 90,1%. ==============================================================================================================================Damage to a machine can occur without any indication. Therefore require monitoring system can be used to detect an anomaly in the machining process. Anomaly detection is a process to identify an error or unexpected event. This research aims to find out between vibration signals and current signals, which signals are the best to detect tool wear on Matsura 510 3-axis milling machine using a cubic SVM machine learning algorithm. In addition, this research also aims to determine the effect of using EMD signal decomposition on the resulting data classification results. The research begins with data collection to obtain current signals and vibration signals, then each signal is preprocessed. Then after that, the signal is converted into numerical features through the features extraction process. Numerical features that have been obtained are then selected using ANOVA to produce good performance metrics. Before features are classified with a machine learning model, it is necessary to validate the model to avoid overfitting and underfitting. After that, the features can be classified using two processes, the training process and the testing process so that predictions about the condition of the machine can be obtained. Based on the research that has been done, it would be concluded that it turns out that the vibration signal processed in frequency domain without using EMD can be used to detect the acidity of the tool on the Matsura 510 3-axis milling machine. That could be proved by the precision and recall values produced in training and testing data. In the training process, the precision value having a percentage of 94,7% and 84,7%. Then in the testing process obtained precision value of 90,1% and recall of 90,1%."
Pengembangan Smart Meter untuk Mendukung Home Energy Management System (HEMS) Mempertimbangkan Kualitas Daya Peralatan Rumah.,"Ibrahim, Ditya Addo",http://repository.its.ac.id/87579/,"Pertumbuhan penduduk pada negara berkembang seperti Indonesia menyebabkan peningkatan kebutuhan energi menjadi tantangan yang harus dihadapi. Konsumsi listrik sektor rumah tangga menjadi salah satu faktor tingginya kenaikan beban listrik di mana diketahui sektor tersebut menghasilkan 30% kerugian dari energi terdistribusi. Sedangkan dalam pemenuhan energi listrik sebesar 88% suplai masih berasal dari energi fosil. Sehingga upaya konservasi energi perlu digiatkan terutama pada kelistrikan rumah tangga, salah satunya dengan konsep Home Energy Management System (HEMS) untuk mengoptimasi penggunaan listrik pada rumah. Pada penelitian tugas akhir ini dilakukan pengembangan pada sistem smart meter untuk monitoring konsumsi daya listrik rumah pendukung HEMS dengan Non-Intrusive Load Monitoring (NILM) untuk memantau penggunaan baik daya total dan per beban aktif dengan kualitas daya peralatan sebagai tambahan parameter identifikasi. Dengan adanya NILM maka sistem dapat mengidentifikasi jenis beban aktif rumah hanya menggunakan satu sensor pada saluran listrik utama sehingga proses monitoring menjadi lebih mudah serta memakan biaya dan energi yang lebih rendah. Proses identifikasi menggunakan model pelatihan dengan implementasi Artificial Neural Network (ANN) dalam mengolah data pengukuran untuk menentukan jenis beban yang sedang menyala. Hasil dari simulasi menunjukkan bahwa dengan konfigurasi 50 hidden neuron, pelatihan ANN dapat memperoleh akurasi dengan MAPE sebesar 2,201% dalam mengidentifikasi beban listrik."
"Implementasi Aplikasi Artificial Neural Network (ANN) Backpropagation untuk Prediksi Debit Harian pada Stasiun Pos Duga Air, DAS Serang-Lusi, Jawa Tengah.","Ilahi, Rizqi Noer",http://repository.its.ac.id/113000/,"Hubungan antara hujan dan limpasan sangat erat. Sebagian hujan yang turun dari permukaan bumi terserap ke dalam tanah yang memungkinkan terjadi infiltrasi, dan sebagian lainnya mengalir ke saluran kecil hingga mencapai aliran sungai. Di tempat ini, limpasan terjadi ketika daratan tergenang oleh air hingga dapat menyebabkan banjir. Adanya sistem analisis yang dapat memprediksi dengan baik diperlukan untuk mengatasi masalah yang ada. Dalam praktiknya, memilih model untuk menganalisis dan menilai sistem DAS sangat sulit, namun, ini tidak berarti bahwa model yang ada tidak baik, salah satu model yang tersedia adalah penggunaan Jaringan Syaraf Tiruan (JST) atau Artificial Neural Network (ANN). Studi ini menyelidiki hasil perhitungan debit pemodelan Artificial Neural Network yang dilakukan menggunakan Matlab dan Python. Tujuan dari Tugas Akhir ini adalah untuk menghasilkan debit pemodelan ANN yang optimal dari model arsitektur jaringan yang digunakan. Untuk masukan program ANN, digunakan data curah hujan, evapotranspirasi, dan koefisien aliran. Data hujan dilakukan Uji konsistensi kurva massa ganda untuk menguji konsisteni data curah hujan. Selanjutnya, diambil hujan rerata kawasan menggunakan Polygon Thiessen. Sementara untuk luaran debit pemodelan dari program ANN ini adalah data debit yang diambil dari stasiun pos duga air. Hasil penelitian menunjukkan bahwa dalam pemodelan debit menggunakan ANN metode backpropagation memiliki kinerja yang sangat baik dengan nilai mean square error (MSE) terbaik adalah 0,032 untuk training, sedangkan untuk testing memiliki nilai MSE 0,047. Nilai keandalan atau akurasi program ANN ini mencapai 98%, yang artinya program ANN ini layak dijadikan metode pendekatan debit lapangan.=================================================================================================================================The relationship between rain and runoff is very close. Some of the rain that falls from the earth's surface is absorbed into the ground, which allows infiltration to occur, and some of it flows into small channels until it reaches the flow of rivers. In this place, runoff occurs when the land is flooded by water so that it can cause flooding. The existence of an analysis system that can predict well is necessary to overcome existing problems. In practice, choosing a model to analyze and assess a watershed system is very difficult, however, this does not mean that the existing model is not good, one of the available models is the use of Artificial Neural Network (JST) or Artificial Neural Network (ANN). This study investigated the results of the calculation of the Artificial Neural Network modeling discharge  conducted using Matlab and Python. The purpose of this Final Project is to produce optimal ANN modeling discharge from the network architecture model used. For the input of the ANN program, rainfall, evapotranspiration, and flow coefficient data are used. Rainfall data was carried out Double mass curve consistency test to test the consistency of rainfall data. Next, the average rainfall of the area was taken using Thiessen's Polygon. Meanwhile, the modeling discharge output of the ANN program is discharge data taken from the suspected water post station. The results show that in the discharge modeling using ANN, the backpropagation  method has excellent performance with  the best mean square error (MSE) value of 0.032 for training, while for testing it has an MSE value of 0.047. The reliability or accuracy value of this ANN program reaches 98%, which means that this ANN program is worthy of being used as a field debit approach method."
Klasifikasi Diagnosa Pasien Berdasarkan Rekam Medis Elektronik Menggunakan Text Mining Dan Support Vector Machine.,"Jamaluddin, M.",http://repository.its.ac.id/86313/,"Rekam Medis Elektronik (RME) adalah elemen penting dari teknologi informasi di bidang kesehatan. RME adalah catatan elektronik yang berisi informasi terkait kesehatan pasien yang dapat dibuat dan dikelola oleh dokter dan staf yang berwenang di organisasi pelayanan kesehatan. RME adalah kerangka kerja untuk menentukan diagnosis dan pengobatan kepada pasien. RME memiliki format teks bebas dan tidak terstruktur yang membuat lebih sulit untuk menggali informasi tersembunyi sebagai sistem pendukung keputusan. Dalam thesis ini, dilakukan penelitian untuk klasifikasi dari RME berbahasa Indonesia sebagai Clinical Decision Support System (CDSS) dalam mengklasifikasikan diagnosis pasien menggunakan Term Frequency-Inverse Document Frequency (Tf-Idf) untuk ekstraksi fitur dan Support Vector Machine (SVM) untuk metode klasifikasi. Diagnosa yang diklasifikasikan dalam thesis ini adalah tuberkulosis, kanker, diabetes mellitus, hipertensi, dan gagal ginjal yang memiliki angka prevalensi tinggi di Indonesia.Model dibangun dengan mempertimbangkan fungsi kernel SVM serta penggunaan stopword removal atau tanpa stopword removal. Akurasi tertinggi didapatkan pada kernel RBF menggunakan stopword removal dan model n-gram (1-3) dengan nilai akurasi 91,71%. Hasil penelitian menunjukkan bahwa metode Tf-Idf dan SVM dapat digunakan secara efektif untuk memprediksi diagnosis.=====================================================================================================Electronic Medical Record (EMR) is an important element of information technology in health sector. EMR is an electronic record containing health-related information on an patient that can be created and managed by authorized physician and staff in a health service organization. EMR is a framework for determining diagnosis and treatment. EMR has free text and unstructured format which makes it more difficult to extract the hidden information as a decision support system. This study performs classification from Indonesian EMR for clinical decision support system (CDSS) in classifying patient diagnosis using Term Frequency-Inverse Document Frequency (Tf-Idf) for feature extraction and Support Vector Machine (SVM) for classifier method. The focus diagnoses classified in this paper are tuberculosis, cancer, diabetes mellitus, hypertension, and kidney failure which have high prevalence rates in Indonesia. The model is built by considering the kernel function and the use of stopword removal or without stopword removal. The highest accuracy is obtained in the RBF kernel with stopword removal and n-gram (1-3) by an accuracy value of 91.71%. The result showed that Tf-Idf and SVM method could be used effectively to predict diagnosis."
Analisis Modifikasi Algoritma YOLO dengan Implementasi Convolutional Block Attention Module (CBAM) terhadap Performa Deteksi Penyu di Lingkungan Bawah Laut.,"Juliantono, Fadly Rachman Drajad",http://repository.its.ac.id/112272/,"Eksplorasi biota laut di seluruh dunia, termasuk Indonesia, memainkan peran penting dalam memahami keanekaragaman hayati dan ekosistem bawah air. Indonesia, bagian dari segitiga karang dunia, memiliki keragaman spesies yang luar biasa, namun penelitian terhadap potensi ini masih terbatas. Penyu, reptil laut yang telah ada selama jutaan tahun, sering menjadi daya tarik wisata utama dan memainkan peran penting dalam ekosistem laut. Konservasi penyu menjadi perhatian penting karena ancaman dari aktivitas manusia dan perubahan iklim. Dengan berkembangnya modernisasi, sektor pariwisata maritim di Indonesia tumbuh pesat, menempatkan tekanan pada ekosistem laut dan menegaskan kebutuhan akan manajemen dan pemantauan yang berkelanjutan. Sistem deteksi objek di lingkungan laut menghadapi tantangan seperti air keruh dan variasi pencahayaan yang mengurangi efektivitas teknologi tradisional. Oleh karena itu, pengembangan model berbasis Deep Learning seperti You Only Look Once (YOLO) menjadi sangat relevan. Penelitian ini mengeksplorasi penerapan YOLO yang dilengkapi dengan Convolutional Block Attention Module (CBAM) dalam pengaruh performa deteksi penyu di lingkungan bawah laut dan bertujuan untuk menguji akurasi dan kinerja model deteksi pada kamera bawah laut yang menggunakan mesin Jetson Nano Dev Kit. Model dengan performa tingkat akurasi tinggi didapatkan oleh YOLOv8n dengan CBAM dengan hasil mAP@0,5: 0,95 senilai 57,1% dan beban Param 8.0M serta FLOPs 8.3. Nilai ini naik sebesar 4% dibandingkan dengan YOLOv8n tanpa CBAM. Dengan performa yang dimiliki, model yang dideploy dapat mendeteksi objek secara real-time dan mendapatkan hingga 10 fps. Dengan pembuatan model ini, dapat digunakan sebagai groundtruth dari sistem deteksi penyu secara akurat dan dapat dikembangkan dengan fitur klasifikasi untuk di masa yang akan datang.===============================================================================================Exploration of marine biota worldwide, including Indonesia, plays a crucial role in understanding biodiversity and underwater ecosystems. Indonesia, being part of the world's coral triangle, boasts an extraordinary diversity of species, yet research into this potential remains limited. Sea turtles, marine reptiles that have existed for millions of years, often become major tourist attractions and play a vital role in marine ecosystems. Turtle conservation is a pressing concern due to threats from human activities and climate change. As modernization progresses, the maritime tourism sector in Indonesia is rapidly growing, putting pressure on marine ecosystems and underscoring the need for ongoing management and monitoring. Object detection systems in marine environments face challenges such as turbid water and varying lighting conditions that reduce the effectiveness of traditional technologies. Therefore, the development of Deep Learning-based models like You Only Look Once (YOLO) becomes highly relevant. This research explores the application of YOLO equipped with the Convolutional Block Attention Module (CBAM) to study its impact on the performance of turtle detection in underwater environments and aims to test the accuracy and performance of the detection model on underwater cameras using the Jetson Nano Dev Kit. The model enhanced by YOLOv8n with CBAM achieved high-performance metrics with a mean Average Precision (mAP) @ 0,5 of 57.1% and a parameter load of 8.0M and FLOPs of 8.3, showing a 4% improvement compared to YOLOv8n without CBAM. With its current capabilities, the deployed model can detect objects in real-time at a rate of 10 fps. With the creation of this model, it can serve as the ground truth for accurately detecting turtles and can be further developed with classification features for future applications."
Klasifikasi Kanker Kulit Dari Citra Dermatoskopi Berbasis Convolutional Neural Network U-Net Dan Support Vector Machine.,"Junior, Amanda Sharon Purwanti",http://repository.its.ac.id/111710/,"Global Burden of Cancer Study (Globocan) dari World Health Organization (WHO), mencatat jumlah kasus kanker di Indonesia pada tahun 2020 mencapai 396.914 kasus, sementara total kematian akibat kanker mencapai 234.511 kasus. 5,9 – 7,8% dari total kasus kanker yang terjadi merupakan kanker kulit.  Tingkat kesembuhan dari kanker kulit dapat meningkat hingga 90% jika ditemukan sejak dini, namun deteksi dini dinilai cukup kompleks  dan cenderung subjektif sehingga diagnosis kanker kulit ini seringkali mengalami keterlambatan. Maka dari itu, mulai dikembangkan Computer-Aided Diagnostic (CAD), sebuah sistem diagnosis otomatis yang dirancang dengan tujuan meningkatkan akurasi diagnosis. Diagnosis otomatis pada citra dermatoskopi masih terhambat oleh variasi kompleks dalam tampilan. Dalam penelitian ini, diusulkan sistem yang terdiri dari preprocessing citra yang dilakukan untuk meningkatkan kualitas citra, segmentasi citra menggunakan U-Net yang dilakukan untuk memisahkan lesi dari latar citra, ekstraksi fitur menggunakan metode GLCM untuk menghitung kontras, energi, homogeneity, dan entropi citra pada sudut 0⁰, 45⁰, 90⁰, dan 135⁰ serta metode ABCD yang mengambil beberapa fitur bentuk dan warna pada citra yaitu asimetri(A), tepian atau border (B), warna atau colour (C), dan diameter(D). Terakhir dilakukan klasifikasi multilabel menggunakan Support Vector Machine dengan pendekatan One-Vs-Rest. Model dengan hasil terbaik dalam penelitian didapatkan dengan metode penyeimbangan data SMOTEENN yang merupakan gabungan dari metode SMOTE (Synthetic Minority Over-sampling Technique) dan ENN (Edited Nearest Neighbors) dengan penggunaan kernel Radial Basis Function (RBF) parameter C dan Gamma sebesar 1000 dan 0,1 dengan memakai 21 fitur. Hasil yang didapatkan dari model ini adalah nilai akurasi, presisi, sensitivitas, spesifisitas, dan MCC (Matthews Correlation Coefficient) sebesar 95,25%, 95,25%, 95,24%, 99,02%, dan 0,94.============================================================The Global Burden of Cancer Study (Globocan) by the World Health Organization (WHO) reported that the number of cancer cases in Indonesia in 2020 reached 396,914, with total cancer-related deaths reaching 234,511 cases. Skin cancer accounted for 5.9 - 7.8% of the total cancer cases. The cure rate can increase up to 90% with early detection, but early detection is considered complex and subjective, often leading to delayed skin cancer diagnosis. Consequently, a Computer-Aided Diagnostic (CAD) system, designed to enhance diagnostic accuracy, has been developed. Automated diagnosis of dermatoscopic images faces challenges due to complex variations in appearance. In this study, a system is proposed consisting of image preprocessing which is done to improve image quality, image segmentation using U-Net which is done to separate the lesion from the image background, feature extraction using the GLCM method to calculate contrast, energy, homogeneity, and entropy of the image at angles of 0⁰, 45⁰, 90⁰, and 135⁰ and the ABCD method which takes several shape and color features in the image, namely asymmetry (A), edge or border (B), color or color (C), and diameter (D). Finally, multilabel classification is performed using Support Vector Machine with One-Vs-Rest approach. The model with the best results in the study was obtained with the SMOTEENN data balancing method which is a combination of the SMOTE (Synthetic Minority Over-sampling Technique) and ENN (Edited Nearest Neighbors) methods with the use of Radial Basis Function (RBF) kernels with C and Gamma parameters of 1000 and 0,1 using 21 features. The results obtained from this model are the values of accuracy, precision, sensitivity, specificity, and MCC (Matthews Correlation Coefficient) of 95,25%, 95,25%, 95,24%, 99,02%, and 0,94."
Prediksi Tingkat Peringatan Kebakaran Semak di Perth Australia Barat menggunakan Metode Support Vector Machine dan Random Forest.,"Kanedi, Fidela Jovita",http://repository.its.ac.id/116645/,"Australia mengalami peningkatan cuaca ekstrem akibat suhu lebih tinggi dan kekeringan yang parah dalam beberapa dekade terakhir. Pada musim semi 2023, bagian barat daya Australia Barat mengalami suhu maksimum bulanan jauh di atas rata-rata untuk Agustus, September, dan Oktober, mencatat suhu terpanas sejak 1910 dan termasuk dalam 10% teratas tahun-tahun paling panas yang tercatat. Perth, ibu kota Australia Barat, adalah kota keempat terpadat di Australia pada 2020 dengan tingkat rawan kebakaran semak mencapai 90%, yang menjadi masalah serius karena populasi yang padat. Perubahan iklim meningkatkan frekuensi dan intensitas cuaca ekstrem seperti gelombang panas lebih panjang dan kekeringan lebih parah. Untuk meningkatkan respons terhadap kebakaran semak di Perth, pendekatan prediktif sangat penting. Prediksi yang akurat tentang potensi kebakaran membantu pihak berwenang mengalokasikan sumber daya secara efisien dan merencanakan strategi pemadaman yang tepat. Tugas Akhir ini bertujuan memprediksi tingkat peringatan kebakaran semak di Perth menggunakan metode Support Vector Machine (SVM) dan Random Forest. Data dikumpulkan melalui teknik data scraping dari laman resmi Biro Meteorologi Australia Barat, diproses, dianalisis, dan digunakan untuk melatih model. Model terbaik dari Random Forest dan SVM menggunakan proporsi data latih sebesar 80%, data uji sebesar 20%, dan sembilan fitur terbaik. Model Random Forest mampu menghasilkan akurasi 93,93% dan F1-score 93,77%, sedangkan Model SVM mampu menghasilkan akurasi 91,5% dan F1-score 91,5%. Model yang dikembangkan diharapkan membantu pemerintah meminimalisir kebakaran semak di masa depan. =================================================================================================================================Australia has experienced increased extreme weather due to higher temperatures and severe droughts in recent decades. In the spring of 2023, the southwest part of Western Australia saw monthly maximum temperatures well above average for August, September, and October, recording the hottest temperatures since 1910 and ranking among the top 10% of the hottest years on record. Perth, the capital of Western Australia, was the fourth most populous city in Australia in 2020 with a bushfire vulnerability rate reaching 90%, posing a serious issue due to its dense population. Climate change is amplifying the frequency and intensity of extreme weather events such as prolonged heatwaves and more severe droughts. To enhance the response to bushfires in Perth, predictive approaches are crucial. Accurate predictions of fire potential assist authorities in allocating resources efficiently and planning appropriate firefighting strategies. This research aims to predict bushfire alert levels in Perth using Support Vector Machine (SVM) and Random Forest methods. Data was collected through web scraping techniques from the official website of the Bureau of Meteorology Western Australia, processed, analyzed, and used to train the models. The best model of Random Forest and SVM used a proportion of training data of 80%, test data of 20%, and nine best features. The Random Forest model was able to produce an accuracy of 93.93% and an F1-score of 93.77%, while the SVM model was able to produce an accuracy of 91.5% and an F1-score of 91.5%. The developed model is expected to provide insights that can be utilized by relevant government authorities to reduce the incidence of bushfires."
Perancangan Model untuk Prediksi Potensi Churn pada Debitur KPR dengan Regresi Logistik.,"Kasidi, Josua Christanto",http://repository.its.ac.id/92487/,"Kredit Kepemilikan Rumah (KPR) merupakan sistem pembiayaan dimana perbankan memberikan pinjaman kepada nasabah untuk mendapatkan rumah, dan melakukan pelunasan dalam waktu yang ditentukan. Oleh sebab itu, dalam persaingan bank di Indonesia, baik bank pemerintah maupun swasta kini berusaha untuk menawarkan program KPR kepada nasabah yang bertujuan agar nasabah merasa puas dengan pelayanan perbankan tersebut. Seiring dengan perjalanan umur KPR debitur, peristiwa churn customers (pelanggan yang meninggalkan perusahaan) dapat menjadi hal yang berdampak bagi pertumbuhan portfolio KPR serta membuat turunnya hubungan antara bank dengan nasabah.Hingga kini, salah satu bank yang terus berusaha untuk mengatasi permasalahan churn customers adalah Bank Mandiri. Namun dalam menjawab tantangan tersebut terdapat beberapa permasalahan yang menjadi halangan untuk dapat menyelesaikannya. Salah satu permasalahan tersebut adalah kurangnya informasi mengenai faktor yang mempengaruhi churn customers akibat analisis yang terbatas karena jumlah perbandingan populasi yang tidak seimbang.. Oleh sebab itu, tujuan dari penelitian ini adalah untuk membuat model prediktif yang mampu melakukan klasifikasi terhadap nasabah churn pada produk KPR agar Bank Mandiri dapat melakukan retensi sedini mungkin.Proses yang dilakukan untuk dapat mencapai tujuan tersebut dapat dimulai dengan mengelompokan kelompok nasabah menjadi data biner, dimana akan terdapat nasabah churn dan nasabah loyal. Kemudian penelitian dilanjutkan dengan mengumpulkan faktor-faktor yang terduga mempengaruhi nasabah churn, antara lain Recency, Frequency, dan Monetary (RFM), saldo tabungan, penghasilan, tagihan, Debt Burden Ratio (DBR), usia, rate, dan Debt Equity Ratio (DER), dan sisa plafon. Data yang digunakan pada penelitian ini adalah data sejarah transaksi, dana, dan kredit nasabah yang dimulai pada tahun 2019 – Mei 2021 yang terdiri dari 50,000 nasabah KPR. Data yang diperoleh akan dilanjutkan dengan melakukan pemodelan menggunakan regresi logistik biner. Untuk hasil pengujian, model yang digunakan akan diuji menggunakan nilai Receiver Operating Characteristic (ROC) dan Area Under Curve (AUC) sebagai nilai kelayakan dalam pengujian model data. Hasil akhir dari model ini diperoleh 7 variabel yang berpengaruh terhadap model disertai dengan nlai AUC dari logistik biner original sebesar 0.68 dan logistik biner SMOTE sebesar 0.72.================================================================================================A mortgage is a loan or financing system whereas banks provide loans to customers to get houses and make repayments within a specified time. Therefore, in banking competition in Indonesia, both state and private banks are now trying to offer mortgage to customers so that customers feel satisfied with banking services. The more customers who take mortgages will certainly have an impact on the quality of a bank's mortgage portfolio. Along with the age of mortgage loan, churn customers can have an impact on the growth of the mortgage portfolio and reduce the relationship between the bank and the customer.	Until now, one of the banks that continues to try to overcome the problem of churn customers is Bank Mandiri. However, in responding to these challenges, there are several problems that become obstacles to solve them. The lack of information about factor that affect churn customers still limited due to lack of information in unbalanced population. As a result, it will have an impact on mitigation actions that can be taken by banks before customer’s churn. Therefore, the purpose of this study is to create a predictive model that is able to classify churn customers on mortgage products so that Bank Mandiri can do retention just in time.	The process carried out to achieve this goal can be started by grouping customer groups into binary data, where there will be churn customers and loyal customers. Then the research continued by collecting factors that were suspected of influencing churn customers, including Recency, Frequency, and Monetary (RFM), savings balances, income, bills, Debt Burden Ratio (DBR), age, rate, Debt Equity Ratio (DER) and outstanding amount. The data used in this study is transaction history data, funds, and customer credit starting in 2019 – May 2021, consisting of 50,000 mortgage customers. The data obtained will be continued by modeling using binary logistic regression algorithm. For model validation, the model used will be tested using the Receiver Operating Characteristic (ROC) and Area Under Curve (AUC) values as the value of the feasibility of testing the data model. Then from the test results will be obtained a model to look for opportunities or predictive value and identification of the significant parameters that influence it based on the value of the important features. The final result of this model obtained 7 variabels that affect the model accompanied by the AUC value of the original binary logistic of 0.68 and the SMOTE binary logistic of 0.72."
Rancang Bangun Plugin Ekstraksi Materi Belajar Berdasarkan Materi Prasyarat pada LMS Moodle.,"Khairunnisa, Aprilia",http://repository.its.ac.id/78014/,"Saat ini banyak instansi pendidikan yang melakukan sistem pembelajaran menggunakan e-learning, begitu juga dengan Departemen Informatika Institut Teknologi Sepuluh Nopember (ITS). Proses pembelajaran menggunakan e-learning memiliki banyak manfaat salah satunya adalah memungkinkan mahasiswa untuk dapat belajar secara mandiri. Saat proses belajar mandiri, mahasiswa dapat menentukan sendiri mata kuliah apa yang ingin dipelajari. Dalam suatu mata kuliah terdapat mata kuliah prasyarat yang harus dipenuhi untuk dapat melanjutkan ke mata kuliah berikutnya. Mata kuliah prasyarat sangat penting untuk mengetahui gambaran materi apa saja yang akan dipelajari dalam mata kuliah tertentu. Namun pada saat ini sistem pembelajaran berbasis e-learning seperti Moodle, belum memberikan fitur untuk dapat mengetahui mata kuliah prasyarat dari sebuah mata kuliah. Selain itu, mata kuliah prasyarat seringkali dicantumkan dalam deskripsi mata kuliah. Hal ini dapat dimanfaatkan untuk mengetahui mata kuliah prasyarat secara lebih mudah.Untuk menentukan mata kuliah prasyarat dari suatu deskripsi diperlukan ekstraksi untuk mendeteksi entitas mata kuliah. Named Entity Recognition (NER) dapat digunakan sebagai solusi untuk melakukan ekstraksi entitas kata. Proses ekstraksi diawali dengan membuat model NER berbahasa Indonesia dengan menggunakan SpaCy dan alat bantu anotasi Prodigy. Selanjutnya hasil anotasi akan diintegrasikan kedalam plugin moodle. Plugin yang akan dibangun bertipe block, dimana plugin ini menampilkan data mata kuliah berserta mata kuliah prasyarat.Maka dari itu, pembuatan plugin ekstraksi materi belajar berdasarkan materi prasyarat pada LMS (Learning Management System) Moodle ini diusulkan sebagai solusi dari permasalahan diatas. Plugin ini dikembangkan melalui Moodle dikarenakan Moodle merupakan salah satu LMS berbasis web yang banyak digunakan pada e-learning. Dengan adanya plugin ini, pengguna yaitu mahasiswa maupun tenaga pengajar dapat melihat mata kuliah prasyarat dari suatu mata kuliah dengan mudah.=========================================================At present many of educational institutions are conducting learning system using e-learning based, as well as in Information Departement Sepuluh Nopember Institute of Technology (ITS). The learning process of e-learning based has many benefits, one of them is for students to be able to learn independently. In the process of independent learning, students can determine their own subjects what they what to learn. In a course, the are certainly prerequisite courses that must be finished to be able to proceed to the next course. The prerequisite courses are very important to know what material will be studied in certain course. But at this time learning sistem based of e-learning such as Moodle, have not provided features to be able to know the prerequisite courses from a course. Beside that, course prerequisite are often indicated in course description. This can be used to find out what is the course prerequisite easily.To determine the prerequisite courses from a description, extraction is needed to detect entity subjects. Named Entity Recognition (NER) can be used as a solution for doing extraction word entities. The extraction process begins by creating an Indonesan-language NER model using SpaCy and Prodigy annotation tools. Then the annotation results will be integrated into moodle plugin. Plugin that will be built are block type, where the plugin will display course data along with prerequisite courses.Therefore, the creation of a learning material extraction plugin based on the prerequisite material on the Moodle LMS (Learning Management System) is proposed as a solution to the above problem. This plugin will be developed through Moodle because Moodle is one of the web-based LMS that is widely used in e-learning system. With this plugin, users which are students and teachers, can see prerequisite courses from a subject easily."
Rancang Bangun Stetoskop Elektronik Berbasis Android untuk Identifikasi Sinyal Suara Jantung.,"Khansa, Shalfienna Alya",http://repository.its.ac.id/102340/,"Penyakit jantung merupakan salah satu penyebab utama kematian di dunia dan masih menjadi penyebab kematian tertinggi di Indonesia. Kondisi geografis Indonesia yang terdiri dari 7000 pulau menyebabkan proses penanganan penyakit jantung lebih sulit, terutama pada daerah terpencil. Proses deteksi dini penyakit jantung perlu dilakukan sebagai upaya mengurangi angka kematian. Namun proses deteksi dini dari penyakit jantung menjadi tantangan yang sulit, karena membutuhkan biaya yang mahal dan bergantung dengan petugas medis untuk hasil deteksi yang akurat. Seiring berkembangnya teknologi, smartphone mulai bermunculan dengan kemampuan yang semakin canggih dan dapat mendukung perkembangan aplikasi mobile health sebagai solusi untuk pemantauan kesehatan jarak jauh. Dalam Tugas Akhir ini, dirancang stetoskop yang terhubung dengan smartphone berbasis android untuk proses analisa sinyal suara jantung menggunakan aplikasi. Aplikasi akan dilengkapi metode identifikasi suara sehingga dapat mengurangi ketergantungan pengguna dengan petugas medis. Sinyal suara jantung akan diproses menggunakan metode Discrete Wavelet Transform untuk denoising dan metode Linear Envelope untuk pemrosesan suara jantung. Alat dirancang dengan menggunakan stetoskop berbiaya rendah yang membedakan dengan stetoskop elektronik di pasaran. Dari proses identifikasi sinyal suara jantung yang dilakukan dengan 20 subjek, 75% dari data perekaman sinyal jantung menghasilkan keluaran identifikasi yang akurat. Data sinyal PCG, pemrosesan, dan hasil ditampilkan pada aplikasi android secara optimal.===================================================================================================================================Heart disease is one of the leading causes of death worldwide and the highest cause of death in Indonesia. The geographic conditions of Indonesia, comprising over 7000 islands, engender significant challenges in managing heart disease, particularly in remote and underdeveloped areas. Early detection is critical for reducing mortality rates associated with heart disease. However, this process poses challenges due to its high cost and reliance on clinicians for accurate detection. With technological advancements, smartphones have emerged with increasingly advanced capabilities, supporting the development of mobile health applications for remote health monitoring. This research aims to create an electronic stethoscope that connects to an Android-based smartphone application for heart sound signal identification. The application offers a reliable validation method to reduce dependency on clinicians. The process of heart sound signal uses the 5^th levels of the Discrete Wavelet Transform method for denoising and the Linear Envelope method for heart sound identification. The instrument design incorporates a cost-effective stethoscope, distinguishing it from existing electronic stethoscopes in the market. The heart sound identification method was applied to 20 individuals, revealing that 75% of the recorded heart signal data generated precise identification results. The Android application effectively showcases PCG signal data, processing, and outcomes."
Pengujian dan Kalibrasi Bubble Detector Photoelectric Infrared pada Mesin Hemodialisis.,"Kirana, Berliana Shafa",http://repository.its.ac.id/112721/,"Hemodialisis adalah prosedur medis yang digunakan untuk menggantikan fungsi ginjal yang rusak. Selama dialisis untuk pasien gagal ginjal dapat muncul gelembung udara dalam darah. Detektor gelembung merupakan salah satu bagian penting dalam proses ini, karena detektor gelembung akan mendeteksi adanya bubble dalam aliran Venous Catheter. Kehadiran bubble dalam sistem vena dapat mengakibatkan kondisi syok atau henti jantung yang berpotensi fatal. Studi sebelumnya telah mengembangkan detektor microbubble menggunakan teknologi Photoelectric Infrared. Sebelumnya dalam memaksimalkan pembacaan dilakukan penyesuaian pancaran sinar infrared dalam memaksimalkan pancaran saja dan belum dilakukan kalibrasi dan pengujian menggunakan darah. Dilakukan  pengujian menggunakan air, performa deteksi bubble setelah dilakukan kalibrasi meningkat dimana error yang dimilikin oleh sensor infrared 0,01060071, dan menjadi 0,00003964, sedangkan akurasi sensor 0,9 menjadi 0,99 dan presisi 0,85 menjadi 0,99. Hasil kalibrasi menggunakan air menunjukkan adanya peningkatan performa deteksi bubble. Kalibrasi sensor ini dilakukan dengan menggunakan metode logistik regresi dengan intercept dan slope yang didapat yakni 65,0197325226436 dan -0,06463164465137253. Pada pengujian menggunakan darah, didapat hasil pembacaan sensor memiliki penurunan performa pembacaan dimana presisi, 0,7158, akurasi 77,45 dan error sebanyak 0,2845. Hasil dari pengujian ini menunjukkan adanya penurunan performa saat pengujian menggunakan darah. Pengujian pada golongan darah yang berbeda (A, B, dan AB) menunjukkan hasil variatif. Darah golongan A memiliki performa yang cukup baik dengan error 0,041666667, akurasi 0,92, dan presisi 0,6. Namun, darah golongan B menunjukkan hasil pembacaan yang terus menerus 1, disebabkan oleh viskositas tinggi yang berbeda jauh dari darah A. Pada darah golongan AB, hasil kalibrasi menunjukkan error 0,073394495, akurasi 0,874, dan presisi 0,868. Hasil ini menegaskan bahwa performa deteksi bubble pada sensor infrared sangat dipengaruhi oleh viskositas medium. Kalibrasi dengan medium yang memiliki viskositas serupa penting untuk memastikan akurasi dan presisi pembacaan sensor.===========================================================================Hemodialysis is a medical procedure used to replace damaged kidney function. During dialysis for kidney failure patients, air bubbles may appear in the blood. The bubble detector is an important part of this process, because the bubble detector will detect the presence of bubbles in the Venous Catheter flow. The presence of bubbles in the venous system can result in potentially fatal shock or cardiac arrest. Previous studies have developed microbubble detectors using Infrared Photoelectric technology. Previously, to maximize readings, adjustments were made to the infrared beam to maximize the beam only and calibration and testing using blood had not been carried out. Testing using water was carried out, the bubble detection performance after calibration increased, where the error of the infrared sensor was 0,01060071, and became 0,00003964, while the sensor accuracy was 0,9 to 0,99 and the precision was 0,85 to 0,99. The results of calibration using water show an increase in bubble detection performance. Calibration of this sensor was carried out using the logistik regression method with the intercept and slope obtained, namely 65,0197325226436 and -0,06463164465137253. In testing using blood, it was found that the sensor reading results had a decrease in reading performance, where the precision was 0,7158, the accuracy was 77,45 and the error was 0,2845. The results of this test show a decrease in performance when testing using blood. Testing on different blood types (A, B, and AB) shows varied results. Type A blood has quite good performance with an error of 0,041666667, accuracy of 0,92, and precision of 0,6. However, type B blood shows a continuous reading of 1, caused by the high viscosity which is very different from blood A. For type AB blood, the calibration results show an error of 0,073394495, an accuracy of 0,874, and a precision of 0,868. These results confirm that the bubble detection performance of the infrared sensor is strongly influenced by the viscosity of the medium. Calibration with a medium that has a similar viscosity is important to ensure the accuracy and precision of sensor readings."
Penerapan Metode K-Means dan Fuzzy C-Means pada Pengelompokkan Kabupaten/Kota di Provinsi Jawa Barat Berdasarkan Indikator Kemiskinan.,"Kiranadhewi, Afi Iffa Praba",http://repository.its.ac.id/119039/,"Kemiskinan adalah masalah sentral yang dihadapi negara-negara berkembang, termasuk Indonesia. Meski beberapa negara telah menunjukkan kemajuan ekonomi, kemiskinan tetap menjadi tantangan signifikan. Di Indonesia, tingkat kemiskinan yang tinggi memerlukan perhatian khusus dari pemerintah pusat dan daerah. Provinsi Jawa Barat, yang memiliki potensi besar dalam berbagai sektor, masih berjuang melawan masalah kemiskinan. Untuk mengatasi ini, diperlukan sistem yang dapat mengelompokkan kabupaten/kota berdasarkan indikator kemiskinan sehingga program pembangunan dapat dirancang dan dilaksanakan lebih efektif. Penelitian ini bertujuan untuk mengelompokkan kabupaten/kota di Jawa Barat berdasarkan faktor-faktor yang mempengaruhi kemiskinan tahun 2023 menggunakan metode K-Means dan Fuzzy C-Means (FCM). Langkah awal penelitian ini adalah melakukan standardisasi data. Selanjutnya, dilakukan analisis deskriptif untuk memahami karakteristik data sebelum melakukan pengelompokan. Hasil pengelompokan kedua metode tersebut dibandingkan untuk menentukan metode yang lebih efektif. Sebagai output akhir, dibuat dashboard untuk memetakan kabupaten/kota di Jawa Barat berdasarkan indikator kemiskinan. Hasil penelitian ini diharapkan dapat memberikan gambaran kondisi kemiskinan di Jawa Barat dan berfungsi sebagai alat monitoring bagi pemerintah dan lembaga terkait dalam upaya mencapai target Sustainable Development Goals (SDGs) 2030 dalam mengurangi kemiskinan.================================================================================================================================Poverty is a central issue facing developing countries, including Indonesia. Although some countries have shown economic progress, poverty remains a significant challenge. In Indonesia, the high poverty rate requires special attention from the central and local governments. West Java Province, which has great potential in various sectors, is still struggling against the problem of poverty. To address this, a system is needed that can cluster districts / municipalities based on poverty indicators so that development programs can be designed and implemented more effectively. This study aims to cluster districts/cities in West Java based on factors affecting poverty in 2023 using the K-Means and Fuzzy C-Means (FCM) methods. The first step of this research is testing the multivariate normal assumption and Bartlett's test to assess the suitability of the data. Next, descriptive analysis was conducted to understand the characteristics of the data before clustering. The clustering results of the two methods were compared to determine the more effective method. As a final output, a dashboard was created to map districts/cities in West Java based on poverty indicators. The results of this research are expected to provide an overview of poverty conditions in West Java and serve as a monitoring tool for the government and related institutions in an effort to achieve the 2030 Sustainable Development Goals (SDGs) target in reducing poverty."
"Pengenalan Ekspresi Wajah dengan Variasi Pencahayaan Menggunakan Local Ternary Pattern, Convolutional Neural Network dan Extreme Learning Machine.","Krisnahati, Ice",http://repository.its.ac.id/95909/,"Pengenalan ekspresi wajah secara otomatis banyak dimanfaatkan pada interaksi manusia dan robot, permainan visual interaktif, dan deteksi gangguan mental. Oleh karena itu, pengenalan ekspresi wajah secara otomatis masih menjadi perhatian peneliti di bidang visi komputer. Berbagai macam metode telah diusulkan untuk mengatasi masalah variasi pencahayaan. Berdasarkan penelitian sebelumnya, citra Local Ternary Pattern (LTP) yang diklasifikasikan dengan metode Convolutional Neural Network (CNN) mampu mengatasi variasi pencahayaan. CNN merupakan metode klasifikasi yang handal, tetapi memiliki waktu pelatihan yang lebih lama untuk arsitektur yang lebih rumit. Pada penelitian lain, Extreme Learning Machine (ELM) dimanfaatkan untuk memodifikasi CNN pada lapisan klasifikasi untuk mengatasi waktu pelatihan yang lama.  Penelitian ini menggabungkan metode yang sudah diteliti sebelumnya dengan memanfaatkan kelebihan masing-masing metode. Citra LTP digunakan untuk mengatasi masalah pencahayaan. Kemudian, citra LTP tersebut digunakan sebagai input pada arsitektur CNN untuk proses ekstraksi fitur. Pada lapisan klasifikasi, CNN dimodifikasi dengan menghilangkan lapisan fully connected dan menggantinya dengan metode ELM. Tujuan dari modifikasi CNN tersebut adalah untuk mengatasi pelatihan yang memakan waktu pada backpropagation. Sehingga, penelitian ini membangun model dengan kombinasi metode LTP, CNN, dan ELM.  Pengujian metode menggunakan dataset KDEF dengan total 980 citra wajah dan tujuh kelas ekspresi wajah, yaitu marah, senang, sedih, takut, netral, jijik, dan terkejut dengan variasi pencahayaan mulai dari agak gelap sampai agak terang. Hasil pola kombinasi yang dihitung berdasarkan rata-rata dari pola atas dan pola bawah citra LTP menghasilkan akurasi paling tinggi jika dibandingkan dengan pola atas dan pola bawah citra LTP. Evaluasi menggunakan 10-fold cross-validation menunjukkan bahwa kinerja kombinasi metode LTP, CNN, dan ELM menghasilkan nilai akurasi sebesar 85,51% dengan waktu pelatihan 1.876 detik. Nilai akurasi ini meningkat bila dibandingkan dengan penelitian sebelumnya. Berdasarkan hasil tersebut, penelitian ini mampu mengatasi masalah pencahayaan pada kasus pengenalan ekspresi wajah============================================================================================================================Automatic facial expression recognition is widely used in human-robot interactions, interactive visual games, and mental disorder detection. Therefore, automatic facial expression recognition is still an exciting task for researchers in computer vision. Various methods have been proposed to solve the lighting variation problem. Based on previous research, Local Ternary Pattern (LTP) images classified by the Convolutional Neural Network (CNN) method can handle lighting variations. CNN is a reliable classification method but has a longer training time for more complex architectures. In another study, Extreme Learning Machine (ELM) was used to modify CNN at the classification layer to overcome the long training problem. This study combines methods that have been previously studied by exploiting the advantages of each method. LTP images are used to solve lighting problems. Then, the LTP image is used as input to the CNN architecture for the feature extraction process. At the classification layer, CNN is modified by removing the fully connected layer and replacing it with the ELM method. The purpose of the CNN modification is to overcome the time-consuming training on backpropagation. Thus, this study builds a model combining LTP, CNN, and ELM methods. This research used the KDEF dataset with 980 facial images (frontal face) and seven facial expressions: angry, happy, sad, scared, neutral, disgusted, and surprised, with lighting variations ranging from dark to bright. The combination pattern results calculated based on the average of the top and bottom patterns of the LTP image produce the highest accuracy compared to the top and bottom patterns of the LTP image. Evaluation using 10-fold cross-validation shows that the performance of the combination of LTP, CNN, and ELM methods produce an accuracy value of 85.51% with a training time of 1,876 seconds. This accuracy value increases when compared to previous studies. Based on these results, this study was able to overcome the lighting problem in the case of facial expression recognition"
Pengembangan Kursi Roda Otonom Berbasis YOLOV8 Untuk Penghindaran Obstacle.,"Kusuma, I Gst Ngr Agung Hari Vijaya",http://repository.its.ac.id/111406/,"Pengembangan kursi roda otonom telah menjadi semakin penting dalam meningkatkan mobilitas bagi individu dengan mobilitas terbatas. Studi ini mengusulkan pengembangan sistem kursi roda otonom berbasis YOLOv8 untuk menghindari obstacle, khususnya fokus pada deteksi obstacle manusia. Dengan memanfaatkan kemampuan deteksi objek yang canggih dari YOLOv8, sistem yang diusulkan bertujuan untuk mendeteksi dan menghindari obstacle manusia secara efektif. Sistem tersebut mendeteksi manusia melalui video menggunakan Intel NUC dan Kamera. Obstacle yang terdeteksi membuat NUC mengirim perintah ke ESP32 untuk menjalankan motor untuk melakukan manuver penghindaran. Pengujian performa keberhasilan penghindaran dilakukan dengan 30 kali percobaan pada objek manusia yang diam. Hasil pengujian menunjukkan bahwa kursi roda berhasil menghindar sebanyak 30 kali tanpa gagal, memberikan tingkat keberhasilan sebesar 100%. Hal ini menunjukkan bahwa sistem kursi roda otonom yang dirancang mampu melakukan penghindaran rintangan dengan sangat baik.========================================================================================================="
Analisis Sentimen Warga Indonesia Terhadap Penanganan Kasus COVID-19 Menggunakan Metode Naïve Bayes Dan Support Vector Machine (SVM).,"Lestari, Dhany Nastiti",http://repository.its.ac.id/91616/,"Kehidupan masyarakat zaman sekarang mengalami banyak perubahan akibat dari perkembangan ilmu pengetahuan  dan teknologi. Masyarakat menjadi lebih reaktif menanggapi fenomena disekitar, termasuk  berita, kebijakan, serta upaya-upaya pemerintah menanggulangi pandemi COVID-19. Feedback masyarakat mengenai upaya-upaya pemerintah menanggulangi bencana dapat dijadikan bahan evaluasi untuk meningkatkan kinerja. Untuk mendapatkan hasil yang dapat dilihat secara jelas maka digunakan proses klasifikasi terhadap opini-opini masyarakat menjadi opini dengan sentimen positif serta sentimen negatif. Data teks yang didapat dari tweet masyarakat Indonesia akan di preprocessing menggunakan tokenisasi, case folding, serta penghapusan stopwords. Data hasil preprocessing akan dilakukan ektraksi fitur Term Frequency-Inverse Document Frequency (TF-IDF), dengan satu term adalah sebuah n-grams dan akan dilakukan klasifikasi menggunakan metode naïve Bayes dan Support Vector Machine (SVM). Hasil dari klasifikasi sentiment menunjukkan bahwa metode SVM lebih baik daripada Naïve Bayes, khususnya SVM dengan menggunakan kernel radial basis karena memiliki F1-score, recall, dan accuracy yang lebih tinggi.===================================================================================================Life in our current society undergoes many changes as a result of the development of science and technology. People have become more reactive in responding to phenomena around them, including news, policies, and government efforts to tackle the COVID-19 pandemic. Public feedback regarding the government's efforts to cope with disasters can be used as evaluation material to improve performance. To get results that can be seen clearly, a classification process is used to classify public opinions into opinions with positive sentiments and negative sentiments. Text data obtained from Indonesian people's tweets will be preprocessed using tokenization, case folding, and removal of stop words. The data from the preprocessing will be extracted with Term Frequency-Inverse Document Frequency (TF-IDF), with one term being n-grams and will be classified using the Nave Bayes method and Support Vector Machine (SVM). The results of the sentiment classification show that the SVM method is better than Naïve Bayes, especially SVM using a radial basis kernel because it has a higher mean  F1-score, recall, and accuracy."
Aspect-Based Sentiment Analysis Pada Ulasan Konsumen Terhadap Kualitas Layanan PT Citilink Indonesia.,"Lestarie, Maisa Haifa",http://repository.its.ac.id/107066/,"Transportasi udara yang menjadi moda transportasi paling sering digunakan oleh konsumen Indonesia. Terciptanya konsep penerbangan Low-Cost Carier (LCC) dimana penerbangan menerapkan strategi penurunan biaya operasional dan mengoptikmalkan biaya disetiap lini. Kompetisi maskapai penerbangan lowcost carrier yang tinggi mendorong perusahaan untuk menguatkan merek dan mengembangkan strategi. Salah satu maskapai LCC di bawah naungan Garuda Indonesia yaitu PT Citilink Indonesia sebagai upaya Garuda Indonesia untuk bersaing pada segment budget traveler. Pada pelaksanaannya PT Citilink Indonesia dinilai memberi informasi delay secara mendadak dan juga penurunan layanan call center dalam menangani keluhan penumpang. Kualitas layanan berpengaruh pada brand image dan brand trust sebagai faktor yang menentukan loyalitas konsumen. Berdasarkan hal tersebut dapat dilakukan analisis sentimen untuk mengetahui pandangan konsumen terhadap PT Citilink Indonesia dengan mengukur kualitas layanan berdasarkan aspek. Metode yang digunakan adalah Aspect Based Sentiment Analysis dengan algoritma Naïve Bayes Classifier dan word2vec. Hasil dari penelitian ini berupa sentimen negatif terhadap aspek tangible, responsiveness, reliability, dan assurance dengan aspect-based sentiment analysis menghasilkan akurasi klasifikasi kelas sentimen sebesar 89% dan kelas aspek sebesar 62%.=============================================================================================================================Air transportation is the most frequently used mode of transportation by Indonesian consumers. The creation of the Low-Cost Carrier (LCC) flight concept where flights implement a strategy of reducing operational costs and optimizing costs in every line. High low-cost carrier airline competition encourages companies to strengthen brands and develop strategies. One of the LCC airlines under Garuda Indonesia is PT Citilink Indonesia as Garuda Indonesia's effort to compete in the budget traveler segment. In its implementation, PT Citilink Indonesia is considered to provide sudden delay information also a decrease in call center services in handling passenger complaints. Service quality affects brand image and brand trust as factors that determine consumer loyalty. Based on this, sentiment analysis can be carried out to determine consumer views on PT Citilink Indonesia by measuring service quality based on aspects. The method used is Aspect Based Sentiment Analysis with the Naïve Bayes Classifier algorithm and word2vec. The results of this study are negative sentiments towards tangible, responsive, reliability, and assurance aspects with aspect-based sentiment analysis resulting in a sentiment class classification accuracy of 89% and an aspect class of 62%."
Pengembangan Model Prediksi Dan Model Bisnis Pada Pembiayaan Kendaraan Berbasis Data Mining.,"Lupitadevi, Citra Judith",http://repository.its.ac.id/92534/,"Pembiayaan kendaraan merupakan salah satu kebutuhan yang diperlukan oleh konsumen pada saat membeli kendaraan. PT Mandiri Tunas Finance (MTF) merupakan salah satu perusahaan pembiayaan kendaraan di Indonesia. Total pembiayaan kendaraan yang telah disalurkan di 2020 adalah sebesar 16.7 trilun. Kondisi Pandemi Covid-19 yang terjadi sejak akhir tahun 2019, memberikan dampak yang signifikan terdapat bisnis perusahaan pembiayaan. Perusahaan pembiayaan mengalami penurunan sebesar 40%, hal ini didorong juga karena penurunan penjualan mobil sebesar 44.6% pada Tahun 2020 dibandingkan Tahun 2019. Sumber order PT Mandiri Tunas Finance mayoritas berasal dari penjualan dealer kendaraan. Turunnya penjualan mobil, berdampak langsung pada bisnis PT Mandiri Tunas Finance. Untuk mengatasi hal tersebut, perlu dikembangkan sumber order lain terutama yang berasal dari pengolahan database customer perusahaan (data mining). Dalam penelitian ini, akan dilakukan penerapan model prediksi dengan regresi logistik biner. Hal ini dilakukan dengan mengembangkan model untuk memprediksi customer yang akan melakukan pengambilan pembiayaan. Tingkat akurasi model prediksi akan diukur dengan menggunakan nilai Area Under Curve (AUC). Selain pengembangan model prediksi, juga dilakukan pengembangan model bisnis pembiayaan berbasis data mining dengan menggunakan pendekatan Businees Model Canvass. Hasil model regresi logistik biner, diketahui variabel prediktor yang mempengaruhi customer dalam mengambil pembiayaan mobil kembali adalah jangka waktu dari pembiayaan sebelumnya, penghasilan customer, jenis produk yang dibiayai, status kepemilikan rumah, status pernikahan, jenis pekerjaan customer dan pendidikan. Dengan pendekatan Area Under Curve diketahui akurasi model yang terbentuk adalah 95,803% yang artinya model ini baik untuk digunakan. Dalam menjalankan model bisnis berbasis data mining ini, perusahaan perlu membentuk fungsi data analytic dan penawaran secara aktif kepada customer.========================================================================================================================================Vehicle financing is one of the financing products needed by consumers when buying a vehicle. PT Mandiri Tunas Finance (MTF) is one of the vehicle financing companies in Indonesia. The total vehicle financing that has been disbursed by MTF in 2020 is 16.7 trillion. The Covid-19 Pandemic condition that has occurred since the end of 2019, has had a significant impact on the financing company business. Finance company’s disbursement decreased by 40%, this was also driven by a 44.6% decline in car sales in 2020 compared to 2019. The main source of orders for MTF comes from vehicle dealer sales. The decline in car sales had a direct impact on MTF’s business. To overcome this, it is necessary to develop other order sources, especially those from the company's customer database processing (data mining). In this research, the prediction model with binary logistic regression will be applied. A model will be used to predict which customers will take financing. The accuracy of the prediction model will be measured using Area Under Curve (AUC) values. In addition, the development of a data mining-based financing business model is also carried out using the Business Model Canvass approach. The results of binary logistic regression models, predictor variables that affect customers in car financing are the period of previous financing, salary, type of product financed, homeownership status, marital status, customer employment type, and education. With the Area Under Curve approach, the accuracy of the model formed is 95.803% which means that this model is good to use. In carrying out this data mining-based business model, companies need to form data analytic functions and build offer activities to customers."
Model Manajemen Persediaan Spare Part Pada Alat Berat Pelabuhan Untuk Meningkatkan Availability.,"Mahardika, I Gede Widya",http://repository.its.ac.id/117176/,"Penelitian ini mengkaji permasalahan pada salah satu terminal petikemas di Indonesia yang menghadapi tantangan dalam pengelolaan suku cadang kritis yang berdampak pada operasional dan ketersediaan alat. Data operasional perusahaan menunjukkan tingkat availability alat straddle carrier hanya mencapai 69,33% pada tahun 2023, di bawah target KPI. Data historis menunjukkan bahwa sekitar 56% dari total downtime disebabkan oleh waktu menunggu ketersediaan suku cadang. Untuk mengatasi permasalahan tersebut, dikembangkan model optimasi manajemen persediaan berbasis continuous review (Q, r) yang mengintegrasikan variabel lead time dan ketidakpastian permintaan berdasarkan pola distribusi permintaan historis. Pengujian model ini dilakukan melalui simulasi Monte Carlo dengan mengaplikasikan berbagai skenario kebutuhan pada 10 jenis spare part yang dipilih berdasarkan tingkat kekritisannya. Performa model dievaluasi menggunakan tiga parameter utama, yaitu total inventory cost (TIC), service level, dan availability. Hasil validasi menunjukkan bahwa model mampu merepresentasikan kondisi aktual dengan perbedaan hanya 1,6% dari data nyata, yang masih berada dalam batas toleransi kesalahan 5%. Implementasi skenario perbaikan dengan modifikasi setup pemesanan pada interval tiga bulan menghasilkan optimasi signifikan berupa reduksi TIC sebesar 33%, peningkatan service level spare part sebesar 7,8% mencapai 95%, serta peningkatan availability alat sebesar 4,9% menjadi 75%.===================================================================================================================================This research examines challenges faced by a container terminal in Indonesia in managing critical spare parts, which impact operations and equipment availability. Operational data from the company reveals that the availability rate of straddle carriers only reached 69.33% in 2023, falling below the KPI target. Historical data indicates that approximately 56% of total downtime was caused by delays in spare part availability. To address this issue, an optimization model for inventory management based on continuous review (Q, r) was developed, integrating lead time and demand uncertainty variables derived from historical demand distribution patterns. The model was tested through Monte Carlo simulations applied to various demand scenarios for 10 types of spare parts, selected based on their criticality. The model's performance was evaluated using three key parameters: total inventory cost (TIC), service level, and equipment availability. Validation results demonstrated that the model accurately represented actual conditions, with a deviation of only 1.6% from real-world data, well within the acceptable error margin of 5%. The implementation of improvement scenarios, involving modifications to ordering setups at three-month intervals, achieved significant optimization, including a 33% reduction in TIC, a 7.8% increase in spare parts service level to 95%, and a 4.9% improvement in equipment availability to 75%."
Implementasi 2D-CNN dengan Teknik Augmentasi EEG untuk Mendeteksi Kejang Epilepsi pada Dataset Siena Scalp EEG.,"Malinus, Azzura Mahendra Putra",http://repository.its.ac.id/117872/,"Epilepsi adalah sebuah penyakit otak dengan gejala yang dialami penderitanya berupa kejang epileptik yang berulang. Untuk mendiagnosis epilepsi, ahli neurologi menganalisis rekaman sinyal otak Electroencephalography (EEG) yang diperoleh dari pasien epilepsi. Masalah yang ditemui adalah proses analisis sinyal EEG untuk menentukan kejadian kejang epilepsi dapat memakan waktu cukup lama karena sinyal EEG memiliki karakteristik yang kompleks dan durasi yang panjang. Oleh karena itu, diperlukan sebuah sistem yang mampu melakukan hal tersebut secara otomatis untuk mempermudah pekerjaan para ahli neurologi. Pada tugas akhir ini, dibuat sebuah sistem yang dapat melakukan anotasi kejadian kejang epilepsi pada rekaman sinyal EEG secara otomatis. Sistem tersebut terdiri dari sebuah model deep learning dengan arsitekstur 2D Convolutional Neural Network (CNN) untuk mengklasifikasi segmen-segmen rekaman EEG dan sebuah aplikasi antarmuka yang menampilkan visualisasi sinyal dari input rekaman EEG dan hasil deteksi dari model deep learning tersebut. Dataset Siena Scalp EEG digunakan sebagai input pengembangan model dan diterapkan beberapa tahap preprocessing, seperti penamaan ulang dan pengurangan durasi, down sampling, bipolar montage, filter Butterworth bandpass, dan segmentasi dengan sliding window. Dari tahap preprocessing, diperoleh beberapa variasi input dengan menggunakan beberapa nilai pada variabel window, stride, dan chunk saat proses segmentasi dengan sliding window. Input-input yang dihasilkan digunakan untuk melatih model dengan menerapkan 5-Fold Cross Validation dan teknik augmentasi EEG, seperti time reverse, sign flip, fourier transform surrogate, dan frequency shift. Aplikasi antarmuka dikembangkan menggunakan HTML, CSS, dan JavaScript untuk sisi klien dan Flask untuk sisi server. Dari seluruh uji coba pengembangan model yang telah dilakukan, diperoleh hasil terbaik pada uji coba penerapan teknik augmentasi fourier transform surrogate dengan gangguan fase 0.8 terhadap model dasar 2D-CNN. Pada uji coba tersebut, input window 15 detik dengan stride 2.5 detik memberikan kinerja model terbaik, yaitu accuracy 91.80%, sensitivity 93.25%, specificity 90.37%, dan mean AUC 97%.===================================================================================================================================Epilepsy is a brain disease whose symptoms include recurrent epileptic seizures. To diagnose epilepsy, neurologists analyze Electroencephalography (EEG) brain signal recordings obtained from epilepsy patients. The problem encountered is that the process of analyzing EEG signals to determine the occurrence of epileptic seizures can take a long time because EEG signals have complex characteristics and long duration. Therefore, a system that is able to do this automatically is needed to facilitate the work of neurologists. In this undergraduate thesis, a system that can annotate epileptic seizure events on EEG signal recordings automatically is created. The system consists of a deep learning model with 2D Convolutional Neural Network (CNN) architecture to classify EEG recording segments and an interface application that displays signal visualization of EEG recording input and detection results from the deep learning model. The Siena Scalp EEG dataset is used as input for model development and several preprocessing stages are applied, such as renaming and duration reduction, down sampling, bipolar montage, Butterworth bandpass filter, and segmentation with sliding window. From the preprocessing stage, several input variations were obtained by using several values for the window, stride, and chunk variables during the sliding window segmentation process. The resulting inputs are used to train the model by applying 5-Fold Cross Validation and EEG augmentation techniques, such as time reverse, sign flip, fourier transform surrogate, and frequency shift. The application interface was developed using HTML, CSS, and JavaScript for the client side and Flask for the server side. From all the model development trials that have been conducted, the best results were obtained in the trial of applying the fourier transform surrogate augmentation technique with a phase noise of 0.8 to the 2D-CNN base model. In this trial, the 15-second input window and 2.5 second stride provide the best model performance, namely accuracy of 91.80%, sensitivity of 93.25%, specificity of 90.37%, and mean AUC of 97%."
Integrasi Servqual Dan Quality Function Deployment Sebagai Upaya Peningkatan Pelayanan Minimarket.,"Maslikhan, Akhmad",http://repository.its.ac.id/109569/,"ABSTRAKMinimarket Minimarket menyediakan produk sehari-hari dengan akses mudah dan jam buka panjang, berfungsi tidak hanya sebagai tempat berbelanja tetapi juga sebagai bagian dari perubahan bisnis dan ritel yang beradaptasi dengan kebutuhan masyarakat. Meskipun lebih kecil dari supermarket, minimarket berusaha menyediakan berbagai produk seperti makanan, minuman, barang rumah tangga, buku, dan kitab keagamaan. Tantangan utama yang dihadapi adalah meningkatnya ketidakpuasan pelanggan yang dapat berdampak negatif pada profitabilitas Minimarket Darut Taqwa yang telah beroperasi sejak 2004, menekankan kenyamanan, kepuasan pelanggan, dan pelayanan terbaik, serta bertujuan mengembangkan keterampilan wirausaha di kalangan santri. Untuk mengatasi ketidakpuasan pelanggan, digunakan analisis dengan metode SERVQUAL dan QFD. Penelitian ini menggunakan tujuh aspek penilaian SERVQUAL yaitu tangibility, reliability, responsiveness, assurance, empathy, communication, dan security. QFD digunakan untuk mengintegrasikan keinginan pelanggan yang diverifikasi oleh perusahaan. Hasil analisis QFD menunjukkan nilai Customer Importance tertinggi (4,60) pada indikator ""Biaya/harga produk sesuai dengan kualitas yang diberikan"" dan terendah (4,02) pada indikator ""Pegawai minimarket melantunkan sapaan kepada customer yang baru berkunjung"". Nilai Customer Satisfaction Level (SCL) tertinggi (4,20) pada indikator ""Kesigapan dan ketegasan keamanan dalam mengamankan serta menertibkan area minimarket"" dan terendah (3,69) pada indikator ""Minimarket sering mengadakan event (promo) atau potongan harga"". Pengolahan data menurut penilaian Techical Requirement menyoroti bahwa prioritas perbaikan tertinggi jatuh pada ""Pelatihan Skill Komunikasi oleh Pihak Manajemen"" dengan bobot total 72 (7,16%) karena kontribusinya yang signifikan terhadap peningkatan kepuasan pelanggan. Prioritas kedua adalah ""Pelatihan karyawan dalam melayani konsumen"" dengan bobot 63 (6,27%) untuk meningkatkan keterampilan layanan pelanggan. Prioritas ketiga adalah ""Memberikan pelatihan dan briefing kepada karyawan"" dengan bobot 53 (5,27%) untuk meningkatkan pengetahuan dan pemahaman tugas. Sedangkan prioritas terendah adalah ""Instore Promo sebagai upaya peningkatan penjulan pada periode tertentu"" dengan bobot 5 (0,50%) karena kontribusi yang rendah terhadap peningkatan pelayanan minimarket."
Klasifikasi NSCLC dengan Arsitektur DenseNet dan GLCM Untuk Deteksi Dini Kanker Paru-Paru Pada Citra CT-Scan.,"Maulana, Irgi Azarya Putra",http://repository.its.ac.id/112781/,"Kanker paru-paru atau kanker pulmoner merupakan penyakin yang memiliki variasi keganasan tergantung kondisi. Kanker paru-paru terjadi ketika sel-sel di dalam paru-paru mengalami pertumbuhan yang tidak terkendali dan menjadi ganas. Ada dua jenis kanker paru-paru utama yaitu Non-Small Cell Lung Cancer (NSCLC) dan Small Cell Lung Cancer (SCLC). NSCLC adalah jenis kanker paru-paru yang paling umum, mencakup sekitar 85% dari semua kasus kanker paru-paru. NSCLC terbagi menjadi beberapa subjenis, termasuk Pulmonary Adenocarcinoma (ADC), dan Pulmonary Squamous Cell Carcinoma (SqCC). Sedangkan SCLC lebih jarang terjadi dan tumbuh lebih cepat daripada NSCLC. SCLC juga lebih cenderung menyebar ke bagian tubuh lain pada saat diagnosis dibandingkan NSCLC. Skrining menggunakan CT scan dosis rendah, yang diizinkan saat ini, seringkali memiliki tingkat sensitivitas yang rendah dan tingkat positif palsu yang tinggi. Lebih dari 90% dari hasil positif sebenarnya tidak menunjukkan adanya kanker. Selain itu, saat ini tidak ada biomarker tambahan yang dapat meningkatkan sensitivitas skrining CT dosis rendah, terutama pada pasien yang memiliki nodul paru-paru yang tidak jelas. Maka dari itu pengembangan machine learning untuk pendiagnosaan kanker paru-paru memudahkan pendiagnosaan dan meningkatkan efisiensi dalam pendiagnosaan non-invasif. Menggunakan metode Gray Level Co-occurance Matrix (GLCM) dan Convolutional Neural Network (CNN) menggunakan arsitektur Densely Connected Convolutional Network (DenseNet) yang digabungkan untuk klasifikasi tipe berdasarkan tekstur yang dilihat dari keabuan dan bentuk serta ukuran nodul.=================================================================================================================================Lung cancer, or pulmonary cancer, is a disease with varying degrees of malignancy depending on the condition. Lung cancer occurs when cells within the lungs experience uncontrolled growth and become malignant. There are two primary types of lung cancer: Non-Small Cell Lung Cancer (NSCLC) and Small Cell Lung Cancer (SCLC). NSCLC is the most common type of lung cancer, accounting for approximately 85% of all lung cancer cases. NSCLC is further divided into subtypes, including pulmonary adenocarcinoma (ADC) and pulmonary squamous cell carcinoma (SqCC). In contrast, SCLC is less common and tends to grow more rapidly than NSCLC, with a higher tendency to spread to other parts of the body at the time of diagnosis. Screening using low-dose CT scans, as currently permitted, often has low sensitivity and a high rate of false positives. More than 90% of positive results do not actually indicate the presence of cancer. Additionally, there are currently no additional biomarkers available to improve the sensitivity of low-dose CT screening, particularly for patients with unclear lung nodules. Therefore, the development of machine learning for lung cancer diagnosis would facilitate non-invasive diagnosis and improve diagnostic efficiency. Using methods such as the Gray Level Co-occurrence Matrix (GLCM) and Convolutional Neural Network (CNN) with the DenseNet architecture combined for classification based on texture, grayscale, shape, and size of nodules."
Reidentifikasi Orang pada Data Visible-Infrared Menggunakan Klasifier Swin Transformer.,"Maulana, Muhammad Azhar",http://repository.its.ac.id/111781/,"Reidentifikasi orang menjadi topik penelitian yang sangat hanget dalam beberapa tahun terakhir dalam visi komputer. Dalam penelitian ini mengusulkan pendekatan reidentifikasi orang yang menggunakan klasifier Swin Transformer pada data citra visual-infrared. Swin Transformer, sebuah arsitektur Transformer yang terkenal karena kinerjanya yang unggul dalam tugas-tugas visi komputer dalam citra visible, diadaptasi untuk tugas reidentifikasi orang dalam citra visible-infrared. Dataset visible-infrared yang digunakan pada penelitian ini adalah dataset RegDB, kemudian model Swin Transformer diaplikasikan sebagai klasifier. Pendekatan ini memungkinkan penangkapan fitur yang efektif dari citra visual dan inframerah, memanfaatkan keunggulan Swin Transformer dalam menangkap dependensi lokal dan global."
Kontrol Formasi Kooperatif dan Penghindaran Rintangan pada Multiple Unmanned Aerial Vehicle dengan Guidance Route dan Artificial Potential Field.,"Maynad, Vincentius Charles",http://repository.its.ac.id/95976/,"Dalam beberapa tahun terakhir, kontrol kooperatif sistem multi-UAV (Unmanned Aerial Vehicle) telah menjadi topik penelitian yang hangat di bidang kontrol penerbangan. Diantaranya, pengendalian formasi dan penghindaran rintangan adalah salah dua tema yang penting untuk diteliti karena kompleksitas kondisi permasalahan yang ingin diselesaikan selalu meningkat seiring waktu. Problema riil ini dapat dimodelkan sebagai permasalahan kontrol penghindaran rintangan pada formasi quadcopter. Sekelompok quadcopter ditugaskan untuk membentuk formasi (berupa bentuk V), bergerak dalam formasi menuju titik tujuan, menghindari tabrakan antar robot, dan menghindari tabrakan dengan rintangan. Model quadcopter yang digunakan adalah Quanser Qdrone dengan enam derajat kebebasan. Quadcopter dikontrol menggunakan fuzzy state feedback controller untuk melacak tujuan. Pada tugas akhir ini dirancang suatu sistem pengaturan formasi menggunakan pendekatan guidance route dengan penghindaran rintangan menggunakan metode Artificial Potential Field (APF). Selain itu, akan dibandingkan dua strategi penghindaran, penghindaran total dan penghindaran minimal. Berdasarkan hasil simulasi, algoritma kontrol yang dikembangkan berhasil melaksanakan tugas pengaturan formasi dan penghindaran rintangan pada sekelompok quadcopter. Hal ini dibuktikan dengan rata-rata indeks performansi formasi bernilai 0.800025 untuk strategi penghindaran total dan 1.2227125 untuk strategi penghindaran minimal serta trayektori masing-masing quadcopteryang bebas tabrakan. ==============================================================================================In recent years, cooperative control of multi-UAV (Unmanned Aerial Vehicle) systems has become a hot research topic in the field of flight control. Among them, formation control and obstacle avoidance are two important themes to study because the complexity of the problem conditions to be solved always increases with time. This real problem can be modeled as an obstacle avoidance control problem in a quadcopter formation. A group of quadcopters is assigned to form a formation (in the form of a V shape), move in formation towards a destination point, avoid collisions between robots, and avoid collisions with obstacles. The quadcopter model used is the Quanser Qdrone with six degrees of freedom. The quadcopter is controlled using a fuzzy state feedback controller to track objectives. In this final project, a formation management system is designed using the guidance route approach with obstacle avoidance using the Artificial Potential Field (APF) method. Moreover, two avoidance strategies will be compared, total avoidance and minimum avoidance. Based on the simulation results, the developed control algorithm successfully performs the task of setting formation and obstacle avoidance on a group of quadcopters. This is evidenced by the average formation performance index of 0.800025 for total avoidance strategy and 1.2227125 for minimum avoidance strategy with the collision-free trajectories of each quadcopter."
Sistem Multi-UAV untuk Pelacakan Multi-Target dalam Ruang Tiga Dimensi.,"Maynad, Vincentius Charles",http://repository.its.ac.id/111865/,"Penelitian ini berkaitan dengan sistem multi-UAV untuk melacak multi-target yang dapat diamati sebagian di lingkungan tiga dimensi yang ber-noise. Permasalahan ini biasa ditemui dalam sistem pertahanan dan pengawasan. Penelitian yang dilakukan merupakan perluasan dari penelitian-penelitian terdahulu yang berfokus terutama pada pengaturan dua dimensi, dapat diamati sepenuhnya, dan atau terukur secara sempurna. Target dimodelkan sebagai sistem linear time-invariant dengan noise Gaussian dan UAV pengejar direpresentasikan dalam model standar enam derajat kebebasan. Persamaan yang diperlukan untuk menggambarkan hubungan antara observasi mengenai target dan state pengejar diturunkan dan direpresentasikan sebagai model Gauss-Markov. Target yang dapat diobservasi sebagian mengharuskan para pengejarnya untuk mempertahankan nilai-nilai keyakinan untuk posisi target. Di hadapan lingkungan yang ber-noise, extended Kalman filter digunakan untuk memperkirakan dan memperbarui keyakinan tersebut. Algoritma Multi-Agent Reinforcement Learning (MARL) terdesentralisasi yang dikenal sebagai Soft Double Q-Learning diusulkan untuk mempelajari kontrol koordinasi di antara para pengejar. Algoritma ini diperkaya dengan regulasi entropi untuk melatih kebijakan stokastik tertentu dan memungkinkan interaksi antar pengejar untuk mendorong perilaku kooperatif. Pengembangan ini mendorong algoritma untuk melakukan eksplorasi area pencarian yang lebih luas dan tidak diketahui yang penting untuk sistem pelacakan multi-target. Algoritma dilatih sebelum diterapkan untuk menyelesaikan beberapa skenario. Percobaan menggunakan berbagai kemampuan sensor menunjukkan bahwa algoritma yang diusulkan memiliki tingkat keberhasilan yang lebih tinggi dibandingkan dengan algoritma dasarnya, hingga 4 kali lipat pada skenario tertentu. Penjelasan tentang banyak perbedaan antara lingkungan dua dimensi dan tiga dimensi juga disediakan.=======================================================================================================This research deals with multi-UAV systems to track partially observable multi-targets in a noisy three-dimensional environment. This problem is commonly encountered in defense and surveillance systems.It is a far extension from previous research which focused primarily on two-dimensional, fully observable, and or perfect measurement settings. The targets are modeled as a linear time-invariant system with Gaussian noise and the pursuers UAV are represented in a standard six degrees of freedom model. The equations required to describe the relationship between observations regarding the targets and the pursuer’sstate are derived and represented as a Gauss-Markov model. Partially observable targets require pursuers to maintain belief values for the target position. In the presence of a noisy environment, an extended Kalman filter is used to imagine and describe the belief. A decentralized Multi-Agent Reinforcement Learning (MARL) algorithm known as Soft Double Q-Learning is proposed to study coordination control among pursuers. The algorithm is enriched with entropy regulation to train specific stochastic policies and allows interaction between pursuers to encourage cooperative behavior. This development encourages the algorithm to perform exploration of wider and unknown search areas which is important for multi-target tracking systems. The algorithm is trained before being applied to complete several scenarios. Experiments using various sensor capabilities show that the proposed algorithm has a higher success rate compared to the baseline algorithm, up to 4 times in certain scenarios. An explanation of the many differences between two-dimensional and three-dimensional environments is also provided"
Identifikasi  dan Klasifikasi  Tingkat Ketidakseimbangan Statis Sela Udara Motor Induksi Berbasis Transformasi Wavelet Arus Stator.,"Mualim, Latif",http://repository.its.ac.id/82331/,"Tugas akhir ini membahas tentang pengidentifikasian dan klasifikasi ketidakseimbangan sela udara pada motor induksi dengan menggunakan transformasi wavelet diskrit yang mana dari wavelet ini diambil nilai statistik dari level tertentu komponen transformasi wavelet untuk dijadikan nilai input pada analisa jaringan saraf tiruan. Dengan memanfaatkan nntool pada MATLAB dibuatlah neuron network dengan input berupa 12 nilai statistik dan target data berupa kondisi motor. Neuron network yang sudah di training menggunakan data arus yang diukur pada tugas akhir ini. Hasilnya adalah neuron network mampu mengidentifikasi dan mengklasifikasi data arus untuk mengetahui keadaan motor tetapi terbatas hanya pada motor induksi yang digunakan pada tugas akhir ini karena keterbatasan data arus dari motor lain =====================================================================================================This final project discusses the identification and classification of airgap eccentricity in induction motors using discrete wavelet transforms, from which the statistical values of certain levels of wavelet transform components are taken to be used as input values in the analysis of artificial neural networks. By utilizing nntool in MATLAB, a neuron network was created with input in the form of 12 statistical values and target data in the form of motor conditions. Neuron networks that have been trained use current data measured in this final project. The result is that the neuron network is able to identify and classify current data of induction motor but it is limited to the induction motor used in this final project due to the limitation of current data from other motors."
Rancang Bangun Sistem Elektronik untuk Menyimak dan Mengetes Hafalan Al-Quran Berbasis Arabic Speech to Text dan Metode Levenshtein Distance.,"Muayyad, Ahmad Saad",http://repository.its.ac.id/87298/,"Al-Quran merupakan kitab suci agama Islam yang secara luas dibaca, dihafalkan, dipelajari, dan diajarkan oleh para pemeluknya. Indonesia merupakan negara dengan pemeluk agama Islam terbanyak di dunia, maka jumlah institusi dimana Al-Quran itu dihafal dan diajarkan juga sangat banyak. Berdasarkan hal tersebut, pada Tugas Akhir ini telah dibuat sebuah sistem untuk menyimak dan mengetes hafalan Al-Quran. Sistem ini menggunakan Arabic Speech-to-Text untuk mengubah input suara menjadi teks bahasa Arab, yang kemudian dibandingkan dengan data teks Al-Quran menggunakan metode Levenshtein Distance. Bila nilai perbandingan antara input dan data teks yang tersimpan melewati batas dan logika yang sudah didesain, maka sistem akan memberikan peringatan melalui output berupa suara dan tampilan visual. Sistem yang dirancang diimplementasikan menggunakan Raspberry Pi 3B+ yang dilengkapi dengan microphone, buzzer, dan Touch Screen Display. Sistem elektronik ini menggunakan data Al-Quran yang diinput secara manual dan data Al-Quran dari PyQuran sebagai rujukan. Dihasilkan persentase error sebesar 0,45% untuk penggunaan data manual dan 3,52% untuk penggunaan data PyQuran dalam pengujian 3 halaman di juz pertama Al-Quran. Latency rata-rata yang dihasilkan untuk satu kata yang diproses dengan kecepatan internet 10 Mbps adalah 0,1292 s. Kedepannya, kualitas sistem koreksi dapat ditambahkan terutama untuk PyQuran agar sistem elektronik ini dapat digunakan untuk 30 juz Al-Quran secara lengkap sehingga dapat membantu para penghafal Al-Quran =====================================================================================================Al-Quran is Islam’s Holy Book that widely recited, memorized, studied, and taught by its followers. Indonesia is a country with the largest number of Muslim, in which many intitutions where Al-Quran are memorized and taught. Based on that, in this Final Project, an electronic system for correcting and testing Al-Quran memorization was designed. This system uses Arabic Speech-to-Text to convert audio input to Arabic text that was compared to Al-Quran text data with Levenshtein Distance Method. If the comparison value between audio input and Al-Quran text data exceeds the limit and logic that has been designed, the system will give a warning by audio and visual output. This system is designed using Raspberry Pi 3B+ equipped with microphone, buzzer, and Touch Screen Display. This electronic system uses Al-Quran data that manually input and PyQuran data as its reference. An error percentage of 0,45% was obtained using Al-Quran manual data and 3,52% was obtained using PyQuran data for 3 pages from the first juz testing. Average latency that was obtained for each word processing for 10 Mbps internet speed is 0,1292 s. In the future research, the quality of correction system can be upgraded especially for PyQuran so this system can be used for 30 juz perfectly and will be a huge benefit for Al-Quran memorizer."
Prediksi Financial Distress Perusahaan Sektor Industri di Indonesia dengan Metode Klasifikasi dan Melibatkan Synthetic Features Generation.,"Muda, Muhammad Adlansyah",http://repository.its.ac.id/83474/,"Masalah kondisi financial distress dapat berakhir dengan kebangkrutan apabila tidak segera ditanggulangi. Untuk mengantisipasi dan meminimalisir dampak dari bangkrutnya suatu perusahaan terutama pada sektor industri, maka dilakukan prediksi financial distress untuk menilai kondisi keuangan perusahaan dan perspektif masa depannya. Pada penelitian ini prediksi financial distress dilakukan dengan metode klasifikasi seperti Generalized Extreme Value Regression, Logistic Regression, Support Vector Machine, dan Extreme Gradient Boosting dengan melibatkan synthetic features generation secara serentak dan seleksi variabel. Berdasarkan nilai accuracy, AUC, dan F1-score dari hasil evaluasi model menggunakan data testing didapatkan bahwa metode synthetic features generation tidak selalu memberikan performansi klasifikasi terbaik pada tiap size. Pada size 0 dan size 1 disimpulkan bahwa model Extreme Gradient Boosting dengan melibatkan synthetic features generation dan seleksi variabel merupakan model dengan performansi klasifikasi terbaik, sedangkan pada size 2 dan size 3 didapatkan bahwa model Extreme Gradient Boosting tanpa melibatkan synthetic features generation dengan seleksi variabel merupakan model dengan performansi klasifikasi terbaik dalam memprediksi kondisi keuangan perusahaan sektor industri di Indonesia.====================================================================================================================The problem of financial distress can lead to bankruptcy if it is not addressed immediately. To anticipate and minimize the impact of a company bankruptcy, especially in the industrial sector, financial distress predictions are made to assess the company’s financial condition and its future perspective. In this study, prediction of financial distress is carried out using classification methods such as Generalized Extreme Value Regression, Logistic Regression, Support Vector Machine, and Extreme Gradient Boosting by involving synthetic features generation simultaneously and variable selection. Based on the accuracy, AUC, and F1-score from the results of model evaluation using data testing, it is found that the synthetic features generation method does not always provide the best classification performance for each size. At size 0 and size 1, it can be concluded that the Extreme Gradient Boosting model involving synthetic features generation with variable selection is the model with the best classification performance, whereas at size 2 and size 3, it is found that the Extreme Gradient Boosting model without involving synthetic features generation with variabel selection is the model with the best classification performance in predicting the financial condition of industrial sector companies in Indonesia."
Secure Indoor Positioning System Model Menggunakan Serangan Boundary Attack Berbasis Aplikasi Mobile.,"Muhammad, Banabil Fawazaim",http://repository.its.ac.id/106076/,"Selama dekade terakhir, perangkat seluler telah berevolusi tidak hanya berfungsi sebagai komunikasi jarak jauh, namun juga sebagai perangkat navigasi menggunakan Global Positioning System (GPS). Karena keterbatasan GPS dalam ruangan, dikembangkan IPS (Indoor Positioning System) sebagai pengganti dari GPS pada saat di dalam ruangan.  Studi ini menyoroti kurangnya perhatian terhadap keamanan dan privasi dalam pengembangan IPS, terutama dalam menghadapi serangan keamanan seperti serangan Boundary Attack.  Penelitian ini bertujuan untuk membuat IPS yang tahan terhadap serangan Boundary Attack dengan mengembangkan model menggunakan data sidik jari Channel State Information (CSI).  Tujuan dari penelitian ini mencakup membandingkan kinerja antara model IPS dan model rekan terhadap serangan serangan perimeter, dan mengintegrasikan model dengan aplikasi seluler untuk menampilkan lokasi pengguna secara real time. Metode penelitiannya antara lain mengumpulkan dataset dari Tower 2 ITS, membangun dan melatih model IPS menggunakan data yang diserang dan tidak diserang, menerapkan serangan Boundary Attack, dan membuat aplikasi seluler terintegrasi.  Hasil penelitian meliputi evaluasi akurasi model sebelum dan sesudah serangan serta perbandingan dengan model pembanding dalam kondisi serangan. Model IPS berhasil dibangun yang dapat menahan serangan Boundary Attack dan menjaga akurasi bahkan setelah serangan tersebut. Membandingkan model IPS dengan model pembanding menunjukkan ketahanan yang baik terhadap serangan.  Dengan mengintegrasikan aplikasi mobile dengan IPS melalui Flask, pengguna dapat melihat lokasinya dengan akurasi tinggi dan real time.=================================================================================================================================Over the past decade, mobile devices have evolved to function not only as long-distance communication, but also as navigation devices using the Global Positioning System (GPS). Due to the limitations of indoor GPS, IPS (Indoor Positioning System) was developed as a replacement for GPS when indoors. This study highlights the lack of attention to security and privacy in the development of IPS, especially in the face of security attacks such as Boundary Attack. This research aims to create an IPS that is resistant to Boundary Attack by developing a model using Channel State Information (CSI) fingerprint data. The objectives of this research include comparing the performance between the IPS model and the peer model against perimeter attack attacks, and integrating the model with a mobile application to display the user's location in real time. The research methods included collecting datasets from Tower 2 ITS, building and training the IPS model using attacked and unattacked data, applying the Boundary Attack, and creating an integrated mobile application. The results include an evaluation of the accuracy of the model before and after the attack as well as a comparison with the comparison model under attack conditions. An IPS model was successfully built that can withstand Boundary Attack attacks and maintain accuracy even after such attacks. Comparing the IPS model with the comparison model shows good resistance to attacks. By integrating a mobile application with the IPS through Flask, users can view their location with high accuracy and in real time."
Sistem Informasi Pengelolaan Keuangan Sekolah (Sipks) Dengan Electronic Dan Digital Signature Recognition Menggunakan Algoritma MobileNet.,"Mukhlishah, Chaniyah Zulfa",http://repository.its.ac.id/83295/,"Pengelolaan anggaran sekolah merupakan aktivitas yang sering dilakukan di berbagai Sekolah, terutama sekolah negeri. Pengelolaan anggaran pun dapat mencakup dalam berbagai hal. Seperti kegiatan penganggaran dana akademik, organisasi, maupun administrasi yang mutlak membutuhkan alokasi dana dalam pelaksanaannya. Oleh karena itu, kegiatan pengelolaan keuangan sekolah membutuhkan perhatian, terutama dalam hal teknis pelaksanaannya agar dapat diimplementasikan lebih mudah. Pada era digital saat ini, metode penganggaran dana yang manual merupakan sebuah permasalahan dimana metode manual ini sering dikhawatirkan oleh pihak sekolah dalam hal pencatatan dan keamanannya."
Aplikasi Discrete Wavelets Transform pada Analisis Regresi Spektrum Tumpang Tindih Senyawa Parasetamol dan Kafein.,"Mulyaningtias, Nadia",http://repository.its.ac.id/90046/,"Obat umumnya berisi kombinasi dari beberapa senyawa aktif. Parasetamol sering digunakan sebagai obat analgesik dan anti piretik. Kafein adalah stimulan sistem saraf pusat (SSP). Dalam pemasaran obat sakit kepala di masyarakat, pemeriksaan mutu obat diperlukan untuk menjamin bahwa obat menggandung bahan aktif dengan mutu dan jumlah sesuai dengan kandungan yang tertera pada label obat. Sehingga diperlukan metode yang efisien tanpa pemisahan, dengan bantuan spektrofotometer UV-Vis, metode Discrete Wavelets Transform dan analisis multikomponen. Sebanyak 25 larutan training set disiapkan dan dianalisis absorbansinya menggunakan metode Multiple Linier Regression, metode Support Vector Regression (SVR), metode Partial Least Square (PLS) Regression, metode AdaBoost Regression. Model yang didapat divalidasi dengan tes data sebelum diaplikasikan pada obat sakit kepala. Penentuan kadar obat yang sesuai dengan kadar dalam label obat, yaitu pada metode Support Vector Regression dimana rata-rata kadar obat prediksi parasetamol sebesar 512,5473 mg dan pada kafein sebesar 67,1091 mg. Sehingga metode berhasil digunakan untuk menetapkan kadar dalam tablet obat sakit kepala.=======================================================================================================Medicine generally contain active ingredients. Paracetamol is often used as an analgesic and anti-pyretic medicine. Caffeine is a central nervous system (CNS) stimulant. In marketing headache medicine in the community, quality inspection of medicine is needed to ensure that the medicine contains active ingredients with the quality and quantity according to the content stated on the medicine label. So an efficient method without separation is needed, with the help of a UV-Vis spectrophotometer, the Discrete Wavelets Transform method and multivariate analysis. A total of 25 training set solutions were prepared and their absorbance analyzed using the Multiple Linear Regression method, the Support Vector Regression (SVR) method, the Partial Least Square (PLS) Regression method, the AdaBoost Regression method. The model obtained was validated by testing the data before it was applied to headache medicine. Determination of medicine levels in accordance with the levels on the medicine label, namely the Support Vector Regression method where the average level of the predicted medicine parasetamol is 512.5473 mg and the caffeine is 67.1091 mg. So that the method was successfully used to determine the levels in headache medicine tablets."
Optimasi Convolutional Neural Network melalui Fungsi Aktivasi dan Inisialisasi Kernel untuk Pengenalan Tulisan Huruf Hijaiyah.,"Nasty, Khairuddin",http://repository.its.ac.id/117839/,"Penelitian ini mengoptimalkan model Convolutional Neural Network (CNN) untuk pengenalan tulisan tangan huruf Hijaiyah dengan menganalisis kombinasi fungsi aktivasi (ReLU, Leaky ReLU, Sigmoid, Tanh) dan metode inisialisasi kernel (He normal, He uniform, LeCun normal, LeCun uniform, Glorot normal, Glorot uniform). Dataset yang digunakan adalah Hossam Magdy Balaha Dataset (HMBD) yang dimodifikasi—dengan penambahan tanda baca fathah, kasrah, dan dhammah—untuk mengevaluasi 24 kombinasi parameter. Hasil eksperimen menunjukkan bahwa kombinasi He normal-ReLU mencapai performa terbaik dengan akurasi 93,84%, presisi 93,96%, recall 93,77%, dan F1-score 93,71%. Analisis konvergensi mengungkapkan kombinasi ini stabil setelah epoch ke-10, dengan validation loss di bawah 0,5, serta fluktuasi akurasi kurang dari ±1%. Kesalahan klasifikasi tertinggi terjadi pada pasangan dengan kemiripan visual, yaitu Ain fathah-Haa fathah (14,63%) yang diidentifikasi melalui confusion matrix. Konversi model ke TensorFlow Lite berhasil mengurangi ukuran dari 29,4 MB menjadi 9,8 MB (66,67%) tanpa penurunan performa, dengan akurasi tetap 93,84%. Temuan ini membuktikan bahwa optimasi inisialisasi kernel dan fungsi aktivasi secara signifikan meningkatkan akurasi dan efisiensi model, sekaligus memberikan panduan implementasi CNN untuk aplikasi mobile edukasi berbasis tulisan tangan non-Latin.==================================================================================================================================This study optimized a Convolutional Neural Network (CNN) model for recognizing handwritten Hijaiyah characters by analyzing combinations of activation functions (ReLU, Leaky ReLU, Sigmoid, Tanh) and kernel initialization methods (He normal, He uniform, LeCun normal, LeCun uniform, Glorot normal, Glorot uniform). The modified Hossam Magdy Balaha Dataset (HMBD)—augmented with diacritical marks (fathah, kasrah, dhammah)—was used to evaluate 24 parameter combinations. Experimental results demonstrated that the He normal-ReLU combination achieved the best performance, with 93.84% accuracy, 93.96% precision, 93.77% recall, and 93.71% F1-score. Convergence analysis revealed this combination stabilized after the 10th epoch, with validation loss below 0.5 and accuracy fluctuations within ±1%. The highest misclassification rate (14.63%) occurred between visually similar pairs, specifically Ain fathah-Haa fathah, as identified through confusion matrices. Model conversion to TensorFlow Lite successfully reduced its size from 29.4 MB to 9.8 MB (66.67%) without performance degradation, maintaining 93.84% accuracy. These findings prove that optimizing kernel initialization and activation functions significantly enhances model accuracy and efficiency, while providing a practical guideline for implementing CNNs in mobile-based educational applications for non-Latin handwriting recognition."
Penyaringan Surel Bersifat Spam Dengan Menggunakan Online Active Ensemble Learning.,"Naufal, Muhammad Rafif Fadhil",http://repository.its.ac.id/107850/,"Surel merupakan salah satu bentuk komunikasi yang sangat umum digunakan di seluruh dunia. Hal ini mengakibatkan traffic keluar-masuk surel yang berkembang di tiap tahunnya. Salah satu masalah yang sering terjadi pada surel adalah adanya surel yang bersifat spam. Spam merupakan surel yang tidak diinginkan oleh penerimanya dan biasanya berisi iklan, penipuan, atau konten yang tidak senonoh. Penyaringan surel merupakan salah satu upaya mewujudkan Pembangunan Berkelanjutan (SDGs). Pada Penelitian ini, akan dibuat sebuah model untuk melakukan penyaringan surel bersifat spam dengan menggunakan metode Online Active Ensemble Learning. Metode ini merupakan perpaduan antara online active learning dengan model klasifikasi ensemble. Model ini akan diimplementasikan menggunakan bahasa pemrograman Python. Dataset yang digunakan penelitian ini merupakan dataset public bernama enron-spam. Dataset ini terdiri dari kumpulan email 6 pegawai Enron. Total email yang terdapat pada dataset ini adalah 33.716 email. Hasil eksperimen menunjukkan bahwa model yang menggunakan metode Online Active Ensemble Learning memiliki performa yang lebih baik dibandingkan dengan model single learning. Hal ini ditunjukkan dengan nilai akurasi, presisi, recall, dan f1-score yang lebih tinggi. Selain itu, penggunaan resource yang dibutuhkan untuk melakukan prediksi dan learning juga lebih rendah, sehingga semakin mendukung efisiensi dan keberlanjutan. Kesimpulannya, metode Online Active Ensemble Learning dapat digunakan untuk melakukan penyaringan surel bersifat spam dengan performa yang baik dan efisien dalam penggunaan resource, sehingga turut berkontribusi terhadap pencapaian beberapa SDGs.============================================================================================================================Email is one of the most common forms of communication used worldwide, leading to a growing volume of incoming and outgoing email traffic each year. One of the recurring issues with email is the presence of spam, which refers to unwanted emails typically containing advertisements, scams, or inappropriate content. Email filtering is one approach to realizing Sustainable Development Goals (SDGs). In this research, a model will be developed to filter spam emails using the Online Active Ensemble Learning method, which combines online active learning with ensemble classification models. This model will be implemented using the Python programming language. The dataset used in this study is a public dataset called enron-spam, consisting of a collection of emails from six Enron employees totaling 33,716 emails. Experimental results indicate that the model utilizing the Online Active Ensemble Learning method outperforms single learning models, as evidenced by higher accuracy, precision, recall, and f1-score values. Additionally, the resource requirements for prediction and learning are lower, further supporting efficiency and sustainability. In conclusion, the Online Active Ensemble Learning method can be employed for effective and resource-efficient spam email filtering, thereby contributing to the achievement of several SDGs."
Segmentasi Jantung Pada Citra Short-Axis View Magnetic Resonance Imaging Menggunakan 2D U-Net.,"Nindita, Nabil Virio Akhsan",http://repository.its.ac.id/108687/,"Penyakit kardiovaskular merupakan masalah kesehatan yang signifikan secara global, menyebabkan banyak kematian, terutama disebabkan oleh penyakit jantung. Diagnosis penyakit jantung yang akurat dan tepat waktu sangat penting untuk pengobatan yang efektif. Adanya kemajuan teknologi medis telah meningkatkan pemahaman dan pengambilan tindakan terhadap penyakit tersebut. Penelitian ini berfokus pada segmentasi struktur jantung pada citra Short Axis Magnetic Resonance Imaging ( SAX MRI) menggunakan model deep learning dengan arsitektur U-Net 2D. Tujuan utama dari penelitian ini adalah untuk mengembangkan model deep learning yang dapat mensegmentasi struktur jantung, yaitu ventrikel kiri (LV), ventrikel kanan (RV), dan miokardium. Penelitian ini menggunakan dataset Automated Cardiac Diagnosis Challenge (ACDC) 2017, yang mencakup pemindaian MRI dari 150 pasien dengan berbagai kondisi jantung. Model segmentasi berbasis U-Net 2D yang diusulkan diharapkan menghasilkan akurasi tinggi, sehingga berpotensi untuk memberi manfaat bagi penanganan penyakit jantung. Berdasarkan pengujian yang telah dilakukan dari skenario-skenario penelitian didapatkan hasil Dice dan IoU Score oleh model sebesar 0,8806 dan 0,7663.=================================================================================================================================Segmentasi Cardiovascular disease is a significant health problem globally, causing many deaths , mainly caused by heart disease. Accurate and timely diagnosis of heart disease is essential for effective treatment. Advances in medical technology have improved the understanding and treatment of these diseases. This research focuses on segmenting cardiac structures in Short Axis Magnetic Resonance Imaging (SAX MRI) images using deep learning model with 2D U-Net architecture. The main objective of this research is to develop a deep learning model that can segment the heart structures, namely the left ventricle (LV), right ventricle (RV), and myocardium. This study uses the Automated Cardiac Diagnosis Challenge (ACDC) 2017 dataset, which includes MRI scans of 150 patients with various heart conditions. The proposed 2D U-Net-based segmentation model is expected to yield high accuracy, potentially benefiting the treatment of heart disease. Based on the tests that have been carried out from the scenarios of this research the Dice and IoU Score results obtained by the model are 0,8806 and 0,7663.Jantung Pada Citra Short-Axis View Magnetic Resonance Imaging Menggunakan 2d U-Net"
Intergrasi Nonlinear Programming (NLP) dan Cost Benefit Analysis (CBA) untuk Pengelolaan Limbah Fly Ash Dan Bottom Ash (FABA) Industri Pupuk (Studi Kasus : PT. Pupuk Indonesia).,"Nubail, Ahmad Azrial",http://repository.its.ac.id/107885/,"Limbah Fly Ash dan Bottom Ash (FABA) pada industri pupuk berdasarkan PP No 22 Tahun 2021 tidak termasuk dalam kategori B3 dimana proses pembakaran batubaranya menggunakan teknologi tungku industri (stocker boiler). Dengan PP No 22 Tahun 2021, maka perlu dilakukan penelitian untuk menentukan skema pengelolaan limbah FABA terbaik antara kondisi eksisting dan skenario perbaikan dengan mempertimbangkan manfaat optimal dari setiap opsi pengelolaan limbah FABA. Perlu dilakukan Cost-Benefit Analysis, menghitung Benefit-Cost Ratio, dan dilanjutkan dengan analisis sensitivitas untuk menghilangkan satu solusi yang mendominasi dari skenario yang dipilih untuk mendapatkan skema pengelolaan terbaik. Untuk melakukan perhitungan dan analisis diperlukan kajian terkait Pupuk Indonesia dan anak perusahaan terkait, pengelolaan FABA, Cost-Benefit Analysis (CBA), Nonlinier Programming (NLP), dan analisis sensitivitas. Berdasarkan analisis kondisi eksisting proses bisnis pengelolaan limbah, diperoleh empat skenario pengelolaan limbah FABA untuk masing-masing perusahaan. Dari keempat skenario perbaikan, dipilih dua skenario untuk dilakukan analisis lanjutan. Kedua skenario tersebut adalah kondisi eksisting dan skenario yang berfokus pada kerjasama pengelolaan limbah FABA dengan mengoptimalkan manfaat yang diperoleh. Hasil perhitungan menunjukkan bahwa dengan skenario perbaikan, biaya pengelolaan limbah yang dikeluarkan oleh perusahaan dapat turun hingga 60% dari kondisi eksisting. Perhitungan Benefit-Cost Ratio (BCR) dari skenario perbaikan untuk masing-masing perusahaan menghasilkan angka dari 1.109 hingga 1.602 dalam kondisi ideal. Pada skenario perbaikan, dilakukan analisis sensitivitas, dan ditemukan bahwa perubahan %bagi hasil dan batas bawah pengelolaan tidak mempengaruhi kelayakan skenario. Sedangkan %penyerapan FABA dan %manfaat lingkungan mempengaruhi kelayakan skenario. Dapat disimpulkan bahwa skenario perbaikan yang diusulkan layak untuk diterapkan dengan mempertimbangkan kondisi masing-masing parameter yang mempengaruhi kelayakan skenario.===================================================================================================================================Fly Ash and Bottom Ash (FABA) waste in the fertilizer industry, based on PP No. 22 of 2021, is excluded from B3 category where the coal combustion process uses industrial furnace technology (stocker boiler). With PP No. 22 of 2021, it is necessary to research to determine the best FABA waste management scheme between existing conditions and improvement scenarios by considering the optimal benefits of each FABA waste management option. It is necessary to do a cost-benefit analysis, calculate the benefit-cost ratio, and proceed with a sensitivity analysis to eliminate one dominating solution from the selected scenario to get the best management scheme. To carry out the necessary calculations and analysis, a study related to Pupuk Indonesia and its related subsidiaries, FABA management, Cost-Benefit Analysis (CBA), Nonlinear Programming (NLP), and sensitivity analysis. Based on the analysis of the existing condition of the existing waste management business process, four FABA waste management scenarios were obtained for each company. From the four scenarios, two scenarios were chosen for further analysis. The two scenarios are the existing condition and the scenario that focuses on cooperation in FABA waste management by optimizing the benefits obtained. The results of the calculations show that with the improvement scenario, the waste management costs incurred by the company can decrease by up to 60% from the existing condition. The calculation of the benefit-cost ratio (BCR) from the improvement scenario for each company produces numbers from 1.109 to 1.602 under ideal conditions. In the improvement scenario, a sensitivity analysis was carried out, and it was found that changes in % profit sharing and the lower management limit did not affect the feasibility of the scenario. Meanwhile, the % absorption of FABA and % environmental benefits influence the feasibility of the scenario. It can be concluded that the proposed improvement scenario is feasible to be applied by considering the conditions of each parameter that affect the feasibility of the scenario."
Pengembangan Model Prediktif Analitik Untuk Menilai Tingkat Maintainabilitas Proyek Perangkat Lunak Di Github.,"Nugroho, Adi",http://repository.its.ac.id/95511/,"Pengembangan proyek perangkat lunak saat ini sudah tidak bisa dilepaskan dari penggunaan library atau produk open source. Terdapat jutaan produk open source dengan fungsi spesifik yang mampu digunakan dan diintegrasikan dalam pengembangan perangkat lunak. Tetapi untuk memilih produk open source yang bagus dan memiliki maintainabilitas yang baik tidaklah mudah. Github sebagai salah satu repositori open source berbasis git, saat ini menyimpan lebih dari 46 juta proyek open source. Pada sebuah repositori proyek open source di Github melekat puluhan fitur yang dapat dianalisis untuk menilai kualitas repositori tersebut. Banyaknya jumlah fitur ini mengakibatkan perlunya keahlian dan pengalaman untuk menilai kualitas repositori. Penelitian sebelumnya menggunakan metode Random Forest untuk menilai tingkat maintainabilitas pada sebuah repositori di Github secara otomatis. Penelitian ini akan memanfaatkan lebih banyak fitur dari repositori di Github serta menggunakan dan membandingkan metode machine learning antara lain Random Forest, Support Vector Machine, Extreme Gradient Boosting dan regresi logistik dalam pembuatan model untuk menilai tingkat maintainabilitas. Model dalam penelitian ini dikembangkan dengan menggunakan 17 variabel prediktor dan satu variabel respon. Hasil dari pengujian model menunjukkan model dari metode Random Forest dan Extreme Gradient Boosting menunjukkan tingkat akurasi yang tinggi masing-masing 94% dan 94,35%. Kedua model juga menunjukkan daftar variabel-variabel prediktor signifikan yang hampir mirip dalam penilaian maintainabilitas.==============================================================================================================================The development of software projects nowadays cannot be separated from open-source libraries or products. There are millions of open-source products with specific functionality that can be used when developing software. But choosing a good open-source product that has good maintainability is not an easy task. Github is one of the git-based open-source repositories and currently stores more than 46 million open-source projects. Lots of Github's repository features can be analyzed the repository quality. But manually assessing a repository's quality by analyzing its features needs skills and experience. Previous research used the Random Forest method to automatically assess the level of maintainability of a Github repository. This study will use more features from the repository and then compare the Random Forest, Support Vector Machine, Extreme Gradient Boosting and Logistic Regression methods in assessing Github's repository maintainability. 17 predictor variables and 1 respond variable were used to create machine learning models. Random Forest's and Extreme Gradient Boosting's models achieved almost similar accuracy rating with 94% and 94.35% respectively. Both models are also displayed almost similar list of significant features in assessing a repository's maintainability."
Klasifikasi Penutup Lahan Menggunakan DTM dan DSM LiDAR dengan Algoritma Support Vector Machine dan Random Forest (Studi Kasus: Institut Teknologi Sepuluh Nopember Kampus Sukolilo).,"Nuraini, Annisa",http://repository.its.ac.id/109916/,"LiDAR adalah teknologi penginderaan jauh aktif yang memanfaatkan sinar laser untuk mendeteksi objek di permukaan bumi. Airborne LiDAR merupakan salah satu jenis lidar yang menggunakan wahana udara untuk proses penyiaman objek. Dari data LiDAR ini dapat diperoleh Digital Surface Model (DSM) yang selanjutnya dapat diekstrak menjadi Digital Terrain Model (DTM). Dalam perkembangannya untuk pengolahan data LiDAR, telah banyak digunakan perangkat lunak maupun dengan menggunakan algoritma yang dibangun seperti machine learning. Tujuan dari penelitian ini adalah memanfaatkan data LiDAR untuk klasifikasi penutup lahan dengan menggunakan machine learning, yaitu dengan algoritma Support Vector Machine (SVM) dan Random Forest (RF). Klasifikasi yang diterapkan adalah supervised classification dimana dibutuhkan data training untuk melakukan klasifikasi. Kelas penutup lahan yang diprediksi pada penelitian ini terbatas pada objek bangunan, vegetasi, jalan, lahan terbuka, dan badan air. Data yang digunakan untuk klasifikasi adalah data turunan dari LiDAR yaitu DTM dan DSM. Skema klasifikasi yang digunakan adalah dengan input satu data dan kombinasi data, serta diterapkan juga skema splitting ratio training point yaitu 70:30, 75:25, 80:20, dan 90:10. Hasilnya skema input satu data belum memberikan hasil yang optimal. Input kombinasi data memberikan penambahan akurasi dan mengasilkan akurasi yang baik yaitu lebih besar dari 0,80. Hasil terbaik didapat dari input kombinasi data DSM dan DTM rasio training testing 75:25. Pada metode SVM dihasilkan overall accuracy 0,824 dan kappa 0,780. Sedangkan pada metode RF dihasilkan overall accuracy 0,832 dan kappa 0,790. Secara keseluruhan, metode RF memiliki keunggulan dalam mengklasifikasikan objek bangunan dan lahan kosong, sedangkan metode SVM memiliki keunggulan dalam mengklasifikasikan objek jalan.=================================================================================================================================LiDAR is an active remote sensing technology that utilizes laser beams to detect objects on the earth's surface. Airborne LiDAR is one type of lidar that uses airborne vehicles for the object's illumination process. From this LiDAR data, a Digital Surface Model (DSM) can be obtained which can then be extracted into a Digital Terrain Model (DTM). In its development for LiDAR data processing, software has been widely used as well as using algorithms built such as machine learning. The purpose of this research is to utilize LiDAR data for land cover classification using machine learning, namely with Support Vector Machine (SVM) and Random Forest (RF) algorithms. The classification applied is supervised classification where training data is required to perform classification. The predicted land cover classes in this study are limited to building objects, vegetation, roads, open land, and water bodies. The data used for classification is derived from LiDAR data, namely DTM and DSM. The classification scheme used is a single data input and a combination of data, and the splitting ratio training point scheme is also applied, namely 70:30, 75:25, 80:20, and 90:10. The result is that the one data input scheme has not provided optimal results. Input data combination provides additional accuracy and produces good accuracy which is greater than 0.80. The best results are obtained from the input of a combination of DSM and DTM data with a training testing ratio of 75:25. In the SVM method, the overall accuracy is 0.824 and kappa is 0.780. While the RF method produced an overall accuracy of 0.832 and kappa 0.790. Overall, the RF method has an advantage in classifying building objects and vacant land, while the SVM method has an advantage in classifying road objects."
Pengembangan Metode Seleksi Fitur Berbasis Chi-Square dan Algoritma Exhaustive untuk Meningkatkan Performa Deteksi pada Jaringan Komputer.,"Nururrahmah, Aulia Teaku",http://repository.its.ac.id/102506/,"Mendeteksi serangan intrusi pada jaringan telah menarik perhatian banyak peneliti. Sejauh ini terdapat dua metode, yakni berbasis signature dan anomaly. Mendeteksi serangan yang berbasis anomaly membutuhkan Machine Learning dalam proses klasifikasinya. Masalah yang banyak diteliti adalah topik tentang bagaimana mereduksi jumlah fitur sebelum dataset diserahkan ke proses klasifikasi. Metode seleksi fitur sendiri dilakukan untuk menentukan fitur relevan dan tidak relevan. Kami mengusulkan metode seleksi fitur berbasis uji chi-square dengan pencarian Exhaustive. Uji Chi-Square digunakan untuk menghitung skor statistik menggunakan uji independence level. Nilai statistik pada masing-masing fitur akan ditentukan relevansinya menggunakan taraf signifikan dan tabel distribusi chi-square. Dari proses uji chi-square maka diperoleh daftar fitur relevan dengan kelas target. Proses selanjutnya adalah mencari kombinasi terbaik antar fitur dengan menggunakan Exhaustive Algorithm. Penelitian ini diuji coba pada empat dataset yakni KDD Cup 99, NSL KDD, Kyoto 2006+, dan UNSW-NB15. Metode klasifikasi yang dimanfaatkan pada penelitian ini adalah Support Vector Machine (SVM), Decision Tree (DT), dan Naïve Bayes (NB). Berdasarkan penelitian yang sudah dilakukan, metode yang diusulkan terbukti memiliki performa yang lebih baik dibanding saat tanpa menggunalan seleksi fitur apapun. Performa terbaik didapatkan pada uji dataset UNSW-NB15 dengan akurasi mencapai 98,71%. Metode yang diusulkan juga melampaui performa dari metode lain===================================================================================================================================Detecting intrusion attacks on networks has attracted the attention of many researchers. So far, there are two methods, namely signature-based and anomaly-based. Detecting anomaly-based attacks requires Machine Learning in the classification process. The feature selection method itself is used to determine relevant and irrelevant features. Irrelevant features will be removed from the feature list. We propose a feature selection method based on the chi-square test with an Exhaustive search. The Chi-Square test is used to calculate statistical scores using the independence level test. The statistical value of each feature will be determined by its relevance using the significant level and the chi-square distribution table. A list of features relevant to the target class is obtained from the chi-square test process. The next process is to find the best combination between features using the Exhaustive Algorithm. This research was tested on four data: KDD Cup 99, NSL KDD, Kyoto 2006+, and UNSW-NB15. The classification methods used in this research are Support Vector Machine (SVM), Decision Tree (DT), and Naïve Bayes (NB). Based on the research that has been done, the proposed method is proven to have better performance than without using any feature selection. The best performance was obtained in the UNSW-NB15 dataset test with an accuracy of 98.71%. The proposed method also surpasses the performance of other methods."
Aplikasi Deteksi Kejadian di Jalan Raya berdasarkan Data Twitter Menggunakan Metode Support Vector Machine.,"Oktavia, Vessa Rizky",http://repository.its.ac.id/50014/,"Twitter adalah salah satu media sosial yang populer belakangan ini. Salah satu karakteristik penting dari Twitter adalah layanannya yang bersifat fleksibel yaitu dapat diakses di mana saja dan kapan saja. Sebagai contoh, saat terjadi suatu kecelakaan atau kemacetan, banyak pengguna Twitter yang mengirimkan  informasi (tweets) tentang kejadian tersebut kepada Twitter. Hal ini memungkinkan dibuatnya sebuah sistem yang mendeteksi terjadinya kecelakaan atau kemacetan dengan melakukan observasi kepada tweet yang masuk.Dalam tugas akhir ini, tweet akan diambil menggunakan Twitter API dan dimasukkan ke dalam sebuah database. Selanjutnya, akan dilakukan preproses yang meliputi stemming, penghapusan stopwords, dan tokenizing. Selain itu, dilakukan juga labeling untuk menentukan kelas dari tweet (kecelakaan, kemacetan, atau lain-lain). Selanjutnya akan dilakukan ekstraksi fitur agar fitur dari setiap tweet dapat menjadi input dalam proses klasifikasi. Untuk mengklasifikasikan tweet, diimplementasikan sebuah metode klasifikasi Support Vector Machine dan parameter regularisasi berupa variabel nu. Model klasifikasi yang dibangun awalnya memberikan nilai akurasi 95,15%. Uji coba dilakukan dengan mengubah kernel dan parameter nu untuk menghasilkan akurasi yang terbaik. Berdasarkan hasil uji coba yang telah dilakukan, didapatkan hasil terbaik dari sistem dengan akurasi 96,25% dengan klasifikasi menggunakan metode SVM dengan menggunakan Kernel Sigmoid dan parameter nu sebesar 0,2.======================================================================================================Twitter is one of the most popular social media lately. One of the important characteristics of Twitter is its flexible service that can be accessed anywhere and anytime. For example, when an accident or traffic jam occurs, many Twitter users are sending tweets about the event to the Twitter. This allows the creation of a system that detects accident or congestion by observing the incoming tweets.In this thesis, tweet will be taken by using Twitter API and put into a database. Next, a preprocess will be done that includes stemming, stopwords removal, and tokenizing. In addition, there is also a labeling to determine the class of tweets (accidents, congestion, or others). Furthermore, feature extraction will be performed so that the features of each tweet can be the input to perform the classification process. To classify tweets, used a Support Vector Machine classification method andnu variable as a regularization parameters.The classification model that was originally built gave an accuracy of 95.15%. The test is done by changing the kernel and the nu parameters to produce the best accuracy. Based on result of experiment which have done, the best result from system is claimed with accuracy 96,25% by using classification using SVM method using Sigmoid Kernel and the number of parameter nu is 0,2."
Multi-Objective Vehicle Routing Problem with Time Window and Drones (MO-VRPTW-D) Menggunakan Algoritma Simulated Annealing dan Ant Colony Optimization untuk Last-Mile Delivery.,"Pamungkas, Meidani Nuzul Tri",http://repository.its.ac.id/93815/,"Drone adalah kendaraan udara tanpa awak yang saat ini sedang marak digunakan dalam bidang fotografi dan bidang lainnya. Dalam kondisi khusus, drone digunakan untuk kendaraan logistik di mana barang-barang harus diangkut oleh truk yang dilengkapi dengan drone karena bentuk lahannya atau bahkan karena lokasinya vertikal (seperti apartemen, hotel, dll) yang tentunya tidak dapat dijangkau oleh truk. Multi-Objective Vehicle Routing Problem with Time Window and Drones (MO-VRPTW-D), di mana tujuannya adalah meminimasi biaya dengan cara mencari rute yang optimal agar konsumsi energi truk, konsumsi energi drone, dan jumlah truk yang dibutuhkan minimal. Problem ini menjadi kompleks apabila jumlah destinasi yang dikunjungi banyak. Pendekatan metaheuristik diperlukan untuk menyelesaikan problem ini karena kompleksitas yang tinggi walaupun solusi yang dihasilkan belum tentu optimal global. Algoritma Simulated Annealing dan Ant Colony Optimization dipilih karena terbukti cukup efektif untuk menyelesaikan problem kombinatorial semacam penentuan rute. Inovasi ini dapat diadopsi oleh perusahaan jasa pengiriman pada masa mendatang karena pengiriman akan menjadi lebih efisien, cepat, dan mengurangi biaya secara signifikan. Eksperimen dilakukan dalam 24 skenario dengan jumlah pelanggan 25 – 200. Algoritma ACO mampu menghasilkan solusi lebih baik daripada Algoritma SA sebanyak 15 dari total 24 skenario.================================================================================================Drone is remote controlled aerial vehicle that is currently being widely used in photography and other fields. In special conditions, drones are used for logistics vehicles where goods must be transported by trucks equipped with drones because of the shape of the land or even because of its vertical location (such as apartments, hotels, etc.) Multi-Objective Vehicle Routing Problem with Time Window and Drones (MO-VRPTW-D), where the goal is to minimize costs by finding the optimal route so that truck energy consumption, drone energy consumption, and the number of trucks needed are minimal. This problem becomes complex if the number of destinations visited is large. A metaheuristic approach is needed to solve this problem because of its high complexity, although the resulting solution is not necessarily global optimal. The Simulated Annealing and Ant Colony Optimization Algorithm was chosen because it proved to be quite effective in solving combinatorial problems such as route determination. This innovation can be applied by shipping service companies in the future because shipping will be more efficient, faster, and reduce costs significantly. Experiments were carried out in 24 scenarios with the number of customers 25 – 200. The ACO Algorithm was able to produce a better solution than the SA Algorithm by 15 out of a total of 24 scenarios."
Implementasi Text Mining pada Data Perhotelan Menggunakan Support Vector Machine (SVM) dan Analisis Topik dengan Model Probabilistik.,"Panjaitan, Yana Rezki Kriswin",http://repository.its.ac.id/91857/,"Kota Bogor merupakan kota yang berpotensi menjadi objek wisata. Covid-19 menyebar secara masif keseluruh dunia termasuk Indonesia sehingga pemerintah mengambil kebijakan seluruh kegiatan dilakukan dari rumah. Perubahan tatanan kehidupan tersebut memberikan tantangan baru bagi pihak hotel untuk tidak memakai cara konvensional seperti kuesioner dalam mengetahui kepuasan tamu sehingga memaksa pihak hotel menggunakan media yang ada salah satunya situs TripAdvisor. Situs ini memuat harga, tipe hotel, ulasan pengunjung dan sebagainya. Hal ini membuat tamu tidak kesulitan mencari informasi hotel, sedangkan pihak hotel diuntungkan dengan ulasan yang ada. Namun jumlah ulasan yang banyak menyita waktu untuk memahami satu persatu ulasan, sehingga diperlukan text mining. Dalam proses text mining ulasan diklasifikasikan terlebih dahulu menjadi sentimen positif dan negatif menggunakan metode SVM. Klasifikasi hanya memberi informasi sentimen positif atau negatif, sehingga dibutuhkan LDA dan LSA untuk menemukan informasi tersembunyi guna mengetahui kepuasan tamu pada pelayanan hotel. Model klasifikasi terbaik dalam penelitian ini menggunakan SVM kernel linear pada data yang telah diatasi imbalancednya dengan SMOTE. Metode LDA menghasilkan topic coherence lebih tinggi dibanding LSA sehingga membentuk topik positif pada Novotel adalah breakfast dan dinner, hotel dapat menjadi tempat rapat, makanan variatif dan hotel ramah anak. Sedangkan topik negatifnya proses high season lambat, makanan habis tidak langsung di refill, hotel tidak sesuai dengan informasi booking online, area kolam pria dan wanita tidak dibedakan, akses menuju tempat bermain anak, drainage tidak baik, paving tidak rata, bau pesing, kamar deluxe kurang baik, bathup teras duduk mengkhawatirkan. Topik positif Grand Savero adalah sarapan variatif, pelayanan cepat, menu enak, ramah anak, konsep indoor modern, booking mudah, terdapat aneka bubur dan buah, kinerja team bagus, fasilitas lengkap, dan ruangan yang segar dan bersih, sedangkan topik negatifnya proses reserve dan akses menuju area hotel sulit dan extra bed berbayar. Topik positif pada Aston adalah menu breakfast variatif dan enak serta hotel ramah anak, sedangkan topik negatifnya sikap staf, menu dinner tidak sesuai harga, fying fox berbayar, area balkon bau, suara mengganggu, request tidak sesuai, tempat bermain anak rusak, bising, perabotan kamar kurang. =====================================================================================================Bogor City is a city that has the potential to become a tourist attraction. Covid-19 has spread massively throughout the world, including Indonesia, so the government has made a policy that all activities are carried out from home. The change in the order of life provides a new challenge for the hotel not to use conventional methods such as questionnaires to determine guest satisfaction, thus forcing the hotel to use media, one of which is the TripAdvisor site. This site contains prices, hotel types, visitor reviews and so on. This makes it easy for guests to find hotel information, while the hotel benefits from existing reviews. However, the large number of reviews takes time to understand one by one review, so text mining is needed. In the text mining process, reviews are classified first into positive and negative sentiments using the SVM method. Classification only provides information on positive or negative sentiments, so LDA and LSA are needed to find hidden information to find out guest satisfaction with hotel services. The best classification model in this study uses a linear kernel SVM on data that has been overcome with SMOTE imbalancednya. The LDA method produces higher topic coherence than LSA so that it forms positive topics at Novotel, namely breakfast and dinner, hotels can be used as meeting places, varied food and child-friendly hotels. While the negative topics are the slow high season process, food runs out not immediately refilled, hotels do not match online booking information, male and female pool areas are not distinguished, access to children's playgrounds, drainage is not good, paving is uneven, urine smells, deluxe rooms not good, the sitting terrace bathtub is worrying. The positive topics of Grand Savero are varied breakfasts, fast service, delicious menus, child friendly, modern indoor concepts, easy booking, there are various porridge and fruit, good team performance, complete facilities, and fresh and clean rooms, while the negative topics are the reserve process and access to the hotel area is difficult and extra beds are paid. Positive topics at Aston are varied and delicious breakfast menus and child-friendly hotels, while the negative topics are staff attitudes, dinner menus don't match the price, paid fying fox, smelly balcony area, annoying sound, inappropriate requests, damaged children's play area, noise, furniture less room."
Implementasi Model Formal untuk Rekonstruksi Peristiwa Forensik Digital.,"Pardede, Immanuel Maruli Tua",http://repository.its.ac.id/117622/,"Penggunaan perangkat digital yang makin meluas telah berdampak pada berbagai sektor, termasuk peningkatan kompleksitas kejahatan siber. Hal ini mendorong hadirnya penelitian tentang analisis forensik digital yang lebih variatif. Analisis forensik digital sering kali menghadapi tantangan seperti ukuran data yang besar dan sifat data yang heterogen. Sementara itu, metode konvensional memiliki keterbatasan dalam menangani data besar dan heterogen, sehingga memerlukan pendekatan alternatif. Penelitian ini mengusulkan implementasi model formal berbasis ontologi untuk mendukung rekonstruksi peristiwa forensik digital. Data digital yang dikumpulkan dianalisis menggunakan Aljabar Interval Allen, yang memungkinkan penentuan hubungan temporal antarperistiwa. Model ini tidak hanya mampu menyusun peristiwa secara kronologis, tetapi juga menganalisis hubungan semantik dan temporal antarentitas yang terlibat dalam peristiwa tersebut. Dengan menggunakan metode yang terstruktur, penelitian ini menganalisis studi kasus dugaan penyalahgunaan sumber daya perusahaan oleh seorang karyawan. Hasil penelitian menunjukkan bahwa model formal berbasis ontologi efektif untuk mendukung proses rekonstruksi peristiwa dan menghasilkan bukti digital yang kredibel. Penelitian ini membuktikan bahwa model formal berbasis ontologi dapat digunakan untuk memproses jejak digital, menerapkan model formal, dan mengukur kinerja rekonstruksi peristiwa dalam konteks forensik digital.==============================================================================================================================The increasingly widespread use of digital devices has had an impact on various sectors, including the increasing complexity of cyber crime. This has encouraged the presence of more varied research on digital forensic analysis. Digital forensic analysis often faces challenges such as large data sizes and heterogeneous data nature. Meanwhile, conventional methods have limitations in handling large and heterogeneous data, requiring alternative approaches. This study proposes the implementation of an ontology-based formal model to support digital forensic event reconstruction. The digital data collected uses Allen Interval Algebra, which allows the determination of temporal relationships between events. This model is not only able to organize events chronologically, but also analyzes the semantic and temporal relationships between entities involved in the event. Using a structured method, this study analyzes a case study of alleged corporate resource context by an employee. The results of the study show that an ontology-based formal model is effective in supporting the event reconstruction process and producing credible digital evidence. This study proves that an ontology-based formal model can be used to process digital traces, apply formal models, and measure event reconstruction performance in the context of digital forensics."
Klasifikasi Multi-label Dangerous User Berdasarkan Fitur Struktural Twitter.,"Parwata, Anak Agung Yatestha",http://repository.its.ac.id/106584/,"Dangerous speech, atau ujaran berbahaya merupakan suatu ujaran yang dapat meningkatkan risiko seseorang atau suatu kelompok orang melakukan kejahatan terhadap orang lain atau kelompok orang lainnya. Dalam dangerous speech ini, terdapat 7 aspek, yaitu: konteks sosial, konteks historis, dehumanisasi, tuduhan, serangan terhadap wanita dan anak kecil, loyalitas suatu kelompok, dan ancaman terhadap suatu kelompok. Dangerous speech sendiri marak ditemukan di media sosial seperti Twitter. Dangerous user merupakan pengguna yang memiliki presentase tweet dangerous speech dan abusive language lebih banyak dibanding tweet neutral speech dan hate speech. Pada penelitian ini, telah dibuat suatu model yang dapat melakukan klasifikasi multi-label dangerous user berdasarkan fitur struktural yang diekstraksi dari graf pengguna yang terbentuk dari kemiripan unggahan Twitter. Fitur struktural yang digunakan adalah degree centrality, eigenvector centrality, betweenness centrality, closeness centrality, dan clustering coefficient. Tahapan yang dilalui mencakup pengolahan data tweet, ekstraksi fitur struktural pada jejaring berdasarkan kemiripan tweet, dan Klasifikasi pengguna dengan multi-label topik dangerous speech. Pengolahan data tweet dilakukan dengan cara pra-proses tweet, pemodelan topik menggunakan LDA, dan pseudo-label aspek dangerous speech menggunakan model IndoBERTweet, Naïve Bayes, dan Logistic Regresion. Tahapan selanjutnya adalah ekstraksi fitur struktural pada jejaring berdasarkan kemiripan tweet yang dilakukan dengan cara membuat graf dimana nodes nya merupakan pengguna twitter dan edgesnya merupakan nilai cosine similiarity atau kemiripan unggahan. Dilakukan pemilihan node dan edge mengunakan metode thresholding. Pengekstraksian fitur dilakukan dengan menggunakan pustaka networkx. Selanjutnya dilakukan pengklasifikasian pengguna dengan multi-label topik dangerous speech menggunakan Logistic Regression, Naïve Bayes, K-nearest Neighbors, Support Vector Classifier Decision Tree dan Random Forest. Pseudo-label aspek dangerous speech terbaik menggunakan model gabungan dari IndoBERTweet, Naïve Bayes, dan Logistic Regresion  dengan nilai akurasi diatas 80%. Dalam pemodelan topik, ditemukan jumlah topik terbaik adalah 6 berdasarkan nilai coherence score, namun masih terdapat sub-topik yang terbentuk, sehingga digunakan jumlah topik 19 berdasarkan nilai coherence scorenya dan ketiadaannya sub-topik baru. Ditemukan metode thresholding terbaik dengan minimal tiap pengguna memiliki average retweet lebih dari 1 dan nilai cosine similiarity lebih dari 0,149. Klasifikasi dangerous user terbaik terdapat pada model Naïve Bayes dengan fitur degree centrality, closeness centrality, dan eigenvecot centrality dengan nilai hamming loss sebesar 0,555.=============================================================================================================================Dangerous speech, or dangerous discourse, refers to a form of expression that can increase the risk of an individual or a group of people committing crimes against others or another group of people. In dangerous speech, there are 7 aspects, namely: social context, historical context, dehumanization, accusations, attacks against women and children, group loyalty, and threats against a group. Dangerous speech is often found on social media platforms like Twitter. A dangerous user is a user who has a higher percentage of dangerous speech and abusive language in their tweets compared to neutral speech and hate speech. In this final project, a model has been developed to perform multi-label classification of dangerous users based on structural features extracted from user graphs formed by the similarity of Twitter posts. The structural features used are degree centrality, eigenvector centrality, betweenness centrality, closeness centrality, and clustering coefficient. The steps involved include tweet data preprocessing, structural feature extraction on the network based on tweet similarity, and user classification with multi-label dangerous speech topics. Tweet data processing is done by pre-processing tweets, topic modeling using LDA, and pseudo-labeling of dangerous speech aspects using IndoBERTweet, Naïve Bayes, and Logistic Regression models. The next step is the extraction of structural features on the network based on tweet similarity, which is done by creating a graph where the nodes represent Twitter users and the edges represent cosine similarity values or post similarity. Node and edge selection is performed using thresholding methods. Feature extraction is done using the networkx library. User classification with multi-label dangerous speech topics is done using Logistic Regression, Naïve Bayes, K-nearest Neighbors, Support Vector Classifier Decision Tree, and Random Forest. The best pseudo-label for dangerous speech aspects is obtained using a combined model of IndoBERTweet, Naïve Bayes, and Logistic Regression with an accuracy above 80%. In topic modeling, it was found that the optimal number of topics is 19 based on their coherence score and the absence of new sub-topics. The best thresholding method involves each account having an average retweet count of more than 1 and a cosine similarity value of more than 0.149. The best classification of dangerous users is achieved with the Naïve Bayes model using degree centrality, closeness centrality, and eigenvector centrality features, with a hamming loss value of 0.555."
Identifikasi Diabetes Melitus Berdasarkan Biomarker pada Sekuens DNA Menggunakan Metode Deep Learning.,"Permatasari, Devindha",http://repository.its.ac.id/103748/,"Diabetes melitus merupakan salah satu penyakit kronis yang tidak dapat disembuhkan yang disebabkan oleh kekurangan atau tidak adanya hormon insulin. Menurut etiopatologi diabetes, ada tiga kategori klinis utama, yaitu: diabetes tipe 1 (DMT1), diabetes tipe 2 (DMT2), dan diabetes melitus gestasional (DMG), serta penyebab khusus lainnya. Diabetes merupakan salah satu penyebab utama kematian di seluruh dunia. Setiap tahunnya sekitar 2-5 juta pasien kehilangan nyawa karena diabetes. Individu dengan diabetes menghadapi risiko mengembangkan beberapa masalah kesehatan sekunder seperti penyakit jantung, kerusakan saraf dan berbagai masalah kesehatan lainnya. Dengan demikian, deteksi dini dan pengobatan diabetes dapat mencegah komplikasi dan membantu mengurangi risiko masalah kesehatan yang parah. Penelitian ini bertujuan untuk mengidentifikasi diabetes berdasarkan biomarker pada sekuens DNA dengan menggunakan metode berbasis deep learning. Pada penelitian ini digunakan data sekuens DNA yang direpresentasikan kedalam gambar spektogram. Data sekuens DNA diubah menjadi numerik menggunakan teknik mapping berbasis entropi yang merupakan turunan fraksional dari Shanon Entropi. Kemudian dibuat gambar spektogramnya menggunakan fungsi specgram yang ada pada libary matplotlib dengan menggunakan STFT untuk merangkai plot tiga dimensi dengan waktu, frekuensi, dan amplitudo yang diwakili oleh skala warna. Gambar spektogram dari sekuens DNA diekstraksi menggunakan modul ViT dan mendapatkan 100 fitur. 100 fitur tersebut diklasifikasi dengan menggunakan SVM dan mendapatkan hasil akurasi sebesar 99%================================================================================================================================Diabetes mellitus is an incurable chronic disease caused by a deficiency or absence of the hormone insulin. According to the etiopathology of diabetes, there are three main clinical categories, namely: type 1 diabetes (T1DM), type 2 diabetes (T2DM), and gestational diabetes mellitus (GDM), as well as other noteworthy causes. Diabetes is one of the leading causes of death worldwide. Every year around 2-5 million patients lose their lives due to diabetes. Individuals with diabetes risk developing secondary health problems, such as heart disease, nerve damage, and various other health problems. Thus, early detection and treatment of diabetes can prevent complications and help reduce the risk of severe health problems. This study aims to identify diabetes based on biomarkers in DNA sequences using a deep learning based method. The study utilizes DNA sequence data represented as spectrogram images. The DNA sequences are transformed into numeric values using entropy-based mapping techniques, which are fractional derivatives of Shannon Entropy. Spectrogram images are then created using the specgram function in the Matplotlib library, employing Short-Time Fourier Transform (STFT) to generate three-dimensional plots with time, frequency, and amplitude represented by color scale. Spectrogram images of DNA sequences extracted using the ViT module and obtaining 100 features. These 100 features are classified using SVM and obtain an accuracy of 99%"
Analisis Sentimen Masyarakat Indonesia Mengenai Vaksin COVID-19 Pada Media Sosial Twitter Menggunakan Metode Naïve Bayes Classifier dan Support Vector Machine.,"Permatasari, Rizka Widya",http://repository.its.ac.id/91280/,"World Health Organization (WHO) mendeklarasi-kan virus COVID-19 sebagai pandemi global pada 11 Maret 2020. Kondisi tersebut memberikan dampak langsung kepada seluruh masyarakat di dunia, dengan mulai diberlakukannya protokol ke-sehatan yang harus diterapkan pada seluruh aspek kegiatan, mulai dari pembatasan sosial hingga lockdown total yang menghambat seluruh kegiatan masyarakat. Salah satu cara yang dilakukan untuk mencegah penyebaran virus ini adalah dengan pemberian vaksin. Kegiatan vaksinasi mulai diberikan kepada masyarakat Indonesia pada bulan Januari 2021. Pada media sosial twitter, pro kontra vaksin COVID-19 sempat menjadi trending topic sehingga dirasa perlu untuk dilakukan penelitian tentang sentimen publik terhadap adanya kegiatan vaksinasi dalam memutus rantai penyebaran COVID-19 di Indonesia. Pada penelitian ini digunakan analisis klasifikasi teks yaitu Naïve Bayes Classifier (NBC) dan Support Vector Machine (SVM). NBC telah banyak digunakan dalam penelitian mengenai Text Mining karena memiliki algoritma yang sederhana namun dapat menghasilkan akurasi yang tinggi, sedangkan SVM memiliki kemampuan yang baik dalam mengolah data berdimensi besar dengan hasil yang efektif. Perbandingan kedua metode menggunakan 10 fold-stratified cross validation dengan kriteria kebaikan klasifikasi AUC dan akurasi menunjukkan bahwa SVM memiliki kinerja klasifikasi yang lebih baik dibanding NBC dan SVM kernel menghasilkan ketepatan klasifikasi lebih tinggi dibanding SVM kernel RBF.====================================================================================================The World Health Organization (WHO) declared the COVID-19 virus as a global pandemic on March 11, 2020. These conditions had a direct impact on all people in the world, with the introduction of health protocols that must be applied to all aspects of activities, starting from from social restrictions to total lockdowns that hinder all community activities. One way to prevent the spread of this virus is by giving vaccines. Vaccination activities began to be given to the people of Indonesia in January 2021. On social media Twitter, the pros and cons of the COVID-19 vaccine had become a trending topic, so it was deemed necessary to conduct research on public sentiment towards vaccination activities in breaking the chain of spread of COVID-19. 19 in Indonesia. This research uses text classification analysis, namely Naïve Bayes Classifier (NBC) and Support Vector Machine (SVM). NBC has been widely used in research on Text Mining because it has a simple algorithm but can produce high accuracy, while SVM has a good ability to process large-dimensional data with effective results. Comparison of the two methods using 10 fold-stratified cross validation with AUC classification goodness criteria and accuracy shows that SVM has better classification performance than NBC and SVM kernel produces higher classification accuracy than SVM kernel RBF."
Pengembangan Sistem Deteksi dan Lokalisasi Kebocoran Pipa Berbasis Deep Learning Residual-Network pada Jaringan Distribusi Air di Perumda Air Minum Tugu Tirta Malang.,"Prabowo, Zhiya Ulhaq",http://repository.its.ac.id/109409/,"Berdasarkan ringkasan SDGs 6.2 tahun 2021, bahwa 46% dari populasi dunia kekurangan air yang tersanitasi. PERUMDA Air Minum Tugu Tirta merupakan salah perusahaan yang berkontribusi dalam penyediaan dan distribusi air bersih. Kehilangan air fisik merupakan tantangan dalam distribusi air bersih yang dialami perusahaan. Demi mengatasi tantangan, diperlukan metode deteksi lokasi kebocoran pada jaringan distribusi air. Penelitian kali ini akan diajukan metode berbasis deep learning residual-network (ResNet) untuk mendeteksi ukuran dan lokasi kebocoran yang terjadi. Pertama, dilakukan pemilihan DMA sebagai objek penelitian. Spesifikasi DMA diambil untuk dilakukan pemodelan dengan software WaterCAD dan kemudian divalidasi serta dilakukan pemodelan kebocoran dengan mengatur Emitter Coefficient serta lokasi kebocorannya. Ukuran kebocoran adalah rendah 0,3 l/s, sedang 0,6 l/s, dan tinggi 1,2 l/s. Ketika kebocoran disimulasikan, data tekanan diambil pada empat titik sensor yang telah ditentukan pada DMA. Kemudian, dilakukan variasi lokasi dengan variasi ukuran yang sama. Data tekanan aktual dari DMA juga diambil dengan menggunakan sensor tekanan yang dipasang pada pressure point dari jaringan. Sistem deteksi dan lokalisasi berbasis ResNet dikembangkan dengan menggunakan data simulasi dalam proses pelatihan sistem. Dari proses pelatihan tersebut didapatkan hasil performa akurasi deteksi ukuran sebesar 98.62% dan lokalisasi sebesar 98.16%, serta F1-Score deteksi ukuran sebesar 98.97% dan lokalisasi sebesar 98.17%. Akan tetapi, pada percobaan dengan data aktual, performa dapat disebut kurang baik, dimana akurasi deteksi ukuran dan lokalisasi sebesar 75%, serta F1-Score deteksi ukuran sebesar 85.71%. dan lokalisasi sebesar 85.71%. =================================================================================================================================According to the 2021 SDGs 6.2 summary, 46% of the world's population lacks access to sanitized water. PERUMDA Air Minum Tugu Tirta is one of the companies contributing to the provision and distribution of clean water. Physical water loss is a significant challenge in the distribution of clean water faced by the company. To address this challenge, a method for detecting leak locations in the water distribution network is necessary. This study proposes a deep learning residual-network (ResNet)-based method to detect the size and location of leaks. First, a District Metered Area (DMA) was selected as the research object. The DMA specifications were used for modeling with WaterCAD software. The model was validated, and leak modeling was performed by adjusting the Emitter Coefficient and the location of the leaks. The leak sizes were categorized as low (0.3 l/s), medium (0.6 l/s), and high (1.2 l/s). During the leak simulation, pressure data was collected at four predetermined sensor points within the DMA. Various locations with the same size variations were tested. Actual pressure data from the DMA was also collected using pressure sensors installed at pressure points in the network. The ResNet-based detection and localization system was developed using simulation data for the system training process. The training process yielded a detection size accuracy is 98.62% and a localization accuracy is 98.16%, with an F1-Score for detection size is 98.97% and for localization is 98.17%. However, when tested with actual data, the performance was less satisfactory, with a detection size and localization accuracy of 75%, and the F1-Score for detection size and localization is 85.71%."
Klasterisasi Kasus Kemiskinan di Indonesia pada Hasil Peramalan Backpropagation Neural Network.,"Pradnyandari, Ni Putu Putri Marinda",http://repository.its.ac.id/99719/,"Kemiskinan merupakan permasalahan sosial yang cukup kompleks dan sulit untuk hilang. Banyak negara sudah memfokuskan tujuan kenegaraan mereka untuk menanggulangi kemiskinan. Hal ini dibuktikan dengan lahirnya Sustainable Development Goals (SDGs) yang disusun oleh Perserikatan Bangsa-Bangsa (PBB) dan mengharuskan Indonesia turut andil dalam penanggulangan kemiskinan. Namun, jika kita lihat berdasarkan data, menurut data Badan Pusat Statistik, angka kemiskinan di Indonesia masih mengalami peningkatan di bulan September 2022 dibandingkan dengan periode sebelumnya, Maret 2022. Berdasarkan permasalahan tersebut, solusi yang dapat ditawarkan untuk membantu pemerintah dan masyarakat dalam menanggulangi kemiskinan adalah dengan melakukan peramalan sebagai landasan dalam mengambil kebijakan. Peramalan ini menggunakan metode Backpropagation Neural Network dan hasil data peramalan dilakukan clustering menggunakan metode K-Means. Objek penelitian yang digunakan adalah data kemiskinan 34 provinsi di Indonesia dari tahun 2015 sampai 2022 yang terdiri dari variabel tingkat kemiskinan, PDRB harga konstan, tingkat pengangguran terbuka, dan rasio gini. Data berupa data semester dengan total jumlah data di setiap variabelnya sebanyak 544 data. Dalam pemodelan BPNN, didapatkan model terbaik dengan jaringan BPNN (4-6-1) dengan hasil MAPE dan MSE sebesar 7,14% dan 0,00000492. Hasil peramalan berdasarkan model BPNN terbaik kemudian dilakukan klasterisasi. Clustering K-Means menghasilkan 3 klaster dengan karakteristik yang berbeda. Jumlah provinsi yang masuk ke dalam klaster 1 sebanyak 8 provinsi, klaster 2 sebanyak 5 provinsi, dan klaster 3 sebanyak 21 provinsi.================================================================================================================================Poverty is a complex social problem that is difficult to eliminate. Many countries have focused their state goals on tackling poverty. This is evidenced by the birth of the Sustainable Development Goals (SDGs) compiled by the United Nations (UN) and requires Indonesia to take part in poverty reduction. However, if we look at the data, according to the Central Bureau of Statistics, the poverty rate in Indonesia still increased in September 2022 compared to the previous period, March 2022. Based on these problems, a solution that can be offered to help the government and society in reducing poverty is to conduct forecasting as a basis for making policies. This forecasting uses the Backpropagation Neural Network method and the results of the forecasting data are clustering using the K-Means method. The research object used is poverty data for 34 provinces in Indonesia from 2015 to 2022 which consists of variables of poverty rate, GRDP at constant prices, open unemployment rate, and Gini ratio. The data is in the form of semester data with a total of 544 data in each variable. In BPNN modeling, the best model is obtained with the BPNN network (4-6-1) with MAPE and MSE results of 7.14% and 0.00000492. Forecasting results based on the best BPNN model are then clusterized. K-Means clustering produces 3 clusters with different characteristics. The number of provinces included in cluster 1 is eight provinces, cluster 2 is five provinces, and cluster 3 is 21 provinces."
Deteksi Dini Financial Distress Pada Perusahaan Sektor Teknologi di Bursa Efek Indonesia Menggunakan Artificial Neural Network dan Support Vector Machine.,"Pradnyaningsih, Ni Luh Eva",http://repository.its.ac.id/118576/,"Kondisi ekonomi dan geopolitik di Indonesia diperkirakan akan memburuk pada beberapa tahun kedepan yang disebabkan oleh beberapa faktor diantaranya inflasi dan biaya operasional yang tinggi. Hal ini berdampak pada minat investor dalam berinvestasi pada perusahaan. Salah satu perusahaan yang paling berdampak besar adalah perusahaan sektor teknologi. Industri teknologi di Indonesia menghadapi tantangan pada pangsa pasar yang relatif rendah dibandingkan pasar global dimana banyak saham teknologi di Indonesia masih tertinggal jauh dibandingkan negara-negara maju. Akibat hal tersebut investor lebih memilih berinvestasi pada emiten yang minim risiko. Penurunan ini memengaruhi kemampuan perusahaan-perusahaan teknologi untuk menarik investasi yang dibutuhkan untuk bertahan dan berkembang. Beberapa perusahaan di sektor teknologi telah mengalami perubahan signifikan dalam kinerja keuangan mereka, menunjukkan adanya potensi kesulitan keuangan. Kesulitan keuangan terjadi ketika kinerja keuangan perusahaan menurun dari waktu ke waktu, yang pada gilirannya memengaruhi stabilitas sistem keuangan dan sumber daya manusia perusahaan. Oleh karena itu, penelitian ini bertujuan untuk memprediksi apakah perusahaan-perusahaan di sektor teknologi di Indonesia akan mengalami kesulitan keuangan di masa depan atau tidak dengan menggunakan metode Artificial Neural Network dan Support Vector Machine. Hasil penelitian menunjukkan bahwa ANN lebih unggul dalam memprediksi kinerja keuangan perusahaan, dengan rasio PER memiliki pengaruh besar dalam memprediksi risiko ini. Selain itu, aplikasi berbasis web yang dikembangkan menggunakan Streamlit memungkinkan pengguna untuk mendeteksi dini kondisi keuangan perusahaan.===================================================================================================================================The economic and geopolitical conditions in Indonesia are expected to deteriorate in the coming years due to several factors, including inflation and high operational costs. This affects investor interest in investing in companies. One of the most significantly impacted sectors is technology companies. The technology industry in Indonesia faces challenges with a relatively low market share compared to the global market, where many technology stocks in Indonesia lag significantly behind those in developed countries. As a result, investors prefer to invest in issuers with minimal risk. This decline affects the ability of technology companies to attract the investment needed to survive and grow. Some companies in the technology sector have experienced significant changes in their financial performance, indicating potential financial difficulties. Financial difficulties occur when a company's financial performance declines over time, which in turn affects the stability of the financial system and the company's human resources. Therefore, this study aims to predict whether technology companies in Indonesia will experience financial distress in the future using Artificial Neural Network and Support Vector Machine methods. The results of the study indicate that ANN outperforms other models in predicting the financial performance of companies, with the PER ratio having a significant impact on forecasting this risk. Additionaly, the web-based application developed using Streamlit enables users to detect companies financial conditions early."
Analisis Faktor Yang Mempengaruhi Penjualan Produk B2B Dengan Menggunakan Metode Support Vector Machine Di PT XYZ.,"Pradnyawati, Ni Kadek Dewi",http://repository.its.ac.id/96203/,"Indonesia merupakan salah satu negara dengan pengguna internet terbesar di seluruh dunia yang menduduki posisi keenam pada tahun 2021 dengan menggunakan berbagai media seperti handphone, laptop, personal computer ataupun alat lainnya yang membutuhkan koneksi internet. PT XYZ adalah suatu perusahaan telekomunikasi yang menyediakan layanan internet di Indonesia dengan berbagai produk yang ditujukan untuk segmen Business to Business (B2B) dan juga Business to Consumer (B2C). Produk B2B yang dihasilkan oleh PT XYZ yaitu IaaS, CPaaS, SaaS, dan Analytics yang kemudian ditawarkan oleh salesperson ke pelanggan atau perusahaan yang membutuhkan dengan melakukan assessment awal yang bertujuan untuk melihat kebutuhannya dan kemudian melakukan mapping produk yang sesuai. PT XYZ memiliki lebih dari 50 salesperson yang ada di Indonesia dengan latar belakang dan profil yang berbeda-beda seperti umur, lokasi, jabatan, status, hingga kondisi keluarga dan juga ekonomi yang dapat mempengaruhi performa dari seorang salesperson. PT XYZ ingin meningkatkan performansi penjualan produk B2B dengan mengetahui faktor-faktor yang berpengaruh berdasarkan karakteristik dari salesperson dengan membandingkan antara status proyek win dan lose. Regresi logistic dan scoring feature digunakan untuk mengetahui korelasi antara variabel sehingga dapat mengetahui faktor-faktor yang berpengaruh terhadap penjualan. Support vector machine (SVM) merupakan salah satu metode dari data mining yang dapat digunakan untuk mengklasifikasikan dan memprediksi dari suatu data (Arifin, 2018). Berdasarkan hasil analisis, faktor yang mempengaruhi penjualan dari salesperson yaitu lama bekerja di PT XYZ, sisa waktu pelunasan KPR, jumlah training, usia pernikahan, dan pendidikan terakhir. Nilai akurasi pada hasil klasifikasi SVM sebesar 81% dengan derajat optimalnya yaitu sebesar 2. Rekomendasi bisnis yang dapat diberikan untuk meningkatkan performansi salesperson PT XYZ adalah dengan memberikan training yang sesuai dengan kebutuhan dan pekerjaan untuk salesperson.==============================================================================================================================PT XYZ is a telecommunication company that provides internet services in Indonesia with various products aimed at the Business to Business (B2B) and also Business to Consumer (B2C) segments. B2B products produced by PT XYZ namely IaaS, CPaaS, SaaS, and Analytics which are then offered by salespersons to customers or companies that need them by conducting an initial assessment which aims to see their needs and then mapping the appropriate products. PT XYZ has more than 50 salespersons in Indonesia with different backgrounds and profiles such as age, location, position, status, to family and economic conditions that can affect the performance of a salesperson. PT XYZ wants to improve the sales performance of B2B products by knowing the influencing factors based on the characteristics of the salesperson by comparing the win and lose project statuses. Logistic regression and scoring features are used to determine the correlation between variabels so that they can determine the factors that influence sales. Support vector machine (SVM) is a method of data mining that can be used to classify and predict data (Arifin, 2018). Based on the results of the analysis, The characteristics that influence sales from salespersons are time spent working, remaining KPR repayment time, number of trainings, marriage age, educational status. Advice that offered to PT XYZ by providing training tailored to the demands of the salesperson and also in accordance with the job is intended to boost salesperson performance, allowing them to win more products. The SVM classification results have an accuracy score of 81% with an ideal degree of 2."
Klasifikasi Tumor Glioma dengan Modalitas Magnetic Resonance Imaging (MRI) berbasis Convolutional Neural Network (CNN) untuk Diagnosis Tingkat Keganasan Tumor Otak.,"Prakosa, Nadhira Anindyafitri",http://repository.its.ac.id/111213/,"Glioma mendominasi 80% dari kasus tumor otak ganas pada pasien, menyebabkan tingginya tingkat mortalitas, disabilitas serta penurunan kualitas hidup yang signifikan. Tumor glioma diklasifikasikan menjadi Low-Grade Glioma (LGG) dan High-Grade Glioma (HGG) berdasarkan tingkat keganasannya. Klasifikasi ini sangat penting karena berdampak signifikan terhadap prognosis, keputusan pengobatan, dan perencanaan bedah. Diagnosis yang akurat oleh para ahli medis sangat penting untuk menentukan tindakan yang tepat. Computer Aided Diagnosis (CAD) dapat digunakan dalam mempermudah dokter menghasilkan diagnosis yang persisi. Metode CAD tradisional mengandalkan teknik machine learning (ML) yang memerlukan pemilihan fitur secara manual, seperti analisis tekstur. Namun, pendekatan ini dapat menyebabkan hilangnya fitur data yang esensial, yang berpotensi mengurangi akurasi diagnosis. Convolutional Neural Networks (CNN) telah merevolusi pencitraan medis dengan kemampuan luar biasa dalam mengenali dan mengidentifikasi tumor otak. Berbeda dengan metode tradisional, CNN mengintegrasikan ekstraksi fitur dalam arsitekturnya, menghilangkan kebutuhan pemilihan fitur manual. Kemampuan ini memungkinkan CNN mencapai akurasi tinggi dalam klasifikasi tumor. Untuk klasifikasi glioma, sangat penting untuk memanfaatkan informasi dari berbagai sequence MRI guna memungkinkan model CNN mengekstraksi fitur representatif secara efektif. Studi ini menggunakan pendekatan multi-sequence fusion, menggabungkan sequence MRI Flair, T1, T1ce, dan T2 dengan fine-tuned model VGG16 untuk mengklasifikasikan tingkat keganasan glioma. Model ini memanfaatkan data dari dataset BraTS 2017, 2018, 2019, dan 2020. Model yang diusulkan mencapai hasil yang luar biasa, meliputi akurasi 100%, presisi 99,04%, recall 100%, skor F1 99,52%, dan spesifisitas 99,03%. Evaluasi metrik yang luar biasa ini menunjukkan efektivitas model dalam mengklasifikasikan tingkat keganasan glioma dengan akurat. Studi ini menunjukkan kemajuan signifikan dalam mendiagnosis tingkat keganasan tumor otak, serta memperlihatkan potensi untuk mempermudah pembuatan prognosis pasien melalui klasifikasi yang akurat dan andal.========================================================================================================================Gliomas dominate 80% of malignant brain tumor cases in patients, presenting a significant challenge in neuro-oncology. These tumors are classified into Low-Grade Glioma (LGG) and High-Grade Glioma (HGG) based on their malignancy levels. This classification is crucial as it significantly impacts prognosis, treatment decisions, and surgical planning. Accurate diagnosis by medical experts is essential for determining the appropriate course of action. Computer-aided diagnosis (CAD) systems have emerged as valuable tools in assisting doctors with precise diagnoses. Traditional CAD methods have often relied on machine learning techniques that require manual feature selection, such as texture analysis. However, this approach can lead to the loss of essential data features, potentially compromising the accuracy of the diagnosis. Convolutional Neural Networks (CNNs) have revolutionized medical imaging by excelling in recognizing and identifying brain tumors. Unlike traditional methods, CNNs integrate feature extraction within their architecture, eliminating the need for manual feature selection. This capability allows CNNs to achieve high accuracy in tumor classification. For glioma classification, it is essential to utilize information from different MRI sequences to enable the CNN model to extract representative features effectively. This study employs a multi-sequence fusion approach, combining Flair, T1, T1ce, and T2 MRI sequences with a fine-tuned VGG16 model to classify glioma malignancy levels. The model leverages data from the BraTS 2017, 2018, 2019, and 2020 datasets. The proposed model achieves remarkable results, including 100% accuracy, 99.04% precision, 100% recall, a 99.52% F1 score, and 99.03% specificity. These exceptional performance metrics highlight the model's effectiveness in accurately classifying glioma malignancy levels. The study demonstrates significant advancements in diagnosing brain tumor malignancy levels, showcasing the potential to facilitate accurate and reliable patient prognoses through precise classification."
Engine Predictive Maintenance Schedule Optimization on Sumbagut-2 Gas Engine Power Plant Using Mixed Integer Nonlinear Programming.,"Pranata, Muhammad Kahari",http://repository.its.ac.id/110691/,"Engine maintenance scheduling is crucial for power plants, particularly those using multiple engines. For example, the Sumbagut-2 Gas Engine Power Plant in Lhokseumawe, Aceh, employs 13 engines to produce 240 MW of power for northern Sumatera, including North Sumatera and Aceh. This project designs an optimized maintenance schedule based on engine usability and the type of maintenance required according to each generator's accumulated operation hours. The goal is to maximize system reliability using a mixed integer nonlinear programming optimization approach. Constraints include maximum duration and maintenance status, while the objective function focuses on reliability. Engine reliability is determined by calculating the components’ respective reliability functions in series, and system reliability is assessed by placing the engines in parallel. The optimized schedule shows that the first maintenance occurs on the 27th day. Most engines are maintained in pairs, with at least one engine undergoing maintenance alone."
Boosting Support Vector Machine pada Data Microarray yang Imbalance.,"Pratama, Risky Frasetio Wahyu",http://repository.its.ac.id/55389/,"Data microarray memainkan peran penting dalam pengklasifikasian hampir semua jenis jaringan kanker. Permasalahan yang seringkali dihadapi dalam klasifikasi menggunakan data microarray adalah high dimensional data dan kelas imbalance. Masalah high dimensional data dapat diatasi dengan menggunakan seleksi fitur Fast Correlated Based Filter. Metode klasifikasi yang digunakan dalam penelitian ini yaitu Support Vector Machines (SVM) karena beberapa kelebihannya, namun SVM sangat sensitif terhadap kelas imbalance. SMOTE merupakan salah satu dalam penanganan data imbalance dengan cara mereplikasi pengamatan pada kelas minoritas. Metode ini seringkali bekerja baik namun terkadang juga terjadi masalah overfitting. Salah satu alternatif lain dalam meningkatkan performansi klasifikasi pada data imbalance yaitu boosting. Metode ini membangun suatu classifier akhir yang kuat dengan menggabungkan sekumpulan SVM sebagai base classifier selama proses iterasi, sehingga dapat meningkatkan performansi klasifikasi. Penelitian ini, bertujuan untuk mengkaji performansi dari SMOTEBoost-SVM jika dibandingkan dengan AdaBoost-SVM dalam melakukan klasifikasi pada data microarray dengan beberapa tingkatan rasio imbalance yang didesain dalam studi simulasi dan penerapan pada data publik microarray. Data publik yang digunakan yaitu data kanker colon dan data myeloma. Hasil analisis yang diperoleh yaitu secara umum, pada studi simulasi, semua classifier mengalami penurunan performansi g-mean seiring bertambahnya rasio kelas imbalance, namun SMOTEBoost-SVM cenderung unggul dan mengalami penurunan performansi lebih kecil (lebih stabil) dibandingkan AdaBoost-SVM, SMOTE-SVM dan SVM. Pada Penerapan data publik, SMOTEBoost SVM juga  mengungguli ketiga metode lain berdasarkan ukuran g-mean dan sensitivity. Efek dari seleksi fitur juga dilihat dalam analisis dimana menggunakan fitur-fitur informatif hasil seleksi fitur, menghasilkan performansi yang lebih baik dibandingkan menggunakan seluruh fitur dalam klasifikasi.========================================================================================================Microarray data plays an important role in the classification of almost all types of cancer tissue. The problems that often appear in the classification using microarray data are high-dimensional data and imbalanced class. The problem of high-dimensional data can be solved by using Fast Correlated Based Filter (FCBF) feature selection. In this paper, Support Vector Machine (SVM) classifier is used because of its advantages. However, SVM are sensitive with respect to imbalanced class. SMOTE is one of the prepocessing data methods in handling imbalanced class based on sampling approach by increasing the number of samples from the minority class. This method often works well but sometimes it might suffer from over-fitting problem. One other alternative approach in improving the performance of imbalanced data classification is boosting. This method constructs a powerful final classifier by combining a set of SVMs as base classifier during the iteration process. So, it can improve the classification performance. This study aims to see the performance of SMOTEBoost-SVM compared with AdaBoost-SVM in classifying microarray data with several levels of imbalance ratio designed in the simulation study and to apply classification process on public microarray datasets. Colon cancer and myeloma data are used in this study. The result showed that in the simulation study, all classifiers get the g-mean performance deacreasing as the ratio of the imbalanced class is increased, but SMOTEBoost-SVM tend to be superior. Its performance is decrease smaller (more stable) than AdaBoost-SVM, SMOTE-SVM and SVM. In the real data classification, SMOTEBoost-SVM outperforms the others with respect to g-mean and sensitivity metrics.The effect of feature selection is also checked in the analysis. Using informative features obtained in feature selection process gave the better performance than using all feature in the classification process by SVM."
Trajectory Tracking Pada Mobil Autonomous Menggunakan Prediction Control Dengan Referensi Waktu.,"Priambudi, Renardi Adryantoro",http://repository.its.ac.id/99705/,"Pengaturan pada kendaraan self-driving khusus nya pada topic trajectory tracking sangat banyak dikembangkan oleh civitas akademisi. Pada kasus ini penulis coba menyelesaikan permasalahan trajectory tracking menggunakan pendekatan non-linear yang memiliki batasan waktu tempuh. Pada penelitan ini akan dibentuk time mission control diaman didalamnya terdapat kontrol lateral dan kontrol longitudinal. Kontrol longitudinal dibentuk menggunakan Bezier curve yang akan membentuk local path baru pada saat ingin mendahului mobil lain.Kontrol lateral dibentuk dari gabungan velocity profile dan adaptive cruise control yang akan mengatur kecepatan mobil. Mobil autonomous juga harus memenuhi time mission, dimana mobil akan bergerak dengan kecepatan dinamis dengan menyesuaikan waktu yang telah ditentukan serta kondisi lalu lintas yang ada. Kontrol trejektori menggunakan PID, Mobil akan diamati hanya terhadap jalan yang dilaluinya. Hasil yang diamati adalah visual path yang dibentuk dari mobilautonomous pada saat bergerak dengan referensi global path dan error waktu tempuhnya.======================================================================================================================================The development of self-driving vehicles, particularly in the field of trajectory tracking, has been extensively explored by academia. In this case, the author attempts to address the trajectory tracking issue using a nonlinear approach with a time constraint. This research focuses on implementing a time mission control system that incorporates both lateral and longitudinal control. The longitudinal control is established using a Bezier curve, which creates a new local path when overtaking other vehicles. The lateral control is a combination of a velocity profile and adaptive cruise control, which regulates the vehicle's speed.The autonomous vehicle must also adhere to the time mission, meaning it moves at a dynamic speed, adjusting to the predetermined time and traffic conditions. Trajectory control is achieved using a PID controller, with the vehicle's observations limited to the road it is traveling on. The observed results include the visual path formed by the autonomous vehicle in relation to the global path reference and the corresponding travel time error."
Optimizing The Pricing of Egrek Merah Putih's Blade with Different Materials Qualities Using Responsive Pricing Strategy.,"Pribadi, Riski Puteri",http://repository.its.ac.id/108309/,"Indonesia's palm oil production significantly contributes to the country's GDP, with a volume of 46.50 million tons and an area of 15.380.981 ha in 2022, making it the world's top producer. However, Indonesia faces challenges in palm oil agriculture, particularly during harvesting. These challenges include difficulty determining fruit ripeness and quality material preferences, leading to a tendency to import harvesting sickle blades from abroad. To overcome these issues, innovative solution like the development of Egrek Merah Putih's blade from Institut Teknologi Sepuluh Nopember offers two quality materials: regular (Japanese Spring Steel) and premium (High-Speed Steel). To compete in the market, strategic pricing decisions based on a responsive pricing strategy are critical, balancing quality differences against market uncertainties influenced by quality valuation and reservation value. The research constructs a profit maximization model for Egrek Merah Putih's blades, considering reservation value and quality valuation in a responsive pricing strategy. The model includes demand, profitability, and constraint functions for regular and premium blades. Parameters include market demand, overall quality valuation, reservation value, customer Willingness to Pay (WTP), production costs, and percentage multiplier of customer Willingness to Pay (WTP). In the obtained data of 6245 demands, the optimal regular blade’s selling price is Rp225.000 with a profit of Rp27.231.105. The optimal premium blade’s selling price is Rp450.000 with a profit of Rp461.113.372. Quality valuation measures customer satisfaction with quality, while reservation value is the minimum price for a basic product. As quality valuation increases, premium blade demand and profit rise while regular blade demand and profit decline. As reservation value increases, regular blade demand and profit increase proportionally. With both increasing, overall demand and profit for both blades improve, with premium blade contributing more profit due to higher prices and quality preferences. The highest profit occurs at maximum quality valuation and maximum reservation value.=================================================================================================================================Produksi minyak sawit Indonesia memberikan kontribusi signifikan terhadap PDB negara, dengan volume sebesar 46,50 juta ton dan luas wilayah 15.380.981 ha pada tahun 2022, menjadikannya produsen terbesar dunia. Namun, Indonesia menghadapi tantangan dalam pertanian kelapa sawit, khususnya pada saat panen. Tantangan tersebut antara lain sulitnya menentukan kematangan buah dan preferensi kualitas bahan sehingga menimbulkan kecenderungan untuk mengimpor bilah dari luar negeri. Untuk mengatasi permasalahan tersebut, solusi inovatif seperti pengembangan bilah Egrek Merah Putih dari Institut Teknologi Sepuluh Nopember menawarkan dua material berkualitas: reguler (Japanese Spring Steel) dan premium (High-Speed Steel). Untuk bersaing di pasar, keputusan penetapan harga strategis berdasarkan strategi penetapan harga yang responsif sangat penting, menyeimbangkan perbedaan kualitas dengan ketidakpastian pasar yang dipengaruhi oleh penilaian kualitas dan nilai reservasi. Penelitian ini membangun model memaksimalkan keuntungan bilah Egrek Merah Putih dengan mempertimbangkan nilai reservasi dan penilaian kualitas dalam strategi penetapan harga yang responsif. Model ini mencakup fungsi permintaan, profitabilitas, dan kendala untuk bilah reguler dan premium. Parameternya meliputi permintaan pasar, penilaian kualitas secara keseluruhan, nilai reservasi, Willingness to Pay (WTP) pelanggan, biaya produksi, dan persentase pengali Willingness to Pay (WTP) pelanggan. Pada data permintaan 6245 yang diperoleh, harga jual bilah reguler optimal adalah Rp225.000 dengan keuntungan Rp27.231.105. Harga jual bilah premium optimal sebesar Rp450.000 dengan keuntungan sebesar Rp461.113.372. Penilaian kualitas mengukur kepuasan pelanggan terhadap kualitas, sedangkan nilai reservasi adalah harga minimum untuk suatu produk dasar. Ketika penilaian kualitas meningkat, permintaan dan keuntungan bilah premium meningkat sementara permintaan dan keuntungan bilah reguler menurun. Ketika nilai reservasi meningkat, permintaan dan keuntungan bilah reguler meningkat secara proporsional. Dengan meningkatkan keduanya, keseluruhan permintaan dan keuntungan untuk kedua bilah meningkat dengan bilah premium memberikan kontribusi keuntungan lebih besar karena harga dan preferensi kualitas yang lebih tinggi. Keuntungan tertinggi terjadi pada penilaian kualitas maksimum dan nilai reservasi maksimum."
Reidentifikasi Orang Pada Data Visible-Infrared Yang Terkorupsi Menggunakan Klasifier Vision Transformer.,"Pusaka, Nathanael Tenno Phileo Wong",http://repository.its.ac.id/111951/,"Teknik Reidentifikasi orang, yaitu mengidentifikasi kembali individu berdasarkan data gambar atau video yang telah ada. Dalam era modern, Reidentifikasi menjadi penting di bidang keamanan dan pemantauan. Dataset RegDB-C berisi gambar tampak dan infrared dari berba gai individu. Vision Transformer (ViT) merupakan arsitektur jaringan saraf yang efektif dalam memproses data visual-infrared, terutama saat data tersebut terkorupsi.Penilitian ini berfokus untuk mengidentifikasi orang pada berbagai kondisi pencahayaan, perubahan cahaya yang ek strim, perubahan suhu, data yang terkena noise pada data Visible-infrred dengan menggunakan dataset RegDB-C yang terdiri dari 2.060 citra visible dan 2.060 cintra infrared.Meskipun terda pat permasalahan berupa dataset yang mengalami korupsi, Vision Transformer dapat mengiden tifikasi individu secara akurat.Penilitian ini menggunakan berbagai konfigurasi model Vision Transformer, dengan pengujian menggunakan batchsize 16, 32, 64, dan modifikasi hyperpa rameter seperti learning rate dan loss function.Hasil yang didapatkan tertinggi pada Vision Transformer yang telah dimodifikasi hyperparameter dengan nilai MAP (mean Average Pre cision) yang didapatkan yaitu senilai 0,436899, dengan Rank@1 senilai :0.396440 , Rank@5 senilai 0.601942,dan Rank@10 senilai 0.702265.Penilitian ini diharapkan dapat berkontribusi dalam mengembangkan sistem reidentifikasi pada data visible-infrared yang terkorupsi meng gunakan klasifer Vision Transformer.====================================================================================================Person Reidentification techniques involve re-identifying individuals based on existing image or video data. In the modern era, reidentification has become crucial in the fields of security and monitoring. The RegDB-C dataset contains visible and infrared images of various individ uals. Vision Transformer (ViT) is a neural network architecture that is effective in processing visual-infrared data, especially when the data is corrupted. This research focuses on identifying people under various lighting conditions, extreme light changes, temperature variations, and noise in the visible-infrared data using the RegDB-C dataset, which consists of 2,060 visible images and 2,060 infrared images. Despite issues such as data corruption, Vision Transformer can accurately identify individuals. This study employs various configurations of the Vision Transformer model, testing with batch sizes of 16, 32, and 64, and modifying hyperparameters such as learning rate and loss function. The highest results were obtained with the Vision Trans former model that had modified hyperparameters, achieving a mean Average Precision (MAP) of 0.436899, with Rank@1 of 0.396440, Rank@5 of 0.601942, and Rank@10 of 0.702265. This research is expected to contribute to the development of reidentification systems for corrupted visible-infrared data using Vision Transformer classifiers."
Analisis Sentimen Pengguna Aplikasi Shopee Pada Situs Google Play Store Menggunakan Metode Support Vector Machine.,"Putra, Fahmi Maulutfi Dwi",http://repository.its.ac.id/103742/,"Marketplace adalah tempat jual beli online dimana penjual baru menerima uangnya jika barang sudah sampai ke pembeli, sedangkan E-Commerce adalah transaksi jual beli atau perdagangan secara online. Salah satu marketplace yang sangat diminati saat ini dikalangan remaja hingga dewasa adalah Shopee. Shopee resmi diperkenalkan di Indonesia pada Desember 2015 dibawah naungan PT Shopee International Indonesia. Shopee adalah sebuah aplikasi yang bergerak dibidang jual beli secara online dan dapat diakses secara mudah dengan menggunakan smartphone. Shopee merupakan aplikasi jual beli elektronik yang dapat diunduh di situs Google Play. Google Play Store memiliki berbagai macam fitur, salah satunya adalah ulasan atau opini. Ulasan atau opini ini digunakan untuk para pengguna menilai sebuah aplikasi. Pengguna aplikasi Shopee dapat memberikan opini yang berisi tanggapan, apresiasi, kritik dan masukan pada aplikasi Shopee yang tersedia di Google Play Store. Opini pada aplikasi Shopee dapat digunakan untuk mendapatkan informasi sebagai bahan perbaikan atau pengembangan aplikasi sehingga pengguna mendapatkan kepuasan. Proses pengembangan membutuhkan opini dari pengguna, hal tersebut bisa didapat dari data opini pada Google Play Store dalam bentuk data teskstual. Data tekstual tersebut bisa dianalisis menggunakan text mining. Banyak metode yang dapat digunakan untuk memudahkan proses klasifikasi sentiment data, setiap metode memiliki karakteristik berbeda sehingga tingkat keefektifan setiap metode berbeda-beda. Dalam menganalisis opini dibutuhkan metode yang cepat dan akurat yaitu analisis sentimen dengan metode Support Vector Machine (SVM). Hasil penelitian menunjukkan bahwa untuk analisis sentimen dengan kategori sentimen positif yaitu sebesar sebesar 53,13%, sedangkan untuk opini pengguna aplikasi Shopee berdasarkan kategori sentimen negatif sebesar 46,87% dengan hasil nilai accuracy sebesar 64,5%, nilai sensitivity sebesar 60,1%, dan nilai specificity sebesar 69,5%.=================================================================================================================================Marketplace is a place for buying and selling online where sellers only receive money if the goods have reached the buyer, while E-Commerce is buying and selling or trading transactions online. One of the marketplaces that is in great demand today among teenagers to adults is Shopee. Shopee was officially introduced in Indonesia in December 2015 under the auspices of PT Shopee International Indonesia. Shopee is an application engaged in buying and selling online and can be accessed easily using a smartphone. Shopee is an electronic buying and selling application that can be downloaded on the Google Play site. The Google Play Store has various features, one of which is reviews or opinions. These reviews or opinions are used for users to rate an application. Shopee application users can provide opinions that contain responses, appreciation, criticism and input on the Shopee application which is available on the Google Play Store. Opinions on the Shopee application can be used to obtain information as material for improvement or application development so that users get satisfaction. The development process requires opinions from users, this can be obtained from opinion data on the Google Play Store in the form of textual data. The textual data can be analyzed using text mining. Many methods can be used to facilitate the sentiment data classification process, each method has different characteristics so that the level of effectiveness of each method varies. In analyzing opinions, a fast and accurate method is needed, namely sentiment analysis using the Support Vector Machine (SVM) method. The results showed that for sentiment analysis the positive sentiment category was 53.13%, while for the opinion of Shopee application users based on the negative sentiment category it was 46.87% with an accuracy value of 64.5%, a sensitivity value of 60.1%, and a specificity value of 69.5%."
Implementasi IndoBERT Dalam Analisis Sentimen Berita Untuk Prediksi Harga Saham PT. Bank Rakyat Indonesia Tbk. Menggunakan Pendekatan Support Vector Regression.,"Putra, Ferdyansyah Permana",http://repository.its.ac.id/105901/,"Fluktuasi harga saham sering dipengaruhi oleh berbagai faktor, dan salah satunya adalah sentimen, yang dapat berasal dari masyarakat umum atau berita terkait saham. Harga saham PT. Bank Rakyat Indonesia Tbk. (BBRI), sebagai salah satu dari ""big four"" bank terbesar di Indonesia, juga dapat dipengaruhi oleh sentimen ini. Dalam usaha untuk meramalkan harga penutupan saham BBRI berdasarkan sentimen berita, penelitian ini mengadopsi pendekatan machine learning dengan menggunakan metode Support Vector Regression (SVR) dan mengoptimalkan fungsi dengan algoritma Fruit Fly Optimization Algorithm (FOA). Sentimen dievaluasi terlebih dahulu dengan metode IndoBERT. Penelitian ini mengusulkan beberapa model, termasuk model tanpa memperhitungkan sentimen, model dengan mempertimbangkan sentimen pada periode ke t, model dengan mempertimbangkan sentimen pada periode ke t-1, dan model dengan mempertimbangkan sentimen pada periode ke t dan periode ke t-1. Analisis hasil sentimen menggunakan IndoBERT menunjukkan tingkat akurasi sentimen secara keseluruhan di atas 90%. Selain itu, hasil pemodelan menunjukkan bahwa model terbaik menggunakan SVR adalah model yang tidak mempertimbangkan sentimen, dengan nilai error peramalan yaitu Mean Average Percentage Error (MAPE) lebih rendah dibandingkan dengan model lain. Hasil peramalan dengan dari model terbaik menunjukkan bahwa data aktual masih berada dalam interval kepercayaan 95% dari hasil ramalan, sehingga menunjukkan relevansi ramalan dengan data aktual.=================================================================================================================================Fluctuations in stock prices are often influenced by various factors, and one of them is sentiment, which can originate from the general public or stock-related news. The stock price of PT. Bank Rakyat Indonesia Tbk. (BBRI), as one of the ""big four"" largest banks in Indonesia, can also be influenced by this sentiment. In an effort to forecast the closing price of BBRI stock based on news sentiment, this research adopts a machine learning approach using the Support Vector Regression (SVR) method and optimizes the function with the Fruit Fly Optimization Algorithm (FOA). Sentiment is first evaluated using the IndoBERT method. This research proposes several models, including a model without considering sentiment, a model considering sentiment on the day of the event, a model considering sentiment on the previous day, and a model considering sentiment on both the day of the event and the previous day. Sentiment analysis results using IndoBERT show an overall accuracy rate above 90%. Furthermore, modelling results indicate that the best-performing SVR model is the one that does not consider sentiment, with a lower Mean Average Percentage Error (MAPE) compared to other models. The forecasting results from the best model show that the actual data still falls within the 95% confidence interval of the forecast, demonstrating the relevance of the forecast to the actual data."
Optimasi Model Klasifikasi Multi-Label Berbahasa Indonesia: Penerapan dan Perbandingan Metode Bi-LSTM dan BERT pada Teks Berita Berbahasa Indonesia.,"Putra, Marsyavero Charisyah",http://repository.its.ac.id/111093/,"Pengguna internet di Indonesia terus meningkat setiap tahunnya. Pada tahun 2023, survei APJII mencatat 78,19% populasi Indonesia menggunakan internet, meningkat 2,67% dari tahun sebelumnya. Peningkatan ini mendorong pertumbuhan media online dan mengubah cara masyarakat mengakses berita dari media cetak ke online. Dengan bertambahnya pengguna internet, volume berita online juga meningkat signifikan. Diperlukan teknik efisien untuk mengelola dan mengklasifikasikan berita agar memudahkan pengguna memahami informasi yang relevan. Penelitian ini mengembangkan model multilabel classification menggunakan Bi-LSTM dan BERT serta membandingkan performanya dengan model dari penelitian sebelumnya. Dataset berasal dari scraping teks berita dari detik.com dan Petakabar, dijadikan satu dataset bernama Topic Mining. Dataset dilabeli secara manual dengan 39 label. Empat model dikembangkan: Bi-LSTM, Bi-LSTM dengan Attention, BERT, dan Hybrid (kombinasi BERT dan Bi-LSTM dengan Attention). Evaluasi kinerja model menggunakan metrik F1-Score, akurasi, recall, dan hamming loss. Model Hybrid menunjukkan performa terbaik dengan mean recall 0,864, mean F1-score 0,893, mean accuracy 0,981, dan mean Hamming Loss 0,019. Label yang berperforma terbaik adalah ""bencana"" dengan F1-score 0,973, sedangkan label yang berperforma terburuk adalah ""politik"" dengan F1-score 0,279.==============================================================================================================================The number of internet users in Indonesia continues to increase every year. In 2023, a survey by APJII recorded that 78.19% of Indonesia's population uses the internet, an increase of 2.67% from the previous year. This growth has driven the rapid expansion of online media and changed the way people access news from print to online. With more internet users, the volume of online news has also increased significantly. Efficient techniques are needed to manage and classify news to help users understand relevant information. This study developed a multi-label classification model using Bi-LSTM and BERT and compared its performance with the previous model from the previous research. The dataset, named Topic Mining, was created by scraping news texts from detik.com and Petakabar. The dataset was manually labeled with 39 labels. Four models were developed: Bi-LSTM, Bi-LSTM with Attention, BERT, and Hybrid (a combination of BERT and Bi-LSTM with Attention). Model performance was evaluated using F1-Score, accuracy, recall, and hamming loss. The Hybrid model showed the best performance with a mean recall of 0,864, a mean F1-score of 0,893, a mean accuracy of 0,981, and a mean hamming loss of 0,019. With the best-performing label is ""disaster"" with an F1-score of 0,973, while the worst performing label is ""politics"" with an F1-score of 0,279."
Sistem Informasi Geografis Berbasis Google Earth API Menggunakan Algoritma K-Nearest Neighbors.,"Putra, Nicky Permana",http://repository.its.ac.id/81664/,"Sistem Informasi Geografis merupakan sistem komputer yang memiliki kemampuan untuk membangun, menyimpan, mengelola dan menampilkan informasi berupa peta geografis suatu daerah. Sistem Informasi Geogafis ini akan digunakan untuk melakukan pengelompokan statistik – statistik daerah dan dikelompokkan pada kategori yang ada untuk kemudian ditampilkan dalam bentuk peta tematik atau peta digital menggunakan algoritma K-Nearest Neighbor. Data – data statistik yang nantinya akan dimasukkan dapat berupa data tingkat kemiskinan, data tingkat pengangguran dari suatu daerah, dll. Algoritma K-NN akan mengelompokkan data sesuai kategori dan saat data-data tersebut sudah terkelompokkan maka peta akan muncul dengan daerah yang sudah diberi warna dimana daerah-daerah tersebut sudah tergolongkan sesuai dengan kategorinya. Hal ini dapat diterapkan di pemerintahan guna untuk mempermudah dalam pengambilan kebijakan dalam suatu daerah"
"Analysis of Bittern Recovery Scenario Using Mixed-Integer Nonlinear Programming: Centralized, Decentralized, and Hybrid Case Study.","Putra, Furqon Sandiva Utomo",http://repository.its.ac.id/89066/,"In the desalination process to produce salts, it left a wastewater with a high concentration of salts, magnesium, and other kinds of mineral called bittern. For some salt producer, these bitterns are considered as waste that are dumped and never be used again. This can be problematic because although bittern water contains similar compounds as seawater, it is much more concentrated. When bittern is directly dumped into the ecosystem, the increase in salinity can pollute and harm the life around the area. Furthermore, it is also a waste in potential since bittern still contains mineral that can be extracted and have selling value. To combat this, bittern recovery has become an increasingly used practice in the salt industry. This is done not only to reduce the environmental impact of salt production, but also create a circular economy. However, there is a strong requirement in determining how the process is carried out. In that, one needs to know the optimal type and number of recovery stations that can meets the supply and demand constrains, cost effective, and beneficial for the environment and economy. This research proposes a mixed-integer nonlinear programming (MINLP) model for analyzing the supply and demand of the bittern recovery to achieve circular economy and environmental sustainability. The research considers the supply and demand structure of bittern and the constrains from the recovery process. The MINLP model is used to optimize the trade-off between the cost of waste transportation, recovery, and station installation, with the benefit from the selling value of the recovered minerals and the environmental sustainability. The objective of the research is to create a model that can determine the best bittern recovery scenario between a centralized, decentralized, or hybrid types of recovery stations based on profit optimization. The proposed system optimizations are tested and analyzed upon its sensitivity.=================================================Dalam proses desalinasi untuk menghasilkan garam, akan meninggalkan limbah cair dengan garam, magnesium, dan jenis mineral lain dengan konsentrasi tinggi yang disebut air tua atau bittern. Bagi produsen garam pada umumnya, bittern ini dianggap sebagai limbah yang dibuang dan tidak akan pernah digunakan lagi. Ini bisa menjadi masalah karena meskipun air bittern mengandung senyawa yang mirip dengan air laut, air tua memiliki kandungan yang jauh lebih pekat sehingga dapat menjadi polusi untuk lingkungan sekitar. Ketika bittern langsung dibuang ke ekosistem, peningkatan salinitas dalam air dapat membahayakan kehidupan di sekitar area tersebut. Selain itu, hal ini juga merupakan penyia-nyiaan potensi, karena bittern masih mengandung mineral yang dapat diekstraksi dan memiliki nilai jual. Untuk mengatasi hal ini, pengolahan bittern telah menjadi praktik yang semakin sering digunakan di industri garam. Hal ini dilakukan tidak hanya untuk mengurangi dampak lingkungan dari produksi garam, tetapi juga menciptakan ekonomi sirkuler. Namun, ada beberapa pertimbangan penting yang menentukan bagaimana proses tersebut dilakukan. Hal ini penting untuk menentukan jenis dan jumlah stasiun pemulihan yang optimal yang dapat memenuhi faktor supply dan demand, kehematan biaya, dan manfaatnya bagi lingkungan serta perekonomian. Penelitian ini mengusulkan model Mixed-Integer Nonlinear programming (MINLP) untuk menganalisis pasok dan permintaan pengolahan bittern untuk mencapai ekonomi sirkuler dan kelestarian lingkungan. Penelitian ini mempertimbangkan struktur supply dan demand bittern dan kendala dan batasan dari proses pemulihan. Model MINLP digunakan untuk mengoptimalkan trade-off antara biaya pengangkutan limbah, pengolahan, dan instalasi stasiun pengolahan, dengan pertimbangan keuntungan yakni nilai jual mineral yang dipulihkan dan kelestarian lingkungan. Tujuan dari penelitian ini adalah untuk memilih skenario pemulihan bittern terbaik antara tipe stasiun pengolahan terpusat, terdesentralisasi, atau hibrid berdasarkan pengoptimalan keuntungan. Optimasi sistem yang diusulkan kemudian diuji dan dianalisis berdasarkan sensitivitasnya======================================================================================================Dalam proses desalinasi untuk menghasilkan garam, akan meninggalkan limbah cair dengan garam, magnesium, dan jenis mineral lain dengan konsentrasi tinggi yang disebut air tua atau bittern. Bagi produsen garam pada umumnya, bittern ini dianggap sebagai limbah yang dibuang dan tidak akan pernah digunakan lagi. Ini bisa menjadi masalah karena meskipun air bittern mengandung senyawa yang mirip dengan air laut, air tua memiliki kandungan yang jauh lebih pekat sehingga dapat menjadi polusi untuk lingkungan sekitar. Ketika bittern langsung dibuang ke ekosistem, peningkatan salinitas dalam air dapat membahayakan kehidupan di sekitar area tersebut. Selain itu, hal ini juga merupakan penyia-nyiaan potensi, karena bittern masih mengandung mineral yang dapat diekstraksi dan memiliki nilai jual. Untuk mengatasi hal ini, pengolahan bittern telah menjadi praktik yang semakin sering digunakan di industri garam. Hal ini dilakukan tidak hanya untuk mengurangi dampak lingkungan dari produksi garam, tetapi juga menciptakan ekonomi sirkuler. Namun, ada beberapa pertimbangan penting yang menentukan bagaimana proses tersebut dilakukan. Hal ini penting untuk menentukan jenis dan jumlah stasiun pemulihan yang optimal yang dapat memenuhi faktor supply dan demand, kehematan biaya, dan manfaatnya bagi lingkungan serta perekonomian. Penelitian ini mengusulkan model Mixed-Integer Nonlinear programming (MINLP) untuk menganalisis pasok dan permintaan pengolahan bittern untuk mencapai ekonomi sirkuler dan kelestarian lingkungan. Penelitian ini mempertimbangkan struktur supply dan demand bittern dan kendala dan batasan dari proses pemulihan. Model MINLP digunakan untuk mengoptimalkan trade-off antara biaya pengangkutan limbah, pengolahan, dan instalasi stasiun pengolahan, dengan pertimbangan keuntungan yakni nilai jual mineral yang dipulihkan dan kelestarian lingkungan. Tujuan dari penelitian ini adalah untuk memilih skenario pemulihan bittern terbaik antara tipe stasiun pengolahan terpusat, terdesentralisasi, atau hibrid berdasarkan pengoptimalan keuntungan. Optimasi sistem yang diusulkan kemudian diuji dan dianalisis berdasarkan sensitivitasnya."
Klasifikasi Electroencephalogram (EEG) Motor Imagery Dengan Fitur Differential Asymmetry Pada Support Vector Machine (SVM).,"Putranto, Yulianto Tejo",http://repository.its.ac.id/97190/,"Selama bertahun-tahun penelitian bidang Brain-Computer Interface (BCI) telah difokuskan pada keinginan untuk menyediakan para penyandang disabilitas kemudahan dan kemampuan untuk berinteraksi dengan lingkungannya. Dalam beberapa tahun terakhir, penelitian BCI telah merambah ke aplikasi yang diperuntukkan bagi orang normal untuk meningkatkan kualitas hidup atau mendapatkan keuntungan komersial bagi suatu komunitas atau target group. Pada penelitian ini dirancang sistem BCI berbasis EEG, khususnya untuk mengenali aktivitas motor imagery untuk diterapkan dalam perangkat keras atau perangkat lunak yang bersifat interaktif. Sistem BCI menuntut akurasi dan kecepatan respon yang tinggi. Permasalahan ini dicoba dipecahkan dengan mengembangkan ekstraksi fitur yaitu differential asymmetry berdasarkan nilai selisih antara hasil pengukuran sinyal otak belahan kiri dan kanan. Fitur-fitur statistik dari hasil dekomposisi sinyal EEG motor imagery menggunakan transformasi wavelet diskrit dan dekomposisi mode empiris dimodifikasi dengan mengambil nilai selisihnya untuk dijadikan fitur baru. Sebagai pengklasifikasi digunakan Support Vector Machine (SVM).Hasil penelitian menunjukkan peningkatan nilai akurasi dari pengklasifikasi dengan menerapkan fitur differential asymmetry dibandingkan tanpa menerapkan fitur differential asymmetri. Dari tiga dataset yang diteliti, dataset I mengalami kenaikan nilai akurasi rata-rata sebesar 30,33%, dataset II sebesar 6,54% dan dataset III sebesar 23,17%. Hasil akurasi dengan menggunakan SVM untuk dataset I, dataset II dan dataset III berturut-turut: 91,70%, 66,91% dan 93,16%.=================================================================================================================================Through the years, research in Brain-Computer Interface (BCI) has focused on providing convenience and ability for disabilities people to interact with the environment. In recent years, BCI research has been enlarge into applications intended for normal people to improve life quality or obtain commercial advantage for a community or group target. In this study, an EEG-based BCI system was designed, especially for recognizing motor imagery activity to be applied in games.The BCI system demands accuracy and response speed. This problem will be solved by developing a feature extraction, namely differential asymmetry based on the value of the difference between the measurement results of the left and right brain hemisphere signals. Statistical features from the decomposition of motor imagery EEG signals using discrete wavelet transform (DWT) and empirical mode decomposition (EMD) are modified by taking those difference values was as a new feature. As a classifier, Support Vector Machine (SVM) is used.The results showed an increase in the accuracy value of the classifier by applying the differential asymmetry feature compared to without applying the differential asymmetry feature. Of the three datasets studied, dataset I experienced an average increase in accuracy by 30.33%, dataset II by 6.54% and dataset III by 23.17%. Accuracy results using SVM for dataset I, dataset II and dataset III are respectively: 91.70%, 66.91% and 93.16%."
Optimization Model for Vehicle Parking Space Unit Proportion And Zoning On Conventional And Digital Parking System Using Mixed Integer Non-Linear Programming And Response Surface Methodology.,"Qisthauzan, Avenzoar Zufar",http://repository.its.ac.id/87645/,"Pemerintah setempat menemukan bahwa pungutan liar masih terjadi pada area parkir di bahu jalan. Tindakan ini mengurangi pendapatan dari retribusi parkir daerah sebesar 72,5% pada tahun 2018. Untuk mengatasi masalah tersebut, pemerintah bekerjasama dengan pihak ketiga untuk mengembangkan aplikasi parkir digital. Studi sebelumnya menyimpulkan bahwa program parkir digital layak secara finansial untuk diterapkan di beberapa lokasi di Indonesia. Namun, studi tersebut berdasar pada asumsi bahwa 100% masyarakat siap menerima perubahan sistem parkir dari konvensional ke digital. Studi lebih lanjut menemukan bahwa hanya 59,3% masyarakat lokal yang siap dengan perubahan sistem; dengan demikian, perlu dilakukan proses transisi sistem secara bertahap. Penelitian ini akan menentukan proporsi optimal satuan ruang parkir (SRP) antara mobil dan sepeda motor yang dikombinasikan dengan proporsi optimal sistem digital dan konvensional yang diterapkan pada suatu area parkir. Tujuan sistem ini untuk memaksimalkan manfaat yang diterima oleh penyedia tempat parkir dan pengguna parkir. Model optimasi dilakukan dengan software LINGO. Response Surface Methodology (RSM) juga digunakan untuk pengambilan keputusan. Dari hasil keputusan optimasi, SRP yang optimum untuk Jalan Gajah Mada di Kabupaten Sidoarjo adalah 188 SRP mobil untuk area parkir digital, 323 SRP sepeda motor untuk area parkir digital, 133 SRP mobil untuk area parkir konvensional, dan 251 SRP sepeda motor untuk area parkir konvensional. Komposisi tersebut diharapkan akan memberikan retribusi yang kepada penyedia jasa parkir sebesar Rp75.798.856 dengan tingkat kepadatan tempat parkir sebesar 68,07%. Dari sisi pengguna parkir, total biaya pengguna parkir sebesar Rp57.358.168.====================================================================================================The Indonesian government imposed a subscription parking policy to improve the on-street parking system, but the execution did not go well. The local government found that illegal levies were still happening. This action negatively impacted the local government by reducing revenue from parking fees by 72.5% in 2018. To overcome this problem, the government collaborates with third parties to develop a digital parking application. A previous study has concluded that the digital parking program is financially feasible to be implemented in several locations in Indonesia. However, the study assumes that 100% of the people are ready to accept the change in the parking system from conventional to digital. A further study found that only 59.3% of the local community is ready for the system changes; thus, a gradual transition is needed. This research will determine the optimal proportion of parking space units between cars and motorcycles combined with the optimal proportion of digital and conventional system proportion applied to the parking area. The objective is to maximize benefits from parking space providers and parking users. The optimization model were carried out with a model built on the LINGO software. Response Surface Methodology will be performed for final decision making. The model found that the optimum SRP arrangement for Gajah Mada Street is 188 car SRP for digital parking area, 323 motorcycle SRP for digital parking area, 133 car SRP for conventional parking area, and 251 motorcycle SRP for conventional parking area. The arrangement will give parking service providers expected retribution of Rp75,798,856 with a parking area utilization rate of 68.07%. From the parking user perspective, the total parking user cost is Rp57,358,168."
"STUDI KINERJA METODE SELEKSI FITUR BERBASIS 
UNCERTAINTY PADA DETEKSI CHRONIC KIDNEY DISEASE
DENGAN KLASIFIKASI SVM.","Qolby, Lailly Syifa`ul",http://repository.its.ac.id/88100/,"Chronic Kidney Disease (CKD) merupakan sebuah kelainan yang merusak fungsi ginjal. Tanda awal penderita CKD sangat sulit untuk diketahui hingga penderita kehilangan 25% dari fungsi ginjalnya. Oleh karena itu dibutuhkan pendeteksian dini dan treatment yang efektif untuk mengurangi tingkat kematian penderita CKD.Dalam penelitian ini penulis melakukan diagnosa pada dataset CKD menggunakan metode klasifikasi Support Vector Machine (SVM) untuk mendapatkan hasil diagnosa yang akurat. Untuk memperoleh hasil klasifikasi yang terbaik, maka penulis mengusulkan perbandingan hasil pada penerapan metodeseleksi fitur agar mendapatkan kandidat fitur terbaik dalam meningkatkan hasil klasifikasi.Proses pengujian dilakukan dengan membandingkan metode seleksi fiturSymmetrical Uncertainty (SU) dan Multivariate Symmetrical Uncertainty (MSU)serta metode SVM sebagai metode klasifikasi. Dengan menggunakan dataset CKD, dilakukan beberapa skenario percobaan baik dengan menggunakan metode seleksi fitur SU maupun MSU. Dari hasil ujicoba yang dilakukan menunjukkan bahwa dengan menggunakan metode seleksi fitur MSU dengan split data 80% : 20% menghasilkan jumlah fitur penting sebanyak 9 fitur dengan nilai akurasi 0.9, sensitivy 0.8400, dan specification 1 serta jika dilihat pada grafik ROC grafik metode MSU menunjukkan nilai true positive lebih tinggi daripada nilai false positive. Sehingga klasifikasi dengan menggunakan metode seleksi fitur MSU lebih baik daripada metode seleksi fitur SU.=====================================================================================================Chronic Kidney Disease (CKD) is a disorder that impairs kidney function. Early signs of CKD patients are very difficult to know until the patient loses 25% of their kidney function. Therefore, early detection and effective treatment are needed to reduce the mortality rate of CKD sufferers.In this study, the authors diagnose the CKD dataset using the Support Vector Machine (SVM) classification method to obtain accurate diagnostic results. The authors propose a comparison of the result on the application of the feature selection method in order to get the best feature candidates in improving the classification result.Testing process is carried out by comparing the Symmetrical Uncertainty (SU) and Multivariate Symmetrical Uncertainty (MSU) feature selection method as well as the SVM method as a classification method. By using the CKD dataset, several experimental scenarios were carried out using both the SU and MSU feature selection methods. From the results of the tests carried out, it shows that using the MSU feature selection method with 80% : 20% data split produces 9 important features with an accuracy value of 0.9, sensitivity 0.8400, specification 1 and when viewed on the ROC graph, the MSU method graph shows the true positive value is higher than the false positive value. So the classification using the MSU feature selection method is better than the SU feature selection method."
Sistem Deteksi Gangguan Spektrum Autisme pada Anak Melalui Metode Facial Landmarks dan Machine Learning pada Citra Respons Emosional.,"Rachmah, Indah Nabila",http://repository.its.ac.id/113008/,"Meskipun prevalensi Autism Spectrum Disorder (ASD) terus meningkat secara global, metode skrining saat ini untuk deteksi dini tetap memakan waktu dan mahal, yang menyoroti kesenjangan penelitian yang kritis. Penelitian ini bertujuan untuk mengembangkan sistem deteksi baru untuk ASD pada anak-anak, memanfaatkan landmark wajah dan metode pembelajaran mesin untuk menganalisis gambar respons emosional. Pendekatan kami melibatkan penangkapan ekspresi wajah spontan menggunakan sensor pencitraan non-invasif, diikuti dengan ekstraksi landmark wajah kunci. Dua model klasifikasi, Support Vector Machine (SVM) dan Convolutional Neural Network (CNN), diimplementasikan untuk menganalisis dan mengklasifikasikan landmark wajah ini. Model SVM mencapai akurasi 92.54%, presisi 93.43%, recall 92.56%, dan skor F1 92.42%, sementara model CNN mencapai akurasi 84.16%, presisi 83.06%, recall 85.83%, dan skor F1 84.42%. Studi ini menunjukkan potensi integrasi teknik pembelajaran mesin lanjutan dengan ekstraksi landmark wajah untuk deteksi dini ASD yang andal dan non-invasi. Kinerja menjanjikan dari model SVM dan CNN menunjukkan bahwa pendekatan kami dapat secara signifikan meningkatkan strategi diagnosis dan intervensi dini untuk anak-anak dengan ASD. Selain itu, penggunaan dataset yang beragam dan real-time serta langkah-langkah pra-pemrosesan yang efektif memastikan akurasi, keandalan, dan generalisasi sistem deteksi ini. Potensi sistem yang diusulkan untuk aplikasi praktis dalam diagnosis dini ASD ditingkatkan oleh integrasi teknik pencitraan non-invasi yang berhasil dan pengembangan GUI yang ramah pengguna, membuka jalan untuk deteksi real-time dan pelaporan otomatis, yang pada akhirnya berkontribusi pada hasil perkembangan yang lebih baik dan kualitas hidup anak-anak yang terkena ASD."
Analisis Hubungan Sentimen Publik di Media Sosial X dan SPI Terhadap Pemerintah Provinsi di Indonesia Menggunakan Algoritma GRU dan LSTM.,"Rafli, Andi Muhammad",http://repository.its.ac.id/111297/,"Media sosial, khususnya Twitter, telah menjadi platform utama bagi masyarakat untuk mengekspresikan pandangan dan opini mereka terhadap berbagai isu, termasuk kinerja pemerintah provinsi di Indonesia. Penelitian ini bertujuan untuk menganalisis sentimen publik di media sosial X (Twitter) terkait pemerintah provinsi dengan menggunakan algoritma Gated Recurrent Unit (GRU) dan Long Short-Term Memory   (LSTM). Tahap pertama penelitian melibatkan pengumpulan dan pra-pemrosesan data teks, termasuk case folding, penghapusan tautan, dan lainnya. Setelah itu, data dilabeli secara manual dan dengan model pra-terlatih IndoBERT untuk klasifikasi ke dalam label positif, negatif, dan netral. Metode oversampling dan parameter tuning diterapkan untuk menghasilkan model LSTM dengan akurasi 0,9313, F1-Score 0,9352, dan loss 0,3269.Analisis topik dengan metode LDA menunjukkan dominasi sentimen negatif pada topik seperti ""Persepsi Publik tentang Program dan Kebijakan Anies Baswedan,"" ""Proyek Infrastruktur dan Pengelolaan Lahan,"" dan ""Kinerja Pemerintah Provinsi dalam Sektor Transportasi."" Ini menunjukkan kecenderungan negatif masyarakat terhadap isu-isu pemerintah provinsi.Penelitian ini juga membandingkan analisis sentimen di lima provinsi dengan hasil Survei Penilaian Integritas (SPI). Perhitungan korelasi Pearson menunjukkan nilai sentimen negatif dan positif terhadap SPI masing-masing sebesar 0,53 dan -0,53. Hasil ini mengindikasikan bahwa tingginya nilai SPI tidak selalu berhubungan langsung dengan tingginya atau rendahnya sentimen positif dan negatif, menunjukkan bahwa faktor lain mungkin mempengaruhi bagaimana masyarakat memandang kinerja pemerintah provinsi.============================================================Social media, especially Twitter, has become a major platform for people to express their views and opinions on various issues, including the performance of provincial governments in Indonesia. This study aims to analyze public sentiment on social media X (Twitter) regarding provincial governments using Gated Recurrent Unit (GRU) and Long Short-Term Memory   (LSTM) algorithms. The first stage of the research involved collecting and preprocessing text data, including case folding, removing links, usernames, punctuation, stopwords, double spaces, duplicate data, emoticons, and tweets with fewer than four words. After that, the data was manually labeled and classified using a pre-trained IndoBERT model into positive, negative, and neutral labels. Data imbalance was addressed using oversampling and parameter tuning methods, resulting in an LSTM model with an accuracy of 0.9313, an F1-Score of 0.9352, and a loss of 0.3269.Topic analysis using the Latent Dirichlet Allocation (LDA) method shows a dominance of negative sentiment on topics such as ""Public Perception of Anies Baswedan's Programs and Policies,"" ""Infrastructure Projects and Land Management by the Provincial Government,"" and ""Public Perception of the Provincial Government's Performance in the Transportation Sector."" This indicates a negative tendency in public sentiment towards provincial government issues.The study also compares sentiment analysis across five provinces with the Integrity Assessment Survey (SPI). Pearson correlation calculations show that the correlations between negative and positive sentiment scores and SPI are 0.53 and -0.53, respectively. This suggests that a high SPI value does not necessarily correlate with high or low positive and negative sentiment, indicating that other factors may influence public perceptions of provincial government performance."
"Tutorial Pemodelan, Perhitungan Volume, dan Biaya Menggunakan Revit 2018.","Rahaditya, Verdi Arya",http://repository.its.ac.id/82609/,"Autodesk Revit adalah software Building Information Modeling (BIM) oleh Autodesk untuk desain arsitektur, struktur serta mekanikal, elektrikal dan plumbing (MEP). Dengan software ini pengguna dapat merancang bangunan dan struktur dengan pemodelan komponen dalam 3D dan sekaligus menyajikan gambar kerja dalam 2D. Data yang digunakan dalam tutorial pemodelan ini adalah data sekunder berupa gambar CAD dengan sumber yang telah dilampirkan. Tugas KP ini memberikan tutorial permodelan untuk komponen struktur sekaligus menghitung Rencana Anggaran Biaya (RAB) secara otomatis. Tujuan dari tugas pengganti KP ini adalah untuk: 1) Memberikan cara pemodelan rumah dua lantai menggunakan Autodesk Revit 2018. 2) Memberikan cara perhitungan volume, dan biaya menggunakan Autodesk Revit 2018. 3) Untuk mengetahui hasil perhitungan biaya total perencanaan rumah dua lantai sederhana yang dihitung menggunakan Autodesk Revit 2018. Tugas pengganti KP diharapkan dapat memberi tutorial mengenai pemodelan dalam Autodesk Revit yang jelas dan mudah dipahami untuk pembaca.=====================================================================================================Autodesk Revit is Autodesk's Building Information Modeling (BIM) software, for architectural, structural, mechanical, electrical and plumbing (MEP) design. With this software users can design buildings and structures with component modeling in 3D and simultaneously present work drawings in 2D. The data used in this modeling tutorial is secondary data in the form of CAD drawings with the attached source. This internship report provides modeling tutorials for structural components as well as calculating the Budget Plan (RAB) automatically. The objectives of this internship report replacement task are to: 1) Provide a two-story house modeling method using Autodesk Revit 2018. 2) Provide a method of calculating volume and costs using Autodesk Revit 2018.3) To find out the results of calculating the total cost of planning a simple two-story house calculated using Autodesk Revit 2018. The task of replacing the internship program is expected to provide a tutorial on modeling in Autodesk Revit that is clear and easy to understand for readers."
Desain Trajektori Kapal Patrol Menggunakan  Deep Reinforcement Learning dalam Operasi  Pengejaran Kapal dengan Losses Data AIS.,"Rahmania, Amanda Caesa",http://repository.its.ac.id/109525/,"Indonesia, sebagai negara kepulauan terbesar, menghadapi tantangan dalam menjaga keamanan maritimnya yang luas. Kehilangan data AIS (Automatic Identification System) pada kapal, seperti yang terjadi di Selat Malaka dan Laut Natuna Utara, mengindikasikan adanya aktivitas ilegal di perairan Indonesia. Penelitian ini bertujuan merancang rute patroli kapal yang optimal menggunakan deep reinforcement learning untuk mengatasi masalah kehilangan data AIS dengan mempertimbangkan faktor lingkungan kapal. Data kapal yang diteliti berada di Selat Malaka terutama Pulau Bengkalis, dengan spesifikasi kapal patrol yaitu KN Ular Laut 406. Penelitian ini dimulai dengan mendeteksi kapal yang mengalami kehilangan data selama lebih dari 1 jam, kemudian dilajutkan dengan deteksi tindakan illegal, setelah mendapatkan data kapal yang mengalami losses data kemudian dilakukan pembuatan trajektori dengan diakhiri dengan pembuatan trajektori dengan berbagai variasi. Hasil dari model yang telah dibuat didapatkan metrik performansi MAE untuk subsistem identifikasi losses data sebesar 0.01312 dan untuk subsistem selektor sebesar 0.12. Pada Deep Reinforcement Learning didapatkan grafik loss dibandingkan dengan 8000episode menunjukkan tren turun dan grafik reward dibandingkan dengan 8000episode menunjukkan tren naik. RMSE juga digunakan untuk perhitungan error dari model visualisasi trajektori dengan nilai terkecil yaitu 0.8104575756222229. Kesimpulan dari penelitian ini antara lain, metode DRL dapat dijadikan sebagai metode dalam pembuatan trajektori kapal patrol, dan model yang digunakan memunculkan grafik loss function dengan tren naik dan reward dengan tren turun maka dapat dikatakan bahwa model bagus.============================================================================================================================================Indonesia, as the largest archipelagic country, faces challenges in maintaining the security of its vast maritime territory. The loss of AIS (Automatic Identification System) data on ships, as observed in the Malacca Strait and the North Natuna Sea, indicates illegal activities in Indonesian waters. This research aims to design an optimal patrol route for ships using deep reinforcement learning to address the problem of AIS data loss and accelerate the capture of illegal vessels by considering the ship's environmental factors. The studied ship data is from the Malacca Strait, particularly around Bengkalis Island, with the patrol vessel specifications being KN Ular Laut 406. The research begins by detecting ships that have experienced data loss for more than 1 hour, followed by the detection of illegal activities. After obtaining data on ships experiencing data loss, trajectory planning is carried out, concluding with the creation of various trajectory variations. The performance metrics of the developed model showed a Mean Absolute Error (MAE) of 0.04 for the data loss identification subsystem and 0.12 for the selector subsystem. In the Deep Reinforcement Learning model, the loss graph over 8000 episodes showed a downward trend, and the reward graph over 8000 episodes showed an upward trend, indicating that the deep reinforcement learning model developed is effective. RMSE was also used to calculate the error of the trajectory visualization model, with the smallest value being 0.8104575756222229."
Klasifikasi Gerakan Pencak Silat Menggunakan Convolutional Neural Network Berbasis Body Pose.,"Rahmawati, Vira Nur",http://repository.its.ac.id/99417/,"Pencak silat selain bermanfaat untuk perlindungan diri, juga memiliki banyak manfaat lainnya, seperti meningkatkan kekuatan fisik, menjaga postur tubuh, dan menjaga kesehatan jantung. Karena pandemi yang belakangan terjadi ini, latihan pencak silat sulit dilakukan secara bersama-sama. Selain itu, jika ada materi pelajaran pencak silat di sekolah, guru olahraga kesulitan untuk mengajarkan gerak secara langsung. Tetapi latihan pencak silat yang dilakukan sendiri tanpa pelatih dapat menyebabkan cedera jika gerakannya tidak benar. Oleh karena itu, penelitian ini membangun sistem pengenalan gerakan pencak silat. Sistem dibangun menggunakan metode CNN berbasis bodypose. Bodypose extraction digunakan untuk mendeteksi keypoint tubuh manusia, kemudian keypoint tersebut digunakan sebagai fitur input ke CNN untuk mengenali gerakan pada setiap frame. Sistem ini menggunakan CNN karena membutuhkan parameter yang lebih sedikit dan daya komputasi yang lebih sedikit sehingga dapat lebih mudah diterapkan untuk studi selanjutnya. Akurasi yang diperoleh mencapai 77% saat diuji pada data yang belum pernah digunakan. Model ini dapat digunakan sebagai titik awal untuk membuat sistem yang mudah digunakan untuk membantu orang berlatih pencak silat dengan gerakan yang lebih banyak.================================================================================================================================Pencak silat, besides from being useful for self-protection, also has many other benefits, such as increasing physical strength, maintaining posture, and maintaining heart health. Due to the recent pandemic, practicing pencak silat is difficult to do together. Even when there is study material on pencak silat at school, it is difficult for the sports teacher to teach the movements directly. Pencak silat exercises that are practiced alone without a coach can cause injury if the movements are not correct. Therefore, this study builds a system to recognize pencak silat movements. The system was built using the bodypose-based CNN method. Bodypose estimation is used to detect human body keypoints, then these keypoints are used as a feature for input to CNN to recognize movement in each frame. This system uses CNN because it requires fewer parameters and less computing power so that it can be more easily applied for further studies. The accuracy obtained reaches 77% when tested on data that has never been used. This model can be used as a starting point for creating an easy-to-use system to help people practice pencak silat with more recognizable moves."
Integrasi Data Multisensor Untuk Peningkatan Lokalisasi Pada Navigasi Mobile Robot Menggunakan Extended Kalman Filter.,"Ramadhan, Fadhly",http://repository.its.ac.id/117061/,"Sistem navigasi robot tidak terlepas dari penggunaan sensor yang digunakan sebagai masukan untuk menentukan persepsi robot baik secara internal maupun eksternal. Setiap sensor memiliki kelebihan dan kekurangannya masing – masing, seperti penggunaan sensor INS menawarkan keunggulan dalam menyediakan data posisi dan orientasi dengan laju tinggi, sementara rotary encoder menyediakan data posisi yang lebih akurat namun rotary encoder yangsensitif terhadap slip. Mengandalkan satu jenis sensor sering kali tidak cukup untuk mencapai estimasi posisi yang akurat dan andal, terutama dalam lingkungan yang kompleks dan dinamis. Kombinasi kedua sistem ini melalui EKF memungkinkan pemanfaatan keunggulan masing-masing sistem, menghasilkan data navigasi yang lebih stabil dan akurat. Dalam penelitian ini, Sensor yang digunakan meliputi Inertial Measurement Unit (IMU) untuk memperoleh orientasi, Rotary Encoder untuk posisi translasi, dan RPLidar A1 untuk deteksi lingkungan. Proses integrasi data melibatkan mekanisasi IMU, filtering menggunakan Kalman Filter, dan pemetaan lingkungan SLAM. Mobile robot yang digunakan memiliki konfigurasi roda omni-directional 4WD yang memungkinkan gerakan bebas dalam ruang dua dimensi. Hasil pengujian menunjukkan bahwa integrasi multisensor dengan EKF signifikan meningkatkan akurasi estimasi posisi dan orientasi dibandingkan metode sensor tunggal.====================================================================================================================================The robot navigation system cannot be separated from the use of sensors which are used as input to determine the robot's perception both internally and externally. Each sensor has its own advantages and disadvantages, such as the use of the INS sensor offers the advantage of providing position and orientation data at a high rate, while the rotary encoder provides more accurate position data but the rotary encoder is sensitive to slip. Relying on one type of sensor is often insufficient to achieve accurate and reliable position estimation, especially in complex and dynamic environments. The combination of these two systems via EKF allows exploiting the advantages of each system, producing more stable and accurate navigation data. In this research, the sensors used include the Inertial Measurement Unit (IMU) to obtain orientation, the Rotary Encoder for translation position, and the RPLidar A1 for environmental detection. The data integration process involves IMU mechanization, filtering using the Kalman Filter, and SLAM environment mapping. The mobile robot used has a 4WD omni-directional wheel configuration which allows free movement in two-dimensional space. Test results show that multisensor integration with EKF significantly increases the accuracy of position and orientation estimation compared to single sensor methods."
Prototipe Sistem Deteksi Maling Menggunakan Wi-Fi Based Secure Indoor Positioning System.,"Ramadhan, Naufal",http://repository.its.ac.id/106170/,"Sistem pemosisian dalam ruangan sudah mulai berkembang dalam beberapa tahun belakangan ini. Berbeda dengan sistem pemosisian yang sudah sangat dikenal oleh masyarakat yakni Global Positioning System (GPS), pada penelitian kali ini akan berfokus melakukan pemosisian di dalam ruangan atau biasa disebut dengan Indoor Positioning System (IPS). Indoor Positiong System (IPS) pada era digitalisasi sangat berpengaruh mengingat seluruh perkembangan infrastruktur sangat maju serta dengan sektor digitalisasi. Pada perkembangan di banyak sektor ini pula maka akan menimbulkan banyak masalah baru seperti contohnya apabila terdapat gedung pencakar langit maka terdapat banyak halangan atau masalah untuk memastikan lokasi dari orang atau pun benda. Masalah tidak berhenti sampai disitu, dimana ancaman juga dapat datang dari manusia baik masuk melalui sistem maupun secara fisik. Pada penelitian kali ini akan digunakan untuk mencari tau perbandingan model terbaik berdasarkan dataset yang sudah ada dengan dataset yang diambil secara langsung dalam salah satu ruangan yang dianggap steril. Kemudian dibandingkan menggunakan beberapa algoritma machine learning sebagai bahan perbandingan algoritma mana yang memiliki akurasi terbaik. Serta dibuat salah satu ujicoba metode serangan yang kemudian dibuat model yang robust. Kemudian dari perbandingan tersebut akan dipilih salah satu model dari dataset yang memiliki akurasi terbaik untuk dibuat prototipe sistem deteksi dimana apabila terdeteksi sebuah anomali di dalam model maka akan mengirimkan pesan warning melalui email dengan harapan sistem ini dapat berguna di ruang atau tempat restricted. Penelitian ini memanfaatkan dataset berbentuk Channel State Information (CSI). Dari beberapa model yang diuji diperoleh akurasi senilai 74,02% menggunakan algoritma random forest. Dimana implementasi serangan menggunakan Decision Tree Attack berhasil dilakukan hingga akurasi turun di angka 52%. Uji coba penerapan metode pertahanan menggunakan featuresqueezing berhasil membuat model lebig tahan dibuktikan dengan akurasi menjadi 68%. Serta implementasi Anomaly Detector dapat mengirimkan pesan bahaya melalui email.=================================================================================================================================Indoor positioning systems have begun to develop in recent years. Different from the positioning system that is well known to the public, namely the Global Positioning System (GPS), this research will focus on indoor positioning or what is usually called the Indoor Positioning System (IPS). The Indoor Positioning System (IPS) in the digitalization era is very influential considering that all infrastructure developments are very advanced as well as the digitalization sector. Development in many of these sectors will also give rise to many new problems, for example if there are skyscrapers then there will be many obstacles or problems in determining the location of people or objects. The problem doesn't stop there, where threats can also come from humans, either through the system or physically. In this research, it will be used to find out the comparison of the best model based on an existing dataset with a dataset taken directly in a room that is considered sterile. Then it is compared using several machine learning algorithms as a comparison which algorithm has the best accuracy. And a test method of attack was made which was then made into a sturdy model. Then, from this comparison, one of the models from the dataset that has the best accuracy will be selected to create a detection system prototype, where if an anomaly is detected in the model, it will send a warning message via email in the hope that this system can be useful in limited spaces or places. This research utilizes a dataset in the form of Channel State Information (CSI). Several models tested obtained an accuracy of 74.02% using the random forest algorithm. Where the implementation of the attack using Decision Tree Attack was successfully carried out until the accuracy fell to 52%. The trial application of the maintenance method using featurequeezing succeeded in making the model more durable, proven by an accuracy of 68%. And the Anomaly Detector implementation can send danger messages via email."
Analisis Gangguan (Noise) Heart Rate Sensor Pada Wearable Device Berdasarkan Artefak Tangan Menggunakan Polar Oh1.,"Ramadhan, Rizqi",http://repository.its.ac.id/110335/,"Penelitian ini bertujuan untuk mengidentifikasi dan menganalisis tingkat noise yang dihasilkan oleh perangkat wearable OH1 selama berbagai gerakan tangan, yang dapat mempengaruhi keakuratan pengukuran detak jantung (HR). Masalah umum yang dihadapi adalah ketidakakuratan data HR yang disebabkan oleh noise saat perangkat digunakan selama aktivitas fisik. Masalah khususnya adalah menentukan gerakan tangan mana yang menghasilkan noise tertinggi dan terendah, serta bagaimana variabilitas data BPM dalam kondisi gerakan tangan yang berbeda-beda. Untuk mengatasi masalah ini, penelitian ini mengumpulkan data HR dari 10 jenis gerakan tangan, yaitu Menekan Tangan Lurus, Horizontal Shoulder Extension, Siku ke Hidung, Menyentuh Bahu, Mengangkat Bahu 90°, Supinate, Pronate, Melenturkan Bahu 180°, Tangan ke Dahi, dan Siku Menekuk 90°. Data tersebut kemudian dianalisis menggunakan metode Support Vector Machine (SVM) untuk mengklasifikasikan tingkat noise yang dihasilkan oleh setiap gerakan.Dengan meenggunakan 11 partisipan yang dalam kondisi sehat. Hasil analisis menunjukkan bahwa gerakan Melenturkan Bahu 180° menghasilkan tingkat noise tertinggi, sementara gerakan Siku Menekuk 90° menghasilkan noise terendah. Variabilitas data BPM menunjukkan perbedaan signifikan dalam stabilitas pengukuran HR yang dipengaruhi oleh jenis gerakan tangan. Dengan menggunakan metode SVM, akurasi klasifikasi mencapai 67%, yang menunjukkan efektivitas metode ini dalam mengidentifikasi dan mengklasifikasikan noise dari berbagai gerakan tangan. Kesimpulannya, penelitian ini memberikan wawasan penting tentang pengaruh gerakan tangan terhadap akurasi pengukuran HR oleh perangkat wearable OH1. Dengan mengetahui gerakan yang menghasilkan noise tinggi, pengguna dapat menghindari gerakan tersebut untuk memperoleh data HR yang lebih akurat dan andal.=================================================================================================================================This study aims to identify and analyze the level of noise produced by the OH1 wearable device during various hand movements, which can affect the accuracy of heart rate (HR) measurements. The general issue addressed is the inaccuracy of HR data caused by noise when the device is used during physical activities. The specific issues include determining which hand movements produce the highest and lowest noise levels and understanding the variability of BPM data under different hand movement conditions. To address these issues, HR data was collected from 10 types of hand movements, including Pressing Straight Hand, Horizontal Shoulder Extension, Elbow to Nose, Touching Shoulder, Lifting Shoulder 90°, Supinate, Pronate, Shoulder Flexion 180°, Hand to Forehead, and Elbow Bent 90°. The data was analyzed using the Support Vector Machine (SVM) method to classify the noise levels generated by each movement. The study involved 11 healthy participants. The analysis results show that the Shoulder Flexion 180° movement produces the highest noise level, while the Elbow Bent 90° movement produces the lowest noise. The variability in BPM data indicates significant differences in the stability of HR measurements influenced by the type of hand movement. Using the SVM method, the classification accuracy reached 67%, demonstrating the effectiveness of this method in identifying and classifying noise from various hand movements. In conclusion, this study provides important insights into the impact of hand movements on the accuracy of HR measurements by the OH1 wearable device. By identifying movements that generate high noise levels, users can avoid these movements to obtain more accurate and reliable HR data."
Peringkasan Pertanyaan Stack Overflow Pada Atribut Kualitas Perangkat Lunak Menggunakan Teknik Penggalian Informasi Dan Klasifikasi Support Vector Machine (SVM).,"Rausanfita, Alqis",http://repository.its.ac.id/92791/,"Stack Overflow merupakan forum diskusi informal yang dapat menjadi bahan untuk evaluasi kualitas suatu perangkat lunak dengan cara penambangan teks. Evaluasi dapat dilakukan dengan menggunakan hasil peringkasan pertanyaan pada Stack Overflow, peringkasan tersebut dapat mengandung persyaratan kebutuhan pelanggan yang dapat dilakukan pemrosesan lebih lanjut. Selain itu, developer juga dapat mengelompokkan kendala yang dialami pengguna berdasarkan kualitas perangkat lunak sehingga dapat memudahkan dalam melakukan maintenance. Metode peringkasan sebelumnya menggunakan 2 jenis bobot, yang mana antara frasa pada sub aspek dengan frasa pada extend domain memiliki bobot yang sama, seharusnya bobot  sub domain lebih besar daripada frasa hasil extend.  Oleh karena itu penelitian ini bertujuan untuk meringkas kebutuhan pengguna pada atribut kualitas perangkat lunak dengan menggunakan informasi retrieval dan klasifikasi kualitas perangkat lunak sehingga diharapkan dapat membantu developer dalam mengevaluasi kualitas perangkat lunak secara otomatis. Ada beberapa tahapan yang dilakukan, yaitu: melakukan klasifikasi. Kemudian hasil klasifikasi tiap atribut kualitas dilakukan peringkasan. Pada penelitian ini, didapatkan hasil akurasi terbaikk dengan menggunakan metode SVM dengan nilai akurasi sebesar 86,63 persen. Hasil akurasi terbaik ini didapatkan dengan membandingkan 5 metode lainnya, yaitu Random Forest, Decision Tree, Logistic Regression, Naïve Bayes, dan Neural Network. Setelah didapatkan hasil klasifikasi kemudian dilakukan proses peringkasan dan mendapatkan nilai akurasi sebesar 73,08 persen. Hal tersebut mengindikasikan bahwa penelitian ini cukup baik dalam menghasilkan ringkasan kebutuhan pengguna pada atribut kualitas perangkat lunak dengan menggunakan information retrieval dan klasifikasi kualitas perangkat lunak. ================================================================================================Stack Overflow is an informal discussion platform that can be used as source for quality evaluation of a software through text mining. Evaluation can be done using the results of the questions summary on the Stack Overflow, the summary can contain the requirements of customer needs that can be processed further. Besides, developer can also group the constraints experienced by users based on the quality of the software so that it can be easier to carry out maintenance. The previous summary method used 2 types of weights with the phrases in the sub-aspects and the phrases in the extend domain had the same weight, in which sub domain should be larger than the extended result phrase. Therefore, this study aims to summarize the user needs on software quality by using retrieval information and software quality classification so that it can help developers in evaluating the software quality automatically. There are several stages that carried out, the first one is classifying. Then the results of the classification of each quality attribute are summarized. In this study, the best accuracy result was obtained using the SVM method with the accuracy value of 86.63 percent. The best accuracy results is obtained by comparing 5 other methods, that are Random Forest, Decision Tree, Logistic Regression, Naïve Bayes, and Neural Network. After obtaining the classification, a summary process was carried out and obtained the accuracy value of 73.08 percent. This indicates that this research is quite good at producing a summary of user needs on software quality attributes using information retrieval and classification of software quality."
Prediksi Curah Hujan Memanfaatkan Statistical Downscaling Data Global Forecast System Menggunakan Support Vector Regression dan Long Short-Term Memory Sebagai Penunjang Keputusan Top Management.,"Rohman, Priya Setiawan A.",http://repository.its.ac.id/116288/,"Wilayah Sungai (WS) Brantas sering mengalami kejadian banjir akibat dari curah hujan yang tinggi, sehingga diperlukan prediksi cuaca yang akurat untuk mendukung keputusan manajemen dalam mitigasi banjir. Data Global Forecast System (GFS) digunakan dalam memprediksi cuaca khususnya prediksi curah hujan, namun resolusinya yang rendah tidak cukup memadai untuk skala lokal di WS Brantas. Masalah yang dihadapi adalah bagaimana cara untuk meningkatkan ketepatan prediksi curah hujan dengan mengintegrasikan data GFS yang memiliki resolusi rendah dengan data curah hujan lokal. Penelitian ini bertujuan untuk meningkatkan akurasi prediksi curah hujan di WS Brantas dengan teknik Statistical downscaling menggunakan metode Support Vector Regression (SVR) yang baik dalam menangani data non-linear dan Long Short-Term Memory (LSTM), sebuah jenis jaringan saraf tiruan yang dapat menangkap hubungan temporal dalam data deret waktu. Data yang diperlukan adalah prediksi curah hujan dari GFS dan data curah hujan lokal hasil pengukuran di WS Brantas. Hasil penelitian menunjukkan bahwa tingkat akurasi prediksi dengan SVR dan LSTM lebih tinggi daripada akurasi data prediksi GFS, sehingga dapat diusulkan untuk diimplementasikan sebagai data penunjang top management.==================================================================================================================================The Brantas River Basin (Brantas RB) often experiences flooding events due to high rainfall, so accurate weather predictions are needed to support management decisions in flood mitigation. Global Forecast System (GFS) data is used in predicting weather, especially rainfall prediction, but its low resolution is not sufficient for the local scale in the Brantas RB. The problem faced is how to improve the accuracy of rainfall prediction by integrating low-resolution GFS data with local rainfall data. This study aims to improve the accuracy of rainfall prediction in Brantas RB with statistical downscaling technique using Support Vector Regression (SVR) method which is good in handling non-linear data and Long Short-Term Memory (LSTM), a type of artificial neural network that can capture temporal relationships in time series data. The data required are rainfall predictions from GFS and local rainfall data measured in Brantas RB. The results show that the accuracy of prediction with SVR and LSTM is higher than the accuracy of GFS prediction data, so it can be proposed to be implemented as top management support data."
Perencanaan Model Distribusi Bahan Baku Baterai Kendaraan Listrik.,"Roihan, Imam Farhannabil",http://repository.its.ac.id/106836/,"Pemerintah Republik Indonesia telah melarang ekspor bijih nikel agar bijih nikel diolah lebih  lanjut di dalam negeri. Kebijakan ini guna meningkatkan nilai tambah dari ekspor nikel  Indonesia. Nikel merupakan salah satu mineral yang melimpah di Indonesia dan merupakan  salah satu bahan baku utama dalam memproduksi baterai kendaraan listrik di samping bahan  baku lainnya seperti mangan, kobalt, dan litium. Indonesia memiliki peluang untuk menjadi  lokasi produksi baterai kendaraan listrik. Untuk menjadi produsen baterai kendaraan listrik,  Indonesia harus membangun industri produksi baterai kendaraan listrik di dalam negeri serta  ngimpor bahan baku lainnya yang tidak melimpah di Indonesia. Industri baterai kendaraan  listrik merupakan industri yang masih tergolong baru di Indonesi sehingga penelitian ini adalah  untuk mencari model distribusi bahan baku baterai kendaraan listrik yang optimum  menggunakan metode optimisasi. Optimisasi dilakukan dengan membagi model distribusi  menjadi beberapa skenario berdasarkan model transportasi laut yang digunakan. Transportasi  laut yang terpilih akan mempengaruhi model distribusi secara keseluruhan. Model distribusi  yang terpilih didapatkan unit cost distribusi bijih nikel Rp22.205/ton, nikel sulfat  Rp2.751.791/ton, kobalt sulfat Rp2.751.791/ton, litium hidroksida Rp1.253.788/ton, mangan  sulfat Rp1.253.788/ton, dan katoda Rp878.723/ton==================================================================================================================================The Government of the Republic of Indonesia has banned the export of nickel ore so that nickel ore can be further processed domestically. This policy is to increase the added value of Indonesian nickel exports. Nickel is one of the minerals that is abundant in Indonesia and is one of the main raw materials for producing electric vehicle batteries alongside other raw materials such as manganese, cobalt and lithium. Indonesia has the opportunity to become a production location for electric vehicle batteries. To become an electric vehicle battery producer, Indonesia must build a domestic electric vehicle battery production industry and import other raw materials that are not abundant in Indonesia. The electric vehicle battery industry is an industry that is still relatively new in Indonesia, so this research is to find an optimum distribution model for electric vehicle battery raw materials using optimization methods. Optimization is carried out by dividing the distribution model into several scenarios based on the sea transportation model used. The selected sea transportation will influence the overall distribution model. The selected distribution model obtained unit distribution costs for nickel ore IDR 22,205/ton, nickel sulfate IDR 2,751,791/ton, cobalt sulfate IDR 2,751,791/ton, lithium hydroxide IDR 1,253,788/ton, manganese sulfate IDR 1,253,788/ton, and cathode IDR 878,723/ton"
DETEKSI PENYAKIT CABAI MERAH BESAR BERDASARKAN CITRA DAUN MENGGUNAKAN METODE SUPPORT VECTOR MACHINE (SVM) DAN LEARNING VECTOR QUANTIZATION (LVQ).,"Rossa, Shevia",http://repository.its.ac.id/114982/,"Salah satu tantangan utama yang menyebabkan rendahnya produksi cabai merah besar adalah gangguan penyakit yang dapat menyerang tanaman mulai dari tahap persemian hingga hasil panen. Gejala visual kunci suatu penyakit menjadi petunjuk kritis dalam menentukan patogen penyebabnya. Beberapa penyakit yang secara signifikan mempengaruhi produksi cabai merah besar di Indonesia meliputi penyakit kuning, embun tepung, mosaik keriting, dan kuning keriting. Penyebaran cepat penyakit ini terjadi karena kurangnya perhatian khusus dari petani, yang mengakibatkan kurangnya pemahaman mereka tentang karakteristik dan penanganan penyakit ini. Oleh karena itu, sangat penting untuk mengembangkan sistem deteksi yang akurat, cepat, dan efisien dalam mengidentifikasi penyakit pada tanaman cabai. Salah satu cara pendeteksian adalah dengan mengklasifikasikan citra daun. Data penelitian bersumber dari pertanian di Kabupaten Bener Meriah Provinsi Aceh pada 21 September hingga 1 Oktober tahun 2023. Teknologi rekognisi citra dilakukan untuk mengenali jenis hama dan penyakit pada tanaman cabai merah besar. Langkah pertama dalam penelitian adalah mengumpulkan citra daun, kemudilan melakukan preprocessing dan dilanjutkan tahap proses ekstraksi fitur warna, fitur tekstur dan fitur bentuk, hasil ekstraksi citra digunakan sebagai input dalam proses klasifikasi menggunakan algoritma Support Vector Machine (SVM) dan Learning Vector Quantization (LVQ). Accuracy hasil prediksi data training dan testing dengan metode SVM kernel polynolial adalah 95% dan 97%, sedangkan accuracy data training dan testing menggunakan metode LVQ adalah 53% dan 57%. Model terbaik dalam memprediksi penyakit cabai adalah model SVM dengan kernel polynomial.========================================================================================================================One of the primary challenges contributing to the low production of large red chili peppers is the prevalence of diseases that can affect plants from the seedling stage to the harvest. Key visual symptoms of a disease serve as critical indicators in determining the causative pathogen. Several diseases significantly impact the production of large red chili peppers in Indonesia, including yellowing disease, powdery mildew, mosaic curl, and yellow curl. The rapid spread of these diseases is attributed to the insufficient specific attention from farmers, resulting in a lack of understanding regarding the characteristics and management of these diseases. Therefore, it is crucial to develop an accurate, rapid, and efficient detection system to identify diseases in chili plants. One method of detection involves classifying leaf images. The research data is sourced from agricultural activities in the Bener Meriah Regency, Aceh Province, from September 21 to October 1, 2023. Image recognition technology is employed to identify types of pests and diseases affecting large red chili plants. The first step in the research involves collecting leaf images, followed by preprocessing and subsequent stages of color feature extraction, texture feature extraction, and shape feature extraction. The extracted image features serve as parameters in the classification process using the Support Vector Machine (SVM) and Learning Vector Quantization (LVQ) algorithms. The accuracy of the prediction results for the training and testing data using the SVM with a polynomial kernel method is 95% and 97%, respectively. In contrast, the accuracy of the training and testing data using the LVQ method is 53% and 57%, respectively. Therefore, the best model for predicting chili plant diseases is the SVM model with a polynomial kernel."
PREDIKSI PENGELUARAN PERKAPITA YANG DISESUAIKAN BERDASARKAN CITRA DIGITAL GOOGLE EARTH MENGGUNAKAN KOMBINASI CONVOLUTIONAL NEURAL NETWORK (CNN) DAN SUPPORT VECTOR REGRESSION(SVR).,"Rouhan, Asva Abadila",http://repository.its.ac.id/81193/,"Kemiskinan dapat didefinisikan sebagai ketidakmampuan seseorang atau rumah tangga dalam memenuhi kebutuhan pokoknya. Kebanyakan negara menggunakan pendapatan atau konsumsi rumah tangga sebagai standar pengukuran kesejahteraan penduduk. Namun, pengumpulan data secara mendetail dari pintu ke pintu merupakan hal banyak memakan waktu dan biaya. Belakangan ini muncul sumber data alternatif pengganti survei, yaitu citra digital satelit. Citra digital umumnya diolah menggunakan Convolutional Neural Network (CNN). Salah satu arsitektur CNN yang dianggap paling baik adalah VGG16. VGG16 dalam tugas akhir ini digunakan sebagai fixed feature extraction sedangkan pemodelan estimasi kemiskinan di Pulau Jawa menggunakan Support Vector Regression (SVR). Kombinasi kedua metode menghasilkan model dengan performa 0,703 pada tahap testing. Terdapat hampir 80% kesesuaian pada 25% golongan pengeluaran perkapita terendah antara hasil estimasi dan data aktual."
Bayisehatkita: Aplikasi Berbasis Web Untuk Klasifikasi Stunting Pada Aud.,"Ruslan, Bima Triadi",http://repository.its.ac.id/88038/,"Malnutrisi merupakan permasalahan umum yang masih banyak terjadi di seluruh dunia, salah satu bentuk dari malnutrisi yang paling banyak diderita oleh anak dibawah 5 tahun adalah stunting. Indonesia masuk ke dalam region Asia Selatan dengan nilai persentase stunting yang masih berada di kategori sangat tinggi. Pada tahun 2019 stunting masih dianggap sebagai permasalahan utama dalam kesehatan masyarakat Indonesia dengan angka prevalensi sebesar 27,67%. Stunting dapat mengakibatkan penurunan kemampuan kognitif dan akademik dari anak, penurunan produktivitas, peningkatan risiko naik berat badan yang eksesif dan penyakit kronis terkait nutrisi pada saat kehidupan dewasa. Dengan angka prevalensi yang masih tinggi dan dampak yang memiliki pengaruh besar pada kehidupan anak, maka perlu diteliti lebih lanjut langkah atau cara apa yang perlu dilakukan untuk menurunkan angka prevalensi stunting di Indonesia.Dalam tugas akhir ini metode yang akan digunakan adalah Binary Logistic Regression. Metode tersebut digunakan karena dapat membandingkan beberapa independent variabel berjenis continuous dan categorical dengan variabel dependent yang terdiri dari dua kemungkinan atau dichotomous. Selain itu dengan menggunakan metode ini maka dapat diperhitungkan probabilitas dari suatu kejadian yang akan terjadi, dalam kasus ini proabilitias anak akan stunting atau probabilitas anak tidak akan stunting. Lalu untuk mengukur kinerja dari metode tersebut akan digunakan confusion matrix untuk memperhitungkan tingkat accuracy, precision, dan recall. Dataset yang akan digunakan dalam tugas akhir ini merupakan dataset Indonesian Family Life Surveys 4 (IFLS 4) dari tahun 2007 dan Indonesian Family Life Survey 5 (IFLS 5) dari tahun 2014-2015 yang diselenggarakan oleh RAND Corporation dan Surveymeter.Hasil analisis dari tugas akhir ini telah diketahui bahwa faktor yang memiliki pengaruh signifikan terhadap perubahan status stunting anak terdiri dari tinggi ayah, tinggi ibu, berat badan ibu, pendidikan ibu, area rumah, dan gender anak. Lalu dalam pengembangan model telah didapatkan bahwa model menggunakan binary logistic regression dengan parameter C bernilai 1, penalty L2 dan solver newton-cg dapat melakukan prediksi status stunting anak dengan cukup baik dengan nilai accuracy sebesar 75,05% dan f1-score sebesar 74,89%.==================================================================================================Malnutrition is a common problem that still occurs throughout the world, one of the most common forms of malnutrition that is suffered by children under years old is stunting. Indonesia is part of the Sout Asia region with a stunting percentage value that is still in the very high category. In 2019 stunting was still considered a major problem in the Indonesian public healthwith a prevalence rate of 27.67%. Stunting can lead to decreased cognitive and academic abilities of children, decreased productivity, increased risk of excessive weight gain and chronic nutrition-related disease when they grow older. With a prevalence rate that is still considered as high and the impact that has a big influence on children’s lives, it is necessary to further investigate what steps or ways that needs to be done to reduce the prevalence of stunting in Indonesia.In this final project the method that is used is binary logistic regression. This method is used based on it’s capabilities to compare several independent variable of continuous and categorical type with a dependent variable which consists of two possibilities or is dichotomous. In addition, by using this method, the probability of an event that will occur can be calculated. In this case the probability of the child being stunted or the probability that the child will not be stunted. To calculate the performance of the model, a confusion matrix will be used to calculate the level of accuracy, precision, and recall. The dataset that is used in this final project is the Indonesian Family Life Surveys 4 (IFLS 4) dataset from 2007 and the Indonesian Family Life Survey 5 (IFLS 5) from 2014-2015 organized by RAND Corporation and Surveymeter. The results of the analysis that is conducted in this final project have shown that the factors that have a significant influence on changes in a child stunting status consist of father’s height, mother’s height, mother’s weight, mother’s education, house area, and child’s gender. Then in the development of the model, it was found that the model using binary logistic regression with a parameter C with a value of 1, penalty of L2, and with the newton-cg solver can predict the stunting status quite well with an accuracy value of 75.05% and f1-score of 74.89%."
Model Optimasi (Mixed Integer Nonlinear Programming) Untuk Menentukan Struktur Rantai Pasok Pengolahan Bittern Dengan Konsolidasi.,"Ryanto, Zido Fairuz",http://repository.its.ac.id/89061/,"Garam merupakan salah satu komoditas dengan tingkat permintaan yang tinggi di Indonesia. Produksi garam terdiri dari beberapa tahap, salah satunya adalah pemisahan air dari garam. Selama proses pemisahan air dari garam, terdapat air sisa yang menjadi limbah. Air tersebut disebut sebagai air tua atau bittern. Bittern merupakan cairan pekat sebagai limbah hasil dari proses produksi garam. Bittern dibuang ke lingkungan sekitar sehingga dapat mencemari lingkungan, terutama sungai dan laut. Namun, bittern dapat diolah dan dijual kembali karena memiliki beberapa kandungan mineral yang dapat dimanfaatkan. Pengolahan bittern membutuhkan fasilitas pengolahan untuk mengolah bittern berupa bahan mentah menjadi bittern yang siap digunakan dan sebagai perantara antara produsen dan konsumen dengan fungsi sebagai fasilitas pengolahan atau gudang. Skenario yang dapat diimplementasikan adalah sentralisasi, desentralisasi dengan konsolidasi, dan campuran dengan konsolidasi. Permasalahan digambarkan melalui model mixed integer nonlinear programming (MINLP) dan penyelesaian dilakukan dengan metode GRG Nonlinear. Berdasarkan penelitian yang telah dilakukan, skenario desentralisasi dengan konsolidasi lebih layak untuk digunakan pada rantai pasok pengolahan bittern. Perubahan keputusan penggunaan skenario dipengaruhi oleh tingkat permintaan konsumen, biaya pengolahan bittern, dan biaya pembangunan fasilitas pengolahan atau gudang sebagai parameter yang paling berpengaruh.=========================================================================================================Salt is one of the commodities with a high level of demand in Indonesia. Salt production consists of several stages, one of them is the separation of water from salt. During the process, there is residual water that becomes waste. This water is known as old water or bittern. Bittern is a concentrated liquid come from the salt production process. Bitterns are thrown into the environment so it can pollute the environment, especially rivers and seas. However, bittern can be processed and resold because it has some mineral that can be used. Bittern processing requires processing facilities to process bittern in the form of raw materials to be ready to use and as intermediaries between producers and consumers with the function as processing facilities or warehouses. The scenarios that can be implemented are centralized, decentralized with consolidation, and mixed with consolidation. Problems in the bittern processing supply chain are described through a mixed integer nonlinear programming (MINLP) model and the solution is solved with GRG Nonlinear method. Based on the research that has been done, decentralized with consolidation scenario is more suitable to use in the bittern processing supply chain. Changes in decision to use scenarios are influenced by the level of consumer demand, bittern processing cost, and the cost to build processing facilities or warehouses as the most influential parameter."
Semi-Kuantifikasi Electronic Nose Berdasarkan HS-SPME/GC-MS Untuk Klasifikasi Jenis Daging.,"Sabilla, Shoffi Izza",http://repository.its.ac.id/91759/,"Masyarakat membedakan jenis daging secara tradisional dengan cara melihat warna, tekstur, dan mencium aromanya. Namun, untuk membedakan potongan jenis daging menggunakan cara tradisional kurang akurat jika dilakukan oleh manusia karena warna, tekstur, dan aroma memiliki beberapa kesamaan antara jenis daging satu dengan jenis daging yang lainnya sehingga butuh keahlian khusus dan pengalaman. Selain itu, hasil yang didapat berbeda antara satu orang dengan orang yang lainnya.Saat ini, electronic nose (e-nose) telah banyak dikembangkan untuk mengidentifikasi berbagai jenis daging dengan cepat dan akurat dengan biaya produksi yang terjangkau. Namun, hasil dari e-nose tidak dapat digunakan sebagai analisis kuantitatif karena tidak dapat memberikan informasi gas atau volatile organic compound (VOC) dan jumlah kadar dari setiap VOC yang dapat membedakan antara jenis daging. Beberapa penelitian sebelumnya telah mengusulkan semi-kuantifikasi e-nose berdasarkan HS-SPME/GC-MS. Namun, hasil dari semi-kuantifikasi pada penelitian tersebut memiliki nilai eror yang tinggi dan tidak dilakukan klasifikasi kembali dari hasil semi-kuantifikasi.Penelitian ini mengusulkan untuk mengembangkan semi-kuantifikasi e- nose berdasarkan Headspace Solid-Phase Microextraction/Gas Chromatography- Mass Spectrometer (HS-SPME/GC-MS) untuk klasifikasi jenis daging. Metode optimasi hyperparameter klasifikasi berbasis Single-Objective Modified Grey Wolf Optimization Deep Neural Network (SOM-GWO-DNN) dan Multi-Objective M- GWO-DNN (MOM-GWO-DNN) yang diusulkan dapat menemukan hyperparameter klasifikasi yang optimal dan dapat digunakan untuk analisis kualitatif jenis daging pada e-nose dengan akurasi 94,03% dan 95,52%. Metode Ensemble MOM-GWO-DNN strategi one versus one (OVO) berhasil meningkatkan akurasi analisis kualitatif pada e-nose sebesar 97,02%.E-nose yang dikembangkan dapat melakukan semi-kuantifikasi dengan mengestimasi kadar %TIC dari VOC berdasarkan hasil HS-SPME/GC-MS menggunakan metode yang diusulkan yaitu Stacking MOM-GWO-DNNR dengan R2 mendekati sempurna yaitu 0,9845. Hasil estimasi kadar %TIC dari metode Stacking MOM-GWO-DNNR digunakan untuk klasifikasi jenis daging menggunakan metode MOM-GWO-DNN dengan akurasi 100% sehingga masyarakat dapat menggunakan aplikasi semi-kuantifikasi e-nose untuk klasifikasi empat jenis daging dengan efektif, efisien, portabel dan murah."
Perencanaan Jalur Quadcopter dan Penghindaran Rintangan Menggunakan Algoritma Fuzzy RRT.,"Sadida, Tiara Asa",http://repository.its.ac.id/110426/,"Sistem kontrol UAV (Unmanned Aerial Vehicle) merupakan topik penelitian yang sering dikembangkan di bidang penerbangan terutama mengenai perencanaan jalur dan penghindaran rintangan di berbagai sektor, sehingga berbagai metode sering diuji untuk memperoleh hasil optimal. Berdasarkan hal tersebut, diperlukan algoritma yang efektif dan efisien untuk eksplorasi ruang pada UAV. Pada tugas akhir ini, dikembangkan dua metode Rapidly exploring Random Tree (RRT) untuk global path planning dan Fuzzy Control Logic untuk local planning refinement. Kedua metode ini dipilih karena keefektifannya dalam optimalisasi jalur pada ruang tiga dimensi dan kemampuan menyesuaikan jalur dengan keadaan sekitar. Pada tugas akhir ini dirancang simulasi dalam MATLAB yang memungkinkan quadcopter merencanakan jalur, menghindari rintangan, dan mencapai tujuan. Dengan mengombinasikan RRT dan Fuzzy Control Logic, proses eksplorasi ruang tiga dimensi dapat ditingkatkan serta menghasilkan jalur yang lebih baik, sehingga lebih efisien dan mudah diikuti oleh quadcopter. Hasil simulasi menunjukkan bahwa kombinasi RRT dan Fuzzy Control Logic mampu memperbaiki perencanaan jalur untuk quadcopter dengan pengurangan panjang jalur total sebesar 9.73% hingga 14.74% setelah fuzzy refinement, pengurangan nilai kesalahan RMSE sebesar 24.44%, MedAE sebesar 20.81%, dan pengurangan curvature serta deviasi jalurnya. ======================================================================================================================================The UAV (Unmanned Aerial Vehicle) control system is a frequently developed research topic in aviation, especially regarding path planning and obstacle avoidance in various sectors. Effective and efficient algorithms are needed for UAV space exploration. In this final project, two methods are developed: Rapidly exploring Random Tree (RRT) for global path planning and Fuzzy Control for local planning refinement. These methods were chosen for their effectiveness in optimizing paths in three dimensional space and adapting to surroundings. Therefore, a MATLAB simulation will be designed, enabling the quadcopter to plan paths, avoid obstacles, and reach destinations. Combining RRT and Fuzzy Control Logic aims to enhance three-dimensional space exploration and produce a better path, making it more efficient and easier for the quadcopter to follow. Simulation results show that the combination of RRT and Fuzzy Control Logic improves path planning for the quadcopter, with a reduction in total path length of 9.73% to 14.74% after fuzzy refinement, a reduction in RMSE error value by 24.44%, MedAE of 20.81%, and a reduction in curvature and path deviation."
Pelabelan dan Pembuatan Model Image Captioning Menggunakan Deep Learning.,"Safitri, Wardatul Amalia",http://repository.its.ac.id/118175/,"Kerja praktik ini dilakukan di Laboratorium Komputasi Cerdas dan Visi (KCV) Departemen Teknik Informatika Institut Teknologi Sepuluh Nopember (ITS). Kegiatan yang dilakukan memiliki tujuan untuk menghasilkan model image captioning dengan memanfaatkan deep learning. Kegiatan kerja praktik dimulai dengan membuat dataset citra trotoar dan lingkungan ITS beserta pelabelan atau pemberian deskripsi di setiap citra. Selanjutnya, dataset citra yang sudah diberi label akan diolah menjadi model image captioning dengan beberapa skenario implementasi deep learning. Metode deep learning yang diimplementasikan dalam kerja praktik ini meliputi LSTM, CNN, dan GRU. Hasil pengembangan model akan dibandingkan performanya menggunakan parameter BLEU Score dan ROUGE. Hasil evaluasi menunjukkan bahwa Dataset 1 menghasilkan performa terbaik dengan BLEU-1 51.49% dan ROUGE-1 40.05%. Metode CNN memberikan hasil terbaik dengan BLEU-1 25.56% dan ROUGE-1 23.44%. Sementara itu, fungsi aktivasi Relu memberikan performa terbaik pada hyperparameter tuning dengan BLEU-1 23.61% dan ROUGE-1 22.37%.============================================================================================================================This project was carried out at the Komputasi Cerdas dan Visi (KCV) Laboratory, Department of Informatics Engineering, Institut Teknologi Sepuluh Nopember (ITS). The activities carried out have the aim of producing an image captioning model by utilizing deep learning. This project begin with creating a dataset of images of ITS pavements and environments along with labeling or giving descriptions in each image. Furthermore, the labeled image dataset will be processed into an image captioning model with several deep learning implementation scenarios. The deep learning methods implemented in this practical work include LSTM, CNN, and GRU. The results of the model development will be compared using the BLEU Score and ROUGE parameters. The evaluation results show that Dataset 1 produces the best performance with BLEU-1 51.49% and ROUGE-1 40.05%. CNN method gives the best result with BLEU-1 25.56% and ROUGE-1 23.44%. Meanwhile, the Relu activation function gives the best performance in hyperparameter tuning with BLEU-1 23.61% and ROUGE-1 22.37%."
Penerapan Artificial Neural Network Untuk Prediksi Energi Listrik Jangka Menengah Menggunakan Backpropagation.,"Sakhis, Badri Ainur",http://repository.its.ac.id/119006/,"Peningkatan kebutuhan energi listrik yang terus berkembang menuntut adanya sistem prediksi untuk mendukung perencanaan dan pengelolaan sumber daya energi. Penelitian ini bertujuan untuk menerapkan metode Artificial Neural Network (ANN) dengan algoritma backpropagation dalam memprediksi konsumsi energi listrik jangka menengah. Metode ini dipilih karena kemampuannya dalam menangkap pola kompleks dan hubungan non-linear dalam data historis konsumsi listrik. Oleh karena itu, penting untuk memilih metode yang tepat untuk melakukan prediksi. Untuk menguji tingkat akurasi hasil peramalan konsumsi energi listrik menggunakan perhitungan nilai Mean Absolute Error (MAE). Tujuan penelitian ini adalah menganalisis akurasi hasil peramalan dengan algoritma backpropagation. Arsitektur ANN pada penelitian ini menggunakan 36 input layer, 2 hidden layer dimana masing masing hidden layer sebanyak 10 neuron, dan 1 output layer yang merupakan total energi yang dikonsumsi. Pada penelitian ini, melakukan beberapa pengujian model dan mengatur parameter-parameter ANN setiap pengujian. Parameter tersebut meliputi banyaknya hidden layer yang digunakan, learning rate, dan epoch. Optimizer yang digunakan untuk membangun model yaitu Adaptive Moment Estimation (Adam). Hasil penelitian menyatakan bahwa dari beberapa pengujian model terdapat nilai persentase error terendah dan persentase akurasi atau valid tertinggi. Pengujian terbaik menghasilkan error sebesar 5,6%, dengan tingkat akurasi atau validasi sebesar 94,4%. Percobaan prediksi kedepannya berdasarkan input tanggal yang ditentukan menghasilkan persentase error sebesar 43% dan persentase valid sebesar 57%.=================================================================================================================================The growing demand for electrical energy requires a prediction system to support the planning and management of energy resources. This research aims to apply the Artificial Neural Network (ANN) method with the backpropagation algorithm in predicting medium-term electrical energy consumption. This method was chosen due to its ability to capture complex patterns and non-linear relationships in historical electricity consumption data. Therefore, it is important to choose the right method for prediction. To test the accuracy of electric energy consumption forecasting results using the calculation of the Mean Absolute Error (MAE) value. The purpose of this research is to analyze the accuracy of forecasting results with the backpropagation algorithm. The ANN architecture in this study uses 36 input layers, 2 hidden layers where each hidden layer is 10 neurons, and 1 output layer which is the total energy consumed. In this research, several model tests were conducted and ANN parameters were set for each test. These parameters include the number of hidden layers used, learning rate, and epoch. The optimizer used to build the model is Adaptive Moment Estimation (Adam). The results state that from several model tests there is the lowest percentage error value and the highest percentage of accuracy or validity. The best test produces an error of 5,6%, with an accuracy or validation rate of 94,4%. Future prediction experiments based on the specified date input resulted in an error percentage of 43% and a valid percentage of 57%."
Model Optimasi Gabungan Pada Manajemen Persediaan Suku Cadang Dan Perencanaan Perawatan Dengan Mempertimbangkan Ketidakpastian Kegagalan.,"Salsabila, Nabila Yuraisyah",http://repository.its.ac.id/79796/,"Suku cadang pada umumnya termasuk dalam kelompok barang kelas C, hal ini disebabkan karena biaya dan permintaan yang rendah dibandingkan dengan barang-barang lainnya. Tetapi, ketersediaan suku cadang sangat penting untukmendukung perawatan. Salah satu masalah utama dalam manajemen persediaan suku cadang adalah meminimalkan jumlah barang yang tersimpan dalam gudang dengan mengoptimalkan parameter persediaan. Teknik optimasi pada umumnya digunakan untuk menyeimbangkan biaya persediaan dan ketersediaan suku cadang. Penelitian ini mengusulkan model optimasi gabungan dari manajemen persediaan suku cadang multi-periode multi-item dan perencanaan perawatan dengan mempertimbangkan ketidakpastian kegagalan. Pertama, model Mixed Integer Nonlinear Programing (MINLP) persediaan suku cadang diformulasikan dengan kebijakan (s, S) dengan tinjauan berkala setiap T periode. Kedua, model persediaan suku cadang ini kemudian digabungkan dengan model perencanaan pemeliharaan berkala. Ketidakpastian kegagalan dimodelkan berdasarkan distribusi probabilitas normal. Pendekatan optimasi eksak akan membutuhkan waktu komputasi yang lama untuk menyelesaikan model gabungan ini dalam skala besar. Sehingga, pendekatan metaheuristik dengan Genetic Algorithm (GA) dikembangkan untuk menyelesaikan permasalahan ini dalam skala besar. Ketiga, analisis komputasi dilakukan pada beberapa contoh dan studi kasus untuk mengevaluasi efektivitas dan efisiensi pendekatan GA yang diusulkan. Berdasarkan hasil simulasi, GA dapat menyelesaikan permasalahan berskala besar. Total biaya pada contoh studi kasus dapat menurun hingga 17,9% dibandingkan dengan kebijakan awal.============================================================================================Spare parts are often considered as Class C items, because of their low cost and low demand among the stocked items, but the availability of spare parts is essential to support maintenance requirements. Optimizing inventory parameters is the main problem of spare parts management to maintain a small number of SKUs kept in a store, and optimization techniques are commonly used to balance inventory cost and spare parts availability. Thus, this research proposes a joint optimization model of single-item multi-period spare parts inventory management and planned maintenance under uncertain failures. We present a Mixed Integer Nonlinear Programming (MINLP) formulation of the inventory optimization model under (s, S) policy with T periods of the order interval. Second, we combine this formulation with the predictive maintenance interval, representing the uncertain failures under predefined distribution. Since the model is nonlinear and stochastic, it is difficult to use exact methods to tackle it. Therefore, we combine the previously introduced MINLP formulation with a metaheuristic approach to solve the problem. Lastly, we perform a computational study on some instances and a real case study to demonstrate the proposed approach’s effectiveness and efficiency. Based on the numerical experiment results, the proposed GA performs efficiently in large scale problem and the total cost of the real case study decreased by 17.9% compared to the current policy."
Sistem Deteksi Ekspresi Toileting Pada Anak Penyandang Multidisabilitas Berdasarkan Ekstraksi Fitur Menggunakan Support Vector Machine.,"Siregar, Salsabiela Khairunnisa",http://repository.its.ac.id/113488/,"Anak-anak dengan disabilitas sering menghadapi kesulitan dalam mengekspresikan keinginan mereka, termasuk saat ingin menggunakan fasilitas toilet. Hambatan ini dapat menyebabkan terjadinya masalah kesehatan ataupun masalah lainnya pada anak, seperti perilaku buang air tidak pada tempatnya. Melalui toilet training, anak akan belajar bagaimana mereka mengendalikan keinginan untuk buang air. Keberhasilan toilet training tergantung pada cara pengajaran bertahap sesuai dengan kemampuan anak. Oleh karena itu, penelitian ini bertujuan untuk menemukan parameter toileting berdasarkan ekspresi wajah anak disabilitas dengan menggunakan kamera. Kamera diposisikan di depan subjek selama kegiatan sekolah berlangsung untuk merekam perubahan ekspresi. Hasil citra akuisisi akan dipilih untuk dibuat dataset berdasarkan perubahan ekspresi yang muncul pada saat kondisi toileting. Ekstraksi fitur dilakukan dari 51 titik landmark wajah untuk mendapatkan nilai sudut, jarak, kemiringan antar titik landmark elemen wajah. Dataset TOP5 dan TOP10 dibuat menggunakan fitur-fitur dengan nilai korelasi pearson tertinggi. Proses klasifikasi menggunakan Support Vector Machine (SVM) menunjukkan bahwa model dengan dataset TOP5 mencapai akurasi tertinggi sebesar 96% dengan kombinasi parameter C=25 dan γ=0.001, menggunakan cross validation 5-folds. Model ini menunjukkan kinerja yang baik dengan nilai precision, recall, dan F1-score yang tinggi. Sistem deteksi ekspresi toileting ini memiliki beberapa kendala pada proses pengambilan data yang membutuhkan banyak pengondisian subjek. Selain itu, terdapat beberapa kesalahan klasifikasi yang perlu diatasi untuk mendapatkan hasil yang lebih baik. Untuk meningkatkan kemampuan dan generalisasi sistem dalam mendeteksi ekspresi toileting, diperlukan dilakukan penambahan jumlah dan variasi dataset dengan melibatkan subjek dari berbagai jenis disabilitas.=========================================================================================Children with disabilities often face challenges in expressing their needs, including when they wish to use toilet facilities. These barriers can lead to health issues or other problems, such as inappropriate toileting behaviors. Toilet training helps children learn to control their urges to urinate or defecate, and its success relies on gradual teaching methods tailored to the child`s abilities. Therefore, this study aims to identify toileting parameters based on the facial expressions of children with disabilities using a camera system. The camera is positioned in front of the subjects during school activities to capture expression changes. The acquired images are selected to create a dataset based on the expression changes observed during toileting events. Feature extraction is performed using 51 facial landmark points to obtain angles, distances, and inclinations between these points. TOP5 and TOP10 datasets are generated using features with the highest Pearson correlation values. The classification process using Support Vector Machine (SVM) demonstrated that the model with the TOP5 dataset achieved the highest accuracy of 96%, with parameter settings of C=25 and γ=0.001, utilizing 5-fold cross validation. This model exhibits robust performance with high precision, recall, and F1-score metrics. Despite this, the toileting expression detection system faces challenges in data collection, such as the extensive conditioning required for data collection and some misclassification errors that need to be addressed for improved results. To enhance the system`s capability and generalization in detecting toileting expressions, it is essential to increase the number and diversity of datasets by involving subjects with various types of disabilities."
Deteksi Kecacatan Perangkat Lunak Menggunakan Support Vector Machine Teroptimasi Berbasis Grey Wolf Optimizer dan Random Walk.,"Siswantoro, Muhammad Zain Fawwaz Nuruddin",http://repository.its.ac.id/118354/,"Deteksi kecacatan perangkat lunak merupakan proses penting dalam pengembangan perangkat lunak untuk mengidentifikasi sebagai bug sehingga aplikasi dapat berfungsi tanpa kesalahan. Namun, proses ini sering memakan biaya dan waktu. Penelitian ini mengusulkan penggunaan Support Vector Machine (SVM) yang hyperparameter-nya dioptimasi menggunakan Grey Wolf Optimizer (GWO) yang dipadukan dengan Random Walk (RW). Selain itu penelitian ini juga menggunakan Principal Component Analysis (PCA) sebagai pengurangan dimensi fitur dan juga oversampling dengan Synthetic Minority Over-sampling Technique (SMOTE) untuk menyeimbangkan dataset. Hasil dari penelitian ini menunjukan bahwa GWO yang dipadukan dengan RW mampu meningkatkan akurasi SVM dalam mengklasifikasi deteksi kecacatan perangkat lunak dibandingkan dengan optimasi lain, dengan akurasi berkisar antara 76,26% - 98,21% dan rata-rata akurasi 87,03% pada berbagai dataset, sehingga membuktikan efektivitasnya dalam deteksi kecacatan perangkat lunak.=================================================================================================================================Software defect detection is an important process in software development to identify as a bug so that the application can function without errors. However, this process is often costly and time consuming. This study proposes the use of Support Vector Machine (SVM) whose hyperparameters are optimized using Grey Wolf Optimizer (GWO) combined with Random Walk (RW). In addition, this study also uses Principal Component Analysis (PCA) as a feature dimension reduction and also oversampling with Synthetic Minority Over-sampling Technique (SMOTE) to balance the dataset. The results of this study show that GWO combined with RW is able to increase the accuracy of SVM in classifying software defect detection compared to other optimizations, with an accuracy ranging from 76.26% - 98.21% and an average accuracy of 87.03% on various datasets, thus proving its effectiveness in software defect detection."
SEGMENTASI DAN EKSTRAKSI CIRI CITRA SEL DARAH PUTIH UNTUK KLASIFIKASI LEUKEMIA AKUT.,"Siti Fatonah, Nenden",http://repository.its.ac.id/77972/,"Penyakit leukemia adalah penyakit yang sangat berbahaya dan mematikan. Penyakit leukemia disebabkan oleh gagalnya kematangan sel-sel yang dihasilkan oleh sumsum tulang dan menyebar keseluruh tubuh. Perhitungan dan analisa sel darah putih saat ini hanya bisa dilakukan oleh ahli hematologi atau dokter di laboratorium dan hasil diagnosa bersifat subyektif berdasarkan pengalaman dokter. Perhitungan dan analisa sel darah putih secara otomatis sangat diperlukan agar lebih mudah dalam membantu dokter melakukan diagnosa penyakit misalnya leukemia. Leukemia akut merupakan penyakit leukemia yang paling banyak diderita pasien. Pengembangan sistem deteksi jenis leukemia akut secara otomatis berdasarkan citra mikroskopis dibagi menjadi tiga tahapan yaitu segmentasi sel darah putih, ekstraksi ciri sel darah putih, dan klasifikasi. Kendala pertama pada segmentasi sel darah putih adalah variasi staining (pewarnaan) pada citra mikroskopis sel darah sehingga perlu metode segmentasi yang bisa menangani permasalahan tersebut. Kendala kedua adalah segmentasi multi sel darah putih yaitu adanya sel-sel yang bersentuhan sehingga perlu dikembangkan metode pemisahan sel yang lebih baik agar perhitungan jumlah sel serta hasil ekstraksi ciri lebih akurat untuk proses klasifikasi. Metode pemisahan sel-sel bersentuhan yang sudah dilakukan penelitian-penelitian sebelumnya masih terkendala adanya oversegmen, undersegmen, dan estimasi kontur sel darah putih yang kurang akurat.Penelitian ini mengusulkan perbaikan metode segmentasi sel darah putih dan melakukan ekstraksi ciri pada citra mikroskopik sel darah untuk klasifikasi jenis leukemia akut. Untuk mendapatkan hasil klasifikasi yang akurat, metode segmentasi sel darah putih yang dikembangkan harus mendapatkan area sel darah putih dengan baik khususnya sel-sel yang bersentuhan sehingga pada tahapan ekstraksi ciri dapat menghasilkan ciri yang merepresentasikan karakteristik sel darah putih dengan baik. Tahapan segmentasi sel darah putih meliputi segmentasi area sel darah putih yaitu area nukleus dan sitoplasma, deteksi sel bersentuhan dan perhitungan jumlah sel, serta estimasi kontur hasil pemisahan sel yang bersentuhan. Sedangkan tahapan ekstraksi ciri adalah ekstraksi ciri warna, bentuk, dan tekstur pada area nukleus dan sitoplasma sel darah putih. Tahapan terakhir melakukan klasifikasi untuk mendapatkan jenis leukemia akut Acute Lymphocytic Leukemia (ALL) yang mempunyai tiga tipe yaitu L1, L2, dan L3. Dataset yang digunakan adalah data pada citra mikroskopis apusan darah tepi ALL yang disediakan oleh Labati, dkk dan dikumpulkan oleh pakar di Pusat Penelitian Tettamanti, Tettamanti Research. Serta menggunakan data citra bone marrow jenis Acute Lymphocytic Leukemia (ALL) dan Acute Myelotic Leukemia (AML) dari RSUD Dr. Soetomo Surabaya. Dari hasil ujicoba yang sudah dilakukan menunjukkan metode segmentasi sel darah putih yang diusulkan meliputi deteksi sel bersentuhan dan estimasi kontur single sel lebih baik dibandingkan metode sebelumnya. Metode segmentasi sel darah putih yang diusulkan kemudian digunakan untuk klasifikasi jenis ALL menghasilkan sensitivitas yang lebih tinggi dibandingkan metode lainnya."
Prediksi Drop Pressure Dan Over Pressure Pada Jaringan Pipa Distribusi Gas Bumi Menggunakan Machine Learning.,"Supriatna, Reza Yudistira",http://repository.its.ac.id/117602/,"Menjaga stabilitas distribusi gas bumi sangat penting untuk memastikan pasokan energi yang dapat diandalkan dan mendukung tujuan energi yang berkelanjutan. Pemantauan dan simulasi secara real time sangat penting untuk mengelola gangguan pasokan sehingga menyebabkan fluktuasi tekanan yang dapat membahayakan jika tidak segera ditangani, serta dapat menyebabkan penurunan produksi sehingga berdampak kepada revenue perusahaan dan risiko keselamatan pada peralatan. Kondisi tekanan over pressure dapat mendorong sistem untuk melampaui batas operasional yang aman, sehingga mengancam infrastruktur dan personel yang berada di sekitar peralatan. Menstabilkan jaringan distribusi tidak hanya mengatasi masalah keselamatan tetapi juga meningkatkan efisiensi energi, mengurangi limbah, dan mendukung upaya keberlanjutan. Studi ini mengevaluasi empat model prediktif ARIMAX, SARIMAX, random forest regression, dan linear regression untuk mengurangi risiko dan meningkatkan pengambilan keputusan operasional dalam distribusi gas alam. Model-model tersebut dinilai dengan menggunakan metrik kinerja utama, termasuk Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), dan Mean Absolute Percentage Error (MAPE), untuk mengidentifikasi metode yang paling akurat dan dapat diandalkan untuk prediksi waktu nyata. Mengingat risiko operasional dan keuangan yang terkait dengan ketidakseimbangan pasokan, memilih model prediksi yang tepat sangat penting untuk menjaga stabilitas jaringan dan meminimalkan potensi kerugian. Temuan ini menunjukkan bahwa random forest regression memberikan akurasi tertinggi dalam pengujian di dunia nyata dimana memiliki nilai MAPE 2.264, menjadikannya model yang paling cocok untuk memprediksi fluktuasi tekanan yang kompleks. Sebaliknya, linear regression kurang efektif karena variabilitasnya yang lebih tinggi ketika menangani kompleksitas manajemen tekanan memiliki nilai MAPE sebesar 31.714. Pada akhirnya, memilih model prediktif yang tepat adalah kunci untuk memastikan stabilitas jaringan, mengurangi risiko, dan mempromosikan praktik energi yang berkelanjutan."
Entity Matching Menggunakan Large Language Model dan Knowledge Graph untuk Mencari Redundansi Fitur dalam Software Specification.,"Syaifudin, Mohamad Fahmi",http://repository.its.ac.id/117535/,"Dalam Software Development Lifecycle (SDLC), berbagai dokumentasi software pendukung dihasilkan, salah satunya adalah dokumen software specification, yang berisi deskripsi fitur yang dibangun. Permasalahan umum dalam pengembangan software adalah munculnya requirement baru yang mirip dengan fungsionalitas modul yang sudah ada. Masalah ini dapat diatasi dengan memanfaatkan entity matching (EM) untuk mendeteksi redundansi antar fitur dalam software atau modul yang berbeda. EM bertujuan untuk menentukan apakah dua entitas yang berbeda mengacu pada entitas yang sama. Pendekatan EM tradisional umumnya menggunakan rule-based, deep learning, atau machine learning. Penelitian ini mengusulkan pendekatan entity matching menggunakan Large Language Model (LLM) dan Knowledge Graph (KG). Dataset yang digunakan dalam penelitian ini antara lain dari dokumen panduan user Odoo, dokumen panduan Zoho Commerce, dan dokumen public user requirement. Entitas dan relasi diekstrak dan dirubah kedalam dimensi vector melalui proses knowledge embedding. Neo4j digunakan untuk menyimpan KG dan memanfaatkan vektor index mencari entitas atau relasi yang relevan untuk EM. Penelitian ini menggunakan metode sentence-based dan graph-based dalam EM. Sentence-based matching memiliki F1-score 0.762, lebih tinggi dibandingkan metode graph-based dengan F1-score maksimum 0.471. Namun, graph-based matching unggul pada Mean Reciprocal Rank dengan nilai 0.660 dibandingkan sentence-based yang hanya 0.477. Keunggulan lain dari graph-based adalah ketidakbergantungannya pada jenis word embedding, yang ditunjukkan oleh konsistensi F1-score dalam rentang 0.4 sampai 0.5 untuk berbagai variasi model embedding.==============================================================================================================================In the Software Development Lifecycle (SDLC), various supporting software documentation is produced, one of which is the software specification document that contains a description of the features being developed. A common issue in software development is the emergence of new requirements that are similar to the functionalities of existing modules. This can be addressed by leveraging entity matching (EM) to identify redundancies between features in different software or modules. EM aims to determine whether two different entities refer to the same entity. Traditional EM approaches generally use rule-based, deep learning, or machine learning methods. This study proposes an entity matching approach using a Large Language Model (LLM) and a Knowledge Graph (KG). The datasets used in this research include user guide documents from Odoo, Zoho Commerce user guide documents, and public user requirement documents. Entities and relationships are extracted and transformed into vector dimensions through a knowledge embedding process. Neo4j is used to store the KG and to utilize vector indexing for finding relevant entities or relationships for EM. This research employs both sentence-based and graph-based methods in EM. Sentence-based matching achieved an F1-score of 0.762, which is higher than the graph-based method with a maximum F1-score of 0.471. However, graph-based matching outperformed in Mean Reciprocal Rank (MRR) with a score of 0.660 compared to 0.477 for the sentence-based approach. Another advantage of the graph-based method is its independence from the type of word embedding, as indicated by the consistent F1-score range of 0.4 to 0.5 across various embedding model variations."
Prediksi Tipe Kepribadian Berdasaran Myers-Briggs Type Indicator Menggunakan Metode Klasifikasi Kolmogorov-Arnold Networks.,"Syamsudin, Afifah Nur Sabrina",http://repository.its.ac.id/117237/,"Pembahasan mengenai prediksi tipe kepribadian di media sosial telah meningkat pesat dalam beberapa tahun terakhir. Salah satu tes kepribadian yang ramai diperbincangkan adalah Myers-Briggs Type Indicator (MBTI). MBTI merupakan sebuah metode penilaian kepribadian yang mengklasifikasikan individu ke dalam salah satu dari 16 tipe kepribadian berdasarkan empat dimensi utama: Ekstroversi-Introversi, Sensing-Intuition, Thinking-Feeling, dan Judging-Perceiving. Terdapat banyak cara dalam memprediksi kepribadian seseorang salah satunya melalui analisis tipe kepribadian berdasarkan tulisan di media sosial, metode yang umum digunakan melibatkan beberapa tahapan analisis teks dan pemrosesan bahasa. Pada penelitian ini akan dipelajari proses dan kinerja dari model klasifikasi KAN. Metode klasifikasi baru ini diharapkan dapat digunakan sebagai cara untuk mengkategorikan teks ke dalam tipe kepribadian yang sesuai. Hasil dari penelitian ini nantinya diharapkan dapat mengetahui penggunaan kata pada unggahan media sosial terhadap tipe kepribadian seseorang serta kinerja model klasifikasi dalam mengenali tipe kepribadian berdasarkan aktivitas media sosial. Hasil dari uji coba pada implementasi metode KAN mendapatkan akurasi data uji senilai 0,2545.===================================================================================================================================Discussions about personality type prediction on social media have increased rapidly in recent years. One of the most discussed personality tests is the Myers-Briggs Type Indicator (MBTI). MBTI is a personality assessment method that classifies individuals into one of 16 personality types based on four main dimensions: Extroversion-Introversion, Sensing-Intuition, Thinking-Feeling, and Judging-Perceiving. There are many ways to predict a person's personality, one of which is through analyzing personality types based on social media posts, a commonly used method involving several stages of text analysis and language processing. In this research, the process and performance of the KAN classification model will be explained. This new classification method is expected to be used to categorize text into the appropriate personality type. The results of this research are expected to determine the use of words in social media posts on a person's personality type and the performance of the classification model in recognizing personality types based on social media activities. The results of the trial on the KAN method show that the implementation gets a test data metric accuracy of 0.2545."
Perancangan Penyelesaian Kinematika Balik Pada Posisi Dan Orientasi End Effector Robot Open Manipulator-X Dengan Metode Neural Network.,"Syauqi, Muhammad Yavi Marsa",http://repository.its.ac.id/98932/,"Robot manipulator merupakan bukti dari perkembangan teknologi otomasi di era 4.0 saat ini, Robot yang memiliki 4 degree of freedom (DoF) dalam pergerakannya merupakan salah satu sistem yang biasa digunakan untuk mengefisiensi dan mengurangi resiko kecelakaan pada dunia Industri. Namun, pada penyelesaian kinematika balik robot manipulator terdapat permasalahan dimana terdapat multi solution dalam mendapatkan nilai sudut keluaran pada setiap joint. Oleh sebab itu, Penelitian ini bertujuan untuk menyelesaikan permasalahan kinematika balik tersebut menggunakan metode neural network menggunakan Robot Open Manipulator-X. Penelitian ini dilakukan dengan pengambilan dataset dengan kinematika maju, perancangan model neural network dengan melakukan pengujian pada jumlah neuron, hidden layer, dan learning rate, serta pembuktian dengan pengujian titik dari hasil neural network pada robot melalui simulasi pada gazebo dan real plant. Hasil dari peneletian ini yaitu metode neural network dapat menemukan single solution sebagai penyelesaian kinematika balik untuk Robot Open Manipulator-X dengan rata-rata error posisi dan orientasi sebesar (0.36 ± 0.06) cm dan (3.224±2.942)° pada simulasi, serta (0.37 ± 0.06) cm dan (3.224±2.942)° pada real plant.====================================================================================================================================Manipulator robot is evidence of the technological advancement in automation in the current era of Industry 4.0. A robot with 4 degrees of freedom (DoF) in its movement is commonly used to improve efficiency and reduce the risk of accidents in the industrial world. However, there is a problem in solving the inverse kinematics of robot manipulators where multiple solutions exist in obtaining the angle values for each joint. Therefore, this research aims to solve the inverse kinematics problem using a neural network method with the Robot Open Manipulator-X. The research involves collecting a dataset with forward kinematics, designing a neural network model by testing various configurations such as the number of neurons, hidden layers, and learning rate, and validating the results through point testing of the neural network's output on the robot using simulations in Gazebo and real plant environments. The result of this research is that the neural network method can find a single solution as the inverse kinematics solution for the Robot Open Manipulator-X with an average position error of (0.36 ± 0.06) cm and orientation error of (3.224±2.942)° in simulation, as well as (0.37 ± 0.06) cm and (3.224±2.942)° in the real plant."
Identifikasi Normality Shift dalam Deteksi Anomali dengan Pendekatan Uji Distribusi.,"Talasari, Resky Ayu Dewi",http://repository.its.ac.id/116720/,"Seiring dengan pesatnya perkembangan teknologi jaringan dan internet, serta meningkatnya ancaman yang beragam dan sulit dideteksi, deteksi anomali menjadi sangat penting, event logs dapat digunakan untuk mencatat setiap aktivitas yang terjadi dan digunakan untuk mendeteksi anomali. Salah satu pendekatan untuk mendeteksi anomali pada event logs adalah berbasis rekonstruksi menggunakan deep learning dengan mempelajari pola normal data, namun tantangannya terletak pada normality shift, yaitu perubahan pola normal data yang dipelajari model. Penelitian ini berfokus pada deteksi normality shift dalam data Windows Event Logs dan Sysmon, menggunakan uji distribusi Jensen Shannon Divergence (JSD) dan Hellinger Distance (HD), hasil penelitian menunjukkan bahwa HD mampu mendeteksi distribution shift dengan baik pada skenario distribution shift kecil dan besar. Proses filtering data dapat mempengaruhi kinerja model deteksi anomali pada skenario distribution shift kecil dengan peningkatan 66% pada precision, 63% pada recall, 40% pada f1-Score dan AUC Score. Namun, model deteksi anomali tidak mampu menghadapi skenario distribution shift besar dengan penurunan performa pada precision, recall, f1-score, dan AUC score. Karena proses filtering data yaitu proses mengidentifikasi data treatment yang berada dalam rentang batas atas dan bawah data control sebagai normal sehingga membuat model deteksi anomali bergantung pada pola normalitas awal pada data control (data training).=================================================================================================================================Along with the rapid development of network and internet technology, as well as the increase in diverse and difficult-to-detect threats, anomaly detection is very important, event logs can be used to record every activity that occurs and used to detect anomalies. One approach to detect anomalies in event logs is reconstruction-based using deep learning by learning the normal pattern of the data, but the challenge lies in normality shift, which is the change in the normal pattern of the data that the model learns. This research focuses on normality shift detection in Windows Event Logs and Sysmon data, using Jensen Shannon Divergence (JSD) and Hellinger Distance (HD) distribution tests, the results show that HD is able to detect distribution shifts well in small and large distribution shift scenarios. The data filtering process can affect the performance of the anomaly detection model in the small distribution shift scenario with an increase of 66% in precision, 63% in recall, 40% in f1-Score and AUC Score.However, the anomaly detection model is not able to deal with large distribution shift scenarios with decreased performance in precision, recall, f1-score, and AUC score. Due to the data filtering process, which is the process of identifying treatment data that is within the upper and lower limits of the control data as normal, the anomaly detection model depends on the initial normality pattern in the control data (training data)."
Klasifikasi Citra Hasil Endoskopi Pada Sistem Gastrointestinal Bagian Bawah Menggunakan Metode Transfer Learning dengan Convolutional Neural Network.,"Tambunan, Rivaldo Panangian",http://repository.its.ac.id/117621/,"Sistem gastrointestinal sering menjadi perhatian utama dalam penelitian medis karena berbagai gangguan, seperti polip dan kolitis ulseratif, yang jika tidak segera ditangani dapat berkembang menjadi kondisi yang serius. Endoskopi merupakan metode utama yang digunakan untuk mendeteksi penyakit ini, meskipun prosesnya sering memakan waktu dan membutuhkan tenaga ahli yang signifikan. Penelitian ini bertujuan untuk klasifikasi citra hasil endoskopi dengan memanfaatkan metode Transfer Learning berbasis Convolutional Neural Network (CNN). Dataset HyperKvasir dan GastroVision digunakan sebagai dataset citra, terdapat tiga kelas : polip, kolitis ulseratif, dan mukosa normal. Model pre-trained seperti VGG19, ResNet101V2, dan InceptionV3 akan digunakan sebagai ekstraksi fitur dan menambahkan fully connected layer untuk melakukan klasifikasi kelas polip, kolitis ulseratif, dan mukosa normal. Dalam penggunaan model pre-trained tersebut akan menggunakan teknik finetuning pada layer awal setiap model pre-trained. Hasil eksperimen menunjukkan bahwa model pre-trained ResNet101V2 memberikan hasil terbaik dengan tingkat akurasi, recall, dan F1-score yang tinggi. Dengan Hasil akurasi sebesar 0.9881, loss 0.0687, Recall 0.9881, Presicion 0.9882, dan F1-Score 0.9881. Penelitian ini diharapkan dapat berkontribusi dalam mendukung deteksi dini penyakit gastrointestinal secara lebih cepat dan efisien, sekaligus mempermudah proses diagnosis di bidang medis.==============================================================================================================================The gastrointestinal system is a major focus in medical research due to various disorders, such as polyps and ulcerative colitis, which, if left untreated, can develop into severe conditions. Endoscopy is the primary method used to detect these diseases, although the process often requires significant time and specialized expertise. This study aims to classify endoscopic images using a Transfer Learning approach based on Convolutional Neural Networks (CNN). The HyperKvasir and GastroVision datasets were utilized, consisting of three main classes: polyps, ulcerative colitis, and normal mucosa. Pre-trained models such as VGG19, ResNet101V2, and InceptionV3 were employed for feature extraction, with the addition of fully connected layers for classifying the three aforementioned categories. Fine-tuning techniques were applied to the initial layers of each pre-trained model to optimize performance. Experimental results demonstrated that the ResNet101V2 pre-trained model achieved the best performance, with high accuracy, recall, and F1-score. The final results include an accuracy of 0.9881, loss of 0.0687, recall of 0.9881, precision of 0.9882, and F1-score of 0.9881.This research is expected to contribute to the early detection of gastrointestinal diseases more efficiently and effectively, thereby facilitating the diagnostic process in the medical field."
Prediksi Kejadian Luar Biasa Pada Kasus Demam Berdarah Dengue Di Kabupaten Malang Menggunakan Support Vector Machines - Flower Pollination Algorithm.,"Tendio, Yusnardo",http://repository.its.ac.id/78859/,"Penyakit demam berdarah dengue (DBD) merupakan salah satu penyakit berbahaya yang menjadi sumber masalah kesehatan bagi masyarakat Indonesia. Jumlah penderita DBD mengalami peningkatan seiring berjalannya waktu. KLB pada kasus DBD dapat diprediksi dengan membuat model prediksi menggunakan keterkaitan antar variabel. Beberapa variabel yang mempengaruhi hasil prediksi antara lain adalah curah hujan, suhu, kecepatan angin, dan kelembaban. Dalam tugas akhir ini, data jumlah kasus DBD per kecamatan diperoleh dari Dinas Kesehatan Kabupaten Malang, sedangkan data curah hujan, suhu, kecepatan angin, dan kelembaban diperoleh dari Badan Meteorologi, Klimatologi, dan Geofisika (BMKG). Dalam Tugas Akhir ini, sebuah model prediksi KLB untuk kasus DBD dibangun menggunakan gabungan metode Support Vector Machine dan Flower Pollination Algorithm (SVM-FPA). Metode SVM digunakan untuk memisahkan kasus yang termasuk dalam kelas KLB dan kelas non-KLB, sedang FPA digunakan untuk memperoleh nilai parameter yang optimal dalam SVM. Hasil uji coba menunjukkan bahwa nilai parameter opti-mal yang dihasilkan oleh FPA berupa kombinasi nilai cost dan gamma berturut-turut sebesar 2.829,0587 dan 0,002801. Kombinasi kedua nilai paremeter ini mem-berikan hasil prediksi SVM terbaik untuk data validasi, di mana berturut-turut diperoleh nilai akurasi, recall, dan presisi sebesar 90,34%, 89,11%, dan 91,32%. Dengan menggunakan nilai parameter yang sama, hasil prediksi untuk data tes berturut-turut diperoleh nilai akurasi, recall, dan presisi sebesar 59,65%, 88,37%, dan 36,53%. Kata Kunci: demam berdarah, prediksi kejadian luar biasa, support vector machines, algoritma penyerbukan bunga.======================================================================================================Dengue fever (DF) is a dangerous disease that causes health problems for the people. The number of DF cases increases as time goes by. DF Outbreak can be predicted by making prediction models using interrelationships among variables. Some relevant variables that influence the results of predictions are rainfall, temperature, wind speed, and humidity. In this final project, the number of dengue cases per district data are obtained from the Public Health Office of Malang Region, while rainfall, temperature, wind speed, and humidity data are obtained from the Meteorology, Climatology and Geophysics Agency. In this Final Project, an outbreak prediction model for DF cases is built using a combination of Support Vector Machine and Flower Pollination Algorithm (SVM-FPA). The SVM method is used to classify cases that are included in the outbreak class or not outbreak class, while the FPA is used to obtain optimal parameter values in the SVM.. The experimental results show that the optimal parameter values produced by the FPA consists of a combination of cost and gamma values respectively of 2,829.0587 and 0.002801. The combination of these two parameter values gives the best SVM prediction results for validation data, where successively obtained values of accuracy, recall, and precision of 90.34%, 89.11%, and 91.32%. By using the same parameter values, the prediction results for test data in terms of accuracy, recall, and precision values of 59.65%, 88.37%, and 36.53% are obtained, respectively. Keywords: dengue fever, outbreak prediction, support vector machines, flower pollination algorithm."
Klasifikasi Tumor Otak Pada Citra MRI Menggunakan en-CNN.,"Tjahyaningtijas, Hapsari Peni Agustin",http://repository.its.ac.id/87168/,"Tumor otak adalah salah satu penyakit yang paling umum terjadi pada sistem saraf pusat dan sifatnya berbahaya. Diagnosis dini sangat penting untuk perawatan pasien yang tepat. Klasifikasi biner tumor otak yang sering dicirikan dengan tumor otak ganas dan jinak yang melibatkan multi-sekuen MRI (T1, T2, T1CE, dan FLAIR), membuat pekerjaan ahli radiologi membosankan dan rawan terjadinya kesalahan. Pada penelitian ini, dikembangkan metode klasifikasi melalui tahap segmentasi dan metode klasifikasi langsung tanpa mealui tahap segmentasi untuk membantu proses klasifikasi tumor otak oleh ahli. Untuk metode klasifikasi melalui segmentasi, fokus penelitian terdapat pada pengembangan metode segmentasi otomatis untuk segmentasi tumor otak ganas yaitu Glioblastoma (GBM) dan tumor otak jinak yaitu Low Grade Glioma (LGG). Metode segmentasi dikembangkan menggunakan modifikasi U-Net. Arsitektur U-Net dievaluasi berdasarkan jumlah epoch dan nilai drop-out untuk mencapai arsitektur yang paling sesuai. Dari hasil eksperimen, model arsitektur yang paling sesuai untuk segmentasi tumor otak  adalah arsitektur modifikasi U-Net atau mU-Net dengan jumlah epoch 90 dan nilai lapisan drop out 0,5. Hasil kinerja segmentasi ditunjukkan dengan nilai dice score sebesar 0,909 yang lebih besar dari penelitian sebelumnya. Metode segmentasi yang diusulkan mampu meningkatkan akurasi klasifikasi tumor otak sebesar 95,65% menggunakan DNN. Nilai akurasi tersebut 2,7% lebih tinggi dari pada jika menggunakan metode SVM yaitu sebesar 92,9%. Dilain pihak, beberapa metode klasifikasi berdasarkan deep learning  digunakan untuk mengklasifikasikan tumor otak. Performa masing-masing model sangat bergantung pada arsitektur CNN yang digunakan. Karena kompleksitas arsitektur CNN yang ada, penyetelan hyperparameter menjadi masalah dalam penerapannya. Pada penelitian ini diusulkan metode CNN yang disebut dengan en-CNN untuk mengatasi masalah ini. Metode ini didasarkan pada VGG-16 yang terdiri dari tujuh jaringan konvolusi, empat ReLU, dan empat max-pooling. Metode yang diusulkan digunakan untuk memfasilitasi penyetelan hyperparameter. Metode ini merupakan pendekatan dimana klasifikasi tumor otak dilakukan secara langsung tanpa terlebih dahulu melakukan proses segmentasi. Pendekatan baru terdiri dari tahapan berikut: preproses, augmentasi citra, dan penerapan metode en-CNN. Klasifikasi tumor otak dilakukan  menggunakan empat sekuen MRI T1, T1CE, T2, dan FLAIR. Metode yang diusulkan memberikan akurasi pada dataset MRI multi-sekuen BraTS 2018 dengan akurasi 95,5% untuk T1, 95,5% untuk T1CE, 94% untuk T2, dan 97% untuk FLAIR dengan ukuran mini-batch 128 dan epoch 200 menggunakan fungsi optimasi ADAM. Akurasinya 4% lebih tinggi dari penelitian sebelumnya dalam dataset yang sama.=====================================================================================================Brain tumors are one of the most common diseases of the central nervous system and are dangerous in nature. Early diagnosis is essential for proper patient care. Radiologists need an automated system to identify brain tumor images. The tumor identification process is a tedious and error-prone task. In addition, the binary classification of brain tumors which are often characterized by malignant and benign brain tumors involving multi-sequence MRI (T1, T2, T1CE, and FLAIR), makes the work of radiologists quite challenging. In this study, a classification method was developed through the segmentation stage. and the direct classification method without going through the segmentation stage. For the classification method through segmentation, the research focus is on the development of automatic segmentation methods using U-Net modifications. The U-Net architecture was evaluated based on the number of epochs and drop-out values to achieve the most suitable architecture for automatic segmentation of glioblastoma brain tumors. From the experimental results, the most suitable architectural model for brain tumor segmentation is the mU-Net architecture with 90 epochs and a dropout layer value of 0.5. The results of segmentation performance are indicated by a dice score of 0.909, which is greater than the previous study. Using DNN, the proposed segmentation method can improve the accuracy of brain tumor classification by 95.65%. The accuracy value is 2.7 % higher than 92.9 % when using the SVM method.On the other hand, several classification methods based on deep learning are used to classify brain tumors. The performance of each model is highly dependent on the CNN architecture used. Due to the complexity of the existing CNN architecture, hyperparameter tuning is a problem in its implementation. In this study, a CNN method called en-CNN is proposed to overcome this problem. This method is based on VGG-16 which consists of seven convolution networks, four ReLUs, and four max-poolings. The proposed method is used to facilitate hyperparameter tuning. This method is an approach where the classification of brain tumors is done directly without first doing the segmentation process. The new approach consists of the following stages: preprocessing, image augmentation, and application of the en-CNN method. Brain tumor classification was performed using four MRI sequences T1, T1CE, T2, and FLAIR. The proposed method provides an accuracy of the 2018 BraTS multi-sequence MRI dataset with an accuracy of 95.5% for T1, 95.5% for T1CE, 94% for T2, and 97% for FLAIR with mini-batch sizes of 128 and epoch 200 using the function ADAM optimization. The accuracy is 4% higher than previous studies in the same dataset"
Analisis Sentimen Terhadap Tweets Samsung Indonesia Menggunakan Metode Support Vector Machine.,"Triantoro, Aris Rendyansyah",http://repository.its.ac.id/90797/,"Samsung sebagai perusahaan smartphone terkemuka di dunia merupakan perusahaan yang memproduksi berbagai jenis perangkat teknologi. Teknologi sebagai penggerak peradaban manusia sangatlah penting. Namun, seiring berjalannya waktu perlu dilakukan peningkatan dan evaluasi secara bertahap agar dapat memenuhi kebutuhan dengan baik dan menghindari hal-hal yang tidak diinginkan.  

Media sosial Twitter adalah aplikasi yang memungkinkan pengguna untuk menulis tentang berbagai topik dan mendiskusikan isu-isu terkini. Layanan yang tersedia memungkinkan pengguna untuk mengirim tweet atau me-retweet pesan yang telah dibagikan. Dengan adanya Twitter, masyarakat menjadi lebih mudah untuk berpendapat. Pendapat yang disampaikan publik merupakan masukan yang sangat berharga dan dapat menjadi instrumen evaluasi. Pendapat-pendapat tersebut dapat dianalisis sehingga diperoleh informasi, tetapi dalam praktiknya, pengolahan data teks memerlukan metode yang tepat agar informasi yang dihasilkan dapat membantu banyak pihak dalam mendukung suatu keputusan atau pilihan.  

Analisis sentimen adalah pengklasifikasian dokumen teks ke dalam kelas sentimen, seperti positif dan negatif. Penelitian ini bertujuan untuk mengklasifikasikan tweet masyarakat terhadap perusahaan Samsung Indonesia di media sosial Twitter menggunakan metode Support Vector Machine dengan sumber data dari crawling tweet menggunakan kata kunci samsungid melalui Twitter API. Hasil penelitian menunjukkan bahwa jumlah tweet dengan sentimen negatif sebesar 13,37%, sentimen positif 26,01%, dan sentimen netral 60,60%. Model terbaik untuk mengklasifikasikan data tweet dengan SVM adalah menggunakan pembagian data dengan 80% data pelatihan dan 20% data pengujian serta nilai C = 1.================================================================================Samsung as the world's leading smartphone company is a company that produces various types of technological devices. Technology as the driving force of human civilization is very important. However, in the course of time it is necessary to improve and evaluate gradually in order to satisfy needs properly and avoid undesirable things.Social media Twitter is an application that allows users to write about various topics and discuss current issues. Services are available to send tweets or re-tweets messages that have been shared. With the existence of Twitter this makes it easier for people to have an opinion. The opinion expressed by the public is a very valuable input and can be an instrument for evaluating. These opinions can be analyzed so that information can be obtained, but in practice, processing a text data requires an appropriate method so that the information generated can help many parties to support a decision or choice.Sentiment analysis is the classification of text documents into sentiment classes, such as positive and negative. This study aims to classify the community's tweets against the Samsung Indonesia company on Twitter social media using the Support Vector Machine method by using the data source from crawling tweets with samsungidas the reference keyword using the Twitter API. This research results that the number of tweets with negative sentiment is 13.37%, positive sentiment is 26.01%, and neutral sentiment is 60.60% tweets and the best model for classifying tweet data with SVM is to use data sharing by sharing training data by 80% and testing data by 20% and using value C = 1."
Sentiment Analysis of Public Figure News using Sentiment Lexicon and Machine Learning.,"Tsabit, Fitriana Zahirah",http://repository.its.ac.id/100969/,"Dalam dunia politik maupun dunia bisnis penilaian yang dibentuk media dapat menjadi sebuah citra dari seseorang. Citra seseorang merupakan komponen penting bagi seorang publik figur untuk mendapatkan popularitas dan keuntungan secara finansial. Saat ini dunia informasi berkembang dengan cepat sehingga lebih mudah mendapatkan informasi melalui situs berita online. Di Indonesia salah satu situs beritaonline terbesar yaitu Detik.com. Situs berita online menyediakan informasi dalam berbagai bentuk (teks, video atau gambar) dengan membaginya sesuai dengan topik-topik tertentu. Sehingga, dapat dilakukan sentimen analisis untuk mengetahui citra publik figur dari situs berita online melalui penerapan metode machine learning yaitu klasifikasi. Data yang digunakan berasal dari situs berita online yang diambil dengan cara scraping. Tahapan yang dilakukan preprocessing, gabungan score feature extraction menggunakan kamus lexicon, InSet, SentIl, Emolex dan juga terhadap gabungan kamus EmoTil (Emolex dan SentIl), EmoSet (Emotil dan InSet) dan SenSet (InSet dan SentIl) dengan TFIDF. Hasil dari penggabungan ini digunakan untuk klasifikasi machine learning dengan algoritma SVM dan Logistic Regression. Model yang telah dibangun akan dievaluasi dengan membandingkan nilai akurasi dari cross validation. Hasil akurasi terbesar dan terkecil akan dilakukan penembahan parameter untuk meningkatkan hasil dari rata-rata cross validation. Hasil dari akurasi terbesar adalah SVM dengan selisih 1.2% dengan Logistic Regression=================================================================================================================================In the world of politics and business, the judgment formed by the media can become an image of a person. A person's image is essential for a public figure to gain popularity and financial benefits. The world of information is developing rapidly, making it easier to get information through online news sites. In Indonesia, one of the largest online news sites is Detik.com. Online news sites provide information in various forms (text, video, or images) by dividing it according to specific topics. Thus, an analysis of sentiment can be carried out to determine the image of public figures from online news sites through machine learning methods, namely classification. The data used comes from online news sites taken by scraping. The stages carried out are preprocessing, combined score feature extraction using lexicon dictionaries, InSet, SentIl, and Emolex and also against the combined dictionaries EmoTil (Emolex and SentIl), EmoSet (Emotil and InSet) and SenSet (InSet and SentIl) with TFIDF. The result of this combination is used for machine learning classification with SVM and Logistic Regression algorithms. The model that has been built will be evaluated by comparing the accuracy value of cross validation. The largest and smallest accuracy results will be parameterised to improve the results of the average cross validation. The result of the greatest accuracy is SVM with a difference of 1.2% with Logistic Regression."
Penerapan Algoritma Blocplan Sebagai Metode Desain Terminal Regasifikasi Gas Alam Cair (LNG).,"Ulfauzi, Zaki",http://repository.its.ac.id/80801/,"Dalam perancangan tata letak fasilitas yang menggunakan aplikasi, seperti dalam bidang teknik sipil, perkapalan, arsitektur, banyak sistem algoritma perancangan yang telah dikembangkan. Algoritma perancangan merupakan salah satu metode pendekatan dalam perancangan dimana sistem komputer telah diolah dengan beberapa rumus untuk menghasilkan rancangan secara otomatis dan efisien. Peneliti mencoba menggunakan salah satu algoritma perancangan untuk mendesain layout terminal LNG yang disebut algoritma BLOCPLAN. Algoritma BLOCPLAN digunakan untuk meningkatkan efisiensi pemanfaatan ruang dan penempatan fasilitas. BLOCPLAN bekerja dengan menghasilkan beberapa tata letak terminal dengan sistem penilaian langsung. Desain yang paling efisien akan dipilih dari desain yang dihasilkan setelah proses analisis ulang. Dalam menentukan fasilitas terminal utama, Excel Solver juga digunakan untuk memilih skenario terbaik dengan parameter modal investasi yang rendah. Dalam penelitian ini, 15 layout dihasilkan oleh algoritma. Untuk proses perankingan, metode AHP digunakan untuk mengubah karakter skor dari cost criteria menjadi benefit criteria. Nilai bobot untuk masing-masing skor adalah 0.1 untuk Adj.Score, 0.3 untuk R.Score, dan 0.6 untuk Rel-Dist Score. Dari hasil pemeringkatan, layout nomor 14 menjadi rekomendasi terbaik dengan total skor 0.14987.======================================================================================================================================================================In the layout design of buildings using applications, such as in the fields of civil engineering, shipping, architecture, many design algorithm systems have been developed. Design algorithm is an approaching method in design where the computer system has been processed with several formulas to produce designs automatically and efficiently. The researcher tries to use one of the design algorithms for designing the LNG terminal layout, called the BLOCPLAN algorithm. The BLOCPLAN algorithm is used to improve the efficiency of space utilization and facility placement. BLOCPLAN works by generating several terminal layouts with a direct appraisal system. A most efficient design will be selected from generated designs after the re-analysis process. In determining the main terminal facilities, Excel Solver is also used to choose the best scenario with low investment capital. In this research, 15 layouts are generated by the algorithm. For the ranking process, the AHP method is used to change the character of the score from the cost criteria to the benefit criteria. The weighted value of each score is 0.1 for Adj.Score, 0.3 for R.Score, and 0.6 for the Rel-Dist Score. From the ranking results, layout number 14 is the best recommendation with a total score of 0.14987."
Model Traffic Forecasting dengan RNN-Based Deep Learning dan Explainable Artificial Intelligence.,"Ulhaq, Naufal Dhiya",http://repository.its.ac.id/106242/,"Peningkatan konsep smart city yang didorong oleh kemajuan Internet of Things (IoT), telah mengubah lanskap perkotaan modern. Salah satu pilar utama dari hal ini adalah Intelligent Transportation System (ITS), di mana model traffic forecasting menjadi perangkat kunci dari sistem ini. Penelitian ini bertujuan untuk mengembangkan model forecasting yang tidak hanya akurat tetapi juga mudah dipahami, dengan menggunakan pendekatan Recurrent Neural Network (RNN) dan menerapkan Explainable Artificial Intelligence (XAI). Hasil pengujian menunjukkan bahwa model dengan algoritma Bidirectional Long Short-Term Memory (BiLSTM) yang merupakan pengembangan RNN, mencapai kinerja terbaik. Model tersebut berhasil mencapai nilai Mean Absolute Error (MAE) sebesar 163,13, Root Mean Square Error (RMSE) sebesar 241,62, dan Mean Absolute Percentage Error (MAPE) sebesar 8,03%. Penggunaan XAI, khususnya metode Shapley Additive Explanations (SHAP), mengungkapkan bahwa fitur ""traffic_volume"" dan timestep pada 1 jam terakhir memberikan kontribusi terbesar dalam pengambilan keputusan model. Lebih lanjut, penelitian ini berhasil mengintegrasikan model dan XAI ke dalam aplikasi website berbasis Flask. Integrasi ini memberikan akses untuk melihat riwayat forecasting, nilai shap value, feature importance, dan dataset. Aplikasi tersebut juga menyertakan formulir untuk input data baru dan tabel dataset.====================================================================================================================================The rise of the smart city concept, driven by the advancement of the Internet of Things (IoT), has changed the modern urban landscape. One of its main pillars is the Intelligent Transportation System (ITS), where traffic forecasting models are a key tool of this system. This research aims to develop a forecasting model that is not only accurate but also easy to understand, by using a Recurrent Neural Network (RNN) approach and applying Explainable Artificial Intelligence (XAI). The results showed that the model with the Bidirectional Long Short-Term Memory (BiLSTM) algorithm, which is a development of RNN, achieved the best performance. The model managed to achieve a Mean Absolute Error (MAE) value of 163.13, Root Mean Square Error (RMSE) of 241.62, and Mean Absolute Percentage Error (MAPE) of 8,03%. The use of XAI, specifically the Shapley Additive Explanations (SHAP) method, revealed that the ""traffic_volume"" feature and the timestep of the last 1 hour contributed the most to the model's decision making. Furthermore, this research successfully integrated the model and XAI into a Flask-based website application. This integration provides access to view forecasting history, shap value, feature importance, and datasets. The application also includes a form for new data input and a dataset table."
Peningkatan Akurasi Klasifikasi Kemurnian Daging Sapi Berbasis Electronic Nose Dengan Menggunakan Ensemble Method.,"Ulhaq, Azzam Jihad",http://repository.its.ac.id/84701/,"Daging sapi merupakan salah satu jenis daging yang sering dikonsumsi oleh manusia. Namun, pencampuran jenis daging sapi dengan daging lainnya seperti daging babi dilakukan dalam praktik jual beli dalam rangka mendapatkan keuntungan yang lebih. Hal ini tidak hanya mengurangi kepercayaan publik tentang keaslian daging juga membahayakan kesehatan dan melanggar aturan-aturan agam tertentu. Dalam penelitian ini, kami merancang dan mengusulkan sistem yang lebih akurat dalam melakukan klasifikasi kemurnian daging sapi berdasarkan data sampel aroma yang ditangkap oleh electronic nose.Sistem ini dibangun melalui tujuh tahap: pengambilan sampel data menggunakan electronic nose yang dibuat dari sensor gas dan Arduino; praproses data sensor; ekstraksi fitur statistik; hyperparameter tunning; seleksi fitur menggunakan ANOVA; klasifikasi menggunakan metode SVM, LDA dan MLP; dan peningkatan akurasi menggunakan ensemble method.Hasil penelitian menunjukkan bahwa sistem ini dapat membedakan daging sapi yang dicampur dengan daging babi dengan perbandingan 0%, 10%, 25%, 50%, 75%, 90%, dan 100% dengan akurasi 89,71% menggunakan Bagging MLP.======================================================================================================Beef is a type of meat that is often consumed by humans. However, mixing types of beef with other meats such as pork is carried out in buying and selling to get more profit. The adulteration undermines public belief in meat's authenticity and harms health, and violates specific religious rules. In this study, we designed and proposed a more accurate system for classifying beef purity based on the aroma sample data captured by the electronic nose.This system has seven stages: data sampling using an electronic nose made from the gas sensor and Arduino; preprocessing sensor data; statistical feature extraction; hyperparameter tunning; feature selection using ANOVA; classification using the SVM, LDA, and MLP methods; and improved accuracy using the ensemble method.The results showed that this system could distinguish beef mixed with pork with a ratio of 0%, 10%, 25%, 50%, 75%, 90%, and 100% with an accuracy of 89.71% using Bagging MLP."
News Classification Using Ensemble Learning Approach.,"Utomo, Erlangga Wahyu",http://repository.its.ac.id/117829/,"The amount of information published online every day can be overwhelming, making it difficult to effectively manage and categorize. This research addresses this problem by combining multiple machine learning and deep learning models in a method known as ensemble learning. Using a set of Huffpost News from Kaggle, the study integrates traditional models, such as logistics regression, random forests and Support for Vector Machines (SVM) with advanced approaches deep learning, such as Long Short Term Memory (LSTM), Bidirectional Long Short Term Memory (BiLSTM) with a mechanism for attention, and the introduction of layers. The data preparation process included cleaning the text, removing unnecessary characters and the conversion of text into numerical forms using Word2Vec embedding field These features were then fed into an ensemble model that combined predictions from different classifiers using a method called soft voting, improving the overall accuracy and reliability of the classification process. To confirm the results, the model was tested using various departments of learning data and test data (80-20 reports). The results indicate that the ensemble model achieved an overall accuracy of 60.19%, outperforming individual models. Among the individual models, BiLSTM with Attention achieved the highest accuracy of 63.9%, followed by LSTM at 54.7%, Random Forest at 48.3%, Logistic Regression at 58.2%, and SVM at 57.5%. Among the individual models, BiLSTM with Attention achieved the best performance, demonstrating its effectiveness in understanding sentence structure and capturing complex patterns in news content. Even though it differs not so much from the individual model, the ensemble still has the best accuracy because it combines all the individual models and combines preprocessing data between machine learning and deep learning, However, the training process for the ensemble model required significant computational resources, taking 10 days to complete."
Nowcasting Jumlah Penduduk dengan Metode Support Vector Regression (SVR) dan Multi-Output Support Vector Regression (M-SVR).,"Vinahari, Riyan Zulmaniar",http://repository.its.ac.id/104274/,"Data dan informasi statistik beserta proyeksinya merupakan dasar penting untuk perencanaan dan evaluasi pembangunan nasional di masa mendatang khususnya jangka menengah maupun jangka panjang. Data tersebut tidak dapat dipenuhi melalui sistem registrasi sehingga data-data diperoleh dari sensus dan survei yang dilakukan Badan Pusat Statistik (BPS) untuk digunakan sebagai dasar proyeksi. Metode proyeksi penduduk yang umum digunakan di berbagai negara dan masih menjadi metode proyeksi penduduk Indonesia adalah Cohort Component Model (CCM). Akan tetapi, metode ini mempunyai beberapa kelemahan sehingga diperlukan metode baru yang lebih akurat salah satunya melalui metode nowcasting. Analisis time series tidak hanya dilakukan menggunakan statistika klasik, tetapi juga machine learning (ML). Metode ML mempunyai performa lebih unggul dibandingkan dengan metode statistika klasik. Algoritma ML yang umum digunakan untuk nowcasting adalah Support Vector Regression (SVR) dan Multi-output SVR (M-SVR). SVR juga mampu menghasilkan performa bagus dalam proyeksi di berbagai macam bidang. Akan tetapi SVR hanya mampu menangani single output. Sedangkan M-SVR mampu menangani permasalahan regresi multi-output seperti jumlah penduduk di beberapa provinsi di Pulau Jawa yang saling berkorelasi. Data yang digunakan bersumber dari BPS dengan variabel output jumlah penduduk di Provinsi DKI Jakarta, Jawa Barat, Jawa Tengah, dan Jawa Timur. Variabel input yang digunakan yaitu jumlah pelanggan listrik kelompok rumah tangga, jumlah angkatan kerja, jumlah rumah tangga, kepadatan penduduk (jiwa/km2), PDRB komponen PKRT ADHK (miliar Rp). Periode data yang digunakan merupakan data tahunan dari tahun 1985 sampai 2022. Pemilihan model terbaik dilakukan dengan membandingkan nilai RMSE dan MAPE out sample nowcasting model SVR dan M-SVR. Hasil penelitian menunjukkan bahwa berdasarkan nilai kebaikan model, nowcasting model SVR mempunyai performa yang lebih baik dibandingkan model M-SVR yang ditunjukkan dari nilai MAPE out sample nowcasting model SVR yang lebih kecil dibanding model M-SVR untuk seluruh variabel output. Selain itu, proyeksi penduduk hasil dari metode nowcasting memberikan performa yang lebih baik dibandingkan dengan metode CCM.===================================================================================================================================Statistical data and information, as well as their projections are an important basis for planning and evaluation of future national development, especially in the medium and long term development. These data cannot be provided through the population registration system. Hence, the data obtained from censuses and surveys conducted by Badan Pusat Statistik (BPS- Statistics Indonesia). The common method is Cohort Component Method (CCM). CCM is widely used in many countries including Indonesia, which still be utilized by BPS. Unfortunately, this method has several drawbacks, and therefore, more accurate method is required to outperform CCM. One of these methods is nowcasting. Time series analysis can now be conducted not only using classical statistical but also machine learning (ML). Machine learning is a new method in statistical forecasting that shows an excellent performance compared to classical statistical methods. Machine learning algorithms that are commonly used in sequential analysis are Support Vector Regression (SVR) and Multioutput SVR (MSVR) where both of these algorithms can perform nowcasting. SVR is also capable of producing excellent projections in a variety of disciplines. However, SVR is only able to handle single output. Meanwhile, M-SVR is capable of handling multi-output regression problems such as the number of populations in several provinces in Java Island which are correlated with each other. The data used was obtained from the BPS, and the output variable is the population of DKI Jakarta, West Java, Central Java, and East Java Provinces.  The variables used as inputs are the number of electricity consumers for the household group, the number of workers, the number of households, the population density (people/km2), and the GRDP of the PKRT ADHK component (billion Rp). The data period used spans from 1985 to 2022 with annual data. Comparing the SVR and MSVR models' RMSE and MAPE values enables the selection of the optimal model. The results showed that based on the quality of the model, the SVR nowcasting model outperformed the M-SVR model, as shown by the SVR nowcasting model's out sample MAPE value, which was lower for all output variables than MAPE value from M-SVR. In addition, the efficacy of the population projections derived from the nowcasting method is outperform than CCM method."
Pengembangan Sistem Deteksi Kebocoran Air Berbasis Support Vector Machine Pada Jaringan Distribusi Air Di Perumda Air Minum Tugu Tirta Malang.,"Wicaksana, Farhan Arief",http://repository.its.ac.id/109411/,"Di Indonesia, PDAM (Perusahaan Daerah Air Minum) mendistribusikan air minum kepada masyarakat melalui jaringan pipa. Pada penggunaan jaringan pipa, seringkali pipa ditempatkan di bawah tanah di area luas, menyulitkan operator untuk memantau aliran air dan kondisi pipa karena keterbatasan peralatan dan tenaga. Oleh karena itu, penelitian ini menggunakan Artificial Intelligence sebagai opsi metode deteksi kebocoran air dengan memprediksi tekanan yang tercatat pada datalogger DMA(District Meter Area). Algoritma SVM (Support Vector Machine)  yang digunakan sendiri untuk memprediksi hasil tekanan pada DMA yang dianalisis. Dalam penelitian tugas akhir ini, setelah melalui studi literatur dan lapangan, kemudian hasil dari software tersebut akan dimasukkan kedalam algoritma SVM. Hasil menunjukkan untuk perfomansi algoritma pada ukuran kebocoran pada DMA TL 2.2I memiliki nilai akurasi sebesar 93.5% dan F1 score sebesar 93.25% dan untuk perfomansi algoritma pada lokalisasi area kebocoran memiliki nilai akurasi sebesar 93.30% dan F1 score sebesar 93.80%. Kemudian untuk perbedaan perfomansi menggunakan data lapangan memiliki perbedaan nilai, untuk nilai akurasi dari pemodelan ukuran kebocoran menggunakan data lapangan yaitu sebesar 82.10% dan F1 score 90% serta untuk pemodelan lokalisasi area kebocoran yaitu memiliki nilai akurasi sebesar 85.71% dan F1 score 92 %. Dengan nilai perfomansi seperti yang ditunjukan pada pemodelan, maka dapat disimpulkan algoritma SVM dapat digunakan untuk mendeteksi adanya kebocoran air pada jaringan distribusi air.====================================================================================================================================In Indonesia, PDAMs (Regional Water Supply Companies) distribute drinking water to the public through pipelines. In the use of pipelines, pipes are often placed underground in large areas, making it difficult for operators to monitor water flow and pipe conditions due to limited equipment and manpower. Therefore, this research uses Artificial Intelligence as an option for water leak detection methods by predicting the pressure recorded in the DMA (District Meter Area) datalogger. The SVM (Support Vector Machine) algorithm is used alone to predict the pressure results on the analyzed DMA. In this final project research, after going through literature and field studies, then the results of the software will be entered into the SVM algorithm. The results show that the algorithm performance on leakage size in DMA TL 2.2I has an accuracy value of 93.5% and F1 score of 93.25% and for the algorithm performance on leakage area localization has an accuracy value of 93.30% and F1 score of 93.80%. Then for the difference in performance using acquisition data has a difference in value, for the accuracy value of the leak size modeling using acquisition data is 82.10% and F1 score 90% and for modeling the leak area localization which has an accuracy value of 85.71% and F1 score 92%. With the performance value as shown in the modeling, it can be concluded that the SVM algorithm can be used to detect water leaks in the water distribution network."
Pemanfaatan Komputasi Awan untuk Pengenalan Ekspresi Wajah menggunakan AWS DeepLens.,"Widojoko, Gregorius Rafael",http://repository.its.ac.id/81986/,"Komunikasi tatap-muka merupakan suatu bentuk interaksi yang sering dilakukan oleh semua orang. Akan tetapi, hal tersebut sulit untuk diimplementasikan bagi penyandang tuna netra, terutama bagi mereka untuk mengenali ekspresi wajah dari lawan bicaranya dan ekspresi wajah dipercayai mempunyai kaitan erat dalam emosi seseorang dan memberikan informasi yang lebih lengkap saat berkomunikasi.  Oleh karena itu, diperlukanlah suatu alat yang bisa membaca ataupun mengenali ekspresi wajah, sehingga para penyandang tuna netra dapat mengenali ekspresi wajah dari lawan bicaranya dengan jelas dan ekspresi itu dikonversikan menjadi informasi non-verbal berupa suara yang mengindikasikan ekspresi dari lawan bicara penyandang tuna netra.Penelitian tentang pengenalan ekspresi wajah kepada penyandang tunanetra telah banyak dilakukan. Akan tetapi, salah satu skenario kendala yang dihadapi dari beberapa penelitian sebelumnya adalah biaya pembuatan dan performa yang kurang sesuai dengan pengguna. Pada penelitian ini akan digunakan perangkat untuk komputasi awan dan pembelajaran mesin AWS DeepLens yang bertujuan untuk mencari performa dari perangkat yang menggunakan layanan komputasi awan AWS dan membandingkannya dengan performa dari alat yang menggunakan pemrograman deep learning tanpa komputasi awan. Semua bentuk keluaran dari perangkat akan menyampaikan informasi pengenalan ekspresi ke pengguna melalui media suara. Keberhasilan algoritma deep learning akan diukur dalam confusion matrix dengan rerata keberhasilan sebesar 73,43 % . Alat yang dikembangkan dari divais AWS DeepLens ini menggunakan sistem komputasi awan dari AWS, dengan harapan alat ini robust secara sistem dan real-time dalam penggunaannya."
Analisis Sentimen Twitter Pada Initial Public  Offering Saham GOTO Tahun 2022 Dengan  Menggunakan Support Vector Machine.,"Wijaya, Ikhlasul Ikhwan",http://repository.its.ac.id/99758/,"Initial Public Offering atau biasa disingkat IPO merupakan sebuah penarawaran saham kepada  publik dengan penjualan pertama dari suatu perusahaan kepada masyarakat sehingga perusahaan yang  bersangkutan status perusahaanya berubah yang semula berupa perusahaan swasta menjadi perusahaan  publik. Initial Public Offering sendiri biasanya dikelola oleh bank yang membantu investasi yang  fungsinya mencatat saham di bursa efek, tujuan dari IPO sebuah perusahaan sendiri adalah untuk  meningkatkan modal ekuitas baru bagi perusahaan. Kinerja dari perusahaan sendiri sangat berpengaruh  pada penawaran kepada publik, apabila dari masyarakat memiliki banyak sentimen buruk maka akan  sangat berpengaruh terhadap minat beli dan harga saham pada pembukaan saham. Oleh karena itu,  penting untuk mengetahui seberapa besar sentimen dan minat pada saham yang akan IPO. Tujuan  penelitian kali ini adalah untuk mengklasifikasi seberapa besar sentimen masyarakat melalui twitter  terhadap beberapa perusahaan pada kuartal 2 tahun 2022 yang rilis ke publik atau IPO. Metode yang  digunakan pada peneliain kali ini adalah support vector machine dengan menggunakan sumber data dari  crawling tweet dengan menggunakan package scrapping dari Python. Dari penelitian kali ini  didapatkan hasil tweets sebanyak 4873 tweets dengan presentase 22,8% sentimen positif dan  77,2% sentimen negatif dengan menggunakan tiga kali percobaan dengan data testing sebesar  20%, 30%, dan 40% dengan tiga kernel yang dicoba yaitu linear, radial basis function, dan  Sigmoid. Berdasarkan ketiga percobaan dengan menggunakan tiga kernel yang berbeda, dapat  didapatkan skor akurasi yang terbesar yaitu dengan menggunakan kernel linear dengan skor  akurasi sebesar 80% pada data testing 30% dan memiliki nilai sensitivity, precission dan recall sebesar 91%, 38%, 85% dan 89% pada nilai cost 50% dengan akurasi cost sebesar 80%===================================================================================================================================Initial Public Offering or commonly abbreviated as IPO is an offering of shares to the public with  the first sale of a company to the public so that the company concerned changes its company status from  a private company to a public company. Initial Public Offering itself is usually managed by an  investment bank whose function is to list shares on the stock exchange, the purpose of a company's own  IPO is to raise new equity capital for the company. The performance of the company itself is very  influential on the offer to the public, if the public has a lot of bad sentiment, it will greatly affect the  buying interest and share price at the opening of the stock. Therefore, it is important to know how much  sentiment and interest in stocks that will IPO. The purpose of this research is to classify how much  public sentiment through twitter towards several companies in the 2nd quarter of 2022 that are released  to the public or IPO. The method used in this research is support vector machine by using data sources  from crawling tweets using the scrapping package from Python. From this research, 4873 tweets were  obtained with a percentage of 22.8% positive sentiment and 77.2% negative sentiment using three  experiments with testing data of 20%, 30%, and 40% with three kernels tried, namely linear, radial basis  function, and Sigmoid. Based on the three experiments using three different kernels, the largest accuracy  score can be obtained by using a linear kernel with an accuracy score of 80% on 30% testing data and  has sensitivity, precission and recall values of 91%, 38%, 85% and 89% at a cost value of 50% with a  cost accuracy of 80%"
Prototipe Sistem Rekomendasi Konten Hiburan Anak-Anak Dan Klasifikasi Kelompok Usia Berbasis Suara Pada Perangkat Tinyml (Tiny Machine Learning).,"Wijaya, Rayhan Kurnia Alunantara",http://repository.its.ac.id/106099/,"Era digital menuntut solusi inovatif untuk memastikan anak-anak mengakses konten hiburan yang sesuai usia. Sistem rekomendasi yang digunakan pada berbagai platform konten hiburan tidak dapat mengklasifikasikan usia anak-anak secara akurat dan memberikan konten yang sesuai untuk mereka. Oleh karena itu, penelitian ini bertujuan untuk mengembangkan prototipe sistem rekomendasi dan klasifikasi usia anak-anak berbasis suara menggunakan perangkat Tiny Machine Learning yang dapat menentukan kelompok usia anak-anak secara akurat. Model kunci dalam penelitian ini adalah Hybrid MLP (Hybrid Multilayer Perceptron), dimana digunakan teknik ekstraksi fitur MFCC (Mel-Frequency Cepstral Coefficients) untuk mengolah data suara. Dalam penelitian ini, dataset utama berasal dari Mozilla Common Voice dan dataset suara anak-anak Indonesia yang dikumpulkan secara mandiri. Dilakukan juga perbandingan dengan model-model yang telah dikembangkan sebelumnya pada dataset yang sama dimana model Hybrid MLP berhasil melebihi akurasi model pembanding tersebut. Pengembangan model klasifikasi usia dilakukan pada platform Edge Impulse dengan menggunakan Arduino Nano BLE 33 Sense Lite. Pengujian model dilakukan dengan memanfaatkan kata kunci 'oke' yang bertujuan untuk mengaktivasi dan mengevaluasi respons sistem. Dalam uji coba untuk mengklasifikasikan kelompok usia anak SD dan SMP dengan skenario optimasi paling optimal, Hybrid MLP berhasil menunjukkan tingkat akurasi pelatihan sebesar 97.6% serta akurasi validasi 87.72%. Hasil ini mengindikasikan efektivitas model dalam proses klasifikasi usia dalam kondisi sumber daya komputasi yang terbatas.==================================================================================================================================The digital age demands innovative solutions to ensure children access age-appropriate entertainment content. Recommendation systems used on various entertainment content platforms are unable to accurately classify children's age and provide appropriate content for them. Therefore, this research aims to develop a prototype of a voice-based children's age classification and recommendation system using Tiny Machine Learning tools that can accurately determine children's age groups. The key model in this research is Hybrid MLP (Hybrid Multilayer Perceptron), where MFCC (Mel-Frequency Cepstral Coefficients) feature extraction technique is used to process voice data. In this research, the main dataset comes from Mozilla Common Voice and Indonesian children's voice dataset collected independently. Comparisons were also made with previously developed models on the same dataset where the Hybrid MLP model successfully exceeded the accuracy of the comparison model. The age classification model development was conducted on the Edge Impulse platform using Arduino Nano BLE 33 Sense Lite. Model testing was conducted by utilizing the keyword 'oke' which aims to activate and evaluate the system response. In the test to classify the age groups of elementary and junior high school children with the most optimal optimization scenario, Hybrid MLP successfully showed a training accuracy rate of 97.6% and a validation accuracy of 87.72%. These results indicate the effectiveness of the model in the age classification process under conditions of limited computational resources."
Inversi Data Magnetotellurik (MT) 1-D Menggunakan Algoritma Ensemble Kalman Inversion (EKI).,"Wijdannysa, Jasinda",http://repository.its.ac.id/115180/,"Metode magnetotellurik (MT) merupakan metode eksplorasi geofisika pasif yang dapat menjangkau kedalaman lapisan batuan yang sangat dalam, sehingga cocok digunakan untuk penentuan kedalaman basemen. Untuk menentukan kedalaman basemen, data MT diinversikan agar mendapatkan estimasi parameter model (resistivitas dan ketebalan lapisan batuan). Pada penelitian ini, algoritma Ensemble Kalman Inversion (EKI) digunakan untuk melakukan inversi data MT 1-D. Algoritma EKI dilakukan uji coba pada data sintetik tipe kurva sounding (A, K, H, Q, D, Q) serta data sintetik kasus cekungan sedimen. Setelahnya, hasil inversi pada setiap data sintetik tersebut dianalisis posterior distribution model (PDM) dan principal component analysis (PCA). Analisis PDM dilakukan untuk mengestimasi ketidakpastian parameter model terbaik hasil inversi, sedangkan analisis PCA digunakan untuk mengkorelasikan parameter model sebenarnya pada data sintetik dengan parameter model hasil inversi. Hasil analisis PDM pada data sintetik A, K, H, Q, D, dan Q menunjukkan estimasi model parameter yang sesuai dengan model sebenarnya, sedangkan hasil analisis PCA menunjukkan model sebenarnya dan model terbaik yang berhimpit untuk setiap tipe kurva dan berada pada nilai fungsi objektif yang minimum. Hal ini mengindikasikan bahwa algoritma EKI terbukti robust dalam uji coba data sintetik tipe kurva sounding. Analisis yang sama juga dilakukan pada data MT sintetik untuk kasus cekungan sedimen. Namun, untuk data ini model terbaik pada analisis PDM menunjukkan hasil yang berbeda dari model sebenarnya, serta jarak model sebenarnya dengan model terbaik hasil inversi yang berjauhan pada ruang PCA. Hal ini menunjukkan bahwa algoritma EKI belum akurat dalam menentukan estimasi model parameter pada kasus cekungan sedimen sintetik, khususnya dalam penentuan parameter model resistivitas lapisan basemen.=================================================================================================================================The magnetotelluric (MT) method is a passive geophysical exploration technique that can probe deep rock layers, making it ideal for determining basement depths. To achieve this, inversion modeling of MT data is performed to estimate model parameters such as resistivity and rock layer thickness. This research utilizes the Ensemble Kalman Inversion (EKI) algorithm for 1-D MT data inversion. The EKI algorithm was tested on synthetic sounding curve data types (A, K, H, Q, D, Q) and synthetic data in the case of sedimentary basins. The inversion results for each synthetic dataset were analyzed using posterior distribution model (PDM) and principal component analysis (PCA). PDM analysis estimates the uncertainty of the best model parameters from the inversion, while PCA correlates the actual model parameters of synthetic data with the inversion results. For synthetic sounding curve data, PDM analysis indicated that the estimated model parameters matched the actual model, and PCA analysis showed the actual and best models coinciding at the minimum objective function value. This demonstrates the robustness of the EKI algorithm for synthetic sounding curve data. For synthetic MT data representing sedimentary basins, the PDM analysis showed discrepancies between the best model and the actual model, with a significant distance between them in PCA space. This suggests that the EKI algorithm is less accurate in estimating model parameters for synthetic sedimentary basin cases, particularly in determining basement layer resistivity model."
Prediksi Mahasiswa Drop Out Institut Teknologi Sepuluh Nopember Menggunakan XGBoost dan SHAP Values Berbasis Dashboard Interaktif.,"Winarso, Raihan Adam Handoyo",http://repository.its.ac.id/105897/,"Peran mahasiswa menjadi aspek penting dalam menentukan keberhasilan penyelenggaraan pendidikan. Namun, tidak semua mahasiswa dapat menyelesaikan studi tepat waktu sesuai dengan yang direncanakan, hingga terancam drop out. Drop out atau pemberhentian status mahasiswa adalah proses pencabutan status kemahasiswaan, yang disebabkan oleh hal-hal tertentu atau sudah ditentukan oleh perguruan tinggi yang bersangkutan. Fenomena ini menjadi tantangan bagi institusi, yang harus ditemukan solusinya, karena drop out menimbulkan kerugian signifikan baik pada mahasiswa maupun institusi. Langkah preventif untuk memprediksi mahasiswa yang berpotensi drop out dilakukan dengan menggunakan teknik klasifikasi menggunakan XGBoost dan SHAP Values. XGBoost adalah algoritma klasifikasi yang menggunakan teknik boosting, yaitu langkah berulang untuk memperkuat performa model klasifikasi lemah hingga akhirnya menjadi model yang lebih kuat. Setelah model XGBoost terbentuk, interpretasi dilakukan dengan melihat rata-rata kontribusi setiap variabel menggunakan SHAP Values. Hasil penelitian ini menunjukkan bahwa semester yang sudah dijalani, IPK persiapan, dan IPK mahasiswa memiliki kontribusi besar dalam menentukan status mahasiswa sebagai drop out atau tidak drop out. Model XGBoost yang terbentuk memberikan kebaikan model dengan akurasi sebesar 100%, sensitivitas sebesar 100%, dan spesifisitas sebesar 100%. Dashboard prediksi mahasiswa drop out atau tidak drop out memiliki 4 menu yaitu menu dashboard untuk melihat karakteristik dari mahasiswa ketika data imbalance dan balance, menu kedua yaitu data mahasiswa untuk menampilkan data mahasiswa secara keseluruhan, menu ketiga yaitu prediksi untuk melakukan prediksi dengan cara input variabel yang diduga memengaruhi status mahasiswa, dan yang terakhir adalah kontribusi variabel untuk melihat besar kontribusi variabel yang digunakan dalam memprediksi status mahasiswa.=================================================================================================================================The role of students is an important aspect in determining the success of educational provision. However, not all students can complete their studies on time as planned, so they are threatened with dropping out. Drop out or termination of student status is the process of revoking student status, which is caused by certain reasons or has been determined by the university concerned. This phenomenon is a challenge for institutions, which must find a solution, because dropping out causes significant losses to both students and institutions. Preventive steps to predict students who have the potential to drop out are carried out using classification techniques using XGBoost and SHAP Values. XGBoost is a classification algorithm that uses a boosting technique, namely repeated steps to strengthen the performance of a weak classification model until it finally becomes a stronger model. After the XGBoost model is formed, interpretation is carried out by looking at the average contribution of each variable using SHAP Values. The results of this research show that the semester that has been completed, the preparatory GPA, and the student's GPA have a major contribution in determining a student's status as a dropout or not. The XGBoost model formed provides a good model with an accuracy of 100%, sensitivity of 100%, and specificity of 100%. The dashboard predicting whether students will drop out or not drop out has 4 menus, namely the dashboard menu to see the characteristics of students when the data is imbalanced and balanced, the second menu is student data to display overall student data, the third menu is prediction to make predictions by inputting the specified variables. is thought to influence student status, and the last is variable contribution to see the contribution of the variables used in predicting student status."
Sistem Klasifikasi Kondisi Motor Dust Collector Menggunakan Model Support Vector Machine (SVM) Guna Menunjang Condition-Based Maintenance.,"Winata, Nurdiwansyah Bagus",http://repository.its.ac.id/115583/,"Perusahaan Pestisida MSI merupakan salah satu perusahaan yang bergerak di bidang formulasi pestisida. Pada proses produksi, terdapat satu mesin penting yang menggunakan motor induksi 3 fasa sebagai penggerak utama, yaitu mesin dust collector. Namun, dalam dua tahun terakhir, terjadi sembilan kali kasus kerusakan pada mesin dust collector di MSI. Kerusakan tersebut terbagi menjadi beberapa jenis kerusakan, seperti kerusakan bearing, shaft misalignment, dan motor terbakar. Untuk mencegah kerusakan pada motor diperlukan penerapan metode maintenance yang efektif. Dengan data historis yang terbatas, metode Condition-Based Maintenance (CBM) adalah metode yang efektif. Dengan melakukan pemeliharaan hanya saat diperlukan berdasarkan kondisi aktual peralatan, CBM dapat mengurangi biaya yang tidak perlu dan mengurangi downtime yang tidak direncanakan. Dibantu dengan model Support Vector Machine (SVM), CBM pada proyek ini bertujuan untuk mengklasifikasikan kondisi motor secara aktual. Motor dengan kondisi normal, shaft miasalignment, dan bearing damage menjadi target klasifikasi pada proyek ini. Klasifikasi kondisi motor tersebut mengacu kepada data historis getaran dan suhu permukaan motor secara aktual. Dari penelitian yang telah dilakukan, pembacaan sensor HVT100 pada nilai getaran memiliki error sebesar 2,16% dan nilai suhu permukaan motor memiliki galat sebesar 3,89% dari 20 kali percobaan. Metode Support Vector Machine (SVM) menggunakan multiclass strategy OneVsOne (OVO) dan OneVsRest (OVR) dapat mengklasifikasikan kondisi motor normal, shaft misalignment, dan bearing damage secara aktual dengan akurasi dari 66% hingga 100%.==================================================================================================================================Pesticide company MSI is one of the companies active in the field of pesticide formulation. In the production process, there's one important engine that uses a three-phase induction motor as its primary driver, a dust collector. However, in the last two years, there have been nine cases of damage to the dust collection machine at MSI. Such damage is divided into several types of damage, such as bearing damage, shaft misalignment, and motorcycle burning. To prevent damage to the motorcycle, effective maintenance methods are required. With limited historical data, the Condition-Based Maintenance (CBM) method is an effective method. By performing maintenance only when necessary based on the actual condition of the equipment, CBM can reduce unnecessary costs and reduce unplanned downtime. Assisted by the Support Vector Machine (SVM) model, the CBM in this project aims to classify the motor condition in actual terms. Motorcycles in normal condition, shaft misalignment, and bearing damage are classified targets on this project. The classification of the condition of the motor refers to the historical data of the vibration and surface temperature of the actual motor. From the research that has been carried out the HVT100 sensor readings on the vibration value had an error of 2.16% and the surface temperature value of the motor had a error of 3.89% of 20 trials. Support Vector Machine (SVM) methods using multiclass strategies OneVsOne (OVO) and OneVsRest (OVR) can classify normal motor conditions, shaft misalignment, and bearing damage effectively with accuracy from 66% up to 100%."
Simulasi Performa Sistem Suspensi Semi Aktif Dengan Kendali PID Pada Kendaraan Roda Dua.,"Yahya, Nur Muhammad Adi",http://repository.its.ac.id/107805/,"Seiring dengan perkembangan sepeda motor dalam masyarakat, spesifikasi kendaraan roda dua masih terbatas pada suspensi standar yang menggunakan sistem pasif. Dimana sistem suspensi ini belum mampu secara optimal mengatasi getaran yang timbul akibat berbagai kondisi jalan. Ketidakmampuan mengisolasi getaran mengakibatkan ketidaknyamanan bagi pengendara. Pada proyek akhir ini, dilakukan perancangan simulasi sistem suspensi semi aktif yang dapat menghasilkan respon keseluruhan dari model kendaraan roda dua yang sesuai dengan standar kenyamanan ISO 2631 dengan menggunakan kendali PID. Metode autotuning digunakan untuk menentukan nilai parameter pengendali PID. Hasil autotuning menghasilkan nilai Kp = 36836, Ki = 212093, dan Kd = 17587. Perancangan simulasi dilakukan dengan variasi kecepatan yang berbeda yaitu 15 km/jam, 30 km/jam, dan 45 km/jam. Terdapat tiga jenis lintasan pengganggu jalan yang digunakan, yaitu step, impulse, dan sinusoidal. Perancangan ini bertujuan untuk mendapatkan hasil respon percepatan dan simpangan yang dialami  bodi kendaraan dari sistem suspensi semi aktif yang dibantu oleh gaya aktuator, dan membandingkannya dengan sistem suspensi pasif. Dari hasil simulasi yang dilakukan, sistem suspensi semi aktif yang dirancang dapat menghasilkan respon percepatan pada bodi kendaraan yang sesuai dengan ISO 2631. Seluruh parameter dari sistem suspensi semi aktif yang dirancang menghasilkan rentang nilai displacement 0.0005 – 0.006 m, nilai settling time selama 0.5 – 2s ,serta nilai a_{rms} sebesar 0.050 – 0.28 {m/s}^2,dimana nilai ini sudah sesuai dengan standar kenyamanan yang sudah ditetapkan ISO 2631 yaitu a_{rms}< 0.315 {m/s}^2.=================================================================================================================================Along with the development of motorbikes in society, the specifications of two-wheeled vehicles are still limited to standard suspensions that use passive systems. Where this suspension system has not been able to optimally overcome vibrations arising from various road conditions. The inability to isolate vibrations results in discomfort for the rider. In this final project, a semi-active suspension system simulation design is carried out that can produce an overall response from a two-wheeled vehicle model that complies with ISO 2631 comfort standards using PID control. The autotuning method is used to determine the value of the PID controller parameters. The autotuning results produce values of Kp = 36836, Ki = 212093, and Kd = 17587. The simulation design is carried out with different speed variations of 15 km/h, 30 km/h, and 45 km/h. There are three types of road disturbance trajectories used, namely step, impulse, and sinusoidal. This design aims to get the results of the acceleration and deviation response experienced by the vehicle body of the semi-active suspension system assisted by the actuator force, and compare it with the passive suspension system. From the simulation results, the designed semi-active suspension system can produce an acceleration response on the vehicle body in accordance with ISO 2631. All parameters of the designed semi-active suspension system produce a displacement value range of 0.0005 - 0.006 m, a settling time value of 0.5 - 2s, and a_{rms} value of 0.050 - 0.28 {m/s}^2., where this value is in accordance with the comfort standards set by ISO 2631, namely a_{rms} < 0.315 {m/s}^2."
Sistem Rejector Label Kemasan Susu Menggunakan Image processing Dengan Metode Support Vector Machine Pada Industri Pengolahan Susu.,"Yuliyanto, Jefrin",http://repository.its.ac.id/89605/,"Pada pabrik pengolahan susu, terdapat beberapa permasalahan saat pemasangan label kemasan botol susu. Permasalahan tersebut adalah terjadinya gagal pemasangan atau sobeknya label pada saat dilakukan pemasangan label botol. Problem tersebut menjadi jobdesk tersendiri pada suatu pabrik, yang menyebabkan produk belum layak jual. Sehingga memerlukan perbaikan pada label dan produk harus di reject terlebih dahulu. Maka dari itu dirancang sebuah alat yang dapat mendeteksi kerusakan atau gagal pemasangan pada label kemasan susu menggunakan image processing dengan metode Gray Level Co-occurance Matrix (GLCM) sebagai pendeteksi texture dari objek dengan mengeluarkan nilai energy, entropy, homogeneity, dan contrast. Kemudian hasil pembacaan GLCM akan dilakukan klasifikasi menggunakan support vector machine (SVM) untuk memilah kondisi label botol. Jika salah label botol cacat maka botol akan di reject dan jika sempurna atau normal akan lanjut ke proses pengemasan. Hasil dari alat rejector label kemasan susu ini, Ketika mendeteksi label kemasan botol susu secara random menghasilkan nilai accuracy sebesar 85%, precission 90%, dan False Positive Rate 20%, Ketika dilakukan pengujian keseluruhan didapat hasil %error sebesar 20%.=====================================================================================================In milk processing plants, there are several problems when installing milk bottle packaging labels. The problem is the occurrence of failed installation or tearing of the label when the bottle label is installed. The problem becomes a separate job desk in a factory, which causes the product to be unfit for sale. So it requires improvement on the label and the product must be rejected first. Therefore, a tool is designed that can detect damage or failure of installation on milk packaging labels using image processing with the Gray Level Co-occurance Matrix (GLCM) method as a texture detector of objects by issuing energy, entropy, homogeneity, and contrast values. Then the results of the GLCM reading will be classified using a support vector machine (SVM) to sort out the condition of the bottle label. If the wrong bottle label is defective, the bottle will be rejected and if it is perfect or normal, it will continue to the packaging process. The results of this milk packaging label rejector tool, when detecting milk bottle packaging labels randomly produce an accuracy value of 85%, precision 90%, and a False Positive Rate of 20%. When the overall test is carried out, the result is an error of 20%."
Analisis Sentimen Dan Clustering Pada Pengguna Tiket.Com Menggunakan Metode Naïve Bayes Classifier Dan Support Vector Machine.,"Yuniar, Iga Amalia",http://repository.its.ac.id/100403/,"Tiket.com adalah perusahaan agen untuk pelayanan perjalanan daring yang berbasis website dan aplikasi untuk mobile phone atau perangkat desktop. Aplikasi tiket.com juga disebut sebagai pionir online travel agent (OTA) terbesar di Indonesia yang selalu memberikan inovasi handal untuk mempermudah pengguna ketika memesan tiket pesawat online, selain itu aplikasi ini melayani pesanan untuk penginapan, sewa mobil maupun menawarkan berbagai macam aktifitas hiburan dan menjadi satu-satunya mitra resmi PT Kereta Api Indonesia. Penelitian ini melakukan penelitian dengan topik analisis sentimen terhadap pengguna tiket.com. Dengan bantuan analisis sentimen, informasi yang sebelumnya tidak terstruktur dapat dirubah menjadi data yang lebih terstruktur. Selain itu sistem analisis sentimen ini dapat membantu perusahaan dalam memahami keinginan pelanggan berdasarkan review atau umpan balik pelanggan yang tulus dan spesifik untuk meningkatkan kualitas produk dan layanan perusahaan. Penelitian ini melakukan perbandingan hasil analisis sentimen pengguna tiket.com dengan menggunakan metode Naïve Bayes Classifier dan Support Vector Machine untuk membandingkan tingkat akurasi yang lebih akurat. dan mengelompokkan review pengguna yang mana memberikan respon positif atau negatif. Akurasi terbaik diperoleh dari klasifikasi dengan menggunakan algoritma Support Vector Machine Kernel RBF dengan indikator kinerja dengan menggunakan akurasi sebesar 93,1%, AUC sebesar 64,3% dan GMean sebesar 53,5%. dan dengan berdasarkan analisis Cluster K-means terdapat 2 kelompok opini yang terbentuk yaitu opini bersentimen positif, negatif.=================================================================================================================================Tiket.com is an online travel agent company which is website based and an application for mobile phone or desktop. Tiket.com is also known as the pioneer of the biggest online travel agent (OTA) in Indonesia which always provides reliable innovation to make users easier when they order a plane online, this application also provides accommodation, rent car or any other entertainment and became the only official partner for PT. Kereta Api Indonesia. This study conducts research on sentiment analysis towards users of tiket.com users. By using sentiment analysis, the unstructured information can be transformed to well-structured data. Besides, this sentiment analysis system can help the company to figure out what users want based on honest and specific reviews to approve quality of the product and company services. Researchers want to compare the result of sentiment analysis of tiket.com users by using the methods of Naive Bayes Classifier and Support Vector Machine. This research is done by comparing the accuracy level of the methods so can get the method with the most accurate analysis result. And cluster user reviews based on their positive, and negative responses using K-Means clustering analysis. The best accuracy is obtained from classification by using Support Vector Machine kernel RBF algorithm with performance indicator by using accuracy as 93,1%, AUC as 64,3% and G-mean as 53,5%. Based on the K-means clustering analysis, two opinion clusters have been formed, namely positive sentiment, negative sentiment."
Pengembangan Algoritma Support Vector Machine (SVM) Multiclass untuk Prediktor Kategorik dengan Proportional Class Constraint.,"Yustanti, Wiyli",http://repository.its.ac.id/107355/,"Terdapat  tiga prinsip penting dalam pengelompokan Uang Kuliah Tunggal (UKT). Pertama, pengelompokan UKT harus berdasarkan pada tingkat kemampuan sosial ekonomi orang tua mahasiswa. Kedua, perguruan tinggi harus mencapai pendapatan negara bukan pajak (PNBP) melalui penerimaan pembayaran UKT berdasarkan target yang ditetapkan, dan yang ketiga adalah bahwa PTN sebagai lembaga pemerintah memiliki tanggung jawab sosial untuk menerima minimal 20% mahasiswa dari keluarga kurang mampu. Ketiga prinsip ini menjadi latar belakang utama dalam penelitian ini, sehingga dibutuhkan sebuah pengembangan metode klasifikasi UKT dengan memperhitungkan target penerimaan (revenue) PTN dan persyaratan proporsi minimal pada kelompok UKT rendah. Untuk penyelesaian masalah tersebut, perlu dikembangkan algoritma klasifikasi yang dapat mengakomodasi faktor kendala (constraint). Faktor kendala yang wajib ada adalah proporsi  kelas tertentu dari hasil klasifikasi (Proportional Class Constraint) dan jumlah minimal penerimaan UKT (revenue). Tipe variabel prediktor dari studi kasus penelitian ini adalah kategorik. Hasil kajian pustaka mendapatkan bahwa metode klasifikasi untuk prediktor kategorik yang secara langsung dapat digunakan adalah metode berbasis Kernel Density Classification (KDC). Akan tetapi, metode KDC memiliki keterbatasan dalam penambahan constraint pada model klasi-fikasinya, selain itu banyak penelitian yang menunjukkan bahwa kinerjanya masih dapat diungguli oleh metode Support Vector Machine (SVM). Pada metode SVM terdapat keterbatasan yaitu bahwa input algoritma harus bertipe numerik. Dengan demikian penelitian ini memberikan kontribusi, yaitu (1) pemilihan metode encoding prediktor kategorik yang mampu meningkatkan kinerja SVM multiclass pada tahap pre-processing, dan (2) pengembangan algoritma SVM multiclass dengan Proportional Class Constraint (SVM-ProClass). Penelitian ini meng-gunakan ordinal encoding dan menghasilkan algoritma SVM-ProClass dengan dua tahapan utama yaitu fase prediksi kelas dan fase pergeseran kelas (Birth-Death Process). Selanjutnya, algoritma SVM-ProClass diterapkan pada dataset UKT untuk menghasilkan dataset yang besifat separable dan imbalanced berbasis proporsi kelas, dimana kinerja dari dataset hasil SVM-ProClass memiliki nilai akurasi F1-Score rata-rata 99,22% dan berbeda secara signifikan dengan α=5% terhadap kinerja dataset tanpa  SVM-ProClass.===================================================================================================================================There are three important principles in grouping single tuition fees (UKT). First, the UKT grouping must be based on the socio-economic ability level of the student's parents. Second, universities must achieve non-tax state income (PNBP) through receipt of UKT payments based on set targets, and third, the public university as government institutions have a social responsibility to accept a minimum of 20% of students from underprivileged families. These three principles are the main background for this research, so it is necessary to develop a UKT classification method that takes into account university revenue targets and minimum proportion requirements in the low UKT group. To solve this problem, it is necessary to develop a classification algorithm that can accommodate constraint factors. The constraint factors that must be present are the proportion of a certain class from the classification results (proportional class constraint) and the minimum amount of UKT receipts (revenue). The type of predictor variable used in the case study is categorical. The results of the literature review found that the classification method for categorical predictors that can be directly used is the Kernel Density Classification (KDC) based method. However, the KDC method has limitations in adding constraints to the classification model; apart from that, many studies show that its performance can still be superior to the Support Vector Machine (SVM) method. There is a limitation to the SVM method, namely that the algorithm input cannot be of the categorical type. Thus, this research provides contributions, namely (1) selecting a categorical predictor encoding method that is able to improve multiclass SVM performance at the pre-processing stage and (2) developing a multiclass SVM algorithm with proportional class constraints (SVM-ProClass). This research uses ordinal encoding and produces the SVM-ProClass algorithm with two main stages, namely the class prediction phase and the class shift phase (Birth-Death Process). Next, the SVM-ProClass algorithm is applied to the UKT dataset to produce a separable and imbalanced dataset based on class proportions, where the performance of the SVM-ProClass dataset has an average F1-Score accuracy value of 99.22% and it is significantly different from the performance of the dataset without SVM-ProClass with α=5%."
Optimisasi Rate of Penetration (ROP) pada Operasi Drilling menggunakan Predictive Modelling dan Particle Swarm Optimization (PSO) untuk Meminimalkan Waktu dan Biaya (Studi Kasus : Sumur X Lapangan Mudi).,"Zahra, Haya Aqilah",http://repository.its.ac.id/109285/,"Operasi pemboran diketahui merepresentasikan 30% dari total biaya produksi pada sumur minyak dan gas. Biaya pemboran memiliki hubungan yang erat dengan waktu pemboran, yang mana semakin singkat waktu pemboran, maka biaya pemboran akan semakin murah, dan begitu juga sebaliknya. Parameter utama yang mempengaruhi secara langsung waktu pemboran adalah Rate of Penetration (ROP). Untuk itu, dalam memecahkan masalah biaya dan waktu pemboran, dilakukan penelitian untuk mengoptimasi ROP dengan mempertimbangan tiga parameter utama, yaitu Weight on Bit (WOB), Rotation per Minute(RPM),dan Flowrate. Metode Predictive Modelling dan Particle Swarm Optimization (PSO) diterapkan untuk mengoptimisasi ROP. Metode Predictive Modelling merupakan metode data-driven based yang menggantikan persamaan tradisional. Penelitian ini menggunakan empat model regresi, memungkinkan model untuk dapat mengidentifikasi hubungan kompleks antara parameter pemboran dengan membaca datahistoris yang diberikan. Empat algoritma predictive modelling yang disimulasikan lalu dievaluasi menggunakan nilai RMSE,R², MAE, dan MAPE. Random Forest Regressor dipilih sebagai model yang paling akurat dengan nilai R² mencapai 0.92. Optimisasi ROP memberikan hasil yang signifikan, yaitu pengurangan waktu pemboran sampai 6.2 hari dan biaya hingga Rp1,812,531.93 atau 16% lebih murah dari biaya aktual.=====================================================================================================================================Drilling operations are known to represent 30% of the total production cost in oil and gas wells. Drilling costs are closely related to drilling time; the shorter the drilling time, the cheaper the drilling costs, and vice versa. The primary parameter that directly influences drilling time is the Rate of Penetration (ROP). Therefore, to address the issues of drilling costs and time, a study was conducted to optimize ROP by considering three main parameters: Weight on Bit (WOB), Revolutions per Minute (RPM), and Flowrate. Predictive Modeling and Particle Swarm Optimization (PSO) methods were applied to optimize ROP. Predictive Modeling is a data-driven method that replaces traditional equations. This study utilized four regression models, allowing the model to identify complex relationships between drilling parameters by reading the provided historical data. Four predictive modeling algorithms were simulated and then evaluated using RMSE, R², MAE, and MAPE values. Random Forest Regressor was selected as the most accurate model with an R² value of 0.92. The ROP optimization yielded significant results, reducing drilling time by up to 6.2 days and costs by Rp1,812,531.93 or 16% cheaper than actual costs."
Deteksi Nodul Paru Pada Citra Ct Scan Berbasis Fitur Glcm Dan Rlm Menggunakan Metode Support Vector Machine (SVM).,"Zai'mah, Permatasari",http://repository.its.ac.id/87680/,"Kanker paru-paru merupakan salah satu jenis kanker yang memiliki  tingkat kematian yang tinggi di dunia. Untuk mengurangi angka kematian  tersebut, maka perlu dilakukan pendeteksian secara dini sehingga pasien dapat  diobati secepat mungkin. Salah satu proses pendeteksian yang dilakukan adalah  dengan cara screening yaitu menggunakan Computed Tomography (CT) scan.  Penelitian ini bertujuan untuk mengembangkan metode yang dapat membedakan karakteristik densitas nodul paru normal dan tidak. Tahap ekstraksi fitur tekstur  berbasis histogram dan Gray Level Co-occurrence Matrix (GLCM) dan (Run Length Matrix) RLM. Nilai fitur tekstur kemudian digunakan sebagai masukan  tahap klasifikasi menggunakan metode Support Vector Machine (SVM) dan  Neural Network Backpropagation. Berdasarkan pada hasil eksperimen,didapatkan bahwa metode SVM dapat mengenali nodul paru lebih baik dibandingkan aNN Backpropagation dengan nilai akurasi terbaik 85,3% sedangan nilai akursi aNN Backpropagation 77.7 % .Hasil ini menyediakan informasi bahwa deteksi nodul paru berdasarkan fitur glcm dan rlm yang dapat dideteksi lebih baik. Lebih jauh, memilih parameter C dan γ pada SVM dan nilai learning dan hidden layer pada aNN Backpropagation untuk mendapatkan hasil klasifikasi yang optimal dapat diemplementasikan untuk mendapatkan hasil yang lebih baik. Kata kunci : Kanker paru-paru, glcm, rlm, Klasifikasi fitur, aNN Backpropagation"
