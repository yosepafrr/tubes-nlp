Judul,Penulis,Link,Abstrak,Preprocessed_Judul,Preprocessed_Abstrak
Klasifikasi Aritmia Sinyal ECG Menggunakan Transformasi Wavelet Dan Analisa Statistik.,"Gusnam, Mu'thiana",http://repository.its.ac.id/95953/,"Pengenalan kelainan aritmia seseorang diketahui dengan melakukan rekam aktivitas jantung menggunakan Electrocardiogram (ECG). Rekaman ECG detak jantung dibagi menjadi gelombang P, QRS, dan T yang menunjukkan aktivitas kelistrikan jantung seperti depolarisasi atrium dari gelombang P, depolarisasi ventrikel dari kompleks QRS dan repolarisasi ventrikel maupun atrium dari segmen ST.",klasifikasi aritmia sinyal ecg transformasi wavelet analisa statistik,kenal lain aritmia rekam aktivitas jantung electrocardiogram ecg rekam ecg detak jantung bagi gelombang p qrs t aktivitas listrik jantung depolarisasi atrium gelombang p depolarisasi ventrikel kompleks qrs repolarisasi ventrikel atrium segmen st
"Klasifikasi Jenis Tumor Otak Meningioma, Glioma, Dan Pituitari Berbasis Hybrid Vgg-16 Dan Svm Untuk Diagnosis Praoperasi.","Hajjanto, Ariq  Dreiki",http://repository.its.ac.id/110912/,"Berdasarkan Global Cancer Statistic pada tahun 2020, kasus baru tumor otak dan CNS mencapai 308.102 dengan kematian mencapai 251.329 di seluruh dunia.  Di Indonesia sendiri, estimasi kejadian dan kematian pada tahun 2016 mencapai 6.337 dan 5.405 kasus. Banyak jenis tumor otak dengan variasi lokasi, ukuran, dan tingkat keganasan membuat melokalisasi dan klasifikasi tumor kompleks bagi ahli medis secara konvensional, menyebabkan kesalahan dalam penentuan jenis tumor otak karena perlu membaca hasil citra dalam jumlah yang sangat banyak. Keakuratan klasifikasi konvensional dapat dipengaruhi oleh beberapa faktor, seperti perbedaan subjektivitas individu dalam mengenali lokasi tumor, waktu, ketelitian, kelelahan, dan faktor manusia lainnya. Maka dari itu, dibutuhkan suatu metode dalam menghasilkan diagnosis tumor yang akurat dengan machine learning. Akan tetapi, penelitian yang menggunakan pendekatan machine learning sangat rentan akan overfitting disebabkan kurangnya dataset ataupun model arsitektur yang digunakan dan juga lamanya proses komputasi yang dibutuhkan. Oleh sebab itu, Pada penelitian ini diusulkan sistem klasifikasi hibrida dengan bantuan machine learning, yaitu menggunakan arsitektur/model VGG-16 dan Support Vector Machine (SVM). VGG-16 memiliki keunggulan dalam ekstraksi fitur hierarkis dan invariansi spasial yang memungkinkan identifikasi tumor dengan akurasi lebih tinggi. Output fitur jenis tumor otak dari VGG-16 direduksi menggunakan Principal Component Analysis (PCA), lalu diklasifikasi dengan bantuan SVM serta dioptimalkan dengan pengujian kombinasi kernel dan hyperparameter. Performa arsitektur dievaluasi menggunakan performance metrics dan komparasi model sebelumnya, yang memungkinkan penilaian objektif terhadap hasil yang dicapai. Hasil penelitian memberikan hasil untuk masing-masing metrik akurasi, presisi, recall¸f1-score, dan spesifisitas secara berturut-turut sebesar 96.9%, 97.3%, 96.67%, 96.67%, dan 99.97% dengan menggunakan kernel polynomial dengan hyperparameter C, degree, dan coef0 sebesar 10, 3, dan 0.5.============================================================According to the 2020 Global Cancer Statistics, there were 308,102 new cases of brain and CNS tumors, resulting in 251,329 deaths worldwide. In Indonesia alone, the estimated incidence and mortality in 2016 were 6,337 and 5,405 cases, respectively. The various types of brain tumors, with variations in location, size, and malignancy levels, make localization and classification complex for conventional medical professionals, leading to errors in brain tumor determination due to the need to analyze a vast amount of imaging results. Conventional classification accuracy can be influenced by factors such as individual subjectivity in recognizing tumor locations, timing, precision, fatigue, and other human factors. Therefore, a method is needed to produce accurate tumor diagnoses using machine learning. However, research using machine learning approaches is highly susceptible to overfitting due to the lack of datasets or the architectural models used and the lengthy computational processes required. Hence, this study proposes a hybrid classification system with the assistance of machine learning, utilizing the VGG-16 architecture/model and Support Vector Machine (SVM). VGG-16 excels in hierarchical feature extraction and spatial invariance, enabling higher accuracy in tumor identification. The output features of brain tumor types from VGG-16 are reduced using Principal Component Analysis (PCA) and then classified with the help of SVM, optimized by testing combinations of kernels and hyperparameters. The architecture performance is evaluated using performance metrics and comparison with previous models, allowing for an objective assessment of the achieved results. The study results for each metric of accuracy, precision, recall, f1-score, and specificity were 96.9%, 97.3%, 96.67%, 96.67%, and 99.97%, respectively, using the polynomial kernel with hyperparameters C, degree, and coef0 of 10, 3, and 0.5.",klasifikasi jenis tumor otak meningioma glioma pituitari bas hybrid vgg16 svm diagnosis praoperasi,dasar global cancer statistic 2020 tumor otak cns capai 308102 mati capai 251329 dunia indonesia estimasi jadi mati 2016 capai 6337 5405 jenis tumor otak variasi lokasi ukur tingkat ganas lokalisasi klasifikasi tumor kompleks ahli medis konvensional sebab salah tentu jenis tumor otak baca hasil citra akurat klasifikasi konvensional pengaruh faktor beda subjektivitas individu nali lokasi tumor teliti lelah faktor manusia butuh metode hasil diagnosis tumor akurat machine learning teliti dekat machine learning rentan overfitting sebab kurang dataset model arsitektur proses komputasi butuh teliti usul sistem klasifikasi hibrida bantu machine learning arsitekturmodel vgg16 support vector machine svm vgg16 milik unggul ekstraksi fitur hierarkis invariansi spasial identifikasi tumor akurasi output fitur jenis tumor otak vgg16 reduksi principal component analysis pca klasifikasi bantu svm optimal uji kombinasi kernel hyperparameter performa arsitektur evaluasi performance metrics komparasi model nilai objektif hasil capai hasil teliti hasil masingmasing metrik akurasi presisi recall f1score spesifisitas berturutturut 969 973 9667 9667 9997 kernel polynomial hyperparameter c degree coef0 10 3 05according to the 2020 global cancer statistics there were 308102 new cases of brain and cns tumors resulting in 251329 deaths worldwide in indonesia alone the estimated incidence and mortality in 2016 were 6337 and 5405 cases respectively the various types of brain tumors with variations in location size and malignancy levels make localization and classification complex for conventional medical professionals leading to errors in brain tumor determination due to the need to analyze a vast amount of imaging results conventional classification accuracy can be influenced by factors such as individual subjectivity in recognizing tumor locations timing precision fatigue and other human factors therefore a method is needed to produce accurate tumor diagnoses using machine learning however research using machine learning approaches is highly susceptible to overfitting due to the lack of datasets or the architectural models used and the lengthy computational processes required hence this study proposes a hybrid classification system with the assistance of machine learning utilizing the vgg16 architecturemodel and support vector machine svm vgg16 excels in hierarchical feature extraction and spatial invariance enabling higher accuracy in tumor identification the output features of brain tumor types from vgg16 are reduced using principal component analysis pca and then classified with the help of svm optimized by testing combinations of kernels and hyperparameters the architecture performance is evaluated using performance metrics and comparison with previous models allowing for an objective assessment of the achieved results the study results for each metric of accuracy precision recall f1score and specificity were 969 973 9667 9667 and 9997 respectively using the polynomial kernel with hyperparameters c degree and coef0 of 10 3 and 05
Pembuatan Sistem Visual Question Answering Berbasis Web Untuk Mendukung Pembelajaran Visual Anak TK Berbahasa Indonesia Menggunakan Deep Learning.,"Hanifah, Asiyah",http://repository.its.ac.id/102392/,"Seiring pesatnya perkembangan teknologi, Indonesia semakin gencar melakukan persiapan transformasi digital untuk menghadapi perubahan teknologi. Salah satunya adalah implementasi e-learning di berbagai sektor, termasuk pendidikan. E-learning telah diterapkan dalam pembelajaran taman kanak-kanak, termasuk pembelajaran visual. Bentuk pembelajaran visual pada e-learning dapat dibuat dengan pembangunan sistem visual question answering. Beberapa penelitian telah dibuat untuk pembangunan sistem visual question answering dan berhasil membuat sistem visual question answering dengan ilmu patologi dalam bahasa inggris, dan dataset objek di sekitar monas dalam bahasa indonesia. Oleh karena itu, dilakukan pengajuan pembuatan sistem visual question answering dengan dataset yang lebih umum dan dapat dikenali oleh anak TK berbahasa indonesia. Dadanya penelitian ini akan dapat membantu tenaga pendidik dalam kegiatan belajar mengajar yang lebih interaktif dalam e-learning. Penelitian ini menggunakan model Bootstrapping Language-Image Pre-training (BLIP) untuk proses pembuatan sistem visual question answering dan mengimplementasikan model No Language Left Behind (NLLB) pada input-output pertanyaan untuk menerjemahkan bahasa yang digunakan. Hasil implementasi kedua model BLIP dan NLLB berhasil membangun sistem visual question answering berbahasa indonesia. Berdasarkan hasil pengujiannya, dari beberapa pertanyaan yang mengandung 6 jenis jawaban: ya/tidak, kata benda, kata kerja, kata sifat, kata keterangan, dan numeral, sistem ini berhasil menjawab tepat untuk jenis jawaban ya/tidak, kata benda, kata kerja, dan kata keterangan dengan nilai ketepatan jawaban ya/tidak 100, kata benda 100, kata kerja 100, dan kata keterangan 87.5.===============================================================================================================================Along with the rapid development of technology, Indonesia is increasingly intensifying its digital transformation preparations to face the existing technological advancements. With the rapid development of technology, Indonesia is increasingly intensifying its preparations for digital transformation to face technological changes. One of these preparations involves the implementation of e-learning across various sectors, including education. E-learning has been applied in kindergarten education, including visual learning. Visual learning in e-learning can be achieved through the development of a visual question answering system. Several studies have been conducted on visual question answering systems and have successfully created such systems using pathology images in English and object datasets around Monas (National Monument) in Indonesian. Therefore, the author proposes the creation of a visual question answering system with a more general dataset that can be recognized by Indonesian-speaking kindergarten children. The purpose of this research is to assist educators in conducting more interactive e-learning activities. The research utilizes the Bootstrapping Language-Image Pre-training (BLIP) model for the development of the visual question answering system and implements the No Language Left Behind (NLLB) model for translating the language used in the input-output questions. The implementation results of both the BLIP and NLLB models successfully build a visual question answering system in the Indonesian language. Based on testing, the system can provide accurate answers for yes/no, nouns, verbs, and adverbial questions, with accuracy rates of 100% for yes/no, 100% for nouns, 100% for verbs, and 87.5% for adverbial questions, all of which contain six types of answers: yes/no, nouns, verbs, adjectives, adverbs, and numerals.",buat sistem visual question answering bas web dukung ajar visual anak tk bahasa indonesia deep learning,iring pesat kembang teknologi indonesia gencar siap transformasi digital hadap ubah teknologi salah satu implementasi elearning sektor didik elearning terap ajar taman kanakkanak ajar visual bentuk ajar visual elearning bangun sistem visual question answering teliti bangun sistem visual question answering hasil sistem visual question answering ilmu patologi bahasa inggris dataset objek monas bahasa indonesia aju buat sistem visual question answering dataset nali anak tk bahasa indonesia dada teliti bantu tenaga didik giat ajar ajar interaktif elearning teliti model bootstrapping languageimage pretraining blip proses buat sistem visual question answering implementasi model no language left behind nllb inputoutput terjemah bahasa hasil implementasi model blip nllb hasil bangun sistem visual question answering bahasa indonesia dasar hasil uji kandung 6 jenis yatidak benda kerja sifat terang numeral sistem hasil jenis yatidak benda kerja terang nilai tepat yatidak 100 benda 100 kerja 100 terang 875along with the rapid development of technology indonesia is increasingly intensifying its digital transformation preparations to face the existing technological advancements with the rapid development of technology indonesia is increasingly intensifying its preparations for digital transformation to face technological changes one of these preparations involves the implementation of elearning across various sectors including education elearning has been applied in kindergarten education including visual learning visual learning in elearning can be achieved through the development of a visual question answering system several studies have been conducted on visual question answering systems and have successfully created such systems using pathology images in english and object datasets around monas national monument in indonesian therefore the author proposes the creation of a visual question answering system with a more general dataset that can be recognized by indonesianspeaking kindergarten children the purpose of this research is to assist educators in conducting more interactive elearning activities the research utilizes the bootstrapping languageimage pretraining blip model for the development of the visual question answering system and implements the no language left behind nllb model for translating the language used in the inputoutput questions the implementation results of both the blip and nllb models successfully build a visual question answering system in the indonesian language based on testing the system can provide accurate answers for yesno nouns verbs and adverbial questions with accuracy rates of 100 for yesno 100 for nouns 100 for verbs and 875 for adverbial questions all of which contain six types of answers yesno nouns verbs adjectives adverbs and numerals
Analisis Prediksi Faktor Intensitas Tegangan Pada Sambungan Tubular Jacket Platform Berbasis Surrogate Model.,"Hardian, Muhammad Akbar",http://repository.its.ac.id/98455/,"Berdasarkan data SKK migas pada tahun 2016, 54,65% anjungan lepas pantai di Indonesia telah berumur lebih dari 20 tahun. Struktur yang telah melebihi umur operasinya perlu ditinjau ulang dari segi kekuatan struktur apakah masih mampu untuk beroperasi. Dalam penelitian ini, penulis akan berfokus pada analisis prediksi faktor intensitas tegangan pada struktur jacket berkaki empat berbasis surrogate model. Faktor intensitas tegangan merupakan faktor yang menentukan kelelahan pada sambungan tubular dengan metode fracture mechanics. Dalam rangkat meningkatkan akurasi dan mengoptimalkan waktu analisis dikembangkan surrogate model dari analisis variasi retak yang didapat dengan metode elemen hingga. Metode analisis yang digunakan dalam penelitian ini meliputi analisis statis inplace untuk analisis tegangan struktur secara global, analisis lokal sambungan tubular kritis, analisis retak pada tubular dengan titik tegangan kritis tertinggi, dan pemodelan faktor intensitas tegangan berbasis surrogate model menggunakan machine learning model SVM berdasarkan variasi kedalaman retak dan panjang retak. Analisis retak menggunakan 30 variasi model retak yang berada pada tegangan maksimum di analisis lokal metode elemen hingga. Analisis lokal struktur berdasarkan hasil analisis statis inplace global struktur dengan sambungan kritisnya adalah sambungan tubular multiplanar DKT. Diperoleh tegangan von-mises tertinggi pada brace 5 dengan tegangan sebesar 327 MPa. Hasil surrogate model variasi model retak dengan algoritma RBF memberikan hasil prediksi dengan validasi R2 dengan variabel rasio (a/2c) sebesar 1 lalu dengan algoritma SVM memberikan hasil prediksi dengan validasi R2 dengan variabel rasio (a/2c) sebesar 0,99.=================================================================================================================================Based on SKK Migas data in 2016, 54.65% of offshore platforms in Indonesia were over 20 years old. Structures that have exceeded their operational life need to be reviewed in terms of their structural strength to determine if they are still capable of operating. In this study, the author will focus on predicting the stress intensity factor on a four-legged jacket structure based on a surrogate model. The stress intensity factor is a factor that determines fatigue in tubular connections using fracture mechanics methods. To improve accuracy and optimize analysis time, a surrogate model was developed from the analysis of crack variations obtained using the finite element method. The analysis methods used in this study include static analysis in-place for global structural stress analysis, local critical tubular connection analysis, crack analysis in tubular with the highest critical stress point, and modeling of stress intensity factors based on a surrogate model using a machine learning SVM model based on variations in crack depth and crack length. Crack analysis used 30 crack model variations located at maximum stress in the local analysis of the finite element method. Local structural analysis is based on the results of global in-place static analysis of the structure with its critical connection, which is the DKT multiplanar tubular connection. The highest von-Mises stress was obtained at brace 5 with a stress of 327 MPa. The surrogate model results of crack model variations with the RBF algorithm provided a prediction result with a validation R2 value of 1 for the ratio variable (a/2c), while the SVM algorithm provided a prediction result with a validation R2 value of 0.99 for the ratio variable (a/2c).",analisis prediksi faktor intensitas tegang sambung tubular jacket platform bas surrogate model,dasar data skk migas 2016 5465 anjung lepas pantai indonesia umur 20 struktur lebih umur operasi tinjau ulang segi kuat struktur operasi teliti tulis fokus analisis prediksi faktor intensitas tegang struktur jacket kak bas surrogate model faktor intensitas tegang faktor tentu lelah sambung tubular metode fracture mechanics rangkat tingkat akurasi optimal analisis kembang surrogate model analisis variasi retak metode elemen metode analisis teliti liput analisis statis inplace analisis tegang struktur global analisis lokal sambung tubular kritis analisis retak tubular titik tegang kritis tinggi model faktor intensitas tegang bas surrogate model machine learning model svm dasar variasi dalam retak retak analisis retak 30 variasi model retak tegang maksimum analisis lokal metode elemen analisis lokal struktur dasar hasil analisis statis inplace global struktur sambung kritis sambung tubular multiplanar dkt oleh tegang vonmises tinggi brace 5 tegang 327 mpa hasil surrogate model variasi model retak algoritma rbf hasil prediksi validasi r2 variabel rasio a2c 1 algoritma svm hasil prediksi validasi r2 variabel rasio a2c 099based on skk migas data in 2016 5465 of offshore platforms in indonesia were over 20 years old structures that have exceeded their operational life need to be reviewed in terms of their structural strength to determine if they are still capable of operating in this study the author will focus on predicting the stress intensity factor on a fourlegged jacket structure based on a surrogate model the stress intensity factor is a factor that determines fatigue in tubular connections using fracture mechanics methods to improve accuracy and optimize analysis time a surrogate model was developed from the analysis of crack variations obtained using the finite element method the analysis methods used in this study include static analysis inplace for global structural stress analysis local critical tubular connection analysis crack analysis in tubular with the highest critical stress point and modeling of stress intensity factors based on a surrogate model using a machine learning svm model based on variations in crack depth and crack length crack analysis used 30 crack model variations located at maximum stress in the local analysis of the finite element method local structural analysis is based on the results of global inplace static analysis of the structure with its critical connection which is the dkt multiplanar tubular connection the highest vonmises stress was obtained at brace 5 with a stress of 327 mpa the surrogate model results of crack model variations with the rbf algorithm provided a prediction result with a validation r2 value of 1 for the ratio variable a2c while the svm algorithm provided a prediction result with a validation r2 value of 099 for the ratio variable a2c
Surrogate-Assisted Model Untuk Prediksi Umur Kelelahan Pada Sambungan Tubular Multiplanar Jacket Platform Berbasis Mekanika Kepecahan.,"Hardian, Muhammad Akbar",http://repository.its.ac.id/108251/,"Berdasarkan informasi yang disampaikan dalam presentasi SKK Migas pada The 3rd Indo Decomm in Oil and Gas Conference, Indonesia telah mengoperasikan 613 unit anjungan lepas pantai terpancang sejak produksi komersial pertama di daerah lepas pantai. Dari total anjungan, sebanyak 54.65% telah berusia lebih dari 20 tahun, sementara 24.63% memiliki usia antara 16-20 tahun. Dengan perpanjangan waktu operasinya, integritas struktur platform tua tentu akan menurun. Salah satu akibatnya potensial terjadi kegagalan struktur karena beban siklis dengan adanya retak yang mayoritas bermula dari bagian las sambungan tubular pada strukturnya. Penelitian ini bertujuan untuk mengembangkan model baru dalam memprediksi umur lelah sambungan tubular multi-planar DKT berbasis Mekanika Kepecahan (Fracture Mechanics) dengan lebih efektif melalui surrogate model. Dengan menganalisis parameter geometri yang dapat mempengaruhi keretakan dan membangkitkan surrogate model yang lebih akurat untuk memprediksi umur kelelahan sambungan tubular multi-planar DKT kritis pada pembebanan aksial, IPB, OPB, dan gabungan. Analisis tersebut berhasil mendapatkan tegangan kritis yang terdapat pada brace 5. Umur lelah hingga kedalaman retak kritis juga didapatkan pada pembebanan aksial, IPB, OPB, dan gabungan untuk digunakan sebagai data training pada pembangkitan surrogate model dengan 2 variasi algoritma machine learning. Penelitian ini menyimpulkan bahwa algoritma radial basis function memberikan hasil yang lebih baik pada pembangkitan surrogate model daripada algoritma kriging. Hasil error yang diberikan pada algoritma radial basis function adalah 0.3%====================================================================================================================================Based on information presented in SKK Migas' presentation at The 3rd Indo Decomm in Oil and Gas Conference, Indonesia has operated 613 units of offshore platforms since the first commercial production in offshore areas. Of the total platforms, 54.65% are more than 20 years old, while 24.63% are between 16-20 years old. With the extension of its operation time, the structural integrity of the old platform will certainly decrease. One of the potential consequences is structural failure due to cyclical loading with cracks, the majority of which originate in the welds of tubular joints in the structure. This research aims to develop a new model to more effectively predict the fatigue life of DKT multi-planar tubular joints based on Fracture Mechanics through a surrogate model. By analysing geometry parameters that can affect cracking and generating a more accurate surrogate model to predict the fatigue life of critical DKT multi-planar tubular joints under axial, IPB, OPB and combined loading. The analysis successfully obtained the critical stress located at brace 5. The fatigue life to critical crack depth was also obtained under axial, IPB, OPB, and combined loading to be used as training data for surrogate model generation with 2 variations of machine learning algorithms. This study concluded that radial basis function algorithm gives better results in surrogate model generation than kriging algorithm. The error result given in the radial basis function algorithm is 0.3%.",surrogateassisted model prediksi umur lelah sambung tubular multiplanar jacket platform bas mekanika pecah,dasar informasi presentasi skk migas the 3rd indo decomm in oil and gas conference indonesia operasi 613 unit anjung lepas pantai pancang produksi komersial daerah lepas pantai total anjung 5465 usia 20 2463 milik usia 1620 panjang operasi integritas struktur platform tua turun salah akibat potensial gagal struktur beban siklis retak mayoritas las sambung tubular struktur teliti tuju kembang model prediksi umur lelah sambung tubular multiplanar dkt bas mekanika pecah fracture mechanics efektif surrogate model analis parameter geometri pengaruh kereta bangkit surrogate model akurat prediksi umur lelah sambung tubular multiplanar dkt kritis beban aksial ipb opb gabung analisis hasil tegang kritis brace 5 umur lelah dalam retak kritis dapat beban aksial ipb opb gabung data training bangkit surrogate model 2 variasi algoritma machine learning teliti simpul algoritma radial basis function hasil bangkit surrogate model algoritma kriging hasil error algoritma radial basis function 03based on information presented in skk migas presentation at the 3rd indo decomm in oil and gas conference indonesia has operated 613 units of offshore platforms since the first commercial production in offshore areas of the total platforms 5465 are more than 20 years old while 2463 are between 1620 years old with the extension of its operation time the structural integrity of the old platform will certainly decrease one of the potential consequences is structural failure due to cyclical loading with cracks the majority of which originate in the welds of tubular joints in the structure this research aims to develop a new model to more effectively predict the fatigue life of dkt multiplanar tubular joints based on fracture mechanics through a surrogate model by analysing geometry parameters that can affect cracking and generating a more accurate surrogate model to predict the fatigue life of critical dkt multiplanar tubular joints under axial ipb opb and combined loading the analysis successfully obtained the critical stress located at brace 5 the fatigue life to critical crack depth was also obtained under axial ipb opb and combined loading to be used as training data for surrogate model generation with 2 variations of machine learning algorithms this study concluded that radial basis function algorithm gives better results in surrogate model generation than kriging algorithm the error result given in the radial basis function algorithm is 03
"Perancangan Sistem Deteksi Keausan Pahat Pada Mesin Milling Menggunakan ""Cubic SVM"".","Hikmah, Zahra Putri Nurul",http://repository.its.ac.id/100911/,"Kerusakan suatu mesin dapat terjadi begitu saja tanpa timbulnya suatu indikasi tertentu. Sehingga dibutuhkan suatu sistem monitoring yang dapat digunakan untuk mendeteksi suatu anomali dalam proses permesinan. Deteksi anomali merupakan suatu proses untuk mengidentifikasikan suatu error atau peristiwa yang tidak terduga. Penelitian ini bertujuan untuk mengetahui sinyal vibrasi atau sinyal arus, sinyal yang paling tepat digunakan untuk mendeteksi keausan pahat pada mesin milling 3 axis Matsura 510 menggunakan model machine learning cubic SVM dan juga untuk mengetahui pengaruh penggunaan dekomposisi sinyal EMD terhadap hasil klasifikasi data yang dihasilkan. Penelitian dimulai dari pengambilan data untuk mendapatkan sinyal arus dan sinyal vibrasi kemudian masing-masing sinyal di-prepocessing. Lalu setelah itu sinyal diubah menjadi numerical features melalui proses features extraction. Numerical features yang sudah didapatkan kemudian diseleksi menggunakan ANOVA supaya menghasilkan hasil performance metrics yang baik. Sebelum features diklasifikasikan dengan model machine learning, maka diperlukan validasi model untuk menghindari overfitting dan underfitting. Setelah itu features dapat diklasifikasikan dengan menggunakan dua proses yaitu proses training dan proses testing sehingga didapatkan prediksi mengenai kondisi mesin. Berdasarkan penelitian yang telah dilakukan dapat disimpulkan bahwa ternyata sinyal vibrasi dalam domain frekuensi yang diolah tanpa menggunakan EMD dapat digunakan untuk mendeteksi keasuan pahat pada mesin milling 3 axis Matsura 510. Hal tersebut dapat dibuktikan dengan nilai precision dan recall yang dihasilkan dari proses training dan testing. Pada proses training didapatkan nilai precision sebesar 94,7% dan recall sebesar 84,7%. Kemudian pada proses testing didapatkan nilai precision sebesar 90,1% dan recall sebesar 90,1%. ==============================================================================================================================Damage to a machine can occur without any indication. Therefore require monitoring system can be used to detect an anomaly in the machining process. Anomaly detection is a process to identify an error or unexpected event. This research aims to find out between vibration signals and current signals, which signals are the best to detect tool wear on Matsura 510 3-axis milling machine using a cubic SVM machine learning algorithm. In addition, this research also aims to determine the effect of using EMD signal decomposition on the resulting data classification results. The research begins with data collection to obtain current signals and vibration signals, then each signal is preprocessed. Then after that, the signal is converted into numerical features through the features extraction process. Numerical features that have been obtained are then selected using ANOVA to produce good performance metrics. Before features are classified with a machine learning model, it is necessary to validate the model to avoid overfitting and underfitting. After that, the features can be classified using two processes, the training process and the testing process so that predictions about the condition of the machine can be obtained. Based on the research that has been done, it would be concluded that it turns out that the vibration signal processed in frequency domain without using EMD can be used to detect the acidity of the tool on the Matsura 510 3-axis milling machine. That could be proved by the precision and recall values produced in training and testing data. In the training process, the precision value having a percentage of 94,7% and 84,7%. Then in the testing process obtained precision value of 90,1% and recall of 90,1%.",ancang sistem deteksi aus pahat mesin milling cubic svm,rusa mesin timbul indikasi butuh sistem monitoring deteksi anomali proses mesin deteksi anomali proses identifikasi error peristiwa duga teliti tuju sinyal vibrasi sinyal arus sinyal deteksi aus pahat mesin milling 3 axis matsura 510 model machine learning cubic svm pengaruh guna dekomposisi sinyal emd hasil klasifikasi data hasil teliti ambil data sinyal arus sinyal vibrasi masingmasing sinyal diprepocessing sinyal ubah numerical features proses features extraction numerical features dapat seleksi anova hasil hasil performance metrics features klasifikasi model machine learning validasi model hindar overfitting underfitting features klasifikasi proses proses training proses testing dapat prediksi kondisi mesin dasar teliti simpul sinyal vibrasi domain frekuensi olah emd deteksi asu pahat mesin milling 3 axis matsura 510 bukti nilai precision recall hasil proses training testing proses training dapat nilai precision 947 recall 847 proses testing dapat nilai precision 901 recall 901 damage to a machine can occur without any indication therefore require monitoring system can be used to detect an anomaly in the machining process anomaly detection is a process to identify an error or unexpected event this research aims to find out between vibration signals and current signals which signals are the best to detect tool wear on matsura 510 3axis milling machine using a cubic svm machine learning algorithm in addition this research also aims to determine the effect of using emd signal decomposition on the resulting data classification results the research begins with data collection to obtain current signals and vibration signals then each signal is preprocessed then after that the signal is converted into numerical features through the features extraction process numerical features that have been obtained are then selected using anova to produce good performance metrics before features are classified with a machine learning model it is necessary to validate the model to avoid overfitting and underfitting after that the features can be classified using two processes the training process and the testing process so that predictions about the condition of the machine can be obtained based on the research that has been done it would be concluded that it turns out that the vibration signal processed in frequency domain without using emd can be used to detect the acidity of the tool on the matsura 510 3axis milling machine that could be proved by the precision and recall values produced in training and testing data in the training process the precision value having a percentage of 947 and 847 then in the testing process obtained precision value of 901 and recall of 901
Pengembangan Smart Meter untuk Mendukung Home Energy Management System (HEMS) Mempertimbangkan Kualitas Daya Peralatan Rumah.,"Ibrahim, Ditya Addo",http://repository.its.ac.id/87579/,"Pertumbuhan penduduk pada negara berkembang seperti Indonesia menyebabkan peningkatan kebutuhan energi menjadi tantangan yang harus dihadapi. Konsumsi listrik sektor rumah tangga menjadi salah satu faktor tingginya kenaikan beban listrik di mana diketahui sektor tersebut menghasilkan 30% kerugian dari energi terdistribusi. Sedangkan dalam pemenuhan energi listrik sebesar 88% suplai masih berasal dari energi fosil. Sehingga upaya konservasi energi perlu digiatkan terutama pada kelistrikan rumah tangga, salah satunya dengan konsep Home Energy Management System (HEMS) untuk mengoptimasi penggunaan listrik pada rumah. Pada penelitian tugas akhir ini dilakukan pengembangan pada sistem smart meter untuk monitoring konsumsi daya listrik rumah pendukung HEMS dengan Non-Intrusive Load Monitoring (NILM) untuk memantau penggunaan baik daya total dan per beban aktif dengan kualitas daya peralatan sebagai tambahan parameter identifikasi. Dengan adanya NILM maka sistem dapat mengidentifikasi jenis beban aktif rumah hanya menggunakan satu sensor pada saluran listrik utama sehingga proses monitoring menjadi lebih mudah serta memakan biaya dan energi yang lebih rendah. Proses identifikasi menggunakan model pelatihan dengan implementasi Artificial Neural Network (ANN) dalam mengolah data pengukuran untuk menentukan jenis beban yang sedang menyala. Hasil dari simulasi menunjukkan bahwa dengan konfigurasi 50 hidden neuron, pelatihan ANN dapat memperoleh akurasi dengan MAPE sebesar 2,201% dalam mengidentifikasi beban listrik.",kembang smart meter dukung home energy management system hems timbang kualitas daya alat rumah,tumbuh duduk negara kembang indonesia sebab tingkat butuh energi tantang hadap konsumsi listrik sektor rumah tangga salah faktor tinggi naik beban listrik sektor hasil 30 rugi energi distribusi penuh energi listrik 88 suplai asal energi fosil upaya konservasi energi giat listrik rumah tangga salah satu konsep home energy management system hems mengoptimasi guna listrik rumah teliti tugas kembang sistem smart meter monitoring konsumsi daya listrik rumah dukung hems nonintrusive load monitoring nilm pantau guna daya total beban aktif kualitas daya alat tambah parameter identifikasi nilm sistem identifikasi jenis beban aktif rumah sensor salur listrik utama proses monitoring mudah makan biaya energi rendah proses identifikasi model latih implementasi artificial neural network ann olah data ukur tentu jenis beban nyala hasil simulasi konfigurasi 50 hidden neuron latih ann oleh akurasi mape 2201 identifikasi beban listrik
"Implementasi Aplikasi Artificial Neural Network (ANN) Backpropagation untuk Prediksi Debit Harian pada Stasiun Pos Duga Air, DAS Serang-Lusi, Jawa Tengah.","Ilahi, Rizqi Noer",http://repository.its.ac.id/113000/,"Hubungan antara hujan dan limpasan sangat erat. Sebagian hujan yang turun dari permukaan bumi terserap ke dalam tanah yang memungkinkan terjadi infiltrasi, dan sebagian lainnya mengalir ke saluran kecil hingga mencapai aliran sungai. Di tempat ini, limpasan terjadi ketika daratan tergenang oleh air hingga dapat menyebabkan banjir. Adanya sistem analisis yang dapat memprediksi dengan baik diperlukan untuk mengatasi masalah yang ada. Dalam praktiknya, memilih model untuk menganalisis dan menilai sistem DAS sangat sulit, namun, ini tidak berarti bahwa model yang ada tidak baik, salah satu model yang tersedia adalah penggunaan Jaringan Syaraf Tiruan (JST) atau Artificial Neural Network (ANN). Studi ini menyelidiki hasil perhitungan debit pemodelan Artificial Neural Network yang dilakukan menggunakan Matlab dan Python. Tujuan dari Tugas Akhir ini adalah untuk menghasilkan debit pemodelan ANN yang optimal dari model arsitektur jaringan yang digunakan. Untuk masukan program ANN, digunakan data curah hujan, evapotranspirasi, dan koefisien aliran. Data hujan dilakukan Uji konsistensi kurva massa ganda untuk menguji konsisteni data curah hujan. Selanjutnya, diambil hujan rerata kawasan menggunakan Polygon Thiessen. Sementara untuk luaran debit pemodelan dari program ANN ini adalah data debit yang diambil dari stasiun pos duga air. Hasil penelitian menunjukkan bahwa dalam pemodelan debit menggunakan ANN metode backpropagation memiliki kinerja yang sangat baik dengan nilai mean square error (MSE) terbaik adalah 0,032 untuk training, sedangkan untuk testing memiliki nilai MSE 0,047. Nilai keandalan atau akurasi program ANN ini mencapai 98%, yang artinya program ANN ini layak dijadikan metode pendekatan debit lapangan.=================================================================================================================================The relationship between rain and runoff is very close. Some of the rain that falls from the earth's surface is absorbed into the ground, which allows infiltration to occur, and some of it flows into small channels until it reaches the flow of rivers. In this place, runoff occurs when the land is flooded by water so that it can cause flooding. The existence of an analysis system that can predict well is necessary to overcome existing problems. In practice, choosing a model to analyze and assess a watershed system is very difficult, however, this does not mean that the existing model is not good, one of the available models is the use of Artificial Neural Network (JST) or Artificial Neural Network (ANN). This study investigated the results of the calculation of the Artificial Neural Network modeling discharge  conducted using Matlab and Python. The purpose of this Final Project is to produce optimal ANN modeling discharge from the network architecture model used. For the input of the ANN program, rainfall, evapotranspiration, and flow coefficient data are used. Rainfall data was carried out Double mass curve consistency test to test the consistency of rainfall data. Next, the average rainfall of the area was taken using Thiessen's Polygon. Meanwhile, the modeling discharge output of the ANN program is discharge data taken from the suspected water post station. The results show that in the discharge modeling using ANN, the backpropagation  method has excellent performance with  the best mean square error (MSE) value of 0.032 for training, while for testing it has an MSE value of 0.047. The reliability or accuracy value of this ANN program reaches 98%, which means that this ANN program is worthy of being used as a field debit approach method.",implementasi aplikasi artificial neural network ann backpropagation prediksi debit hari stasiun pos duga air das seranglusi jawa,hubung hujan limpas erat hujan turun muka bumi serap tanah infiltrasi alir salur capai alir sungai limpas darat genang air sebab banjir sistem analisis prediksi atas praktik pilih model analis nilai sistem das sulit model salah model sedia guna jaring syaraf tiru jst artificial neural network ann studi selidik hasil hitung debit model artificial neural network matlab python tuju tugas hasil debit model ann optimal model arsitektur jaring masuk program ann data curah hujan evapotranspirasi koefisien alir data hujan uji konsistensi kurva massa ganda uji konsisten data curah hujan ambil hujan rerata kawasan polygon thiessen luar debit model program ann data debit ambil stasiun pos duga air hasil teliti model debit ann metode backpropagation milik kerja nilai mean square error mse baik 0032 training testing milik nilai mse 0047 nilai andal akurasi program ann capai 98 program ann layak jadi metode dekat debit lapanganthe relationship between rain and runoff is very close some of the rain that falls from the earths surface is absorbed into the ground which allows infiltration to occur and some of it flows into small channels until it reaches the flow of rivers in this place runoff occurs when the land is flooded by water so that it can cause flooding the existence of an analysis system that can predict well is necessary to overcome existing problems in practice choosing a model to analyze and assess a watershed system is very difficult however this does not mean that the existing model is not good one of the available models is the use of artificial neural network jst or artificial neural network ann this study investigated the results of the calculation of the artificial neural network modeling discharge conducted using matlab and python the purpose of this final project is to produce optimal ann modeling discharge from the network architecture model used for the input of the ann program rainfall evapotranspiration and flow coefficient data are used rainfall data was carried out double mass curve consistency test to test the consistency of rainfall data next the average rainfall of the area was taken using thiessens polygon meanwhile the modeling discharge output of the ann program is discharge data taken from the suspected water post station the results show that in the discharge modeling using ann the backpropagation method has excellent performance with the best mean square error mse value of 0032 for training while for testing it has an mse value of 0047 the reliability or accuracy value of this ann program reaches 98 which means that this ann program is worthy of being used as a field debit approach method
Klasifikasi Diagnosa Pasien Berdasarkan Rekam Medis Elektronik Menggunakan Text Mining Dan Support Vector Machine.,"Jamaluddin, M.",http://repository.its.ac.id/86313/,"Rekam Medis Elektronik (RME) adalah elemen penting dari teknologi informasi di bidang kesehatan. RME adalah catatan elektronik yang berisi informasi terkait kesehatan pasien yang dapat dibuat dan dikelola oleh dokter dan staf yang berwenang di organisasi pelayanan kesehatan. RME adalah kerangka kerja untuk menentukan diagnosis dan pengobatan kepada pasien. RME memiliki format teks bebas dan tidak terstruktur yang membuat lebih sulit untuk menggali informasi tersembunyi sebagai sistem pendukung keputusan. Dalam thesis ini, dilakukan penelitian untuk klasifikasi dari RME berbahasa Indonesia sebagai Clinical Decision Support System (CDSS) dalam mengklasifikasikan diagnosis pasien menggunakan Term Frequency-Inverse Document Frequency (Tf-Idf) untuk ekstraksi fitur dan Support Vector Machine (SVM) untuk metode klasifikasi. Diagnosa yang diklasifikasikan dalam thesis ini adalah tuberkulosis, kanker, diabetes mellitus, hipertensi, dan gagal ginjal yang memiliki angka prevalensi tinggi di Indonesia.Model dibangun dengan mempertimbangkan fungsi kernel SVM serta penggunaan stopword removal atau tanpa stopword removal. Akurasi tertinggi didapatkan pada kernel RBF menggunakan stopword removal dan model n-gram (1-3) dengan nilai akurasi 91,71%. Hasil penelitian menunjukkan bahwa metode Tf-Idf dan SVM dapat digunakan secara efektif untuk memprediksi diagnosis.=====================================================================================================Electronic Medical Record (EMR) is an important element of information technology in health sector. EMR is an electronic record containing health-related information on an patient that can be created and managed by authorized physician and staff in a health service organization. EMR is a framework for determining diagnosis and treatment. EMR has free text and unstructured format which makes it more difficult to extract the hidden information as a decision support system. This study performs classification from Indonesian EMR for clinical decision support system (CDSS) in classifying patient diagnosis using Term Frequency-Inverse Document Frequency (Tf-Idf) for feature extraction and Support Vector Machine (SVM) for classifier method. The focus diagnoses classified in this paper are tuberculosis, cancer, diabetes mellitus, hypertension, and kidney failure which have high prevalence rates in Indonesia. The model is built by considering the kernel function and the use of stopword removal or without stopword removal. The highest accuracy is obtained in the RBF kernel with stopword removal and n-gram (1-3) by an accuracy value of 91.71%. The result showed that Tf-Idf and SVM method could be used effectively to predict diagnosis.",klasifikasi diagnosa pasien dasar rekam medis elektronik text mining support vector machine,rekam medis elektronik rme elemen teknologi informasi bidang sehat rme catat elektronik isi informasi kait sehat pasien kelola dokter staf wenang organisasi layan sehat rme kerangka kerja tentu diagnosis obat pasien rme milik format teks bebas struktur sulit gali informasi sembunyi sistem dukung putus thesis teliti klasifikasi rme bahasa indonesia clinical decision support system cdss klasifikasi diagnosis pasien term frequencyinverse document frequency tfidf ekstraksi fitur support vector machine svm metode klasifikasi diagnosa klasifikasi thesis tuberkulosis kanker diabetes mellitus hipertensi gagal ginjal milik angka prevalensi indonesiamodel bangun timbang fungsi kernel svm guna stopword removal stopword removal akurasi tinggi dapat kernel rbf stopword removal model ngram 13 nilai akurasi 9171 hasil teliti metode tfidf svm efektif prediksi diagnosiselectronic medical record emr is an important element of information technology in health sector emr is an electronic record containing healthrelated information on an patient that can be created and managed by authorized physician and staff in a health service organization emr is a framework for determining diagnosis and treatment emr has free text and unstructured format which makes it more difficult to extract the hidden information as a decision support system this study performs classification from indonesian emr for clinical decision support system cdss in classifying patient diagnosis using term frequencyinverse document frequency tfidf for feature extraction and support vector machine svm for classifier method the focus diagnoses classified in this paper are tuberculosis cancer diabetes mellitus hypertension and kidney failure which have high prevalence rates in indonesia the model is built by considering the kernel function and the use of stopword removal or without stopword removal the highest accuracy is obtained in the rbf kernel with stopword removal and ngram 13 by an accuracy value of 9171 the result showed that tfidf and svm method could be used effectively to predict diagnosis
Analisis Modifikasi Algoritma YOLO dengan Implementasi Convolutional Block Attention Module (CBAM) terhadap Performa Deteksi Penyu di Lingkungan Bawah Laut.,"Juliantono, Fadly Rachman Drajad",http://repository.its.ac.id/112272/,"Eksplorasi biota laut di seluruh dunia, termasuk Indonesia, memainkan peran penting dalam memahami keanekaragaman hayati dan ekosistem bawah air. Indonesia, bagian dari segitiga karang dunia, memiliki keragaman spesies yang luar biasa, namun penelitian terhadap potensi ini masih terbatas. Penyu, reptil laut yang telah ada selama jutaan tahun, sering menjadi daya tarik wisata utama dan memainkan peran penting dalam ekosistem laut. Konservasi penyu menjadi perhatian penting karena ancaman dari aktivitas manusia dan perubahan iklim. Dengan berkembangnya modernisasi, sektor pariwisata maritim di Indonesia tumbuh pesat, menempatkan tekanan pada ekosistem laut dan menegaskan kebutuhan akan manajemen dan pemantauan yang berkelanjutan. Sistem deteksi objek di lingkungan laut menghadapi tantangan seperti air keruh dan variasi pencahayaan yang mengurangi efektivitas teknologi tradisional. Oleh karena itu, pengembangan model berbasis Deep Learning seperti You Only Look Once (YOLO) menjadi sangat relevan. Penelitian ini mengeksplorasi penerapan YOLO yang dilengkapi dengan Convolutional Block Attention Module (CBAM) dalam pengaruh performa deteksi penyu di lingkungan bawah laut dan bertujuan untuk menguji akurasi dan kinerja model deteksi pada kamera bawah laut yang menggunakan mesin Jetson Nano Dev Kit. Model dengan performa tingkat akurasi tinggi didapatkan oleh YOLOv8n dengan CBAM dengan hasil mAP@0,5: 0,95 senilai 57,1% dan beban Param 8.0M serta FLOPs 8.3. Nilai ini naik sebesar 4% dibandingkan dengan YOLOv8n tanpa CBAM. Dengan performa yang dimiliki, model yang dideploy dapat mendeteksi objek secara real-time dan mendapatkan hingga 10 fps. Dengan pembuatan model ini, dapat digunakan sebagai groundtruth dari sistem deteksi penyu secara akurat dan dapat dikembangkan dengan fitur klasifikasi untuk di masa yang akan datang.===============================================================================================Exploration of marine biota worldwide, including Indonesia, plays a crucial role in understanding biodiversity and underwater ecosystems. Indonesia, being part of the world's coral triangle, boasts an extraordinary diversity of species, yet research into this potential remains limited. Sea turtles, marine reptiles that have existed for millions of years, often become major tourist attractions and play a vital role in marine ecosystems. Turtle conservation is a pressing concern due to threats from human activities and climate change. As modernization progresses, the maritime tourism sector in Indonesia is rapidly growing, putting pressure on marine ecosystems and underscoring the need for ongoing management and monitoring. Object detection systems in marine environments face challenges such as turbid water and varying lighting conditions that reduce the effectiveness of traditional technologies. Therefore, the development of Deep Learning-based models like You Only Look Once (YOLO) becomes highly relevant. This research explores the application of YOLO equipped with the Convolutional Block Attention Module (CBAM) to study its impact on the performance of turtle detection in underwater environments and aims to test the accuracy and performance of the detection model on underwater cameras using the Jetson Nano Dev Kit. The model enhanced by YOLOv8n with CBAM achieved high-performance metrics with a mean Average Precision (mAP) @ 0,5 of 57.1% and a parameter load of 8.0M and FLOPs of 8.3, showing a 4% improvement compared to YOLOv8n without CBAM. With its current capabilities, the deployed model can detect objects in real-time at a rate of 10 fps. With the creation of this model, it can serve as the ground truth for accurately detecting turtles and can be further developed with classification features for future applications.",analisis modifikasi algoritma yolo implementasi convolutional block attention module cbam performa deteksi penyu lingkung laut,eksplorasi biota laut dunia indonesia main peran paham keanekaragaman hayati ekosistem air indonesia segitiga karang dunia milik ragam spesies teliti potensi batas penyu reptil laut juta daya tarik wisata utama main peran ekosistem laut konservasi penyu perhati ancam aktivitas manusia ubah iklim kembang modernisasi sektor pariwisata maritim indonesia tumbuh pesat tempat tekan ekosistem laut butuh manajemen pantau lanjut sistem deteksi objek lingkung laut hadap tantang air keruh variasi cahaya kurang efektivitas teknologi tradisional kembang model bas deep learning you only look once yolo relevan teliti eksplorasi terap yolo lengkap convolutional block attention module cbam pengaruh performa deteksi penyu lingkung laut tuju uji akurasi kerja model deteksi kamera laut mesin jetson nano dev kit model performa tingkat akurasi dapat yolov8n cbam hasil map05 095 nila 571 beban param 80m flops 83 nilai 4 banding yolov8n cbam performa milik model dideploy deteksi objek realtime 10 fps buat model groundtruth sistem deteksi penyu akurat kembang fitur klasifikasi datangexploration of marine biota worldwide including indonesia plays a crucial role in understanding biodiversity and underwater ecosystems indonesia being part of the worlds coral triangle boasts an extraordinary diversity of species yet research into this potential remains limited sea turtles marine reptiles that have existed for millions of years often become major tourist attractions and play a vital role in marine ecosystems turtle conservation is a pressing concern due to threats from human activities and climate change as modernization progresses the maritime tourism sector in indonesia is rapidly growing putting pressure on marine ecosystems and underscoring the need for ongoing management and monitoring object detection systems in marine environments face challenges such as turbid water and varying lighting conditions that reduce the effectiveness of traditional technologies therefore the development of deep learningbased models like you only look once yolo becomes highly relevant this research explores the application of yolo equipped with the convolutional block attention module cbam to study its impact on the performance of turtle detection in underwater environments and aims to test the accuracy and performance of the detection model on underwater cameras using the jetson nano dev kit the model enhanced by yolov8n with cbam achieved highperformance metrics with a mean average precision map 05 of 571 and a parameter load of 80m and flops of 83 showing a 4 improvement compared to yolov8n without cbam with its current capabilities the deployed model can detect objects in realtime at a rate of 10 fps with the creation of this model it can serve as the ground truth for accurately detecting turtles and can be further developed with classification features for future applications
Klasifikasi Kanker Kulit Dari Citra Dermatoskopi Berbasis Convolutional Neural Network U-Net Dan Support Vector Machine.,"Junior, Amanda Sharon Purwanti",http://repository.its.ac.id/111710/,"Global Burden of Cancer Study (Globocan) dari World Health Organization (WHO), mencatat jumlah kasus kanker di Indonesia pada tahun 2020 mencapai 396.914 kasus, sementara total kematian akibat kanker mencapai 234.511 kasus. 5,9 – 7,8% dari total kasus kanker yang terjadi merupakan kanker kulit.  Tingkat kesembuhan dari kanker kulit dapat meningkat hingga 90% jika ditemukan sejak dini, namun deteksi dini dinilai cukup kompleks  dan cenderung subjektif sehingga diagnosis kanker kulit ini seringkali mengalami keterlambatan. Maka dari itu, mulai dikembangkan Computer-Aided Diagnostic (CAD), sebuah sistem diagnosis otomatis yang dirancang dengan tujuan meningkatkan akurasi diagnosis. Diagnosis otomatis pada citra dermatoskopi masih terhambat oleh variasi kompleks dalam tampilan. Dalam penelitian ini, diusulkan sistem yang terdiri dari preprocessing citra yang dilakukan untuk meningkatkan kualitas citra, segmentasi citra menggunakan U-Net yang dilakukan untuk memisahkan lesi dari latar citra, ekstraksi fitur menggunakan metode GLCM untuk menghitung kontras, energi, homogeneity, dan entropi citra pada sudut 0⁰, 45⁰, 90⁰, dan 135⁰ serta metode ABCD yang mengambil beberapa fitur bentuk dan warna pada citra yaitu asimetri(A), tepian atau border (B), warna atau colour (C), dan diameter(D). Terakhir dilakukan klasifikasi multilabel menggunakan Support Vector Machine dengan pendekatan One-Vs-Rest. Model dengan hasil terbaik dalam penelitian didapatkan dengan metode penyeimbangan data SMOTEENN yang merupakan gabungan dari metode SMOTE (Synthetic Minority Over-sampling Technique) dan ENN (Edited Nearest Neighbors) dengan penggunaan kernel Radial Basis Function (RBF) parameter C dan Gamma sebesar 1000 dan 0,1 dengan memakai 21 fitur. Hasil yang didapatkan dari model ini adalah nilai akurasi, presisi, sensitivitas, spesifisitas, dan MCC (Matthews Correlation Coefficient) sebesar 95,25%, 95,25%, 95,24%, 99,02%, dan 0,94.============================================================The Global Burden of Cancer Study (Globocan) by the World Health Organization (WHO) reported that the number of cancer cases in Indonesia in 2020 reached 396,914, with total cancer-related deaths reaching 234,511 cases. Skin cancer accounted for 5.9 - 7.8% of the total cancer cases. The cure rate can increase up to 90% with early detection, but early detection is considered complex and subjective, often leading to delayed skin cancer diagnosis. Consequently, a Computer-Aided Diagnostic (CAD) system, designed to enhance diagnostic accuracy, has been developed. Automated diagnosis of dermatoscopic images faces challenges due to complex variations in appearance. In this study, a system is proposed consisting of image preprocessing which is done to improve image quality, image segmentation using U-Net which is done to separate the lesion from the image background, feature extraction using the GLCM method to calculate contrast, energy, homogeneity, and entropy of the image at angles of 0⁰, 45⁰, 90⁰, and 135⁰ and the ABCD method which takes several shape and color features in the image, namely asymmetry (A), edge or border (B), color or color (C), and diameter (D). Finally, multilabel classification is performed using Support Vector Machine with One-Vs-Rest approach. The model with the best results in the study was obtained with the SMOTEENN data balancing method which is a combination of the SMOTE (Synthetic Minority Over-sampling Technique) and ENN (Edited Nearest Neighbors) methods with the use of Radial Basis Function (RBF) kernels with C and Gamma parameters of 1000 and 0,1 using 21 features. The results obtained from this model are the values of accuracy, precision, sensitivity, specificity, and MCC (Matthews Correlation Coefficient) of 95,25%, 95,25%, 95,24%, 99,02%, and 0,94.",klasifikasi kanker kulit citra dermatoskopi bas convolutional neural network unet support vector machine,global burden of cancer study globocan world health organization who catat kanker indonesia 2020 capai 396914 total mati akibat kanker capai 234511 59  78 total kanker kanker kulit tingkat sembuh kanker kulit tingkat 90 temu deteksi nilai kompleks cenderung subjektif diagnosis kanker kulit seringkali alami lambat kembang computeraided diagnostic cad sistem diagnosis otomatis rancang tuju tingkat akurasi diagnosis diagnosis otomatis citra dermatoskopi hambat variasi kompleks tampil teliti usul sistem preprocessing citra tingkat kualitas citra segmentasi citra unet pisah lesi latar citra ekstraksi fitur metode glcm hitung kontras energi homogeneity entropi citra sudut 0 45 90 135 metode abcd ambil fitur bentuk warna citra asimetria tepi border b warna colour c diameterd klasifikasi multilabel support vector machine dekat onevsrest model hasil baik teliti dapat metode imbang data smoteenn gabung metode smote synthetic minority oversampling technique enn edited nearest neighbors guna kernel radial basis function rbf parameter c gamma 1000 01 pakai 21 fitur hasil dapat model nilai akurasi presisi sensitivitas spesifisitas mcc matthews correlation coefficient 9525 9525 9524 9902 094the global burden of cancer study globocan by the world health organization who reported that the number of cancer cases in indonesia in 2020 reached 396914 with total cancerrelated deaths reaching 234511 cases skin cancer accounted for 59 78 of the total cancer cases the cure rate can increase up to 90 with early detection but early detection is considered complex and subjective often leading to delayed skin cancer diagnosis consequently a computeraided diagnostic cad system designed to enhance diagnostic accuracy has been developed automated diagnosis of dermatoscopic images faces challenges due to complex variations in appearance in this study a system is proposed consisting of image preprocessing which is done to improve image quality image segmentation using unet which is done to separate the lesion from the image background feature extraction using the glcm method to calculate contrast energy homogeneity and entropy of the image at angles of 0 45 90 and 135 and the abcd method which takes several shape and color features in the image namely asymmetry a edge or border b color or color c and diameter d finally multilabel classification is performed using support vector machine with onevsrest approach the model with the best results in the study was obtained with the smoteenn data balancing method which is a combination of the smote synthetic minority oversampling technique and enn edited nearest neighbors methods with the use of radial basis function rbf kernels with c and gamma parameters of 1000 and 01 using 21 features the results obtained from this model are the values of accuracy precision sensitivity specificity and mcc matthews correlation coefficient of 9525 9525 9524 9902 and 094
Prediksi Tingkat Peringatan Kebakaran Semak di Perth Australia Barat menggunakan Metode Support Vector Machine dan Random Forest.,"Kanedi, Fidela Jovita",http://repository.its.ac.id/116645/,"Australia mengalami peningkatan cuaca ekstrem akibat suhu lebih tinggi dan kekeringan yang parah dalam beberapa dekade terakhir. Pada musim semi 2023, bagian barat daya Australia Barat mengalami suhu maksimum bulanan jauh di atas rata-rata untuk Agustus, September, dan Oktober, mencatat suhu terpanas sejak 1910 dan termasuk dalam 10% teratas tahun-tahun paling panas yang tercatat. Perth, ibu kota Australia Barat, adalah kota keempat terpadat di Australia pada 2020 dengan tingkat rawan kebakaran semak mencapai 90%, yang menjadi masalah serius karena populasi yang padat. Perubahan iklim meningkatkan frekuensi dan intensitas cuaca ekstrem seperti gelombang panas lebih panjang dan kekeringan lebih parah. Untuk meningkatkan respons terhadap kebakaran semak di Perth, pendekatan prediktif sangat penting. Prediksi yang akurat tentang potensi kebakaran membantu pihak berwenang mengalokasikan sumber daya secara efisien dan merencanakan strategi pemadaman yang tepat. Tugas Akhir ini bertujuan memprediksi tingkat peringatan kebakaran semak di Perth menggunakan metode Support Vector Machine (SVM) dan Random Forest. Data dikumpulkan melalui teknik data scraping dari laman resmi Biro Meteorologi Australia Barat, diproses, dianalisis, dan digunakan untuk melatih model. Model terbaik dari Random Forest dan SVM menggunakan proporsi data latih sebesar 80%, data uji sebesar 20%, dan sembilan fitur terbaik. Model Random Forest mampu menghasilkan akurasi 93,93% dan F1-score 93,77%, sedangkan Model SVM mampu menghasilkan akurasi 91,5% dan F1-score 91,5%. Model yang dikembangkan diharapkan membantu pemerintah meminimalisir kebakaran semak di masa depan. =================================================================================================================================Australia has experienced increased extreme weather due to higher temperatures and severe droughts in recent decades. In the spring of 2023, the southwest part of Western Australia saw monthly maximum temperatures well above average for August, September, and October, recording the hottest temperatures since 1910 and ranking among the top 10% of the hottest years on record. Perth, the capital of Western Australia, was the fourth most populous city in Australia in 2020 with a bushfire vulnerability rate reaching 90%, posing a serious issue due to its dense population. Climate change is amplifying the frequency and intensity of extreme weather events such as prolonged heatwaves and more severe droughts. To enhance the response to bushfires in Perth, predictive approaches are crucial. Accurate predictions of fire potential assist authorities in allocating resources efficiently and planning appropriate firefighting strategies. This research aims to predict bushfire alert levels in Perth using Support Vector Machine (SVM) and Random Forest methods. Data was collected through web scraping techniques from the official website of the Bureau of Meteorology Western Australia, processed, analyzed, and used to train the models. The best model of Random Forest and SVM used a proportion of training data of 80%, test data of 20%, and nine best features. The Random Forest model was able to produce an accuracy of 93.93% and an F1-score of 93.77%, while the SVM model was able to produce an accuracy of 91.5% and an F1-score of 91.5%. The developed model is expected to provide insights that can be utilized by relevant government authorities to reduce the incidence of bushfires.",prediksi tingkat ingat bakar semak perth australia barat metode support vector machine random forest,australia alami tingkat cuaca ekstrem akibat suhu kering parah dekade musim semi 2023 barat daya australia barat alami suhu maksimum bulan ratarata agustus september oktober catat suhu panas 1910 10 atas tahuntahun panas catat perth kota australia barat kota empat padat australia 2020 tingkat rawan bakar semak capai 90 serius populasi padat ubah iklim tingkat frekuensi intensitas cuaca ekstrem gelombang panas kering parah tingkat respons bakar semak perth dekat prediktif prediksi akurat potensi bakar bantu wenang alokasi sumber daya efisien rencana strategi madam tugas tuju prediksi tingkat ingat bakar semak perth metode support vector machine svm random forest data kumpul teknik data scraping laman resmi biro meteorologi australia barat proses analis latih model model baik random forest svm proporsi data latih 80 data uji 20 sembilan fitur baik model random forest hasil akurasi 9393 f1score 9377 model svm hasil akurasi 915 f1score 915 model kembang harap bantu perintah meminimalisir bakar semak australia has experienced increased extreme weather due to higher temperatures and severe droughts in recent decades in the spring of 2023 the southwest part of western australia saw monthly maximum temperatures well above average for august september and october recording the hottest temperatures since 1910 and ranking among the top 10 of the hottest years on record perth the capital of western australia was the fourth most populous city in australia in 2020 with a bushfire vulnerability rate reaching 90 posing a serious issue due to its dense population climate change is amplifying the frequency and intensity of extreme weather events such as prolonged heatwaves and more severe droughts to enhance the response to bushfires in perth predictive approaches are crucial accurate predictions of fire potential assist authorities in allocating resources efficiently and planning appropriate firefighting strategies this research aims to predict bushfire alert levels in perth using support vector machine svm and random forest methods data was collected through web scraping techniques from the official website of the bureau of meteorology western australia processed analyzed and used to train the models the best model of random forest and svm used a proportion of training data of 80 test data of 20 and nine best features the random forest model was able to produce an accuracy of 9393 and an f1score of 9377 while the svm model was able to produce an accuracy of 915 and an f1score of 915 the developed model is expected to provide insights that can be utilized by relevant government authorities to reduce the incidence of bushfires
Perancangan Model untuk Prediksi Potensi Churn pada Debitur KPR dengan Regresi Logistik.,"Kasidi, Josua Christanto",http://repository.its.ac.id/92487/,"Kredit Kepemilikan Rumah (KPR) merupakan sistem pembiayaan dimana perbankan memberikan pinjaman kepada nasabah untuk mendapatkan rumah, dan melakukan pelunasan dalam waktu yang ditentukan. Oleh sebab itu, dalam persaingan bank di Indonesia, baik bank pemerintah maupun swasta kini berusaha untuk menawarkan program KPR kepada nasabah yang bertujuan agar nasabah merasa puas dengan pelayanan perbankan tersebut. Seiring dengan perjalanan umur KPR debitur, peristiwa churn customers (pelanggan yang meninggalkan perusahaan) dapat menjadi hal yang berdampak bagi pertumbuhan portfolio KPR serta membuat turunnya hubungan antara bank dengan nasabah.Hingga kini, salah satu bank yang terus berusaha untuk mengatasi permasalahan churn customers adalah Bank Mandiri. Namun dalam menjawab tantangan tersebut terdapat beberapa permasalahan yang menjadi halangan untuk dapat menyelesaikannya. Salah satu permasalahan tersebut adalah kurangnya informasi mengenai faktor yang mempengaruhi churn customers akibat analisis yang terbatas karena jumlah perbandingan populasi yang tidak seimbang.. Oleh sebab itu, tujuan dari penelitian ini adalah untuk membuat model prediktif yang mampu melakukan klasifikasi terhadap nasabah churn pada produk KPR agar Bank Mandiri dapat melakukan retensi sedini mungkin.Proses yang dilakukan untuk dapat mencapai tujuan tersebut dapat dimulai dengan mengelompokan kelompok nasabah menjadi data biner, dimana akan terdapat nasabah churn dan nasabah loyal. Kemudian penelitian dilanjutkan dengan mengumpulkan faktor-faktor yang terduga mempengaruhi nasabah churn, antara lain Recency, Frequency, dan Monetary (RFM), saldo tabungan, penghasilan, tagihan, Debt Burden Ratio (DBR), usia, rate, dan Debt Equity Ratio (DER), dan sisa plafon. Data yang digunakan pada penelitian ini adalah data sejarah transaksi, dana, dan kredit nasabah yang dimulai pada tahun 2019 – Mei 2021 yang terdiri dari 50,000 nasabah KPR. Data yang diperoleh akan dilanjutkan dengan melakukan pemodelan menggunakan regresi logistik biner. Untuk hasil pengujian, model yang digunakan akan diuji menggunakan nilai Receiver Operating Characteristic (ROC) dan Area Under Curve (AUC) sebagai nilai kelayakan dalam pengujian model data. Hasil akhir dari model ini diperoleh 7 variabel yang berpengaruh terhadap model disertai dengan nlai AUC dari logistik biner original sebesar 0.68 dan logistik biner SMOTE sebesar 0.72.================================================================================================A mortgage is a loan or financing system whereas banks provide loans to customers to get houses and make repayments within a specified time. Therefore, in banking competition in Indonesia, both state and private banks are now trying to offer mortgage to customers so that customers feel satisfied with banking services. The more customers who take mortgages will certainly have an impact on the quality of a bank's mortgage portfolio. Along with the age of mortgage loan, churn customers can have an impact on the growth of the mortgage portfolio and reduce the relationship between the bank and the customer.	Until now, one of the banks that continues to try to overcome the problem of churn customers is Bank Mandiri. However, in responding to these challenges, there are several problems that become obstacles to solve them. The lack of information about factor that affect churn customers still limited due to lack of information in unbalanced population. As a result, it will have an impact on mitigation actions that can be taken by banks before customer’s churn. Therefore, the purpose of this study is to create a predictive model that is able to classify churn customers on mortgage products so that Bank Mandiri can do retention just in time.	The process carried out to achieve this goal can be started by grouping customer groups into binary data, where there will be churn customers and loyal customers. Then the research continued by collecting factors that were suspected of influencing churn customers, including Recency, Frequency, and Monetary (RFM), savings balances, income, bills, Debt Burden Ratio (DBR), age, rate, Debt Equity Ratio (DER) and outstanding amount. The data used in this study is transaction history data, funds, and customer credit starting in 2019 – May 2021, consisting of 50,000 mortgage customers. The data obtained will be continued by modeling using binary logistic regression algorithm. For model validation, the model used will be tested using the Receiver Operating Characteristic (ROC) and Area Under Curve (AUC) values as the value of the feasibility of testing the data model. Then from the test results will be obtained a model to look for opportunities or predictive value and identification of the significant parameters that influence it based on the value of the important features. The final result of this model obtained 7 variabels that affect the model accompanied by the AUC value of the original binary logistic of 0.68 and the SMOTE binary logistic of 0.72.",ancang model prediksi potensi churn debitur kpr regresi logistik,kredit milik rumah kpr sistem biaya mana perban pinjam nasabah rumah lunas tentu saing bank indonesia bank perintah swasta usaha tawar program kpr nasabah tuju nasabah puas layan perban iring jalan umur kpr debitur peristiwa churn customers langgan tinggal usaha dampak tumbuh portfolio kpr turun hubung bank nasabahhingga salah bank usaha atas masalah churn customers bank mandiri tantang masalah halang selesai salah masalah kurang informasi faktor pengaruh churn customers akibat analisis batas banding populasi imbang tuju teliti model prediktif klasifikasi nasabah churn produk kpr bank mandiri retensi din mungkinproses capai tuju kelompok kelompok nasabah data biner mana nasabah churn nasabah loyal teliti lanjut kumpul faktorfaktor duga pengaruh nasabah churn recency frequency monetary rfm saldo tabung hasil tagih debt burden ratio dbr usia rate debt equity ratio der sisa plafon data teliti data sejarah transaksi dana kredit nasabah 2019  mei 2021 50000 nasabah kpr data oleh lanjut model regresi logistik biner hasil uji model uji nilai receiver operating characteristic roc area under curve auc nilai layak uji model data hasil model oleh 7 variabel pengaruh model serta nlai auc logistik biner original 068 logistik biner smote 072a mortgage is a loan or financing system whereas banks provide loans to customers to get houses and make repayments within a specified time therefore in banking competition in indonesia both state and private banks are now trying to offer mortgage to customers so that customers feel satisfied with banking services the more customers who take mortgages will certainly have an impact on the quality of a banks mortgage portfolio along with the age of mortgage loan churn customers can have an impact on the growth of the mortgage portfolio and reduce the relationship between the bank and the customer until now one of the banks that continues to try to overcome the problem of churn customers is bank mandiri however in responding to these challenges there are several problems that become obstacles to solve them the lack of information about factor that affect churn customers still limited due to lack of information in unbalanced population as a result it will have an impact on mitigation actions that can be taken by banks before customer  s churn therefore the purpose of this study is to create a predictive model that is able to classify churn customers on mortgage products so that bank mandiri can do retention just in time the process carried out to achieve this goal can be started by grouping customer groups into binary data where there will be churn customers and loyal customers then the research continued by collecting factors that were suspected of influencing churn customers including recency frequency and monetary rfm savings balances income bills debt burden ratio dbr age rate debt equity ratio der and outstanding amount the data used in this study is transaction history data funds and customer credit starting in 2019  may 2021 consisting of 50000 mortgage customers the data obtained will be continued by modeling using binary logistic regression algorithm for model validation the model used will be tested using the receiver operating characteristic roc and area under curve auc values as the value of the feasibility of testing the data model then from the test results will be obtained a model to look for opportunities or predictive value and identification of the significant parameters that influence it based on the value of the important features the final result of this model obtained 7 variabels that affect the model accompanied by the auc value of the original binary logistic of 068 and the smote binary logistic of 072
Rancang Bangun Plugin Ekstraksi Materi Belajar Berdasarkan Materi Prasyarat pada LMS Moodle.,"Khairunnisa, Aprilia",http://repository.its.ac.id/78014/,"Saat ini banyak instansi pendidikan yang melakukan sistem pembelajaran menggunakan e-learning, begitu juga dengan Departemen Informatika Institut Teknologi Sepuluh Nopember (ITS). Proses pembelajaran menggunakan e-learning memiliki banyak manfaat salah satunya adalah memungkinkan mahasiswa untuk dapat belajar secara mandiri. Saat proses belajar mandiri, mahasiswa dapat menentukan sendiri mata kuliah apa yang ingin dipelajari. Dalam suatu mata kuliah terdapat mata kuliah prasyarat yang harus dipenuhi untuk dapat melanjutkan ke mata kuliah berikutnya. Mata kuliah prasyarat sangat penting untuk mengetahui gambaran materi apa saja yang akan dipelajari dalam mata kuliah tertentu. Namun pada saat ini sistem pembelajaran berbasis e-learning seperti Moodle, belum memberikan fitur untuk dapat mengetahui mata kuliah prasyarat dari sebuah mata kuliah. Selain itu, mata kuliah prasyarat seringkali dicantumkan dalam deskripsi mata kuliah. Hal ini dapat dimanfaatkan untuk mengetahui mata kuliah prasyarat secara lebih mudah.Untuk menentukan mata kuliah prasyarat dari suatu deskripsi diperlukan ekstraksi untuk mendeteksi entitas mata kuliah. Named Entity Recognition (NER) dapat digunakan sebagai solusi untuk melakukan ekstraksi entitas kata. Proses ekstraksi diawali dengan membuat model NER berbahasa Indonesia dengan menggunakan SpaCy dan alat bantu anotasi Prodigy. Selanjutnya hasil anotasi akan diintegrasikan kedalam plugin moodle. Plugin yang akan dibangun bertipe block, dimana plugin ini menampilkan data mata kuliah berserta mata kuliah prasyarat.Maka dari itu, pembuatan plugin ekstraksi materi belajar berdasarkan materi prasyarat pada LMS (Learning Management System) Moodle ini diusulkan sebagai solusi dari permasalahan diatas. Plugin ini dikembangkan melalui Moodle dikarenakan Moodle merupakan salah satu LMS berbasis web yang banyak digunakan pada e-learning. Dengan adanya plugin ini, pengguna yaitu mahasiswa maupun tenaga pengajar dapat melihat mata kuliah prasyarat dari suatu mata kuliah dengan mudah.=========================================================At present many of educational institutions are conducting learning system using e-learning based, as well as in Information Departement Sepuluh Nopember Institute of Technology (ITS). The learning process of e-learning based has many benefits, one of them is for students to be able to learn independently. In the process of independent learning, students can determine their own subjects what they what to learn. In a course, the are certainly prerequisite courses that must be finished to be able to proceed to the next course. The prerequisite courses are very important to know what material will be studied in certain course. But at this time learning sistem based of e-learning such as Moodle, have not provided features to be able to know the prerequisite courses from a course. Beside that, course prerequisite are often indicated in course description. This can be used to find out what is the course prerequisite easily.To determine the prerequisite courses from a description, extraction is needed to detect entity subjects. Named Entity Recognition (NER) can be used as a solution for doing extraction word entities. The extraction process begins by creating an Indonesan-language NER model using SpaCy and Prodigy annotation tools. Then the annotation results will be integrated into moodle plugin. Plugin that will be built are block type, where the plugin will display course data along with prerequisite courses.Therefore, the creation of a learning material extraction plugin based on the prerequisite material on the Moodle LMS (Learning Management System) is proposed as a solution to the above problem. This plugin will be developed through Moodle because Moodle is one of the web-based LMS that is widely used in e-learning system. With this plugin, users which are students and teachers, can see prerequisite courses from a subject easily.",rancang bangun plugin ekstraksi materi ajar dasar materi prasyarat lms moodle,instansi didik sistem ajar elearning departemen informatika institut teknologi puluh nopember its proses ajar elearning milik manfaat salah satu mahasiswa ajar mandiri proses ajar mandiri mahasiswa tentu mata kuliah ajar mata kuliah mata kuliah prasyarat penuh lanjut mata kuliah mata kuliah prasyarat gambar materi ajar mata kuliah sistem ajar bas elearning moodle fitur mata kuliah prasyarat mata kuliah mata kuliah prasyarat seringkali cantum deskripsi mata kuliah manfaat mata kuliah prasyarat mudahuntuk tentu mata kuliah prasyarat deskripsi ekstraksi deteksi entitas mata kuliah named entity recognition ner solusi ekstraksi entitas proses ekstraksi awal model ner bahasa indonesia spacy alat bantu anotasi prodigy hasil anotasi integrasi dalam plugin moodle plugin bangun tipe block mana plugin tampil data mata kuliah serta mata kuliah prasyaratmaka buat plugin ekstraksi materi ajar dasar materi prasyarat lms learning management system moodle usul solusi masalah atas plugin kembang moodle moodle salah lms bas web elearning plugin guna mahasiswa tenaga ajar mata kuliah prasyarat mata kuliah mudahat present many of educational institutions are conducting learning system using elearning based as well as in information departement puluh nopember institute of technology its the learning process of elearning based has many benefits one of them is for students to be able to learn independently in the process of independent learning students can determine their own subjects what they what to learn in a course the are certainly prerequisite courses that must be finished to be able to proceed to the next course the prerequisite courses are very important to know what material will be studied in certain course but at this time learning sistem based of elearning such as moodle have not provided features to be able to know the prerequisite courses from a course beside that course prerequisite are often indicated in course description this can be used to find out what is the course prerequisite easilyto determine the prerequisite courses from a description extraction is needed to detect entity subjects named entity recognition ner can be used as a solution for doing extraction word entities the extraction process begins by creating an indonesanlanguage ner model using spacy and prodigy annotation tools then the annotation results will be integrated into moodle plugin plugin that will be built are block type where the plugin will display course data along with prerequisite coursestherefore the creation of a learning material extraction plugin based on the prerequisite material on the moodle lms learning management system is proposed as a solution to the above problem this plugin will be developed through moodle because moodle is one of the webbased lms that is widely used in elearning system with this plugin users which are students and teachers can see prerequisite courses from a subject easily
Rancang Bangun Stetoskop Elektronik Berbasis Android untuk Identifikasi Sinyal Suara Jantung.,"Khansa, Shalfienna Alya",http://repository.its.ac.id/102340/,"Penyakit jantung merupakan salah satu penyebab utama kematian di dunia dan masih menjadi penyebab kematian tertinggi di Indonesia. Kondisi geografis Indonesia yang terdiri dari 7000 pulau menyebabkan proses penanganan penyakit jantung lebih sulit, terutama pada daerah terpencil. Proses deteksi dini penyakit jantung perlu dilakukan sebagai upaya mengurangi angka kematian. Namun proses deteksi dini dari penyakit jantung menjadi tantangan yang sulit, karena membutuhkan biaya yang mahal dan bergantung dengan petugas medis untuk hasil deteksi yang akurat. Seiring berkembangnya teknologi, smartphone mulai bermunculan dengan kemampuan yang semakin canggih dan dapat mendukung perkembangan aplikasi mobile health sebagai solusi untuk pemantauan kesehatan jarak jauh. Dalam Tugas Akhir ini, dirancang stetoskop yang terhubung dengan smartphone berbasis android untuk proses analisa sinyal suara jantung menggunakan aplikasi. Aplikasi akan dilengkapi metode identifikasi suara sehingga dapat mengurangi ketergantungan pengguna dengan petugas medis. Sinyal suara jantung akan diproses menggunakan metode Discrete Wavelet Transform untuk denoising dan metode Linear Envelope untuk pemrosesan suara jantung. Alat dirancang dengan menggunakan stetoskop berbiaya rendah yang membedakan dengan stetoskop elektronik di pasaran. Dari proses identifikasi sinyal suara jantung yang dilakukan dengan 20 subjek, 75% dari data perekaman sinyal jantung menghasilkan keluaran identifikasi yang akurat. Data sinyal PCG, pemrosesan, dan hasil ditampilkan pada aplikasi android secara optimal.===================================================================================================================================Heart disease is one of the leading causes of death worldwide and the highest cause of death in Indonesia. The geographic conditions of Indonesia, comprising over 7000 islands, engender significant challenges in managing heart disease, particularly in remote and underdeveloped areas. Early detection is critical for reducing mortality rates associated with heart disease. However, this process poses challenges due to its high cost and reliance on clinicians for accurate detection. With technological advancements, smartphones have emerged with increasingly advanced capabilities, supporting the development of mobile health applications for remote health monitoring. This research aims to create an electronic stethoscope that connects to an Android-based smartphone application for heart sound signal identification. The application offers a reliable validation method to reduce dependency on clinicians. The process of heart sound signal uses the 5^th levels of the Discrete Wavelet Transform method for denoising and the Linear Envelope method for heart sound identification. The instrument design incorporates a cost-effective stethoscope, distinguishing it from existing electronic stethoscopes in the market. The heart sound identification method was applied to 20 individuals, revealing that 75% of the recorded heart signal data generated precise identification results. The Android application effectively showcases PCG signal data, processing, and outcomes.",rancang bangun stetoskop elektronik bas android identifikasi sinyal suara jantung,sakit jantung salah sebab utama mati dunia sebab mati tinggi indonesia kondisi geografis indonesia 7000 pulau sebab proses tangan sakit jantung sulit daerah pencil proses deteksi sakit jantung upaya kurang angka mati proses deteksi sakit jantung tantang sulit butuh biaya mahal gantung tugas medis hasil deteksi akurat iring kembang teknologi smartphone muncul mampu canggih dukung kembang aplikasi mobile health solusi pantau sehat jarak tugas rancang stetoskop hubung smartphone bas android proses analisa sinyal suara jantung aplikasi aplikasi lengkap metode identifikasi suara kurang gantung guna tugas medis sinyal suara jantung proses metode discrete wavelet transform denoising metode linear envelope pemrosesan suara jantung alat rancang stetoskop biaya rendah beda stetoskop elektronik pasar proses identifikasi sinyal suara jantung 20 subjek 75 data rekam sinyal jantung hasil keluar identifikasi akurat data sinyal pcg pemrosesan hasil tampil aplikasi android optimalheart disease is one of the leading causes of death worldwide and the highest cause of death in indonesia the geographic conditions of indonesia comprising over 7000 islands engender significant challenges in managing heart disease particularly in remote and underdeveloped areas early detection is critical for reducing mortality rates associated with heart disease however this process poses challenges due to its high cost and reliance on clinicians for accurate detection with technological advancements smartphones have emerged with increasingly advanced capabilities supporting the development of mobile health applications for remote health monitoring this research aims to create an electronic stethoscope that connects to an androidbased smartphone application for heart sound signal identification the application offers a reliable validation method to reduce dependency on clinicians the process of heart sound signal uses the 5th levels of the discrete wavelet transform method for denoising and the linear envelope method for heart sound identification the instrument design incorporates a costeffective stethoscope distinguishing it from existing electronic stethoscopes in the market the heart sound identification method was applied to 20 individuals revealing that 75 of the recorded heart signal data generated precise identification results the android application effectively showcases pcg signal data processing and outcomes
Pengujian dan Kalibrasi Bubble Detector Photoelectric Infrared pada Mesin Hemodialisis.,"Kirana, Berliana Shafa",http://repository.its.ac.id/112721/,"Hemodialisis adalah prosedur medis yang digunakan untuk menggantikan fungsi ginjal yang rusak. Selama dialisis untuk pasien gagal ginjal dapat muncul gelembung udara dalam darah. Detektor gelembung merupakan salah satu bagian penting dalam proses ini, karena detektor gelembung akan mendeteksi adanya bubble dalam aliran Venous Catheter. Kehadiran bubble dalam sistem vena dapat mengakibatkan kondisi syok atau henti jantung yang berpotensi fatal. Studi sebelumnya telah mengembangkan detektor microbubble menggunakan teknologi Photoelectric Infrared. Sebelumnya dalam memaksimalkan pembacaan dilakukan penyesuaian pancaran sinar infrared dalam memaksimalkan pancaran saja dan belum dilakukan kalibrasi dan pengujian menggunakan darah. Dilakukan  pengujian menggunakan air, performa deteksi bubble setelah dilakukan kalibrasi meningkat dimana error yang dimilikin oleh sensor infrared 0,01060071, dan menjadi 0,00003964, sedangkan akurasi sensor 0,9 menjadi 0,99 dan presisi 0,85 menjadi 0,99. Hasil kalibrasi menggunakan air menunjukkan adanya peningkatan performa deteksi bubble. Kalibrasi sensor ini dilakukan dengan menggunakan metode logistik regresi dengan intercept dan slope yang didapat yakni 65,0197325226436 dan -0,06463164465137253. Pada pengujian menggunakan darah, didapat hasil pembacaan sensor memiliki penurunan performa pembacaan dimana presisi, 0,7158, akurasi 77,45 dan error sebanyak 0,2845. Hasil dari pengujian ini menunjukkan adanya penurunan performa saat pengujian menggunakan darah. Pengujian pada golongan darah yang berbeda (A, B, dan AB) menunjukkan hasil variatif. Darah golongan A memiliki performa yang cukup baik dengan error 0,041666667, akurasi 0,92, dan presisi 0,6. Namun, darah golongan B menunjukkan hasil pembacaan yang terus menerus 1, disebabkan oleh viskositas tinggi yang berbeda jauh dari darah A. Pada darah golongan AB, hasil kalibrasi menunjukkan error 0,073394495, akurasi 0,874, dan presisi 0,868. Hasil ini menegaskan bahwa performa deteksi bubble pada sensor infrared sangat dipengaruhi oleh viskositas medium. Kalibrasi dengan medium yang memiliki viskositas serupa penting untuk memastikan akurasi dan presisi pembacaan sensor.===========================================================================Hemodialysis is a medical procedure used to replace damaged kidney function. During dialysis for kidney failure patients, air bubbles may appear in the blood. The bubble detector is an important part of this process, because the bubble detector will detect the presence of bubbles in the Venous Catheter flow. The presence of bubbles in the venous system can result in potentially fatal shock or cardiac arrest. Previous studies have developed microbubble detectors using Infrared Photoelectric technology. Previously, to maximize readings, adjustments were made to the infrared beam to maximize the beam only and calibration and testing using blood had not been carried out. Testing using water was carried out, the bubble detection performance after calibration increased, where the error of the infrared sensor was 0,01060071, and became 0,00003964, while the sensor accuracy was 0,9 to 0,99 and the precision was 0,85 to 0,99. The results of calibration using water show an increase in bubble detection performance. Calibration of this sensor was carried out using the logistik regression method with the intercept and slope obtained, namely 65,0197325226436 and -0,06463164465137253. In testing using blood, it was found that the sensor reading results had a decrease in reading performance, where the precision was 0,7158, the accuracy was 77,45 and the error was 0,2845. The results of this test show a decrease in performance when testing using blood. Testing on different blood types (A, B, and AB) shows varied results. Type A blood has quite good performance with an error of 0,041666667, accuracy of 0,92, and precision of 0,6. However, type B blood shows a continuous reading of 1, caused by the high viscosity which is very different from blood A. For type AB blood, the calibration results show an error of 0,073394495, an accuracy of 0,874, and a precision of 0,868. These results confirm that the bubble detection performance of the infrared sensor is strongly influenced by the viscosity of the medium. Calibration with a medium that has a similar viscosity is important to ensure the accuracy and precision of sensor readings.",uji kalibrasi bubble detector photoelectric infrared mesin hemodialisis,hemodialisis prosedur medis ganti fungsi ginjal rusak dialisis pasien gagal ginjal muncul gelembung udara darah detektor gelembung salah proses detektor gelembung deteksi bubble alir venous catheter hadir bubble sistem vena akibat kondisi syok henti jantung potensi fatal studi kembang detektor microbubble teknologi photoelectric infrared maksimal baca sesuai pancar sinar infrared maksimal pancar kalibrasi uji darah uji air performa deteksi bubble kalibrasi tingkat mana error dimilikin sensor infrared 001060071 000003964 akurasi sensor 09 099 presisi 085 099 hasil kalibrasi air tingkat performa deteksi bubble kalibrasi sensor metode logistik regresi intercept slope 650197325226436 006463164465137253 uji darah hasil baca sensor milik turun performa baca mana presisi 07158 akurasi 7745 error 02845 hasil uji turun performa uji darah uji golong darah beda a b ab hasil variatif darah golong a milik performa error 0041666667 akurasi 092 presisi 06 darah golong b hasil baca terus 1 sebab viskositas beda darah a darah golong ab hasil kalibrasi error 0073394495 akurasi 0874 presisi 0868 hasil performa deteksi bubble sensor infrared pengaruh viskositas medium kalibrasi medium milik viskositas akurasi presisi baca sensorhemodialysis is a medical procedure used to replace damaged kidney function during dialysis for kidney failure patients air bubbles may appear in the blood the bubble detector is an important part of this process because the bubble detector will detect the presence of bubbles in the venous catheter flow the presence of bubbles in the venous system can result in potentially fatal shock or cardiac arrest previous studies have developed microbubble detectors using infrared photoelectric technology previously to maximize readings adjustments were made to the infrared beam to maximize the beam only and calibration and testing using blood had not been carried out testing using water was carried out the bubble detection performance after calibration increased where the error of the infrared sensor was 001060071 and became 000003964 while the sensor accuracy was 09 to 099 and the precision was 085 to 099 the results of calibration using water show an increase in bubble detection performance calibration of this sensor was carried out using the logistik regression method with the intercept and slope obtained namely 650197325226436 and 006463164465137253 in testing using blood it was found that the sensor reading results had a decrease in reading performance where the precision was 07158 the accuracy was 7745 and the error was 02845 the results of this test show a decrease in performance when testing using blood testing on different blood types a b and ab shows varied results type a blood has quite good performance with an error of 0041666667 accuracy of 092 and precision of 06 however type b blood shows a continuous reading of 1 caused by the high viscosity which is very different from blood a for type ab blood the calibration results show an error of 0073394495 an accuracy of 0874 and a precision of 0868 these results confirm that the bubble detection performance of the infrared sensor is strongly influenced by the viscosity of the medium calibration with a medium that has a similar viscosity is important to ensure the accuracy and precision of sensor readings
Penerapan Metode K-Means dan Fuzzy C-Means pada Pengelompokkan Kabupaten/Kota di Provinsi Jawa Barat Berdasarkan Indikator Kemiskinan.,"Kiranadhewi, Afi Iffa Praba",http://repository.its.ac.id/119039/,"Kemiskinan adalah masalah sentral yang dihadapi negara-negara berkembang, termasuk Indonesia. Meski beberapa negara telah menunjukkan kemajuan ekonomi, kemiskinan tetap menjadi tantangan signifikan. Di Indonesia, tingkat kemiskinan yang tinggi memerlukan perhatian khusus dari pemerintah pusat dan daerah. Provinsi Jawa Barat, yang memiliki potensi besar dalam berbagai sektor, masih berjuang melawan masalah kemiskinan. Untuk mengatasi ini, diperlukan sistem yang dapat mengelompokkan kabupaten/kota berdasarkan indikator kemiskinan sehingga program pembangunan dapat dirancang dan dilaksanakan lebih efektif. Penelitian ini bertujuan untuk mengelompokkan kabupaten/kota di Jawa Barat berdasarkan faktor-faktor yang mempengaruhi kemiskinan tahun 2023 menggunakan metode K-Means dan Fuzzy C-Means (FCM). Langkah awal penelitian ini adalah melakukan standardisasi data. Selanjutnya, dilakukan analisis deskriptif untuk memahami karakteristik data sebelum melakukan pengelompokan. Hasil pengelompokan kedua metode tersebut dibandingkan untuk menentukan metode yang lebih efektif. Sebagai output akhir, dibuat dashboard untuk memetakan kabupaten/kota di Jawa Barat berdasarkan indikator kemiskinan. Hasil penelitian ini diharapkan dapat memberikan gambaran kondisi kemiskinan di Jawa Barat dan berfungsi sebagai alat monitoring bagi pemerintah dan lembaga terkait dalam upaya mencapai target Sustainable Development Goals (SDGs) 2030 dalam mengurangi kemiskinan.================================================================================================================================Poverty is a central issue facing developing countries, including Indonesia. Although some countries have shown economic progress, poverty remains a significant challenge. In Indonesia, the high poverty rate requires special attention from the central and local governments. West Java Province, which has great potential in various sectors, is still struggling against the problem of poverty. To address this, a system is needed that can cluster districts / municipalities based on poverty indicators so that development programs can be designed and implemented more effectively. This study aims to cluster districts/cities in West Java based on factors affecting poverty in 2023 using the K-Means and Fuzzy C-Means (FCM) methods. The first step of this research is testing the multivariate normal assumption and Bartlett's test to assess the suitability of the data. Next, descriptive analysis was conducted to understand the characteristics of the data before clustering. The clustering results of the two methods were compared to determine the more effective method. As a final output, a dashboard was created to map districts/cities in West Java based on poverty indicators. The results of this research are expected to provide an overview of poverty conditions in West Java and serve as a monitoring tool for the government and related institutions in an effort to achieve the 2030 Sustainable Development Goals (SDGs) target in reducing poverty.",terap metode kmeans fuzzy cmeans kelompok kabupatenkota provinsi jawa barat dasar indikator miskin,miskin sentral hadap negaranegara kembang indonesia negara maju ekonomi miskin tantang signifikan indonesia tingkat miskin perhati khusus perintah pusat daerah provinsi jawa barat milik potensi sektor juang lawan miskin atas sistem kelompok kabupatenkota dasar indikator miskin program bangun rancang laksana efektif teliti tuju kelompok kabupatenkota jawa barat dasar faktorfaktor pengaruh miskin 2023 metode kmeans fuzzy cmeans fcm langkah teliti standardisasi data analisis deskriptif paham karakteristik data kelompok hasil kelompok metode banding tentu metode efektif output dashboard meta kabupatenkota jawa barat dasar indikator miskin hasil teliti harap gambar kondisi miskin jawa barat fungsi alat monitoring perintah lembaga kait upaya capai target sustainable development goals sdgs 2030 kurang kemiskinanpoverty is a central issue facing developing countries including indonesia although some countries have shown economic progress poverty remains a significant challenge in indonesia the high poverty rate requires special attention from the central and local governments west java province which has great potential in various sectors is still struggling against the problem of poverty to address this a system is needed that can cluster districts municipalities based on poverty indicators so that development programs can be designed and implemented more effectively this study aims to cluster districtscities in west java based on factors affecting poverty in 2023 using the kmeans and fuzzy cmeans fcm methods the first step of this research is testing the multivariate normal assumption and bartletts test to assess the suitability of the data next descriptive analysis was conducted to understand the characteristics of the data before clustering the clustering results of the two methods were compared to determine the more effective method as a final output a dashboard was created to map districtscities in west java based on poverty indicators the results of this research are expected to provide an overview of poverty conditions in west java and serve as a monitoring tool for the government and related institutions in an effort to achieve the 2030 sustainable development goals sdgs target in reducing poverty
"Pengenalan Ekspresi Wajah dengan Variasi Pencahayaan Menggunakan Local Ternary Pattern, Convolutional Neural Network dan Extreme Learning Machine.","Krisnahati, Ice",http://repository.its.ac.id/95909/,"Pengenalan ekspresi wajah secara otomatis banyak dimanfaatkan pada interaksi manusia dan robot, permainan visual interaktif, dan deteksi gangguan mental. Oleh karena itu, pengenalan ekspresi wajah secara otomatis masih menjadi perhatian peneliti di bidang visi komputer. Berbagai macam metode telah diusulkan untuk mengatasi masalah variasi pencahayaan. Berdasarkan penelitian sebelumnya, citra Local Ternary Pattern (LTP) yang diklasifikasikan dengan metode Convolutional Neural Network (CNN) mampu mengatasi variasi pencahayaan. CNN merupakan metode klasifikasi yang handal, tetapi memiliki waktu pelatihan yang lebih lama untuk arsitektur yang lebih rumit. Pada penelitian lain, Extreme Learning Machine (ELM) dimanfaatkan untuk memodifikasi CNN pada lapisan klasifikasi untuk mengatasi waktu pelatihan yang lama.  Penelitian ini menggabungkan metode yang sudah diteliti sebelumnya dengan memanfaatkan kelebihan masing-masing metode. Citra LTP digunakan untuk mengatasi masalah pencahayaan. Kemudian, citra LTP tersebut digunakan sebagai input pada arsitektur CNN untuk proses ekstraksi fitur. Pada lapisan klasifikasi, CNN dimodifikasi dengan menghilangkan lapisan fully connected dan menggantinya dengan metode ELM. Tujuan dari modifikasi CNN tersebut adalah untuk mengatasi pelatihan yang memakan waktu pada backpropagation. Sehingga, penelitian ini membangun model dengan kombinasi metode LTP, CNN, dan ELM.  Pengujian metode menggunakan dataset KDEF dengan total 980 citra wajah dan tujuh kelas ekspresi wajah, yaitu marah, senang, sedih, takut, netral, jijik, dan terkejut dengan variasi pencahayaan mulai dari agak gelap sampai agak terang. Hasil pola kombinasi yang dihitung berdasarkan rata-rata dari pola atas dan pola bawah citra LTP menghasilkan akurasi paling tinggi jika dibandingkan dengan pola atas dan pola bawah citra LTP. Evaluasi menggunakan 10-fold cross-validation menunjukkan bahwa kinerja kombinasi metode LTP, CNN, dan ELM menghasilkan nilai akurasi sebesar 85,51% dengan waktu pelatihan 1.876 detik. Nilai akurasi ini meningkat bila dibandingkan dengan penelitian sebelumnya. Berdasarkan hasil tersebut, penelitian ini mampu mengatasi masalah pencahayaan pada kasus pengenalan ekspresi wajah============================================================================================================================Automatic facial expression recognition is widely used in human-robot interactions, interactive visual games, and mental disorder detection. Therefore, automatic facial expression recognition is still an exciting task for researchers in computer vision. Various methods have been proposed to solve the lighting variation problem. Based on previous research, Local Ternary Pattern (LTP) images classified by the Convolutional Neural Network (CNN) method can handle lighting variations. CNN is a reliable classification method but has a longer training time for more complex architectures. In another study, Extreme Learning Machine (ELM) was used to modify CNN at the classification layer to overcome the long training problem. This study combines methods that have been previously studied by exploiting the advantages of each method. LTP images are used to solve lighting problems. Then, the LTP image is used as input to the CNN architecture for the feature extraction process. At the classification layer, CNN is modified by removing the fully connected layer and replacing it with the ELM method. The purpose of the CNN modification is to overcome the time-consuming training on backpropagation. Thus, this study builds a model combining LTP, CNN, and ELM methods. This research used the KDEF dataset with 980 facial images (frontal face) and seven facial expressions: angry, happy, sad, scared, neutral, disgusted, and surprised, with lighting variations ranging from dark to bright. The combination pattern results calculated based on the average of the top and bottom patterns of the LTP image produce the highest accuracy compared to the top and bottom patterns of the LTP image. Evaluation using 10-fold cross-validation shows that the performance of the combination of LTP, CNN, and ELM methods produce an accuracy value of 85.51% with a training time of 1,876 seconds. This accuracy value increases when compared to previous studies. Based on these results, this study was able to overcome the lighting problem in the case of facial expression recognition",kenal ekspresi wajah variasi cahaya local ternary pattern convolutional neural network extreme learning machine,kenal ekspresi wajah otomatis manfaat interaksi manusia robot main visual interaktif deteksi ganggu mental kenal ekspresi wajah otomatis perhati teliti bidang visi komputer metode usul atas variasi cahaya dasar teliti citra local ternary pattern ltp klasifikasi metode convolutional neural network cnn atas variasi cahaya cnn metode klasifikasi handal milik latih arsitektur rumit teliti extreme learning machine elm manfaat modifikasi cnn lapis klasifikasi atas latih teliti gabung metode teliti manfaat lebih masingmasing metode citra ltp atas cahaya citra ltp input arsitektur cnn proses ekstraksi fitur lapis klasifikasi cnn modifikasi hilang lapis fully connected ganti metode elm tuju modifikasi cnn atas latih makan backpropagation teliti bangun model kombinasi metode ltp cnn elm uji metode dataset kdef total 980 citra wajah tujuh kelas ekspresi wajah marah senang sedih takut netral jijik kejut variasi cahaya gelap terang hasil pola kombinasi hitung dasar ratarata pola pola citra ltp hasil akurasi banding pola pola citra ltp evaluasi 10fold crossvalidation kerja kombinasi metode ltp cnn elm hasil nilai akurasi 8551 latih 1876 detik nilai akurasi tingkat banding teliti dasar hasil teliti atas cahaya kenal ekspresi wajahautomatic facial expression recognition is widely used in humanrobot interactions interactive visual games and mental disorder detection therefore automatic facial expression recognition is still an exciting task for researchers in computer vision various methods have been proposed to solve the lighting variation problem based on previous research local ternary pattern ltp images classified by the convolutional neural network cnn method can handle lighting variations cnn is a reliable classification method but has a longer training time for more complex architectures in another study extreme learning machine elm was used to modify cnn at the classification layer to overcome the long training problem this study combines methods that have been previously studied by exploiting the advantages of each method ltp images are used to solve lighting problems then the ltp image is used as input to the cnn architecture for the feature extraction process at the classification layer cnn is modified by removing the fully connected layer and replacing it with the elm method the purpose of the cnn modification is to overcome the timeconsuming training on backpropagation thus this study builds a model combining ltp cnn and elm methods this research used the kdef dataset with 980 facial images frontal face and seven facial expressions angry happy sad scared neutral disgusted and surprised with lighting variations ranging from dark to bright the combination pattern results calculated based on the average of the top and bottom patterns of the ltp image produce the highest accuracy compared to the top and bottom patterns of the ltp image evaluation using 10fold crossvalidation shows that the performance of the combination of ltp cnn and elm methods produce an accuracy value of 8551 with a training time of 1876 seconds this accuracy value increases when compared to previous studies based on these results this study was able to overcome the lighting problem in the case of facial expression recognition
Pengembangan Kursi Roda Otonom Berbasis YOLOV8 Untuk Penghindaran Obstacle.,"Kusuma, I Gst Ngr Agung Hari Vijaya",http://repository.its.ac.id/111406/,"Pengembangan kursi roda otonom telah menjadi semakin penting dalam meningkatkan mobilitas bagi individu dengan mobilitas terbatas. Studi ini mengusulkan pengembangan sistem kursi roda otonom berbasis YOLOv8 untuk menghindari obstacle, khususnya fokus pada deteksi obstacle manusia. Dengan memanfaatkan kemampuan deteksi objek yang canggih dari YOLOv8, sistem yang diusulkan bertujuan untuk mendeteksi dan menghindari obstacle manusia secara efektif. Sistem tersebut mendeteksi manusia melalui video menggunakan Intel NUC dan Kamera. Obstacle yang terdeteksi membuat NUC mengirim perintah ke ESP32 untuk menjalankan motor untuk melakukan manuver penghindaran. Pengujian performa keberhasilan penghindaran dilakukan dengan 30 kali percobaan pada objek manusia yang diam. Hasil pengujian menunjukkan bahwa kursi roda berhasil menghindar sebanyak 30 kali tanpa gagal, memberikan tingkat keberhasilan sebesar 100%. Hal ini menunjukkan bahwa sistem kursi roda otonom yang dirancang mampu melakukan penghindaran rintangan dengan sangat baik.=========================================================================================================",kembang kursi roda otonom bas yolov8 hindar obstacle,kembang kursi roda otonom tingkat mobilitas individu mobilitas batas studi usul kembang sistem kursi roda otonom bas yolov8 hindar obstacle fokus deteksi obstacle manusia manfaat mampu deteksi objek canggih yolov8 sistem usul tuju deteksi hindar obstacle manusia efektif sistem deteksi manusia video intel nuc kamera obstacle deteksi nuc kirim perintah esp32 jalan motor manuver hindar uji performa hasil hindar 30 kali coba objek manusia diam hasil uji kursi roda hasil hindar 30 kali gagal tingkat hasil 100 sistem kursi roda otonom rancang hindar rintang
Analisis Sentimen Warga Indonesia Terhadap Penanganan Kasus COVID-19 Menggunakan Metode Naïve Bayes Dan Support Vector Machine (SVM).,"Lestari, Dhany Nastiti",http://repository.its.ac.id/91616/,"Kehidupan masyarakat zaman sekarang mengalami banyak perubahan akibat dari perkembangan ilmu pengetahuan  dan teknologi. Masyarakat menjadi lebih reaktif menanggapi fenomena disekitar, termasuk  berita, kebijakan, serta upaya-upaya pemerintah menanggulangi pandemi COVID-19. Feedback masyarakat mengenai upaya-upaya pemerintah menanggulangi bencana dapat dijadikan bahan evaluasi untuk meningkatkan kinerja. Untuk mendapatkan hasil yang dapat dilihat secara jelas maka digunakan proses klasifikasi terhadap opini-opini masyarakat menjadi opini dengan sentimen positif serta sentimen negatif. Data teks yang didapat dari tweet masyarakat Indonesia akan di preprocessing menggunakan tokenisasi, case folding, serta penghapusan stopwords. Data hasil preprocessing akan dilakukan ektraksi fitur Term Frequency-Inverse Document Frequency (TF-IDF), dengan satu term adalah sebuah n-grams dan akan dilakukan klasifikasi menggunakan metode naïve Bayes dan Support Vector Machine (SVM). Hasil dari klasifikasi sentiment menunjukkan bahwa metode SVM lebih baik daripada Naïve Bayes, khususnya SVM dengan menggunakan kernel radial basis karena memiliki F1-score, recall, dan accuracy yang lebih tinggi.===================================================================================================Life in our current society undergoes many changes as a result of the development of science and technology. People have become more reactive in responding to phenomena around them, including news, policies, and government efforts to tackle the COVID-19 pandemic. Public feedback regarding the government's efforts to cope with disasters can be used as evaluation material to improve performance. To get results that can be seen clearly, a classification process is used to classify public opinions into opinions with positive sentiments and negative sentiments. Text data obtained from Indonesian people's tweets will be preprocessed using tokenization, case folding, and removal of stop words. The data from the preprocessing will be extracted with Term Frequency-Inverse Document Frequency (TF-IDF), with one term being n-grams and will be classified using the Nave Bayes method and Support Vector Machine (SVM). The results of the sentiment classification show that the SVM method is better than Naïve Bayes, especially SVM using a radial basis kernel because it has a higher mean  F1-score, recall, and accuracy.",analisis sentimen warga indonesia tangan covid19 metode na ve bayes support vector machine svm,hidup masyarakat zaman alami ubah akibat kembang ilmu tahu teknologi masyarakat reaktif tanggap fenomena sekitar berita bijak upayaupaya perintah tanggulang pandemi covid19 feedback masyarakat upayaupaya perintah tanggulang bencana jadi bahan evaluasi tingkat kerja hasil proses klasifikasi opiniopini masyarakat opini sentimen positif sentimen negatif data teks tweet masyarakat indonesia preprocessing tokenisasi case folding hapus stopwords data hasil preprocessing ektraksi fitur term frequencyinverse document frequency tfidf term ngrams klasifikasi metode na ve bayes support vector machine svm hasil klasifikasi sentiment metode svm na ve bayes svm kernel radial basis milik f1score recall accuracy tinggilife in our current society undergoes many changes as a result of the development of science and technology people have become more reactive in responding to phenomena around them including news policies and government efforts to tackle the covid19 pandemic public feedback regarding the governments efforts to cope with disasters can be used as evaluation material to improve performance to get results that can be seen clearly a classification process is used to classify public opinions into opinions with positive sentiments and negative sentiments text data obtained from indonesian peoples tweets will be preprocessed using tokenization case folding and removal of stop words the data from the preprocessing will be extracted with term frequencyinverse document frequency tfidf with one term being ngrams and will be classified using the nave bayes method and support vector machine svm the results of the sentiment classification show that the svm method is better than na ve bayes especially svm using a radial basis kernel because it has a higher mean f1score recall and accuracy
Aspect-Based Sentiment Analysis Pada Ulasan Konsumen Terhadap Kualitas Layanan PT Citilink Indonesia.,"Lestarie, Maisa Haifa",http://repository.its.ac.id/107066/,"Transportasi udara yang menjadi moda transportasi paling sering digunakan oleh konsumen Indonesia. Terciptanya konsep penerbangan Low-Cost Carier (LCC) dimana penerbangan menerapkan strategi penurunan biaya operasional dan mengoptikmalkan biaya disetiap lini. Kompetisi maskapai penerbangan lowcost carrier yang tinggi mendorong perusahaan untuk menguatkan merek dan mengembangkan strategi. Salah satu maskapai LCC di bawah naungan Garuda Indonesia yaitu PT Citilink Indonesia sebagai upaya Garuda Indonesia untuk bersaing pada segment budget traveler. Pada pelaksanaannya PT Citilink Indonesia dinilai memberi informasi delay secara mendadak dan juga penurunan layanan call center dalam menangani keluhan penumpang. Kualitas layanan berpengaruh pada brand image dan brand trust sebagai faktor yang menentukan loyalitas konsumen. Berdasarkan hal tersebut dapat dilakukan analisis sentimen untuk mengetahui pandangan konsumen terhadap PT Citilink Indonesia dengan mengukur kualitas layanan berdasarkan aspek. Metode yang digunakan adalah Aspect Based Sentiment Analysis dengan algoritma Naïve Bayes Classifier dan word2vec. Hasil dari penelitian ini berupa sentimen negatif terhadap aspek tangible, responsiveness, reliability, dan assurance dengan aspect-based sentiment analysis menghasilkan akurasi klasifikasi kelas sentimen sebesar 89% dan kelas aspek sebesar 62%.=============================================================================================================================Air transportation is the most frequently used mode of transportation by Indonesian consumers. The creation of the Low-Cost Carrier (LCC) flight concept where flights implement a strategy of reducing operational costs and optimizing costs in every line. High low-cost carrier airline competition encourages companies to strengthen brands and develop strategies. One of the LCC airlines under Garuda Indonesia is PT Citilink Indonesia as Garuda Indonesia's effort to compete in the budget traveler segment. In its implementation, PT Citilink Indonesia is considered to provide sudden delay information also a decrease in call center services in handling passenger complaints. Service quality affects brand image and brand trust as factors that determine consumer loyalty. Based on this, sentiment analysis can be carried out to determine consumer views on PT Citilink Indonesia by measuring service quality based on aspects. The method used is Aspect Based Sentiment Analysis with the Naïve Bayes Classifier algorithm and word2vec. The results of this study are negative sentiments towards tangible, responsive, reliability, and assurance aspects with aspect-based sentiment analysis resulting in a sentiment class classification accuracy of 89% and an aspect class of 62%.",aspectbased sentiment analysis ulas konsumen kualitas layan pt citilink indonesia,transportasi udara moda transportasi konsumen indonesia cipta konsep terbang lowcost carier lcc mana terbang terap strategi turun biaya operasional mengoptikmalkan biaya tiap lini kompetisi maskapai terbang lowcost carrier dorong usaha kuat merek kembang strategi salah maskapai lcc naung garuda indonesia pt citilink indonesia upaya garuda indonesia saing segment budget traveler laksana pt citilink indonesia nilai informasi delay dadak turun layan call center tangan keluh tumpang kualitas layan pengaruh brand image brand trust faktor tentu loyalitas konsumen dasar analisis sentimen pandang konsumen pt citilink indonesia ukur kualitas layan dasar aspek metode aspect based sentiment analysis algoritma na ve bayes classifier word2vec hasil teliti sentimen negatif aspek tangible responsiveness reliability assurance aspectbased sentiment analysis hasil akurasi klasifikasi kelas sentimen 89 kelas aspek 62air transportation is the most frequently used mode of transportation by indonesian consumers the creation of the lowcost carrier lcc flight concept where flights implement a strategy of reducing operational costs and optimizing costs in every line high lowcost carrier airline competition encourages companies to strengthen brands and develop strategies one of the lcc airlines under garuda indonesia is pt citilink indonesia as garuda indonesias effort to compete in the budget traveler segment in its implementation pt citilink indonesia is considered to provide sudden delay information also a decrease in call center services in handling passenger complaints service quality affects brand image and brand trust as factors that determine consumer loyalty based on this sentiment analysis can be carried out to determine consumer views on pt citilink indonesia by measuring service quality based on aspects the method used is aspect based sentiment analysis with the na ve bayes classifier algorithm and word2vec the results of this study are negative sentiments towards tangible responsive reliability and assurance aspects with aspectbased sentiment analysis resulting in a sentiment class classification accuracy of 89 and an aspect class of 62
Pengembangan Model Prediksi Dan Model Bisnis Pada Pembiayaan Kendaraan Berbasis Data Mining.,"Lupitadevi, Citra Judith",http://repository.its.ac.id/92534/,"Pembiayaan kendaraan merupakan salah satu kebutuhan yang diperlukan oleh konsumen pada saat membeli kendaraan. PT Mandiri Tunas Finance (MTF) merupakan salah satu perusahaan pembiayaan kendaraan di Indonesia. Total pembiayaan kendaraan yang telah disalurkan di 2020 adalah sebesar 16.7 trilun. Kondisi Pandemi Covid-19 yang terjadi sejak akhir tahun 2019, memberikan dampak yang signifikan terdapat bisnis perusahaan pembiayaan. Perusahaan pembiayaan mengalami penurunan sebesar 40%, hal ini didorong juga karena penurunan penjualan mobil sebesar 44.6% pada Tahun 2020 dibandingkan Tahun 2019. Sumber order PT Mandiri Tunas Finance mayoritas berasal dari penjualan dealer kendaraan. Turunnya penjualan mobil, berdampak langsung pada bisnis PT Mandiri Tunas Finance. Untuk mengatasi hal tersebut, perlu dikembangkan sumber order lain terutama yang berasal dari pengolahan database customer perusahaan (data mining). Dalam penelitian ini, akan dilakukan penerapan model prediksi dengan regresi logistik biner. Hal ini dilakukan dengan mengembangkan model untuk memprediksi customer yang akan melakukan pengambilan pembiayaan. Tingkat akurasi model prediksi akan diukur dengan menggunakan nilai Area Under Curve (AUC). Selain pengembangan model prediksi, juga dilakukan pengembangan model bisnis pembiayaan berbasis data mining dengan menggunakan pendekatan Businees Model Canvass. Hasil model regresi logistik biner, diketahui variabel prediktor yang mempengaruhi customer dalam mengambil pembiayaan mobil kembali adalah jangka waktu dari pembiayaan sebelumnya, penghasilan customer, jenis produk yang dibiayai, status kepemilikan rumah, status pernikahan, jenis pekerjaan customer dan pendidikan. Dengan pendekatan Area Under Curve diketahui akurasi model yang terbentuk adalah 95,803% yang artinya model ini baik untuk digunakan. Dalam menjalankan model bisnis berbasis data mining ini, perusahaan perlu membentuk fungsi data analytic dan penawaran secara aktif kepada customer.========================================================================================================================================Vehicle financing is one of the financing products needed by consumers when buying a vehicle. PT Mandiri Tunas Finance (MTF) is one of the vehicle financing companies in Indonesia. The total vehicle financing that has been disbursed by MTF in 2020 is 16.7 trillion. The Covid-19 Pandemic condition that has occurred since the end of 2019, has had a significant impact on the financing company business. Finance company’s disbursement decreased by 40%, this was also driven by a 44.6% decline in car sales in 2020 compared to 2019. The main source of orders for MTF comes from vehicle dealer sales. The decline in car sales had a direct impact on MTF’s business. To overcome this, it is necessary to develop other order sources, especially those from the company's customer database processing (data mining). In this research, the prediction model with binary logistic regression will be applied. A model will be used to predict which customers will take financing. The accuracy of the prediction model will be measured using Area Under Curve (AUC) values. In addition, the development of a data mining-based financing business model is also carried out using the Business Model Canvass approach. The results of binary logistic regression models, predictor variables that affect customers in car financing are the period of previous financing, salary, type of product financed, homeownership status, marital status, customer employment type, and education. With the Area Under Curve approach, the accuracy of the model formed is 95.803% which means that this model is good to use. In carrying out this data mining-based business model, companies need to form data analytic functions and build offer activities to customers.",kembang model prediksi model bisnis biaya kendara bas data mining,biaya kendara salah butuh konsumen beli kendara pt mandiri tunas finance mtf salah usaha biaya kendara indonesia total biaya kendara salur 2020 167 trilun kondisi pandemi covid19 2019 dampak signifikan bisnis usaha biaya usaha biaya alami turun 40 dorong turun jual mobil 446 2020 banding 2019 sumber order pt mandiri tunas finance mayoritas asal jual dealer kendara turun jual mobil dampak langsung bisnis pt mandiri tunas finance atas kembang sumber order asal olah database customer usaha data mining teliti terap model prediksi regresi logistik biner kembang model prediksi customer ambil biaya tingkat akurasi model prediksi ukur nilai area under curve auc kembang model prediksi kembang model bisnis biaya bas data mining dekat businees model canvass hasil model regresi logistik biner variabel prediktor pengaruh customer ambil biaya mobil jangka biaya hasil customer jenis produk biaya status milik rumah status nikah jenis kerja customer didik dekat area under curve akurasi model bentuk 95803 model jalan model bisnis bas data mining usaha bentuk fungsi data analytic tawar aktif customervehicle financing is one of the financing products needed by consumers when buying a vehicle pt mandiri tunas finance mtf is one of the vehicle financing companies in indonesia the total vehicle financing that has been disbursed by mtf in 2020 is 167 trillion the covid19 pandemic condition that has occurred since the end of 2019 has had a significant impact on the financing company business finance company  s disbursement decreased by 40 this was also driven by a 446 decline in car sales in 2020 compared to 2019 the main source of orders for mtf comes from vehicle dealer sales the decline in car sales had a direct impact on mtf  s business to overcome this it is necessary to develop other order sources especially those from the companys customer database processing data mining in this research the prediction model with binary logistic regression will be applied a model will be used to predict which customers will take financing the accuracy of the prediction model will be measured using area under curve auc values in addition the development of a data miningbased financing business model is also carried out using the business model canvass approach the results of binary logistic regression models predictor variables that affect customers in car financing are the period of previous financing salary type of product financed homeownership status marital status customer employment type and education with the area under curve approach the accuracy of the model formed is 95803 which means that this model is good to use in carrying out this data miningbased business model companies need to form data analytic functions and build offer activities to customers
Model Manajemen Persediaan Spare Part Pada Alat Berat Pelabuhan Untuk Meningkatkan Availability.,"Mahardika, I Gede Widya",http://repository.its.ac.id/117176/,"Penelitian ini mengkaji permasalahan pada salah satu terminal petikemas di Indonesia yang menghadapi tantangan dalam pengelolaan suku cadang kritis yang berdampak pada operasional dan ketersediaan alat. Data operasional perusahaan menunjukkan tingkat availability alat straddle carrier hanya mencapai 69,33% pada tahun 2023, di bawah target KPI. Data historis menunjukkan bahwa sekitar 56% dari total downtime disebabkan oleh waktu menunggu ketersediaan suku cadang. Untuk mengatasi permasalahan tersebut, dikembangkan model optimasi manajemen persediaan berbasis continuous review (Q, r) yang mengintegrasikan variabel lead time dan ketidakpastian permintaan berdasarkan pola distribusi permintaan historis. Pengujian model ini dilakukan melalui simulasi Monte Carlo dengan mengaplikasikan berbagai skenario kebutuhan pada 10 jenis spare part yang dipilih berdasarkan tingkat kekritisannya. Performa model dievaluasi menggunakan tiga parameter utama, yaitu total inventory cost (TIC), service level, dan availability. Hasil validasi menunjukkan bahwa model mampu merepresentasikan kondisi aktual dengan perbedaan hanya 1,6% dari data nyata, yang masih berada dalam batas toleransi kesalahan 5%. Implementasi skenario perbaikan dengan modifikasi setup pemesanan pada interval tiga bulan menghasilkan optimasi signifikan berupa reduksi TIC sebesar 33%, peningkatan service level spare part sebesar 7,8% mencapai 95%, serta peningkatan availability alat sebesar 4,9% menjadi 75%.===================================================================================================================================This research examines challenges faced by a container terminal in Indonesia in managing critical spare parts, which impact operations and equipment availability. Operational data from the company reveals that the availability rate of straddle carriers only reached 69.33% in 2023, falling below the KPI target. Historical data indicates that approximately 56% of total downtime was caused by delays in spare part availability. To address this issue, an optimization model for inventory management based on continuous review (Q, r) was developed, integrating lead time and demand uncertainty variables derived from historical demand distribution patterns. The model was tested through Monte Carlo simulations applied to various demand scenarios for 10 types of spare parts, selected based on their criticality. The model's performance was evaluated using three key parameters: total inventory cost (TIC), service level, and equipment availability. Validation results demonstrated that the model accurately represented actual conditions, with a deviation of only 1.6% from real-world data, well within the acceptable error margin of 5%. The implementation of improvement scenarios, involving modifications to ordering setups at three-month intervals, achieved significant optimization, including a 33% reduction in TIC, a 7.8% increase in spare parts service level to 95%, and a 4.9% improvement in equipment availability to 75%.",model manajemen sedia spare part alat berat labuh tingkat availability,teliti kaji masalah salah terminal petikemas indonesia hadap tantang kelola suku cadang kritis dampak operasional sedia alat data operasional usaha tingkat availability alat straddle carrier capai 6933 2023 target kpi data historis 56 total downtime sebab tunggu sedia suku cadang atas masalah kembang model optimasi manajemen sedia bas continuous review q r integrasi variabel lead time ketidakpastian minta dasar pola distribusi minta historis uji model simulasi monte carlo aplikasi skenario butuh 10 jenis spare part pilih dasar tingkat kritis performa model evaluasi parameter utama total inventory cost tic service level availability hasil validasi model representasi kondisi aktual beda 16 data nyata batas toleransi salah 5 implementasi skenario baik modifikasi setup mesan interval hasil optimasi signifikan reduksi tic 33 tingkat service level spare part 78 capai 95 tingkat availability alat 49 75this research examines challenges faced by a container terminal in indonesia in managing critical spare parts which impact operations and equipment availability operational data from the company reveals that the availability rate of straddle carriers only reached 6933 in 2023 falling below the kpi target historical data indicates that approximately 56 of total downtime was caused by delays in spare part availability to address this issue an optimization model for inventory management based on continuous review q r was developed integrating lead time and demand uncertainty variables derived from historical demand distribution patterns the model was tested through monte carlo simulations applied to various demand scenarios for 10 types of spare parts selected based on their criticality the models performance was evaluated using three key parameters total inventory cost tic service level and equipment availability validation results demonstrated that the model accurately represented actual conditions with a deviation of only 16 from realworld data well within the acceptable error margin of 5 the implementation of improvement scenarios involving modifications to ordering setups at threemonth intervals achieved significant optimization including a 33 reduction in tic a 78 increase in spare parts service level to 95 and a 49 improvement in equipment availability to 75
Implementasi 2D-CNN dengan Teknik Augmentasi EEG untuk Mendeteksi Kejang Epilepsi pada Dataset Siena Scalp EEG.,"Malinus, Azzura Mahendra Putra",http://repository.its.ac.id/117872/,"Epilepsi adalah sebuah penyakit otak dengan gejala yang dialami penderitanya berupa kejang epileptik yang berulang. Untuk mendiagnosis epilepsi, ahli neurologi menganalisis rekaman sinyal otak Electroencephalography (EEG) yang diperoleh dari pasien epilepsi. Masalah yang ditemui adalah proses analisis sinyal EEG untuk menentukan kejadian kejang epilepsi dapat memakan waktu cukup lama karena sinyal EEG memiliki karakteristik yang kompleks dan durasi yang panjang. Oleh karena itu, diperlukan sebuah sistem yang mampu melakukan hal tersebut secara otomatis untuk mempermudah pekerjaan para ahli neurologi. Pada tugas akhir ini, dibuat sebuah sistem yang dapat melakukan anotasi kejadian kejang epilepsi pada rekaman sinyal EEG secara otomatis. Sistem tersebut terdiri dari sebuah model deep learning dengan arsitekstur 2D Convolutional Neural Network (CNN) untuk mengklasifikasi segmen-segmen rekaman EEG dan sebuah aplikasi antarmuka yang menampilkan visualisasi sinyal dari input rekaman EEG dan hasil deteksi dari model deep learning tersebut. Dataset Siena Scalp EEG digunakan sebagai input pengembangan model dan diterapkan beberapa tahap preprocessing, seperti penamaan ulang dan pengurangan durasi, down sampling, bipolar montage, filter Butterworth bandpass, dan segmentasi dengan sliding window. Dari tahap preprocessing, diperoleh beberapa variasi input dengan menggunakan beberapa nilai pada variabel window, stride, dan chunk saat proses segmentasi dengan sliding window. Input-input yang dihasilkan digunakan untuk melatih model dengan menerapkan 5-Fold Cross Validation dan teknik augmentasi EEG, seperti time reverse, sign flip, fourier transform surrogate, dan frequency shift. Aplikasi antarmuka dikembangkan menggunakan HTML, CSS, dan JavaScript untuk sisi klien dan Flask untuk sisi server. Dari seluruh uji coba pengembangan model yang telah dilakukan, diperoleh hasil terbaik pada uji coba penerapan teknik augmentasi fourier transform surrogate dengan gangguan fase 0.8 terhadap model dasar 2D-CNN. Pada uji coba tersebut, input window 15 detik dengan stride 2.5 detik memberikan kinerja model terbaik, yaitu accuracy 91.80%, sensitivity 93.25%, specificity 90.37%, dan mean AUC 97%.===================================================================================================================================Epilepsy is a brain disease whose symptoms include recurrent epileptic seizures. To diagnose epilepsy, neurologists analyze Electroencephalography (EEG) brain signal recordings obtained from epilepsy patients. The problem encountered is that the process of analyzing EEG signals to determine the occurrence of epileptic seizures can take a long time because EEG signals have complex characteristics and long duration. Therefore, a system that is able to do this automatically is needed to facilitate the work of neurologists. In this undergraduate thesis, a system that can annotate epileptic seizure events on EEG signal recordings automatically is created. The system consists of a deep learning model with 2D Convolutional Neural Network (CNN) architecture to classify EEG recording segments and an interface application that displays signal visualization of EEG recording input and detection results from the deep learning model. The Siena Scalp EEG dataset is used as input for model development and several preprocessing stages are applied, such as renaming and duration reduction, down sampling, bipolar montage, Butterworth bandpass filter, and segmentation with sliding window. From the preprocessing stage, several input variations were obtained by using several values for the window, stride, and chunk variables during the sliding window segmentation process. The resulting inputs are used to train the model by applying 5-Fold Cross Validation and EEG augmentation techniques, such as time reverse, sign flip, fourier transform surrogate, and frequency shift. The application interface was developed using HTML, CSS, and JavaScript for the client side and Flask for the server side. From all the model development trials that have been conducted, the best results were obtained in the trial of applying the fourier transform surrogate augmentation technique with a phase noise of 0.8 to the 2D-CNN base model. In this trial, the 15-second input window and 2.5 second stride provide the best model performance, namely accuracy of 91.80%, sensitivity of 93.25%, specificity of 90.37%, and mean AUC of 97%.",implementasi 2dcnn teknik augmentasi eeg deteksi kejang epilepsi dataset siena scalp eeg,epilepsi sakit otak gejala alami derita kejang epileptik ulang diagnosis epilepsi ahli neurologi analis rekam sinyal otak electroencephalography eeg oleh pasien epilepsi temu proses analisis sinyal eeg tentu jadi kejang epilepsi makan sinyal eeg milik karakteristik kompleks durasi sistem otomatis mudah kerja ahli neurologi tugas sistem anotasi jadi kejang epilepsi rekam sinyal eeg otomatis sistem model deep learning arsitekstur 2d convolutional neural network cnn klasifikasi segmensegmen rekam eeg aplikasi antarmuka tampil visualisasi sinyal input rekam eeg hasil deteksi model deep learning dataset siena scalp eeg input kembang model terap tahap preprocessing nama ulang kurang durasi down sampling bipolar montage filter butterworth bandpass segmentasi sliding window tahap preprocessing oleh variasi input nilai variabel window stride chunk proses segmentasi sliding window inputinput hasil latih model terap 5fold cross validation teknik augmentasi eeg time reverse sign flip fourier transform surrogate frequency shift aplikasi antarmuka kembang html css javascript sisi klien flask sisi server uji coba kembang model oleh hasil baik uji coba terap teknik augmentasi fourier transform surrogate ganggu fase 08 model dasar 2dcnn uji coba input window 15 detik stride 25 detik kerja model baik accuracy 9180 sensitivity 9325 specificity 9037 mean auc 97epilepsy is a brain disease whose symptoms include recurrent epileptic seizures to diagnose epilepsy neurologists analyze electroencephalography eeg brain signal recordings obtained from epilepsy patients the problem encountered is that the process of analyzing eeg signals to determine the occurrence of epileptic seizures can take a long time because eeg signals have complex characteristics and long duration therefore a system that is able to do this automatically is needed to facilitate the work of neurologists in this undergraduate thesis a system that can annotate epileptic seizure events on eeg signal recordings automatically is created the system consists of a deep learning model with 2d convolutional neural network cnn architecture to classify eeg recording segments and an interface application that displays signal visualization of eeg recording input and detection results from the deep learning model the siena scalp eeg dataset is used as input for model development and several preprocessing stages are applied such as renaming and duration reduction down sampling bipolar montage butterworth bandpass filter and segmentation with sliding window from the preprocessing stage several input variations were obtained by using several values for the window stride and chunk variables during the sliding window segmentation process the resulting inputs are used to train the model by applying 5fold cross validation and eeg augmentation techniques such as time reverse sign flip fourier transform surrogate and frequency shift the application interface was developed using html css and javascript for the client side and flask for the server side from all the model development trials that have been conducted the best results were obtained in the trial of applying the fourier transform surrogate augmentation technique with a phase noise of 08 to the 2dcnn base model in this trial the 15second input window and 25 second stride provide the best model performance namely accuracy of 9180 sensitivity of 9325 specificity of 9037 and mean auc of 97
Integrasi Servqual Dan Quality Function Deployment Sebagai Upaya Peningkatan Pelayanan Minimarket.,"Maslikhan, Akhmad",http://repository.its.ac.id/109569/,"ABSTRAKMinimarket Minimarket menyediakan produk sehari-hari dengan akses mudah dan jam buka panjang, berfungsi tidak hanya sebagai tempat berbelanja tetapi juga sebagai bagian dari perubahan bisnis dan ritel yang beradaptasi dengan kebutuhan masyarakat. Meskipun lebih kecil dari supermarket, minimarket berusaha menyediakan berbagai produk seperti makanan, minuman, barang rumah tangga, buku, dan kitab keagamaan. Tantangan utama yang dihadapi adalah meningkatnya ketidakpuasan pelanggan yang dapat berdampak negatif pada profitabilitas Minimarket Darut Taqwa yang telah beroperasi sejak 2004, menekankan kenyamanan, kepuasan pelanggan, dan pelayanan terbaik, serta bertujuan mengembangkan keterampilan wirausaha di kalangan santri. Untuk mengatasi ketidakpuasan pelanggan, digunakan analisis dengan metode SERVQUAL dan QFD. Penelitian ini menggunakan tujuh aspek penilaian SERVQUAL yaitu tangibility, reliability, responsiveness, assurance, empathy, communication, dan security. QFD digunakan untuk mengintegrasikan keinginan pelanggan yang diverifikasi oleh perusahaan. Hasil analisis QFD menunjukkan nilai Customer Importance tertinggi (4,60) pada indikator ""Biaya/harga produk sesuai dengan kualitas yang diberikan"" dan terendah (4,02) pada indikator ""Pegawai minimarket melantunkan sapaan kepada customer yang baru berkunjung"". Nilai Customer Satisfaction Level (SCL) tertinggi (4,20) pada indikator ""Kesigapan dan ketegasan keamanan dalam mengamankan serta menertibkan area minimarket"" dan terendah (3,69) pada indikator ""Minimarket sering mengadakan event (promo) atau potongan harga"". Pengolahan data menurut penilaian Techical Requirement menyoroti bahwa prioritas perbaikan tertinggi jatuh pada ""Pelatihan Skill Komunikasi oleh Pihak Manajemen"" dengan bobot total 72 (7,16%) karena kontribusinya yang signifikan terhadap peningkatan kepuasan pelanggan. Prioritas kedua adalah ""Pelatihan karyawan dalam melayani konsumen"" dengan bobot 63 (6,27%) untuk meningkatkan keterampilan layanan pelanggan. Prioritas ketiga adalah ""Memberikan pelatihan dan briefing kepada karyawan"" dengan bobot 53 (5,27%) untuk meningkatkan pengetahuan dan pemahaman tugas. Sedangkan prioritas terendah adalah ""Instore Promo sebagai upaya peningkatan penjulan pada periode tertentu"" dengan bobot 5 (0,50%) karena kontribusi yang rendah terhadap peningkatan pelayanan minimarket.",integrasi servqual quality function deployment upaya tingkat layan minimarket,abstrakminimarket minimarket sedia produk seharihari akses mudah jam buka fungsi belanja ubah bisnis ritel adaptasi butuh masyarakat supermarket minimarket usaha sedia produk makan minum barang rumah tangga buku kitab agama tantang utama hadap tingkat ketidakpuasan langgan dampak negatif profitabilitas minimarket darut taqwa operasi 2004 tekan nyaman puas langgan layan baik tuju kembang terampil wirausaha kalang santri atas ketidakpuasan langgan analisis metode servqual qfd teliti tujuh aspek nilai servqual tangibility reliability responsiveness assurance empathy communication security qfd integrasi langgan verifikasi usaha hasil analisis qfd nilai customer importance tinggi 460 indikator biayaharga produk sesuai kualitas rendah 402 indikator pegawai minimarket lantun sapa customer kunjung nilai customer satisfaction level scl tinggi 420 indikator sigap tegas aman aman tertib area minimarket rendah 369 indikator minimarket ada event promo potong harga olah data nilai techical requirement sorot prioritas baik tinggi jatuh latih skill komunikasi manajemen bobot total 72 716 kontribusi signifikan tingkat puas langgan prioritas latih karyawan layan konsumen bobot 63 627 tingkat terampil layan langgan prioritas tiga latih briefing karyawan bobot 53 527 tingkat tahu paham tugas prioritas rendah instore promo upaya tingkat penjulan periode bobot 5 050 kontribusi rendah tingkat layan minimarket
Klasifikasi NSCLC dengan Arsitektur DenseNet dan GLCM Untuk Deteksi Dini Kanker Paru-Paru Pada Citra CT-Scan.,"Maulana, Irgi Azarya Putra",http://repository.its.ac.id/112781/,"Kanker paru-paru atau kanker pulmoner merupakan penyakin yang memiliki variasi keganasan tergantung kondisi. Kanker paru-paru terjadi ketika sel-sel di dalam paru-paru mengalami pertumbuhan yang tidak terkendali dan menjadi ganas. Ada dua jenis kanker paru-paru utama yaitu Non-Small Cell Lung Cancer (NSCLC) dan Small Cell Lung Cancer (SCLC). NSCLC adalah jenis kanker paru-paru yang paling umum, mencakup sekitar 85% dari semua kasus kanker paru-paru. NSCLC terbagi menjadi beberapa subjenis, termasuk Pulmonary Adenocarcinoma (ADC), dan Pulmonary Squamous Cell Carcinoma (SqCC). Sedangkan SCLC lebih jarang terjadi dan tumbuh lebih cepat daripada NSCLC. SCLC juga lebih cenderung menyebar ke bagian tubuh lain pada saat diagnosis dibandingkan NSCLC. Skrining menggunakan CT scan dosis rendah, yang diizinkan saat ini, seringkali memiliki tingkat sensitivitas yang rendah dan tingkat positif palsu yang tinggi. Lebih dari 90% dari hasil positif sebenarnya tidak menunjukkan adanya kanker. Selain itu, saat ini tidak ada biomarker tambahan yang dapat meningkatkan sensitivitas skrining CT dosis rendah, terutama pada pasien yang memiliki nodul paru-paru yang tidak jelas. Maka dari itu pengembangan machine learning untuk pendiagnosaan kanker paru-paru memudahkan pendiagnosaan dan meningkatkan efisiensi dalam pendiagnosaan non-invasif. Menggunakan metode Gray Level Co-occurance Matrix (GLCM) dan Convolutional Neural Network (CNN) menggunakan arsitektur Densely Connected Convolutional Network (DenseNet) yang digabungkan untuk klasifikasi tipe berdasarkan tekstur yang dilihat dari keabuan dan bentuk serta ukuran nodul.=================================================================================================================================Lung cancer, or pulmonary cancer, is a disease with varying degrees of malignancy depending on the condition. Lung cancer occurs when cells within the lungs experience uncontrolled growth and become malignant. There are two primary types of lung cancer: Non-Small Cell Lung Cancer (NSCLC) and Small Cell Lung Cancer (SCLC). NSCLC is the most common type of lung cancer, accounting for approximately 85% of all lung cancer cases. NSCLC is further divided into subtypes, including pulmonary adenocarcinoma (ADC) and pulmonary squamous cell carcinoma (SqCC). In contrast, SCLC is less common and tends to grow more rapidly than NSCLC, with a higher tendency to spread to other parts of the body at the time of diagnosis. Screening using low-dose CT scans, as currently permitted, often has low sensitivity and a high rate of false positives. More than 90% of positive results do not actually indicate the presence of cancer. Additionally, there are currently no additional biomarkers available to improve the sensitivity of low-dose CT screening, particularly for patients with unclear lung nodules. Therefore, the development of machine learning for lung cancer diagnosis would facilitate non-invasive diagnosis and improve diagnostic efficiency. Using methods such as the Gray Level Co-occurrence Matrix (GLCM) and Convolutional Neural Network (CNN) with the DenseNet architecture combined for classification based on texture, grayscale, shape, and size of nodules.",klasifikasi nsclc arsitektur densenet glcm deteksi kanker paruparu citra ctscan,kanker paruparu kanker pulmoner penyakin milik variasi ganas gantung kondisi kanker paruparu selsel paruparu alami tumbuh kendali ganas jenis kanker paruparu utama nonsmall cell lung cancer nsclc small cell lung cancer sclc nsclc jenis kanker paruparu cakup 85 kanker paruparu nsclc bagi subjenis pulmonary adenocarcinoma adc pulmonary squamous cell carcinoma sqcc sclc jarang tumbuh cepat nsclc sclc cenderung sebar tubuh diagnosis banding nsclc skrining ct scan dosis rendah izin seringkali milik tingkat sensitivitas rendah tingkat positif palsu 90 hasil positif kanker biomarker tambah tingkat sensitivitas skrining ct dosis rendah pasien milik nodul paruparu kembang machine learning pendiagnosaan kanker paruparu mudah pendiagnosaan tingkat efisiensi pendiagnosaan noninvasif metode gray level cooccurance matrix glcm convolutional neural network cnn arsitektur densely connected convolutional network densenet gabung klasifikasi tipe dasar tekstur abu bentuk ukur nodullung cancer or pulmonary cancer is a disease with varying degrees of malignancy depending on the condition lung cancer occurs when cells within the lungs experience uncontrolled growth and become malignant there are two primary types of lung cancer nonsmall cell lung cancer nsclc and small cell lung cancer sclc nsclc is the most common type of lung cancer accounting for approximately 85 of all lung cancer cases nsclc is further divided into subtypes including pulmonary adenocarcinoma adc and pulmonary squamous cell carcinoma sqcc in contrast sclc is less common and tends to grow more rapidly than nsclc with a higher tendency to spread to other parts of the body at the time of diagnosis screening using lowdose ct scans as currently permitted often has low sensitivity and a high rate of false positives more than 90 of positive results do not actually indicate the presence of cancer additionally there are currently no additional biomarkers available to improve the sensitivity of lowdose ct screening particularly for patients with unclear lung nodules therefore the development of machine learning for lung cancer diagnosis would facilitate noninvasive diagnosis and improve diagnostic efficiency using methods such as the gray level cooccurrence matrix glcm and convolutional neural network cnn with the densenet architecture combined for classification based on texture grayscale shape and size of nodules
Reidentifikasi Orang pada Data Visible-Infrared Menggunakan Klasifier Swin Transformer.,"Maulana, Muhammad Azhar",http://repository.its.ac.id/111781/,"Reidentifikasi orang menjadi topik penelitian yang sangat hanget dalam beberapa tahun terakhir dalam visi komputer. Dalam penelitian ini mengusulkan pendekatan reidentifikasi orang yang menggunakan klasifier Swin Transformer pada data citra visual-infrared. Swin Transformer, sebuah arsitektur Transformer yang terkenal karena kinerjanya yang unggul dalam tugas-tugas visi komputer dalam citra visible, diadaptasi untuk tugas reidentifikasi orang dalam citra visible-infrared. Dataset visible-infrared yang digunakan pada penelitian ini adalah dataset RegDB, kemudian model Swin Transformer diaplikasikan sebagai klasifier. Pendekatan ini memungkinkan penangkapan fitur yang efektif dari citra visual dan inframerah, memanfaatkan keunggulan Swin Transformer dalam menangkap dependensi lokal dan global.",reidentifikasi orang data visibleinfrared klasifier swin transformer,reidentifikasi orang topik teliti hanget visi komputer teliti usul dekat reidentifikasi orang klasifier swin transformer data citra visualinfrared swin transformer arsitektur transformer kenal kerja unggul tugastugas visi komputer citra visible adaptasi tugas reidentifikasi orang citra visibleinfrared dataset visibleinfrared teliti dataset regdb model swin transformer aplikasi klasifier dekat tangkap fitur efektif citra visual inframerah manfaat unggul swin transformer tangkap dependensi lokal global
Kontrol Formasi Kooperatif dan Penghindaran Rintangan pada Multiple Unmanned Aerial Vehicle dengan Guidance Route dan Artificial Potential Field.,"Maynad, Vincentius Charles",http://repository.its.ac.id/95976/,"Dalam beberapa tahun terakhir, kontrol kooperatif sistem multi-UAV (Unmanned Aerial Vehicle) telah menjadi topik penelitian yang hangat di bidang kontrol penerbangan. Diantaranya, pengendalian formasi dan penghindaran rintangan adalah salah dua tema yang penting untuk diteliti karena kompleksitas kondisi permasalahan yang ingin diselesaikan selalu meningkat seiring waktu. Problema riil ini dapat dimodelkan sebagai permasalahan kontrol penghindaran rintangan pada formasi quadcopter. Sekelompok quadcopter ditugaskan untuk membentuk formasi (berupa bentuk V), bergerak dalam formasi menuju titik tujuan, menghindari tabrakan antar robot, dan menghindari tabrakan dengan rintangan. Model quadcopter yang digunakan adalah Quanser Qdrone dengan enam derajat kebebasan. Quadcopter dikontrol menggunakan fuzzy state feedback controller untuk melacak tujuan. Pada tugas akhir ini dirancang suatu sistem pengaturan formasi menggunakan pendekatan guidance route dengan penghindaran rintangan menggunakan metode Artificial Potential Field (APF). Selain itu, akan dibandingkan dua strategi penghindaran, penghindaran total dan penghindaran minimal. Berdasarkan hasil simulasi, algoritma kontrol yang dikembangkan berhasil melaksanakan tugas pengaturan formasi dan penghindaran rintangan pada sekelompok quadcopter. Hal ini dibuktikan dengan rata-rata indeks performansi formasi bernilai 0.800025 untuk strategi penghindaran total dan 1.2227125 untuk strategi penghindaran minimal serta trayektori masing-masing quadcopteryang bebas tabrakan. ==============================================================================================In recent years, cooperative control of multi-UAV (Unmanned Aerial Vehicle) systems has become a hot research topic in the field of flight control. Among them, formation control and obstacle avoidance are two important themes to study because the complexity of the problem conditions to be solved always increases with time. This real problem can be modeled as an obstacle avoidance control problem in a quadcopter formation. A group of quadcopters is assigned to form a formation (in the form of a V shape), move in formation towards a destination point, avoid collisions between robots, and avoid collisions with obstacles. The quadcopter model used is the Quanser Qdrone with six degrees of freedom. The quadcopter is controlled using a fuzzy state feedback controller to track objectives. In this final project, a formation management system is designed using the guidance route approach with obstacle avoidance using the Artificial Potential Field (APF) method. Moreover, two avoidance strategies will be compared, total avoidance and minimum avoidance. Based on the simulation results, the developed control algorithm successfully performs the task of setting formation and obstacle avoidance on a group of quadcopters. This is evidenced by the average formation performance index of 0.800025 for total avoidance strategy and 1.2227125 for minimum avoidance strategy with the collision-free trajectories of each quadcopter.",kontrol formasi kooperatif hindar rintang multiple unmanned aerial vehicle guidance route artificial potential field,kontrol kooperatif sistem multiuav unmanned aerial vehicle topik teliti hangat bidang kontrol terbang kendali formasi hindar rintang salah tema teliti kompleksitas kondisi masalah selesai tingkat iring problema riil model masalah kontrol hindar rintang formasi quadcopter kelompok quadcopter tugas bentuk formasi bentuk v gerak formasi titik tuju hindar tabrak robot hindar tabrak rintang model quadcopter quanser qdrone enam derajat bebas quadcopter kontrol fuzzy state feedback controller lacak tuju tugas rancang sistem atur formasi dekat guidance route hindar rintang metode artificial potential field apf banding strategi hindar hindar total hindar minimal dasar hasil simulasi algoritma kontrol kembang hasil laksana tugas atur formasi hindar rintang kelompok quadcopter bukti ratarata indeks performansi formasi nila 0800025 strategi hindar total 12227125 strategi hindar minimal trayektori masingmasing quadcopteryang bebas tabrak in recent years cooperative control of multiuav unmanned aerial vehicle systems has become a hot research topic in the field of flight control among them formation control and obstacle avoidance are two important themes to study because the complexity of the problem conditions to be solved always increases with time this real problem can be modeled as an obstacle avoidance control problem in a quadcopter formation a group of quadcopters is assigned to form a formation in the form of a v shape move in formation towards a destination point avoid collisions between robots and avoid collisions with obstacles the quadcopter model used is the quanser qdrone with six degrees of freedom the quadcopter is controlled using a fuzzy state feedback controller to track objectives in this final project a formation management system is designed using the guidance route approach with obstacle avoidance using the artificial potential field apf method moreover two avoidance strategies will be compared total avoidance and minimum avoidance based on the simulation results the developed control algorithm successfully performs the task of setting formation and obstacle avoidance on a group of quadcopters this is evidenced by the average formation performance index of 0800025 for total avoidance strategy and 12227125 for minimum avoidance strategy with the collisionfree trajectories of each quadcopter
Sistem Multi-UAV untuk Pelacakan Multi-Target dalam Ruang Tiga Dimensi.,"Maynad, Vincentius Charles",http://repository.its.ac.id/111865/,"Penelitian ini berkaitan dengan sistem multi-UAV untuk melacak multi-target yang dapat diamati sebagian di lingkungan tiga dimensi yang ber-noise. Permasalahan ini biasa ditemui dalam sistem pertahanan dan pengawasan. Penelitian yang dilakukan merupakan perluasan dari penelitian-penelitian terdahulu yang berfokus terutama pada pengaturan dua dimensi, dapat diamati sepenuhnya, dan atau terukur secara sempurna. Target dimodelkan sebagai sistem linear time-invariant dengan noise Gaussian dan UAV pengejar direpresentasikan dalam model standar enam derajat kebebasan. Persamaan yang diperlukan untuk menggambarkan hubungan antara observasi mengenai target dan state pengejar diturunkan dan direpresentasikan sebagai model Gauss-Markov. Target yang dapat diobservasi sebagian mengharuskan para pengejarnya untuk mempertahankan nilai-nilai keyakinan untuk posisi target. Di hadapan lingkungan yang ber-noise, extended Kalman filter digunakan untuk memperkirakan dan memperbarui keyakinan tersebut. Algoritma Multi-Agent Reinforcement Learning (MARL) terdesentralisasi yang dikenal sebagai Soft Double Q-Learning diusulkan untuk mempelajari kontrol koordinasi di antara para pengejar. Algoritma ini diperkaya dengan regulasi entropi untuk melatih kebijakan stokastik tertentu dan memungkinkan interaksi antar pengejar untuk mendorong perilaku kooperatif. Pengembangan ini mendorong algoritma untuk melakukan eksplorasi area pencarian yang lebih luas dan tidak diketahui yang penting untuk sistem pelacakan multi-target. Algoritma dilatih sebelum diterapkan untuk menyelesaikan beberapa skenario. Percobaan menggunakan berbagai kemampuan sensor menunjukkan bahwa algoritma yang diusulkan memiliki tingkat keberhasilan yang lebih tinggi dibandingkan dengan algoritma dasarnya, hingga 4 kali lipat pada skenario tertentu. Penjelasan tentang banyak perbedaan antara lingkungan dua dimensi dan tiga dimensi juga disediakan.=======================================================================================================This research deals with multi-UAV systems to track partially observable multi-targets in a noisy three-dimensional environment. This problem is commonly encountered in defense and surveillance systems.It is a far extension from previous research which focused primarily on two-dimensional, fully observable, and or perfect measurement settings. The targets are modeled as a linear time-invariant system with Gaussian noise and the pursuers UAV are represented in a standard six degrees of freedom model. The equations required to describe the relationship between observations regarding the targets and the pursuer’sstate are derived and represented as a Gauss-Markov model. Partially observable targets require pursuers to maintain belief values for the target position. In the presence of a noisy environment, an extended Kalman filter is used to imagine and describe the belief. A decentralized Multi-Agent Reinforcement Learning (MARL) algorithm known as Soft Double Q-Learning is proposed to study coordination control among pursuers. The algorithm is enriched with entropy regulation to train specific stochastic policies and allows interaction between pursuers to encourage cooperative behavior. This development encourages the algorithm to perform exploration of wider and unknown search areas which is important for multi-target tracking systems. The algorithm is trained before being applied to complete several scenarios. Experiments using various sensor capabilities show that the proposed algorithm has a higher success rate compared to the baseline algorithm, up to 4 times in certain scenarios. An explanation of the many differences between two-dimensional and three-dimensional environments is also provided",sistem multiuav lacak multitarget ruang dimensi,teliti kait sistem multiuav lacak multitarget amat lingkung dimensi bernoise masalah temu sistem tahan awas teliti luas penelitianpenelitian fokus atur dimensi amat sepenuh ukur sempurna target model sistem linear timeinvariant noise gaussian uav kejar representasi model standar enam derajat bebas sama gambar hubung observasi target state kejar turun representasi model gaussmarkov target observasi harus kejar tahan nilainilai yakin posisi target hadap lingkung bernoise extended kalman filter baru yakin algoritma multiagent reinforcement learning marl desentralisasi kenal soft double qlearning usul ajar kontrol koordinasi kejar algoritma kaya regulasi entropi latih bijak stokastik interaksi kejar dorong perilaku kooperatif kembang dorong algoritma eksplorasi area cari luas sistem lacak multitarget algoritma latih terap selesai skenario coba mampu sensor algoritma usul milik tingkat hasil banding algoritma dasar 4 kali lipat skenario jelas beda lingkung dimensi dimensi disediakanthis research deals with multiuav systems to track partially observable multitargets in a noisy threedimensional environment this problem is commonly encountered in defense and surveillance systemsit is a far extension from previous research which focused primarily on twodimensional fully observable and or perfect measurement settings the targets are modeled as a linear timeinvariant system with gaussian noise and the pursuers uav are represented in a standard six degrees of freedom model the equations required to describe the relationship between observations regarding the targets and the pursuer  sstate are derived and represented as a gaussmarkov model partially observable targets require pursuers to maintain belief values for the target position in the presence of a noisy environment an extended kalman filter is used to imagine and describe the belief a decentralized multiagent reinforcement learning marl algorithm known as soft double qlearning is proposed to study coordination control among pursuers the algorithm is enriched with entropy regulation to train specific stochastic policies and allows interaction between pursuers to encourage cooperative behavior this development encourages the algorithm to perform exploration of wider and unknown search areas which is important for multitarget tracking systems the algorithm is trained before being applied to complete several scenarios experiments using various sensor capabilities show that the proposed algorithm has a higher success rate compared to the baseline algorithm up to 4 times in certain scenarios an explanation of the many differences between twodimensional and threedimensional environments is also provided
Identifikasi  dan Klasifikasi  Tingkat Ketidakseimbangan Statis Sela Udara Motor Induksi Berbasis Transformasi Wavelet Arus Stator.,"Mualim, Latif",http://repository.its.ac.id/82331/,"Tugas akhir ini membahas tentang pengidentifikasian dan klasifikasi ketidakseimbangan sela udara pada motor induksi dengan menggunakan transformasi wavelet diskrit yang mana dari wavelet ini diambil nilai statistik dari level tertentu komponen transformasi wavelet untuk dijadikan nilai input pada analisa jaringan saraf tiruan. Dengan memanfaatkan nntool pada MATLAB dibuatlah neuron network dengan input berupa 12 nilai statistik dan target data berupa kondisi motor. Neuron network yang sudah di training menggunakan data arus yang diukur pada tugas akhir ini. Hasilnya adalah neuron network mampu mengidentifikasi dan mengklasifikasi data arus untuk mengetahui keadaan motor tetapi terbatas hanya pada motor induksi yang digunakan pada tugas akhir ini karena keterbatasan data arus dari motor lain =====================================================================================================This final project discusses the identification and classification of airgap eccentricity in induction motors using discrete wavelet transforms, from which the statistical values of certain levels of wavelet transform components are taken to be used as input values in the analysis of artificial neural networks. By utilizing nntool in MATLAB, a neuron network was created with input in the form of 12 statistical values and target data in the form of motor conditions. Neuron networks that have been trained use current data measured in this final project. The result is that the neuron network is able to identify and classify current data of induction motor but it is limited to the induction motor used in this final project due to the limitation of current data from other motors.",identifikasi klasifikasi tingkat ketidakseimbangan statis udara motor induksi bas transformasi wavelet arus stator,tugas bahas identifikasi klasifikasi ketidakseimbangan udara motor induksi transformasi wavelet diskrit wavelet ambil nilai statistik level komponen transformasi wavelet jadi nilai input analisa jaring saraf tiru manfaat nntool matlab buat neuron network input 12 nilai statistik target data kondisi motor neuron network training data arus ukur tugas hasil neuron network identifikasi klasifikasi data arus motor batas motor induksi tugas batas data arus motor this final project discusses the identification and classification of airgap eccentricity in induction motors using discrete wavelet transforms from which the statistical values of certain levels of wavelet transform components are taken to be used as input values in the analysis of artificial neural networks by utilizing nntool in matlab a neuron network was created with input in the form of 12 statistical values and target data in the form of motor conditions neuron networks that have been trained use current data measured in this final project the result is that the neuron network is able to identify and classify current data of induction motor but it is limited to the induction motor used in this final project due to the limitation of current data from other motors
Rancang Bangun Sistem Elektronik untuk Menyimak dan Mengetes Hafalan Al-Quran Berbasis Arabic Speech to Text dan Metode Levenshtein Distance.,"Muayyad, Ahmad Saad",http://repository.its.ac.id/87298/,"Al-Quran merupakan kitab suci agama Islam yang secara luas dibaca, dihafalkan, dipelajari, dan diajarkan oleh para pemeluknya. Indonesia merupakan negara dengan pemeluk agama Islam terbanyak di dunia, maka jumlah institusi dimana Al-Quran itu dihafal dan diajarkan juga sangat banyak. Berdasarkan hal tersebut, pada Tugas Akhir ini telah dibuat sebuah sistem untuk menyimak dan mengetes hafalan Al-Quran. Sistem ini menggunakan Arabic Speech-to-Text untuk mengubah input suara menjadi teks bahasa Arab, yang kemudian dibandingkan dengan data teks Al-Quran menggunakan metode Levenshtein Distance. Bila nilai perbandingan antara input dan data teks yang tersimpan melewati batas dan logika yang sudah didesain, maka sistem akan memberikan peringatan melalui output berupa suara dan tampilan visual. Sistem yang dirancang diimplementasikan menggunakan Raspberry Pi 3B+ yang dilengkapi dengan microphone, buzzer, dan Touch Screen Display. Sistem elektronik ini menggunakan data Al-Quran yang diinput secara manual dan data Al-Quran dari PyQuran sebagai rujukan. Dihasilkan persentase error sebesar 0,45% untuk penggunaan data manual dan 3,52% untuk penggunaan data PyQuran dalam pengujian 3 halaman di juz pertama Al-Quran. Latency rata-rata yang dihasilkan untuk satu kata yang diproses dengan kecepatan internet 10 Mbps adalah 0,1292 s. Kedepannya, kualitas sistem koreksi dapat ditambahkan terutama untuk PyQuran agar sistem elektronik ini dapat digunakan untuk 30 juz Al-Quran secara lengkap sehingga dapat membantu para penghafal Al-Quran =====================================================================================================Al-Quran is Islam’s Holy Book that widely recited, memorized, studied, and taught by its followers. Indonesia is a country with the largest number of Muslim, in which many intitutions where Al-Quran are memorized and taught. Based on that, in this Final Project, an electronic system for correcting and testing Al-Quran memorization was designed. This system uses Arabic Speech-to-Text to convert audio input to Arabic text that was compared to Al-Quran text data with Levenshtein Distance Method. If the comparison value between audio input and Al-Quran text data exceeds the limit and logic that has been designed, the system will give a warning by audio and visual output. This system is designed using Raspberry Pi 3B+ equipped with microphone, buzzer, and Touch Screen Display. This electronic system uses Al-Quran data that manually input and PyQuran data as its reference. An error percentage of 0,45% was obtained using Al-Quran manual data and 3,52% was obtained using PyQuran data for 3 pages from the first juz testing. Average latency that was obtained for each word processing for 10 Mbps internet speed is 0,1292 s. In the future research, the quality of correction system can be upgraded especially for PyQuran so this system can be used for 30 juz perfectly and will be a huge benefit for Al-Quran memorizer.",rancang bangun sistem elektronik simak ketes hafal alquran bas arabic speech to text metode levenshtein distance,alquran kitab suci agama islam luas baca hafal ajar ajar peluk indonesia negara peluk agama islam dunia institusi mana alquran hafal ajar dasar tugas sistem simak ketes hafal alquran sistem arabic speechtotext ubah input suara teks bahasa arab banding data teks alquran metode levenshtein distance nilai banding input data teks simpan lewat batas logika desain sistem ingat output suara tampil visual sistem rancang implementasi raspberry pi 3b lengkap microphone buzzer touch screen display sistem elektronik data alquran diinput manual data alquran pyquran rujuk hasil persentase error 045 guna data manual 352 guna data pyquran uji 3 halaman juz alquran latency ratarata hasil proses cepat internet 10 mbps 01292 s depan kualitas sistem koreksi pyquran sistem elektronik 30 juz alquran lengkap bantu hafal alquran alquran is islam  s holy book that widely recited memorized studied and taught by its followers indonesia is a country with the largest number of muslim in which many intitutions where alquran are memorized and taught based on that in this final project an electronic system for correcting and testing alquran memorization was designed this system uses arabic speechtotext to convert audio input to arabic text that was compared to alquran text data with levenshtein distance method if the comparison value between audio input and alquran text data exceeds the limit and logic that has been designed the system will give a warning by audio and visual output this system is designed using raspberry pi 3b equipped with microphone buzzer and touch screen display this electronic system uses alquran data that manually input and pyquran data as its reference an error percentage of 045 was obtained using alquran manual data and 352 was obtained using pyquran data for 3 pages from the first juz testing average latency that was obtained for each word processing for 10 mbps internet speed is 01292 s in the future research the quality of correction system can be upgraded especially for pyquran so this system can be used for 30 juz perfectly and will be a huge benefit for alquran memorizer
Prediksi Financial Distress Perusahaan Sektor Industri di Indonesia dengan Metode Klasifikasi dan Melibatkan Synthetic Features Generation.,"Muda, Muhammad Adlansyah",http://repository.its.ac.id/83474/,"Masalah kondisi financial distress dapat berakhir dengan kebangkrutan apabila tidak segera ditanggulangi. Untuk mengantisipasi dan meminimalisir dampak dari bangkrutnya suatu perusahaan terutama pada sektor industri, maka dilakukan prediksi financial distress untuk menilai kondisi keuangan perusahaan dan perspektif masa depannya. Pada penelitian ini prediksi financial distress dilakukan dengan metode klasifikasi seperti Generalized Extreme Value Regression, Logistic Regression, Support Vector Machine, dan Extreme Gradient Boosting dengan melibatkan synthetic features generation secara serentak dan seleksi variabel. Berdasarkan nilai accuracy, AUC, dan F1-score dari hasil evaluasi model menggunakan data testing didapatkan bahwa metode synthetic features generation tidak selalu memberikan performansi klasifikasi terbaik pada tiap size. Pada size 0 dan size 1 disimpulkan bahwa model Extreme Gradient Boosting dengan melibatkan synthetic features generation dan seleksi variabel merupakan model dengan performansi klasifikasi terbaik, sedangkan pada size 2 dan size 3 didapatkan bahwa model Extreme Gradient Boosting tanpa melibatkan synthetic features generation dengan seleksi variabel merupakan model dengan performansi klasifikasi terbaik dalam memprediksi kondisi keuangan perusahaan sektor industri di Indonesia.====================================================================================================================The problem of financial distress can lead to bankruptcy if it is not addressed immediately. To anticipate and minimize the impact of a company bankruptcy, especially in the industrial sector, financial distress predictions are made to assess the company’s financial condition and its future perspective. In this study, prediction of financial distress is carried out using classification methods such as Generalized Extreme Value Regression, Logistic Regression, Support Vector Machine, and Extreme Gradient Boosting by involving synthetic features generation simultaneously and variable selection. Based on the accuracy, AUC, and F1-score from the results of model evaluation using data testing, it is found that the synthetic features generation method does not always provide the best classification performance for each size. At size 0 and size 1, it can be concluded that the Extreme Gradient Boosting model involving synthetic features generation with variable selection is the model with the best classification performance, whereas at size 2 and size 3, it is found that the Extreme Gradient Boosting model without involving synthetic features generation with variabel selection is the model with the best classification performance in predicting the financial condition of industrial sector companies in Indonesia.",prediksi financial distress usaha sektor industri indonesia metode klasifikasi libat synthetic features generation,kondisi financial distress bangkrut tanggulang antisipasi meminimalisir dampak bangkrut usaha sektor industri prediksi financial distress nilai kondisi uang usaha perspektif depan teliti prediksi financial distress metode klasifikasi generalized extreme value regression logistic regression support vector machine extreme gradient boosting libat synthetic features generation serentak seleksi variabel dasar nilai accuracy auc f1score hasil evaluasi model data testing dapat metode synthetic features generation performansi klasifikasi baik size size 0 size 1 simpul model extreme gradient boosting libat synthetic features generation seleksi variabel model performansi klasifikasi baik size 2 size 3 dapat model extreme gradient boosting libat synthetic features generation seleksi variabel model performansi klasifikasi baik prediksi kondisi uang usaha sektor industri indonesiathe problem of financial distress can lead to bankruptcy if it is not addressed immediately to anticipate and minimize the impact of a company bankruptcy especially in the industrial sector financial distress predictions are made to assess the company  s financial condition and its future perspective in this study prediction of financial distress is carried out using classification methods such as generalized extreme value regression logistic regression support vector machine and extreme gradient boosting by involving synthetic features generation simultaneously and variable selection based on the accuracy auc and f1score from the results of model evaluation using data testing it is found that the synthetic features generation method does not always provide the best classification performance for each size at size 0 and size 1 it can be concluded that the extreme gradient boosting model involving synthetic features generation with variable selection is the model with the best classification performance whereas at size 2 and size 3 it is found that the extreme gradient boosting model without involving synthetic features generation with variabel selection is the model with the best classification performance in predicting the financial condition of industrial sector companies in indonesia
Secure Indoor Positioning System Model Menggunakan Serangan Boundary Attack Berbasis Aplikasi Mobile.,"Muhammad, Banabil Fawazaim",http://repository.its.ac.id/106076/,"Selama dekade terakhir, perangkat seluler telah berevolusi tidak hanya berfungsi sebagai komunikasi jarak jauh, namun juga sebagai perangkat navigasi menggunakan Global Positioning System (GPS). Karena keterbatasan GPS dalam ruangan, dikembangkan IPS (Indoor Positioning System) sebagai pengganti dari GPS pada saat di dalam ruangan.  Studi ini menyoroti kurangnya perhatian terhadap keamanan dan privasi dalam pengembangan IPS, terutama dalam menghadapi serangan keamanan seperti serangan Boundary Attack.  Penelitian ini bertujuan untuk membuat IPS yang tahan terhadap serangan Boundary Attack dengan mengembangkan model menggunakan data sidik jari Channel State Information (CSI).  Tujuan dari penelitian ini mencakup membandingkan kinerja antara model IPS dan model rekan terhadap serangan serangan perimeter, dan mengintegrasikan model dengan aplikasi seluler untuk menampilkan lokasi pengguna secara real time. Metode penelitiannya antara lain mengumpulkan dataset dari Tower 2 ITS, membangun dan melatih model IPS menggunakan data yang diserang dan tidak diserang, menerapkan serangan Boundary Attack, dan membuat aplikasi seluler terintegrasi.  Hasil penelitian meliputi evaluasi akurasi model sebelum dan sesudah serangan serta perbandingan dengan model pembanding dalam kondisi serangan. Model IPS berhasil dibangun yang dapat menahan serangan Boundary Attack dan menjaga akurasi bahkan setelah serangan tersebut. Membandingkan model IPS dengan model pembanding menunjukkan ketahanan yang baik terhadap serangan.  Dengan mengintegrasikan aplikasi mobile dengan IPS melalui Flask, pengguna dapat melihat lokasinya dengan akurasi tinggi dan real time.=================================================================================================================================Over the past decade, mobile devices have evolved to function not only as long-distance communication, but also as navigation devices using the Global Positioning System (GPS). Due to the limitations of indoor GPS, IPS (Indoor Positioning System) was developed as a replacement for GPS when indoors. This study highlights the lack of attention to security and privacy in the development of IPS, especially in the face of security attacks such as Boundary Attack. This research aims to create an IPS that is resistant to Boundary Attack by developing a model using Channel State Information (CSI) fingerprint data. The objectives of this research include comparing the performance between the IPS model and the peer model against perimeter attack attacks, and integrating the model with a mobile application to display the user's location in real time. The research methods included collecting datasets from Tower 2 ITS, building and training the IPS model using attacked and unattacked data, applying the Boundary Attack, and creating an integrated mobile application. The results include an evaluation of the accuracy of the model before and after the attack as well as a comparison with the comparison model under attack conditions. An IPS model was successfully built that can withstand Boundary Attack attacks and maintain accuracy even after such attacks. Comparing the IPS model with the comparison model shows good resistance to attacks. By integrating a mobile application with the IPS through Flask, users can view their location with high accuracy and in real time.",secure indoor positioning system model serang boundary attack bas aplikasi mobile,dekade perangkat seluler evolusi fungsi komunikasi jarak perangkat navigasi global positioning system gps batas gps ruang kembang ips indoor positioning system ganti gps ruang studi sorot kurang perhati aman privasi kembang ips hadap serang aman serang boundary attack teliti tuju ips tahan serang boundary attack kembang model data sidik jari channel state information csi tuju teliti cakup banding kerja model ips model rekan serang serang perimeter integrasi model aplikasi seluler tampil lokasi guna real time metode teliti kumpul dataset tower 2 its bangun latih model ips data serang serang terap serang boundary attack aplikasi seluler integrasi hasil teliti liput evaluasi akurasi model serang banding model banding kondisi serang model ips hasil bangun tahan serang boundary attack jaga akurasi serang banding model ips model banding tahan serang integrasi aplikasi mobile ips flask guna lokasi akurasi real timeover the past decade mobile devices have evolved to function not only as longdistance communication but also as navigation devices using the global positioning system gps due to the limitations of indoor gps ips indoor positioning system was developed as a replacement for gps when indoors this study highlights the lack of attention to security and privacy in the development of ips especially in the face of security attacks such as boundary attack this research aims to create an ips that is resistant to boundary attack by developing a model using channel state information csi fingerprint data the objectives of this research include comparing the performance between the ips model and the peer model against perimeter attack attacks and integrating the model with a mobile application to display the users location in real time the research methods included collecting datasets from tower 2 its building and training the ips model using attacked and unattacked data applying the boundary attack and creating an integrated mobile application the results include an evaluation of the accuracy of the model before and after the attack as well as a comparison with the comparison model under attack conditions an ips model was successfully built that can withstand boundary attack attacks and maintain accuracy even after such attacks comparing the ips model with the comparison model shows good resistance to attacks by integrating a mobile application with the ips through flask users can view their location with high accuracy and in real time
Sistem Informasi Pengelolaan Keuangan Sekolah (Sipks) Dengan Electronic Dan Digital Signature Recognition Menggunakan Algoritma MobileNet.,"Mukhlishah, Chaniyah Zulfa",http://repository.its.ac.id/83295/,"Pengelolaan anggaran sekolah merupakan aktivitas yang sering dilakukan di berbagai Sekolah, terutama sekolah negeri. Pengelolaan anggaran pun dapat mencakup dalam berbagai hal. Seperti kegiatan penganggaran dana akademik, organisasi, maupun administrasi yang mutlak membutuhkan alokasi dana dalam pelaksanaannya. Oleh karena itu, kegiatan pengelolaan keuangan sekolah membutuhkan perhatian, terutama dalam hal teknis pelaksanaannya agar dapat diimplementasikan lebih mudah. Pada era digital saat ini, metode penganggaran dana yang manual merupakan sebuah permasalahan dimana metode manual ini sering dikhawatirkan oleh pihak sekolah dalam hal pencatatan dan keamanannya.",sistem informasi kelola uang sekolah sipks electronic digital signature recognition algoritma mobilenet,kelola anggar sekolah aktivitas sekolah sekolah negeri kelola anggar cakup giat anggar dana akademik organisasi administrasi mutlak butuh alokasi dana laksana giat kelola uang sekolah butuh perhati teknis laksana implementasi mudah era digital metode anggar dana manual masalah mana metode manual khawatir sekolah catat aman
Aplikasi Discrete Wavelets Transform pada Analisis Regresi Spektrum Tumpang Tindih Senyawa Parasetamol dan Kafein.,"Mulyaningtias, Nadia",http://repository.its.ac.id/90046/,"Obat umumnya berisi kombinasi dari beberapa senyawa aktif. Parasetamol sering digunakan sebagai obat analgesik dan anti piretik. Kafein adalah stimulan sistem saraf pusat (SSP). Dalam pemasaran obat sakit kepala di masyarakat, pemeriksaan mutu obat diperlukan untuk menjamin bahwa obat menggandung bahan aktif dengan mutu dan jumlah sesuai dengan kandungan yang tertera pada label obat. Sehingga diperlukan metode yang efisien tanpa pemisahan, dengan bantuan spektrofotometer UV-Vis, metode Discrete Wavelets Transform dan analisis multikomponen. Sebanyak 25 larutan training set disiapkan dan dianalisis absorbansinya menggunakan metode Multiple Linier Regression, metode Support Vector Regression (SVR), metode Partial Least Square (PLS) Regression, metode AdaBoost Regression. Model yang didapat divalidasi dengan tes data sebelum diaplikasikan pada obat sakit kepala. Penentuan kadar obat yang sesuai dengan kadar dalam label obat, yaitu pada metode Support Vector Regression dimana rata-rata kadar obat prediksi parasetamol sebesar 512,5473 mg dan pada kafein sebesar 67,1091 mg. Sehingga metode berhasil digunakan untuk menetapkan kadar dalam tablet obat sakit kepala.=======================================================================================================Medicine generally contain active ingredients. Paracetamol is often used as an analgesic and anti-pyretic medicine. Caffeine is a central nervous system (CNS) stimulant. In marketing headache medicine in the community, quality inspection of medicine is needed to ensure that the medicine contains active ingredients with the quality and quantity according to the content stated on the medicine label. So an efficient method without separation is needed, with the help of a UV-Vis spectrophotometer, the Discrete Wavelets Transform method and multivariate analysis. A total of 25 training set solutions were prepared and their absorbance analyzed using the Multiple Linear Regression method, the Support Vector Regression (SVR) method, the Partial Least Square (PLS) Regression method, the AdaBoost Regression method. The model obtained was validated by testing the data before it was applied to headache medicine. Determination of medicine levels in accordance with the levels on the medicine label, namely the Support Vector Regression method where the average level of the predicted medicine parasetamol is 512.5473 mg and the caffeine is 67.1091 mg. So that the method was successfully used to determine the levels in headache medicine tablets.",aplikasi discrete wavelets transform analisis regresi spektrum tumpang tindih senyawa parasetamol kafein,obat isi kombinasi senyawa aktif parasetamol obat analgesik anti piretik kafein stimulan sistem saraf pusat ssp pasar obat sakit kepala masyarakat periksa mutu obat jamin obat gandung bahan aktif mutu sesuai kandung tera label obat metode efisien pisah bantu spektrofotometer uvvis metode discrete wavelets transform analisis multikomponen 25 larut training set siap analis absorbansinya metode multiple linier regression metode support vector regression svr metode partial least square pls regression metode adaboost regression model divalidasi tes data aplikasi obat sakit kepala tentu kadar obat sesuai kadar label obat metode support vector regression mana ratarata kadar obat prediksi parasetamol 5125473 mg kafein 671091 mg metode hasil tetap kadar tablet obat sakit kepalamedicine generally contain active ingredients paracetamol is often used as an analgesic and antipyretic medicine caffeine is a central nervous system cns stimulant in marketing headache medicine in the community quality inspection of medicine is needed to ensure that the medicine contains active ingredients with the quality and quantity according to the content stated on the medicine label so an efficient method without separation is needed with the help of a uvvis spectrophotometer the discrete wavelets transform method and multivariate analysis a total of 25 training set solutions were prepared and their absorbance analyzed using the multiple linear regression method the support vector regression svr method the partial least square pls regression method the adaboost regression method the model obtained was validated by testing the data before it was applied to headache medicine determination of medicine levels in accordance with the levels on the medicine label namely the support vector regression method where the average level of the predicted medicine parasetamol is 5125473 mg and the caffeine is 671091 mg so that the method was successfully used to determine the levels in headache medicine tablets
Optimasi Convolutional Neural Network melalui Fungsi Aktivasi dan Inisialisasi Kernel untuk Pengenalan Tulisan Huruf Hijaiyah.,"Nasty, Khairuddin",http://repository.its.ac.id/117839/,"Penelitian ini mengoptimalkan model Convolutional Neural Network (CNN) untuk pengenalan tulisan tangan huruf Hijaiyah dengan menganalisis kombinasi fungsi aktivasi (ReLU, Leaky ReLU, Sigmoid, Tanh) dan metode inisialisasi kernel (He normal, He uniform, LeCun normal, LeCun uniform, Glorot normal, Glorot uniform). Dataset yang digunakan adalah Hossam Magdy Balaha Dataset (HMBD) yang dimodifikasi—dengan penambahan tanda baca fathah, kasrah, dan dhammah—untuk mengevaluasi 24 kombinasi parameter. Hasil eksperimen menunjukkan bahwa kombinasi He normal-ReLU mencapai performa terbaik dengan akurasi 93,84%, presisi 93,96%, recall 93,77%, dan F1-score 93,71%. Analisis konvergensi mengungkapkan kombinasi ini stabil setelah epoch ke-10, dengan validation loss di bawah 0,5, serta fluktuasi akurasi kurang dari ±1%. Kesalahan klasifikasi tertinggi terjadi pada pasangan dengan kemiripan visual, yaitu Ain fathah-Haa fathah (14,63%) yang diidentifikasi melalui confusion matrix. Konversi model ke TensorFlow Lite berhasil mengurangi ukuran dari 29,4 MB menjadi 9,8 MB (66,67%) tanpa penurunan performa, dengan akurasi tetap 93,84%. Temuan ini membuktikan bahwa optimasi inisialisasi kernel dan fungsi aktivasi secara signifikan meningkatkan akurasi dan efisiensi model, sekaligus memberikan panduan implementasi CNN untuk aplikasi mobile edukasi berbasis tulisan tangan non-Latin.==================================================================================================================================This study optimized a Convolutional Neural Network (CNN) model for recognizing handwritten Hijaiyah characters by analyzing combinations of activation functions (ReLU, Leaky ReLU, Sigmoid, Tanh) and kernel initialization methods (He normal, He uniform, LeCun normal, LeCun uniform, Glorot normal, Glorot uniform). The modified Hossam Magdy Balaha Dataset (HMBD)—augmented with diacritical marks (fathah, kasrah, dhammah)—was used to evaluate 24 parameter combinations. Experimental results demonstrated that the He normal-ReLU combination achieved the best performance, with 93.84% accuracy, 93.96% precision, 93.77% recall, and 93.71% F1-score. Convergence analysis revealed this combination stabilized after the 10th epoch, with validation loss below 0.5 and accuracy fluctuations within ±1%. The highest misclassification rate (14.63%) occurred between visually similar pairs, specifically Ain fathah-Haa fathah, as identified through confusion matrices. Model conversion to TensorFlow Lite successfully reduced its size from 29.4 MB to 9.8 MB (66.67%) without performance degradation, maintaining 93.84% accuracy. These findings prove that optimizing kernel initialization and activation functions significantly enhances model accuracy and efficiency, while providing a practical guideline for implementing CNNs in mobile-based educational applications for non-Latin handwriting recognition.",optimasi convolutional neural network fungsi aktivasi inisial kernel kenal tulis huruf hijaiyah,teliti optimal model convolutional neural network cnn kenal tulis tangan huruf hijaiyah analis kombinasi fungsi aktivasi relu leaky relu sigmoid tanh metode inisial kernel he normal he uniform lecun normal lecun uniform glorot normal glorot uniform dataset hossam magdy balaha dataset hmbd modifikasi dengan tambah tanda baca fathah kasrah dhammah untuk evaluasi 24 kombinasi parameter hasil eksperimen kombinasi he normalrelu capai performa baik akurasi 9384 presisi 9396 recall 9377 f1score 9371 analisis konvergensi kombinasi stabil epoch ke10 validation loss 05 fluktuasi akurasi 1 salah klasifikasi tinggi pasang mirip visual ain fathahhaa fathah 1463 identifikasi confusion matrix konversi model tensorflow lite hasil kurang ukur 294 mb 98 mb 6667 turun performa akurasi 9384 temu bukti optimasi inisial kernel fungsi aktivasi signifikan tingkat akurasi efisiensi model pandu implementasi cnn aplikasi mobile edukasi bas tulis tangan nonlatinthis study optimized a convolutional neural network cnn model for recognizing handwritten hijaiyah characters by analyzing combinations of activation functions relu leaky relu sigmoid tanh and kernel initialization methods he normal he uniform lecun normal lecun uniform glorot normal glorot uniform the modified hossam magdy balaha dataset hmbd augmented with diacritical marks fathah kasrah dhammah was used to evaluate 24 parameter combinations experimental results demonstrated that the he normalrelu combination achieved the best performance with 9384 accuracy 9396 precision 9377 recall and 9371 f1score convergence analysis revealed this combination stabilized after the 10th epoch with validation loss below 05 and accuracy fluctuations within 1 the highest misclassification rate 1463 occurred between visually similar pairs specifically ain fathahhaa fathah as identified through confusion matrices model conversion to tensorflow lite successfully reduced its size from 294 mb to 98 mb 6667 without performance degradation maintaining 9384 accuracy these findings prove that optimizing kernel initialization and activation functions significantly enhances model accuracy and efficiency while providing a practical guideline for implementing cnns in mobilebased educational applications for nonlatin handwriting recognition
Penyaringan Surel Bersifat Spam Dengan Menggunakan Online Active Ensemble Learning.,"Naufal, Muhammad Rafif Fadhil",http://repository.its.ac.id/107850/,"Surel merupakan salah satu bentuk komunikasi yang sangat umum digunakan di seluruh dunia. Hal ini mengakibatkan traffic keluar-masuk surel yang berkembang di tiap tahunnya. Salah satu masalah yang sering terjadi pada surel adalah adanya surel yang bersifat spam. Spam merupakan surel yang tidak diinginkan oleh penerimanya dan biasanya berisi iklan, penipuan, atau konten yang tidak senonoh. Penyaringan surel merupakan salah satu upaya mewujudkan Pembangunan Berkelanjutan (SDGs). Pada Penelitian ini, akan dibuat sebuah model untuk melakukan penyaringan surel bersifat spam dengan menggunakan metode Online Active Ensemble Learning. Metode ini merupakan perpaduan antara online active learning dengan model klasifikasi ensemble. Model ini akan diimplementasikan menggunakan bahasa pemrograman Python. Dataset yang digunakan penelitian ini merupakan dataset public bernama enron-spam. Dataset ini terdiri dari kumpulan email 6 pegawai Enron. Total email yang terdapat pada dataset ini adalah 33.716 email. Hasil eksperimen menunjukkan bahwa model yang menggunakan metode Online Active Ensemble Learning memiliki performa yang lebih baik dibandingkan dengan model single learning. Hal ini ditunjukkan dengan nilai akurasi, presisi, recall, dan f1-score yang lebih tinggi. Selain itu, penggunaan resource yang dibutuhkan untuk melakukan prediksi dan learning juga lebih rendah, sehingga semakin mendukung efisiensi dan keberlanjutan. Kesimpulannya, metode Online Active Ensemble Learning dapat digunakan untuk melakukan penyaringan surel bersifat spam dengan performa yang baik dan efisien dalam penggunaan resource, sehingga turut berkontribusi terhadap pencapaian beberapa SDGs.============================================================================================================================Email is one of the most common forms of communication used worldwide, leading to a growing volume of incoming and outgoing email traffic each year. One of the recurring issues with email is the presence of spam, which refers to unwanted emails typically containing advertisements, scams, or inappropriate content. Email filtering is one approach to realizing Sustainable Development Goals (SDGs). In this research, a model will be developed to filter spam emails using the Online Active Ensemble Learning method, which combines online active learning with ensemble classification models. This model will be implemented using the Python programming language. The dataset used in this study is a public dataset called enron-spam, consisting of a collection of emails from six Enron employees totaling 33,716 emails. Experimental results indicate that the model utilizing the Online Active Ensemble Learning method outperforms single learning models, as evidenced by higher accuracy, precision, recall, and f1-score values. Additionally, the resource requirements for prediction and learning are lower, further supporting efficiency and sustainability. In conclusion, the Online Active Ensemble Learning method can be employed for effective and resource-efficient spam email filtering, thereby contributing to the achievement of several SDGs.",nyaring surel sifat spam online active ensemble learning,surel salah bentuk komunikasi dunia akibat traffic keluarmasuk surel kembang tahun salah surel surel sifat spam spam surel terima isi iklan tipu konten senonoh nyaring surel salah upaya wujud bangun lanjut sdgs teliti model nyaring surel sifat spam metode online active ensemble learning metode padu online active learning model klasifikasi ensemble model implementasi bahasa pemrograman python dataset teliti dataset public nama enronspam dataset kumpul email 6 pegawai enron total email dataset 33716 email hasil eksperimen model metode online active ensemble learning milik performa banding model single learning nilai akurasi presisi recall f1score guna resource butuh prediksi learning rendah dukung efisiensi lanjut simpul metode online active ensemble learning nyaring surel sifat spam performa efisien guna resource kontribusi capai sdgsemail is one of the most common forms of communication used worldwide leading to a growing volume of incoming and outgoing email traffic each year one of the recurring issues with email is the presence of spam which refers to unwanted emails typically containing advertisements scams or inappropriate content email filtering is one approach to realizing sustainable development goals sdgs in this research a model will be developed to filter spam emails using the online active ensemble learning method which combines online active learning with ensemble classification models this model will be implemented using the python programming language the dataset used in this study is a public dataset called enronspam consisting of a collection of emails from six enron employees totaling 33716 emails experimental results indicate that the model utilizing the online active ensemble learning method outperforms single learning models as evidenced by higher accuracy precision recall and f1score values additionally the resource requirements for prediction and learning are lower further supporting efficiency and sustainability in conclusion the online active ensemble learning method can be employed for effective and resourceefficient spam email filtering thereby contributing to the achievement of several sdgs
Segmentasi Jantung Pada Citra Short-Axis View Magnetic Resonance Imaging Menggunakan 2D U-Net.,"Nindita, Nabil Virio Akhsan",http://repository.its.ac.id/108687/,"Penyakit kardiovaskular merupakan masalah kesehatan yang signifikan secara global, menyebabkan banyak kematian, terutama disebabkan oleh penyakit jantung. Diagnosis penyakit jantung yang akurat dan tepat waktu sangat penting untuk pengobatan yang efektif. Adanya kemajuan teknologi medis telah meningkatkan pemahaman dan pengambilan tindakan terhadap penyakit tersebut. Penelitian ini berfokus pada segmentasi struktur jantung pada citra Short Axis Magnetic Resonance Imaging ( SAX MRI) menggunakan model deep learning dengan arsitektur U-Net 2D. Tujuan utama dari penelitian ini adalah untuk mengembangkan model deep learning yang dapat mensegmentasi struktur jantung, yaitu ventrikel kiri (LV), ventrikel kanan (RV), dan miokardium. Penelitian ini menggunakan dataset Automated Cardiac Diagnosis Challenge (ACDC) 2017, yang mencakup pemindaian MRI dari 150 pasien dengan berbagai kondisi jantung. Model segmentasi berbasis U-Net 2D yang diusulkan diharapkan menghasilkan akurasi tinggi, sehingga berpotensi untuk memberi manfaat bagi penanganan penyakit jantung. Berdasarkan pengujian yang telah dilakukan dari skenario-skenario penelitian didapatkan hasil Dice dan IoU Score oleh model sebesar 0,8806 dan 0,7663.=================================================================================================================================Segmentasi Cardiovascular disease is a significant health problem globally, causing many deaths , mainly caused by heart disease. Accurate and timely diagnosis of heart disease is essential for effective treatment. Advances in medical technology have improved the understanding and treatment of these diseases. This research focuses on segmenting cardiac structures in Short Axis Magnetic Resonance Imaging (SAX MRI) images using deep learning model with 2D U-Net architecture. The main objective of this research is to develop a deep learning model that can segment the heart structures, namely the left ventricle (LV), right ventricle (RV), and myocardium. This study uses the Automated Cardiac Diagnosis Challenge (ACDC) 2017 dataset, which includes MRI scans of 150 patients with various heart conditions. The proposed 2D U-Net-based segmentation model is expected to yield high accuracy, potentially benefiting the treatment of heart disease. Based on the tests that have been carried out from the scenarios of this research the Dice and IoU Score results obtained by the model are 0,8806 and 0,7663.Jantung Pada Citra Short-Axis View Magnetic Resonance Imaging Menggunakan 2d U-Net",segmentasi jantung citra shortaxis view magnetic resonance imaging 2d unet,sakit kardiovaskular sehat signifikan global sebab mati sebab sakit jantung diagnosis sakit jantung akurat obat efektif maju teknologi medis tingkat paham ambil tindak sakit teliti fokus segmentasi struktur jantung citra short axis magnetic resonance imaging sax mri model deep learning arsitektur unet 2d tuju utama teliti kembang model deep learning segmentasi struktur jantung ventrikel kiri lv ventrikel kanan rv miokardium teliti dataset automated cardiac diagnosis challenge acdc 2017 cakup pindai mri 150 pasien kondisi jantung model segmentasi bas unet 2d usul harap hasil akurasi potensi manfaat tangan sakit jantung dasar uji skenarioskenario teliti dapat hasil dice iou score model 08806 07663segmentasi cardiovascular disease is a significant health problem globally causing many deaths mainly caused by heart disease accurate and timely diagnosis of heart disease is essential for effective treatment advances in medical technology have improved the understanding and treatment of these diseases this research focuses on segmenting cardiac structures in short axis magnetic resonance imaging sax mri images using deep learning model with 2d unet architecture the main objective of this research is to develop a deep learning model that can segment the heart structures namely the left ventricle lv right ventricle rv and myocardium this study uses the automated cardiac diagnosis challenge acdc 2017 dataset which includes mri scans of 150 patients with various heart conditions the proposed 2d unetbased segmentation model is expected to yield high accuracy potentially benefiting the treatment of heart disease based on the tests that have been carried out from the scenarios of this research the dice and iou score results obtained by the model are 08806 and 07663jantung citra shortaxis view magnetic resonance imaging 2d unet
Intergrasi Nonlinear Programming (NLP) dan Cost Benefit Analysis (CBA) untuk Pengelolaan Limbah Fly Ash Dan Bottom Ash (FABA) Industri Pupuk (Studi Kasus : PT. Pupuk Indonesia).,"Nubail, Ahmad Azrial",http://repository.its.ac.id/107885/,"Limbah Fly Ash dan Bottom Ash (FABA) pada industri pupuk berdasarkan PP No 22 Tahun 2021 tidak termasuk dalam kategori B3 dimana proses pembakaran batubaranya menggunakan teknologi tungku industri (stocker boiler). Dengan PP No 22 Tahun 2021, maka perlu dilakukan penelitian untuk menentukan skema pengelolaan limbah FABA terbaik antara kondisi eksisting dan skenario perbaikan dengan mempertimbangkan manfaat optimal dari setiap opsi pengelolaan limbah FABA. Perlu dilakukan Cost-Benefit Analysis, menghitung Benefit-Cost Ratio, dan dilanjutkan dengan analisis sensitivitas untuk menghilangkan satu solusi yang mendominasi dari skenario yang dipilih untuk mendapatkan skema pengelolaan terbaik. Untuk melakukan perhitungan dan analisis diperlukan kajian terkait Pupuk Indonesia dan anak perusahaan terkait, pengelolaan FABA, Cost-Benefit Analysis (CBA), Nonlinier Programming (NLP), dan analisis sensitivitas. Berdasarkan analisis kondisi eksisting proses bisnis pengelolaan limbah, diperoleh empat skenario pengelolaan limbah FABA untuk masing-masing perusahaan. Dari keempat skenario perbaikan, dipilih dua skenario untuk dilakukan analisis lanjutan. Kedua skenario tersebut adalah kondisi eksisting dan skenario yang berfokus pada kerjasama pengelolaan limbah FABA dengan mengoptimalkan manfaat yang diperoleh. Hasil perhitungan menunjukkan bahwa dengan skenario perbaikan, biaya pengelolaan limbah yang dikeluarkan oleh perusahaan dapat turun hingga 60% dari kondisi eksisting. Perhitungan Benefit-Cost Ratio (BCR) dari skenario perbaikan untuk masing-masing perusahaan menghasilkan angka dari 1.109 hingga 1.602 dalam kondisi ideal. Pada skenario perbaikan, dilakukan analisis sensitivitas, dan ditemukan bahwa perubahan %bagi hasil dan batas bawah pengelolaan tidak mempengaruhi kelayakan skenario. Sedangkan %penyerapan FABA dan %manfaat lingkungan mempengaruhi kelayakan skenario. Dapat disimpulkan bahwa skenario perbaikan yang diusulkan layak untuk diterapkan dengan mempertimbangkan kondisi masing-masing parameter yang mempengaruhi kelayakan skenario.===================================================================================================================================Fly Ash and Bottom Ash (FABA) waste in the fertilizer industry, based on PP No. 22 of 2021, is excluded from B3 category where the coal combustion process uses industrial furnace technology (stocker boiler). With PP No. 22 of 2021, it is necessary to research to determine the best FABA waste management scheme between existing conditions and improvement scenarios by considering the optimal benefits of each FABA waste management option. It is necessary to do a cost-benefit analysis, calculate the benefit-cost ratio, and proceed with a sensitivity analysis to eliminate one dominating solution from the selected scenario to get the best management scheme. To carry out the necessary calculations and analysis, a study related to Pupuk Indonesia and its related subsidiaries, FABA management, Cost-Benefit Analysis (CBA), Nonlinear Programming (NLP), and sensitivity analysis. Based on the analysis of the existing condition of the existing waste management business process, four FABA waste management scenarios were obtained for each company. From the four scenarios, two scenarios were chosen for further analysis. The two scenarios are the existing condition and the scenario that focuses on cooperation in FABA waste management by optimizing the benefits obtained. The results of the calculations show that with the improvement scenario, the waste management costs incurred by the company can decrease by up to 60% from the existing condition. The calculation of the benefit-cost ratio (BCR) from the improvement scenario for each company produces numbers from 1.109 to 1.602 under ideal conditions. In the improvement scenario, a sensitivity analysis was carried out, and it was found that changes in % profit sharing and the lower management limit did not affect the feasibility of the scenario. Meanwhile, the % absorption of FABA and % environmental benefits influence the feasibility of the scenario. It can be concluded that the proposed improvement scenario is feasible to be applied by considering the conditions of each parameter that affect the feasibility of the scenario.",intergrasi nonlinear programming nlp cost benefit analysis cba kelola limbah fly ash bottom ash faba industri pupuk studi pt pupuk indonesia,limbah fly ash bottom ash faba industri pupuk dasar pp no 22 2021 kategori b3 mana proses bakar batubaranya teknologi tungku industri stocker boiler pp no 22 2021 teliti tentu skema kelola limbah faba baik kondisi eksisting skenario baik timbang manfaat optimal opsi kelola limbah faba costbenefit analysis hitung benefitcost ratio lanjut analisis sensitivitas hilang solusi dominasi skenario pilih skema kelola baik hitung analisis kaji kait pupuk indonesia anak usaha kait kelola faba costbenefit analysis cba nonlinier programming nlp analisis sensitivitas dasar analisis kondisi eksisting proses bisnis kelola limbah oleh skenario kelola limbah faba masingmasing usaha empat skenario baik pilih skenario analisis lanjut skenario kondisi eksisting skenario fokus kerjasama kelola limbah faba optimal manfaat oleh hasil hitung skenario baik biaya kelola limbah keluar usaha turun 60 kondisi eksisting hitung benefitcost ratio bcr skenario baik masingmasing usaha hasil angka 1109 1602 kondisi ideal skenario baik analisis sensitivitas temu ubah hasil batas kelola pengaruh layak skenario serap faba manfaat lingkung pengaruh layak skenario simpul skenario baik usul layak terap timbang kondisi masingmasing parameter pengaruh layak skenariofly ash and bottom ash faba waste in the fertilizer industry based on pp no 22 of 2021 is excluded from b3 category where the coal combustion process uses industrial furnace technology stocker boiler with pp no 22 of 2021 it is necessary to research to determine the best faba waste management scheme between existing conditions and improvement scenarios by considering the optimal benefits of each faba waste management option it is necessary to do a costbenefit analysis calculate the benefitcost ratio and proceed with a sensitivity analysis to eliminate one dominating solution from the selected scenario to get the best management scheme to carry out the necessary calculations and analysis a study related to pupuk indonesia and its related subsidiaries faba management costbenefit analysis cba nonlinear programming nlp and sensitivity analysis based on the analysis of the existing condition of the existing waste management business process four faba waste management scenarios were obtained for each company from the four scenarios two scenarios were chosen for further analysis the two scenarios are the existing condition and the scenario that focuses on cooperation in faba waste management by optimizing the benefits obtained the results of the calculations show that with the improvement scenario the waste management costs incurred by the company can decrease by up to 60 from the existing condition the calculation of the benefitcost ratio bcr from the improvement scenario for each company produces numbers from 1109 to 1602 under ideal conditions in the improvement scenario a sensitivity analysis was carried out and it was found that changes in profit sharing and the lower management limit did not affect the feasibility of the scenario meanwhile the absorption of faba and environmental benefits influence the feasibility of the scenario it can be concluded that the proposed improvement scenario is feasible to be applied by considering the conditions of each parameter that affect the feasibility of the scenario
Pengembangan Model Prediktif Analitik Untuk Menilai Tingkat Maintainabilitas Proyek Perangkat Lunak Di Github.,"Nugroho, Adi",http://repository.its.ac.id/95511/,"Pengembangan proyek perangkat lunak saat ini sudah tidak bisa dilepaskan dari penggunaan library atau produk open source. Terdapat jutaan produk open source dengan fungsi spesifik yang mampu digunakan dan diintegrasikan dalam pengembangan perangkat lunak. Tetapi untuk memilih produk open source yang bagus dan memiliki maintainabilitas yang baik tidaklah mudah. Github sebagai salah satu repositori open source berbasis git, saat ini menyimpan lebih dari 46 juta proyek open source. Pada sebuah repositori proyek open source di Github melekat puluhan fitur yang dapat dianalisis untuk menilai kualitas repositori tersebut. Banyaknya jumlah fitur ini mengakibatkan perlunya keahlian dan pengalaman untuk menilai kualitas repositori. Penelitian sebelumnya menggunakan metode Random Forest untuk menilai tingkat maintainabilitas pada sebuah repositori di Github secara otomatis. Penelitian ini akan memanfaatkan lebih banyak fitur dari repositori di Github serta menggunakan dan membandingkan metode machine learning antara lain Random Forest, Support Vector Machine, Extreme Gradient Boosting dan regresi logistik dalam pembuatan model untuk menilai tingkat maintainabilitas. Model dalam penelitian ini dikembangkan dengan menggunakan 17 variabel prediktor dan satu variabel respon. Hasil dari pengujian model menunjukkan model dari metode Random Forest dan Extreme Gradient Boosting menunjukkan tingkat akurasi yang tinggi masing-masing 94% dan 94,35%. Kedua model juga menunjukkan daftar variabel-variabel prediktor signifikan yang hampir mirip dalam penilaian maintainabilitas.==============================================================================================================================The development of software projects nowadays cannot be separated from open-source libraries or products. There are millions of open-source products with specific functionality that can be used when developing software. But choosing a good open-source product that has good maintainability is not an easy task. Github is one of the git-based open-source repositories and currently stores more than 46 million open-source projects. Lots of Github's repository features can be analyzed the repository quality. But manually assessing a repository's quality by analyzing its features needs skills and experience. Previous research used the Random Forest method to automatically assess the level of maintainability of a Github repository. This study will use more features from the repository and then compare the Random Forest, Support Vector Machine, Extreme Gradient Boosting and Logistic Regression methods in assessing Github's repository maintainability. 17 predictor variables and 1 respond variable were used to create machine learning models. Random Forest's and Extreme Gradient Boosting's models achieved almost similar accuracy rating with 94% and 94.35% respectively. Both models are also displayed almost similar list of significant features in assessing a repository's maintainability.",kembang model prediktif analitik nilai tingkat maintainabilitas proyek perangkat lunak github,kembang proyek perangkat lunak lepas guna library produk open source juta produk open source fungsi spesifik integrasi kembang perangkat lunak pilih produk open source bagus milik maintainabilitas mudah github salah repositori open source bas git simpan 46 juta proyek open source repositori proyek open source github lekat puluh fitur analis nilai kualitas repositori banyak fitur akibat ahli alam nilai kualitas repositori teliti metode random forest nilai tingkat maintainabilitas repositori github otomatis teliti manfaat fitur repositori github banding metode machine learning random forest support vector machine extreme gradient boosting regresi logistik buat model nilai tingkat maintainabilitas model teliti kembang 17 variabel prediktor variabel respon hasil uji model model metode random forest extreme gradient boosting tingkat akurasi masingmasing 94 9435 model daftar variabelvariabel prediktor signifikan nilai maintainabilitasthe development of software projects nowadays can not be separated from opensource libraries or products there are millions of opensource products with specific functionality that can be used when developing software but choosing a good opensource product that has good maintainability is not an easy task github is one of the gitbased opensource repositories and currently stores more than 46 million opensource projects lots of githubs repository features can be analyzed the repository quality but manually assessing a repositorys quality by analyzing its features needs skills and experience previous research used the random forest method to automatically assess the level of maintainability of a github repository this study will use more features from the repository and then compare the random forest support vector machine extreme gradient boosting and logistic regression methods in assessing githubs repository maintainability 17 predictor variables and 1 respond variable were used to create machine learning models random forests and extreme gradient boostings models achieved almost similar accuracy rating with 94 and 9435 respectively both models are also displayed almost similar list of significant features in assessing a repositorys maintainability
Klasifikasi Penutup Lahan Menggunakan DTM dan DSM LiDAR dengan Algoritma Support Vector Machine dan Random Forest (Studi Kasus: Institut Teknologi Sepuluh Nopember Kampus Sukolilo).,"Nuraini, Annisa",http://repository.its.ac.id/109916/,"LiDAR adalah teknologi penginderaan jauh aktif yang memanfaatkan sinar laser untuk mendeteksi objek di permukaan bumi. Airborne LiDAR merupakan salah satu jenis lidar yang menggunakan wahana udara untuk proses penyiaman objek. Dari data LiDAR ini dapat diperoleh Digital Surface Model (DSM) yang selanjutnya dapat diekstrak menjadi Digital Terrain Model (DTM). Dalam perkembangannya untuk pengolahan data LiDAR, telah banyak digunakan perangkat lunak maupun dengan menggunakan algoritma yang dibangun seperti machine learning. Tujuan dari penelitian ini adalah memanfaatkan data LiDAR untuk klasifikasi penutup lahan dengan menggunakan machine learning, yaitu dengan algoritma Support Vector Machine (SVM) dan Random Forest (RF). Klasifikasi yang diterapkan adalah supervised classification dimana dibutuhkan data training untuk melakukan klasifikasi. Kelas penutup lahan yang diprediksi pada penelitian ini terbatas pada objek bangunan, vegetasi, jalan, lahan terbuka, dan badan air. Data yang digunakan untuk klasifikasi adalah data turunan dari LiDAR yaitu DTM dan DSM. Skema klasifikasi yang digunakan adalah dengan input satu data dan kombinasi data, serta diterapkan juga skema splitting ratio training point yaitu 70:30, 75:25, 80:20, dan 90:10. Hasilnya skema input satu data belum memberikan hasil yang optimal. Input kombinasi data memberikan penambahan akurasi dan mengasilkan akurasi yang baik yaitu lebih besar dari 0,80. Hasil terbaik didapat dari input kombinasi data DSM dan DTM rasio training testing 75:25. Pada metode SVM dihasilkan overall accuracy 0,824 dan kappa 0,780. Sedangkan pada metode RF dihasilkan overall accuracy 0,832 dan kappa 0,790. Secara keseluruhan, metode RF memiliki keunggulan dalam mengklasifikasikan objek bangunan dan lahan kosong, sedangkan metode SVM memiliki keunggulan dalam mengklasifikasikan objek jalan.=================================================================================================================================LiDAR is an active remote sensing technology that utilizes laser beams to detect objects on the earth's surface. Airborne LiDAR is one type of lidar that uses airborne vehicles for the object's illumination process. From this LiDAR data, a Digital Surface Model (DSM) can be obtained which can then be extracted into a Digital Terrain Model (DTM). In its development for LiDAR data processing, software has been widely used as well as using algorithms built such as machine learning. The purpose of this research is to utilize LiDAR data for land cover classification using machine learning, namely with Support Vector Machine (SVM) and Random Forest (RF) algorithms. The classification applied is supervised classification where training data is required to perform classification. The predicted land cover classes in this study are limited to building objects, vegetation, roads, open land, and water bodies. The data used for classification is derived from LiDAR data, namely DTM and DSM. The classification scheme used is a single data input and a combination of data, and the splitting ratio training point scheme is also applied, namely 70:30, 75:25, 80:20, and 90:10. The result is that the one data input scheme has not provided optimal results. Input data combination provides additional accuracy and produces good accuracy which is greater than 0.80. The best results are obtained from the input of a combination of DSM and DTM data with a training testing ratio of 75:25. In the SVM method, the overall accuracy is 0.824 and kappa is 0.780. While the RF method produced an overall accuracy of 0.832 and kappa 0.790. Overall, the RF method has an advantage in classifying building objects and vacant land, while the SVM method has an advantage in classifying road objects.",klasifikasi tutup lahan dtm dsm lidar algoritma support vector machine random forest studi institut teknologi puluh nopember kampus sukolilo,lidar teknologi penginderaan aktif manfaat sinar laser deteksi objek muka bumi airborne lidar salah jenis lidar wahana udara proses siam objek data lidar oleh digital surface model dsm ekstrak digital terrain model dtm kembang olah data lidar perangkat lunak algoritma bangun machine learning tuju teliti manfaat data lidar klasifikasi tutup lahan machine learning algoritma support vector machine svm random forest rf klasifikasi terap supervised classification mana butuh data training klasifikasi kelas tutup lahan prediksi teliti batas objek bangun vegetasi jalan lahan buka badan air data klasifikasi data turun lidar dtm dsm skema klasifikasi input data kombinasi data terap skema splitting ratio training point 7030 7525 8020 9010 hasil skema input data hasil optimal input kombinasi data tambah akurasi asil akurasi 080 hasil baik input kombinasi data dsm dtm rasio training testing 7525 metode svm hasil overall accuracy 0824 kappa 0780 metode rf hasil overall accuracy 0832 kappa 0790 metode rf milik unggul klasifikasi objek bangun lahan kosong metode svm milik unggul klasifikasi objek jalanlidar is an active remote sensing technology that utilizes laser beams to detect objects on the earths surface airborne lidar is one type of lidar that uses airborne vehicles for the objects illumination process from this lidar data a digital surface model dsm can be obtained which can then be extracted into a digital terrain model dtm in its development for lidar data processing software has been widely used as well as using algorithms built such as machine learning the purpose of this research is to utilize lidar data for land cover classification using machine learning namely with support vector machine svm and random forest rf algorithms the classification applied is supervised classification where training data is required to perform classification the predicted land cover classes in this study are limited to building objects vegetation roads open land and water bodies the data used for classification is derived from lidar data namely dtm and dsm the classification scheme used is a single data input and a combination of data and the splitting ratio training point scheme is also applied namely 7030 7525 8020 and 9010 the result is that the one data input scheme has not provided optimal results input data combination provides additional accuracy and produces good accuracy which is greater than 080 the best results are obtained from the input of a combination of dsm and dtm data with a training testing ratio of 7525 in the svm method the overall accuracy is 0824 and kappa is 0780 while the rf method produced an overall accuracy of 0832 and kappa 0790 overall the rf method has an advantage in classifying building objects and vacant land while the svm method has an advantage in classifying road objects
Pengembangan Metode Seleksi Fitur Berbasis Chi-Square dan Algoritma Exhaustive untuk Meningkatkan Performa Deteksi pada Jaringan Komputer.,"Nururrahmah, Aulia Teaku",http://repository.its.ac.id/102506/,"Mendeteksi serangan intrusi pada jaringan telah menarik perhatian banyak peneliti. Sejauh ini terdapat dua metode, yakni berbasis signature dan anomaly. Mendeteksi serangan yang berbasis anomaly membutuhkan Machine Learning dalam proses klasifikasinya. Masalah yang banyak diteliti adalah topik tentang bagaimana mereduksi jumlah fitur sebelum dataset diserahkan ke proses klasifikasi. Metode seleksi fitur sendiri dilakukan untuk menentukan fitur relevan dan tidak relevan. Kami mengusulkan metode seleksi fitur berbasis uji chi-square dengan pencarian Exhaustive. Uji Chi-Square digunakan untuk menghitung skor statistik menggunakan uji independence level. Nilai statistik pada masing-masing fitur akan ditentukan relevansinya menggunakan taraf signifikan dan tabel distribusi chi-square. Dari proses uji chi-square maka diperoleh daftar fitur relevan dengan kelas target. Proses selanjutnya adalah mencari kombinasi terbaik antar fitur dengan menggunakan Exhaustive Algorithm. Penelitian ini diuji coba pada empat dataset yakni KDD Cup 99, NSL KDD, Kyoto 2006+, dan UNSW-NB15. Metode klasifikasi yang dimanfaatkan pada penelitian ini adalah Support Vector Machine (SVM), Decision Tree (DT), dan Naïve Bayes (NB). Berdasarkan penelitian yang sudah dilakukan, metode yang diusulkan terbukti memiliki performa yang lebih baik dibanding saat tanpa menggunalan seleksi fitur apapun. Performa terbaik didapatkan pada uji dataset UNSW-NB15 dengan akurasi mencapai 98,71%. Metode yang diusulkan juga melampaui performa dari metode lain===================================================================================================================================Detecting intrusion attacks on networks has attracted the attention of many researchers. So far, there are two methods, namely signature-based and anomaly-based. Detecting anomaly-based attacks requires Machine Learning in the classification process. The feature selection method itself is used to determine relevant and irrelevant features. Irrelevant features will be removed from the feature list. We propose a feature selection method based on the chi-square test with an Exhaustive search. The Chi-Square test is used to calculate statistical scores using the independence level test. The statistical value of each feature will be determined by its relevance using the significant level and the chi-square distribution table. A list of features relevant to the target class is obtained from the chi-square test process. The next process is to find the best combination between features using the Exhaustive Algorithm. This research was tested on four data: KDD Cup 99, NSL KDD, Kyoto 2006+, and UNSW-NB15. The classification methods used in this research are Support Vector Machine (SVM), Decision Tree (DT), and Naïve Bayes (NB). Based on the research that has been done, the proposed method is proven to have better performance than without using any feature selection. The best performance was obtained in the UNSW-NB15 dataset test with an accuracy of 98.71%. The proposed method also surpasses the performance of other methods.",kembang metode seleksi fitur bas chisquare algoritma exhaustive tingkat performa deteksi jaring komputer,deteksi serang intrusi jaring tarik perhati teliti metode bas signature anomaly deteksi serang bas anomaly butuh machine learning proses klasifikasi teliti topik reduksi fitur dataset serah proses klasifikasi metode seleksi fitur tentu fitur relevan relevan usul metode seleksi fitur bas uji chisquare cari exhaustive uji chisquare hitung skor statistik uji independence level nilai statistik masingmasing fitur tentu relevansi taraf signifikan tabel distribusi chisquare proses uji chisquare oleh daftar fitur relevan kelas target proses cari kombinasi baik fitur exhaustive algorithm teliti uji coba dataset kdd cup 99 nsl kdd kyoto 2006 unswnb15 metode klasifikasi manfaat teliti support vector machine svm decision tree dt na ve bayes nb dasar teliti metode usul bukti milik performa banding menggunalan seleksi fitur apa performa baik dapat uji dataset unswnb15 akurasi capai 9871 metode usul lampau performa metode laindetecting intrusion attacks on networks has attracted the attention of many researchers so far there are two methods namely signaturebased and anomalybased detecting anomalybased attacks requires machine learning in the classification process the feature selection method itself is used to determine relevant and irrelevant features irrelevant features will be removed from the feature list we propose a feature selection method based on the chisquare test with an exhaustive search the chisquare test is used to calculate statistical scores using the independence level test the statistical value of each feature will be determined by its relevance using the significant level and the chisquare distribution table a list of features relevant to the target class is obtained from the chisquare test process the next process is to find the best combination between features using the exhaustive algorithm this research was tested on four data kdd cup 99 nsl kdd kyoto 2006 and unswnb15 the classification methods used in this research are support vector machine svm decision tree dt and na ve bayes nb based on the research that has been done the proposed method is proven to have better performance than without using any feature selection the best performance was obtained in the unswnb15 dataset test with an accuracy of 9871 the proposed method also surpasses the performance of other methods
Aplikasi Deteksi Kejadian di Jalan Raya berdasarkan Data Twitter Menggunakan Metode Support Vector Machine.,"Oktavia, Vessa Rizky",http://repository.its.ac.id/50014/,"Twitter adalah salah satu media sosial yang populer belakangan ini. Salah satu karakteristik penting dari Twitter adalah layanannya yang bersifat fleksibel yaitu dapat diakses di mana saja dan kapan saja. Sebagai contoh, saat terjadi suatu kecelakaan atau kemacetan, banyak pengguna Twitter yang mengirimkan  informasi (tweets) tentang kejadian tersebut kepada Twitter. Hal ini memungkinkan dibuatnya sebuah sistem yang mendeteksi terjadinya kecelakaan atau kemacetan dengan melakukan observasi kepada tweet yang masuk.Dalam tugas akhir ini, tweet akan diambil menggunakan Twitter API dan dimasukkan ke dalam sebuah database. Selanjutnya, akan dilakukan preproses yang meliputi stemming, penghapusan stopwords, dan tokenizing. Selain itu, dilakukan juga labeling untuk menentukan kelas dari tweet (kecelakaan, kemacetan, atau lain-lain). Selanjutnya akan dilakukan ekstraksi fitur agar fitur dari setiap tweet dapat menjadi input dalam proses klasifikasi. Untuk mengklasifikasikan tweet, diimplementasikan sebuah metode klasifikasi Support Vector Machine dan parameter regularisasi berupa variabel nu. Model klasifikasi yang dibangun awalnya memberikan nilai akurasi 95,15%. Uji coba dilakukan dengan mengubah kernel dan parameter nu untuk menghasilkan akurasi yang terbaik. Berdasarkan hasil uji coba yang telah dilakukan, didapatkan hasil terbaik dari sistem dengan akurasi 96,25% dengan klasifikasi menggunakan metode SVM dengan menggunakan Kernel Sigmoid dan parameter nu sebesar 0,2.======================================================================================================Twitter is one of the most popular social media lately. One of the important characteristics of Twitter is its flexible service that can be accessed anywhere and anytime. For example, when an accident or traffic jam occurs, many Twitter users are sending tweets about the event to the Twitter. This allows the creation of a system that detects accident or congestion by observing the incoming tweets.In this thesis, tweet will be taken by using Twitter API and put into a database. Next, a preprocess will be done that includes stemming, stopwords removal, and tokenizing. In addition, there is also a labeling to determine the class of tweets (accidents, congestion, or others). Furthermore, feature extraction will be performed so that the features of each tweet can be the input to perform the classification process. To classify tweets, used a Support Vector Machine classification method andnu variable as a regularization parameters.The classification model that was originally built gave an accuracy of 95.15%. The test is done by changing the kernel and the nu parameters to produce the best accuracy. Based on result of experiment which have done, the best result from system is claimed with accuracy 96,25% by using classification using SVM method using Sigmoid Kernel and the number of parameter nu is 0,2.",aplikasi deteksi jadi jalan raya dasar data twitter metode support vector machine,twitter salah media sosial populer salah karakteristik twitter layan sifat fleksibel akses contoh celaka macet guna twitter kirim informasi tweets jadi twitter sistem deteksi celaka macet observasi tweet masukdalam tugas tweet ambil twitter api masuk database preproses liput stemming hapus stopwords tokenizing labeling tentu kelas tweet celaka macet lainlain ekstraksi fitur fitur tweet input proses klasifikasi klasifikasi tweet implementasi metode klasifikasi support vector machine parameter regularisasi variabel nu model klasifikasi bangun nilai akurasi 9515 uji coba ubah kernel parameter nu hasil akurasi baik dasar hasil uji coba dapat hasil baik sistem akurasi 9625 klasifikasi metode svm kernel sigmoid parameter nu 02twitter is one of the most popular social media lately one of the important characteristics of twitter is its flexible service that can be accessed anywhere and anytime for example when an accident or traffic jam occurs many twitter users are sending tweets about the event to the twitter this allows the creation of a system that detects accident or congestion by observing the incoming tweetsin this thesis tweet will be taken by using twitter api and put into a database next a preprocess will be done that includes stemming stopwords removal and tokenizing in addition there is also a labeling to determine the class of tweets accidents congestion or others furthermore feature extraction will be performed so that the features of each tweet can be the input to perform the classification process to classify tweets used a support vector machine classification method andnu variable as a regularization parametersthe classification model that was originally built gave an accuracy of 9515 the test is done by changing the kernel and the nu parameters to produce the best accuracy based on result of experiment which have done the best result from system is claimed with accuracy 9625 by using classification using svm method using sigmoid kernel and the number of parameter nu is 02
Multi-Objective Vehicle Routing Problem with Time Window and Drones (MO-VRPTW-D) Menggunakan Algoritma Simulated Annealing dan Ant Colony Optimization untuk Last-Mile Delivery.,"Pamungkas, Meidani Nuzul Tri",http://repository.its.ac.id/93815/,"Drone adalah kendaraan udara tanpa awak yang saat ini sedang marak digunakan dalam bidang fotografi dan bidang lainnya. Dalam kondisi khusus, drone digunakan untuk kendaraan logistik di mana barang-barang harus diangkut oleh truk yang dilengkapi dengan drone karena bentuk lahannya atau bahkan karena lokasinya vertikal (seperti apartemen, hotel, dll) yang tentunya tidak dapat dijangkau oleh truk. Multi-Objective Vehicle Routing Problem with Time Window and Drones (MO-VRPTW-D), di mana tujuannya adalah meminimasi biaya dengan cara mencari rute yang optimal agar konsumsi energi truk, konsumsi energi drone, dan jumlah truk yang dibutuhkan minimal. Problem ini menjadi kompleks apabila jumlah destinasi yang dikunjungi banyak. Pendekatan metaheuristik diperlukan untuk menyelesaikan problem ini karena kompleksitas yang tinggi walaupun solusi yang dihasilkan belum tentu optimal global. Algoritma Simulated Annealing dan Ant Colony Optimization dipilih karena terbukti cukup efektif untuk menyelesaikan problem kombinatorial semacam penentuan rute. Inovasi ini dapat diadopsi oleh perusahaan jasa pengiriman pada masa mendatang karena pengiriman akan menjadi lebih efisien, cepat, dan mengurangi biaya secara signifikan. Eksperimen dilakukan dalam 24 skenario dengan jumlah pelanggan 25 – 200. Algoritma ACO mampu menghasilkan solusi lebih baik daripada Algoritma SA sebanyak 15 dari total 24 skenario.================================================================================================Drone is remote controlled aerial vehicle that is currently being widely used in photography and other fields. In special conditions, drones are used for logistics vehicles where goods must be transported by trucks equipped with drones because of the shape of the land or even because of its vertical location (such as apartments, hotels, etc.) Multi-Objective Vehicle Routing Problem with Time Window and Drones (MO-VRPTW-D), where the goal is to minimize costs by finding the optimal route so that truck energy consumption, drone energy consumption, and the number of trucks needed are minimal. This problem becomes complex if the number of destinations visited is large. A metaheuristic approach is needed to solve this problem because of its high complexity, although the resulting solution is not necessarily global optimal. The Simulated Annealing and Ant Colony Optimization Algorithm was chosen because it proved to be quite effective in solving combinatorial problems such as route determination. This innovation can be applied by shipping service companies in the future because shipping will be more efficient, faster, and reduce costs significantly. Experiments were carried out in 24 scenarios with the number of customers 25 – 200. The ACO Algorithm was able to produce a better solution than the SA Algorithm by 15 out of a total of 24 scenarios.",multiobjective vehicle routing problem with time window and drones movrptwd algoritma simulated annealing ant colony optimization lastmile delivery,drone kendara udara awak marak bidang fotografi bidang kondisi khusus drone kendara logistik barangbarang angkut truk lengkap drone bentuk lahan lokasi vertikal apartemen hotel dll jangkau truk multiobjective vehicle routing problem with time window and drones movrptwd tuju meminimasi biaya cari rute optimal konsumsi energi truk konsumsi energi drone truk butuh minimal problem kompleks destinasi kunjung dekat metaheuristik selesai problem kompleksitas solusi hasil optimal global algoritma simulated annealing ant colony optimization pilih bukti efektif selesai problem kombinatorial tentu rute inovasi adopsi usaha jasa kirim kirim efisien cepat kurang biaya signifikan eksperimen 24 skenario langgan 25  200 algoritma aco hasil solusi algoritma sa 15 total 24 skenariodrone is remote controlled aerial vehicle that is currently being widely used in photography and other fields in special conditions drones are used for logistics vehicles where goods must be transported by trucks equipped with drones because of the shape of the land or even because of its vertical location such as apartments hotels etc multiobjective vehicle routing problem with time window and drones movrptwd where the goal is to minimize costs by finding the optimal route so that truck energy consumption drone energy consumption and the number of trucks needed are minimal this problem becomes complex if the number of destinations visited is large a metaheuristic approach is needed to solve this problem because of its high complexity although the resulting solution is not necessarily global optimal the simulated annealing and ant colony optimization algorithm was chosen because it proved to be quite effective in solving combinatorial problems such as route determination this innovation can be applied by shipping service companies in the future because shipping will be more efficient faster and reduce costs significantly experiments were carried out in 24 scenarios with the number of customers 25  200 the aco algorithm was able to produce a better solution than the sa algorithm by 15 out of a total of 24 scenarios
Implementasi Text Mining pada Data Perhotelan Menggunakan Support Vector Machine (SVM) dan Analisis Topik dengan Model Probabilistik.,"Panjaitan, Yana Rezki Kriswin",http://repository.its.ac.id/91857/,"Kota Bogor merupakan kota yang berpotensi menjadi objek wisata. Covid-19 menyebar secara masif keseluruh dunia termasuk Indonesia sehingga pemerintah mengambil kebijakan seluruh kegiatan dilakukan dari rumah. Perubahan tatanan kehidupan tersebut memberikan tantangan baru bagi pihak hotel untuk tidak memakai cara konvensional seperti kuesioner dalam mengetahui kepuasan tamu sehingga memaksa pihak hotel menggunakan media yang ada salah satunya situs TripAdvisor. Situs ini memuat harga, tipe hotel, ulasan pengunjung dan sebagainya. Hal ini membuat tamu tidak kesulitan mencari informasi hotel, sedangkan pihak hotel diuntungkan dengan ulasan yang ada. Namun jumlah ulasan yang banyak menyita waktu untuk memahami satu persatu ulasan, sehingga diperlukan text mining. Dalam proses text mining ulasan diklasifikasikan terlebih dahulu menjadi sentimen positif dan negatif menggunakan metode SVM. Klasifikasi hanya memberi informasi sentimen positif atau negatif, sehingga dibutuhkan LDA dan LSA untuk menemukan informasi tersembunyi guna mengetahui kepuasan tamu pada pelayanan hotel. Model klasifikasi terbaik dalam penelitian ini menggunakan SVM kernel linear pada data yang telah diatasi imbalancednya dengan SMOTE. Metode LDA menghasilkan topic coherence lebih tinggi dibanding LSA sehingga membentuk topik positif pada Novotel adalah breakfast dan dinner, hotel dapat menjadi tempat rapat, makanan variatif dan hotel ramah anak. Sedangkan topik negatifnya proses high season lambat, makanan habis tidak langsung di refill, hotel tidak sesuai dengan informasi booking online, area kolam pria dan wanita tidak dibedakan, akses menuju tempat bermain anak, drainage tidak baik, paving tidak rata, bau pesing, kamar deluxe kurang baik, bathup teras duduk mengkhawatirkan. Topik positif Grand Savero adalah sarapan variatif, pelayanan cepat, menu enak, ramah anak, konsep indoor modern, booking mudah, terdapat aneka bubur dan buah, kinerja team bagus, fasilitas lengkap, dan ruangan yang segar dan bersih, sedangkan topik negatifnya proses reserve dan akses menuju area hotel sulit dan extra bed berbayar. Topik positif pada Aston adalah menu breakfast variatif dan enak serta hotel ramah anak, sedangkan topik negatifnya sikap staf, menu dinner tidak sesuai harga, fying fox berbayar, area balkon bau, suara mengganggu, request tidak sesuai, tempat bermain anak rusak, bising, perabotan kamar kurang. =====================================================================================================Bogor City is a city that has the potential to become a tourist attraction. Covid-19 has spread massively throughout the world, including Indonesia, so the government has made a policy that all activities are carried out from home. The change in the order of life provides a new challenge for the hotel not to use conventional methods such as questionnaires to determine guest satisfaction, thus forcing the hotel to use media, one of which is the TripAdvisor site. This site contains prices, hotel types, visitor reviews and so on. This makes it easy for guests to find hotel information, while the hotel benefits from existing reviews. However, the large number of reviews takes time to understand one by one review, so text mining is needed. In the text mining process, reviews are classified first into positive and negative sentiments using the SVM method. Classification only provides information on positive or negative sentiments, so LDA and LSA are needed to find hidden information to find out guest satisfaction with hotel services. The best classification model in this study uses a linear kernel SVM on data that has been overcome with SMOTE imbalancednya. The LDA method produces higher topic coherence than LSA so that it forms positive topics at Novotel, namely breakfast and dinner, hotels can be used as meeting places, varied food and child-friendly hotels. While the negative topics are the slow high season process, food runs out not immediately refilled, hotels do not match online booking information, male and female pool areas are not distinguished, access to children's playgrounds, drainage is not good, paving is uneven, urine smells, deluxe rooms not good, the sitting terrace bathtub is worrying. The positive topics of Grand Savero are varied breakfasts, fast service, delicious menus, child friendly, modern indoor concepts, easy booking, there are various porridge and fruit, good team performance, complete facilities, and fresh and clean rooms, while the negative topics are the reserve process and access to the hotel area is difficult and extra beds are paid. Positive topics at Aston are varied and delicious breakfast menus and child-friendly hotels, while the negative topics are staff attitudes, dinner menus don't match the price, paid fying fox, smelly balcony area, annoying sound, inappropriate requests, damaged children's play area, noise, furniture less room.",implementasi text mining data hotel support vector machine svm analisis topik model probabilistik,kota bogor kota potensi objek wisata covid19 sebar masif seluruh dunia indonesia perintah ambil bijak giat rumah ubah tatanan hidup tantang hotel pakai konvensional kuesioner puas tamu paksa hotel media salah satu situs tripadvisor situs muat harga tipe hotel ulas unjung tamu sulit cari informasi hotel hotel untung ulas ulas sita paham satu ulas text mining proses text mining ulas klasifikasi sentimen positif negatif metode svm klasifikasi informasi sentimen positif negatif butuh lda lsa temu informasi sembunyi puas tamu layan hotel model klasifikasi baik teliti svm kernel linear data atas imbalancednya smote metode lda hasil topic coherence banding lsa bentuk topik positif novotel breakfast dinner hotel rapat makan variatif hotel ramah anak topik negatif proses high season lambat makan habis langsung refill hotel sesuai informasi booking online area kolam pria wanita beda akses main anak drainage paving bau pesing kamar deluxe bathup teras duduk khawatir topik positif grand savero sarap variatif layan cepat menu enak ramah anak konsep indoor modern booking mudah aneka bubur buah kerja team bagus fasilitas lengkap ruang segar bersih topik negatif proses reserve akses area hotel sulit extra bed bayar topik positif aston menu breakfast variatif enak hotel ramah anak topik negatif sikap staf menu dinner sesuai harga fying fox bayar area balkon bau suara ganggu request sesuai main anak rusak bising perabot kamar bogor city is a city that has the potential to become a tourist attraction covid19 has spread massively throughout the world including indonesia so the government has made a policy that all activities are carried out from home the change in the order of life provides a new challenge for the hotel not to use conventional methods such as questionnaires to determine guest satisfaction thus forcing the hotel to use media one of which is the tripadvisor site this site contains prices hotel types visitor reviews and so on this makes it easy for guests to find hotel information while the hotel benefits from existing reviews however the large number of reviews takes time to understand one by one review so text mining is needed in the text mining process reviews are classified first into positive and negative sentiments using the svm method classification only provides information on positive or negative sentiments so lda and lsa are needed to find hidden information to find out guest satisfaction with hotel services the best classification model in this study uses a linear kernel svm on data that has been overcome with smote imbalancednya the lda method produces higher topic coherence than lsa so that it forms positive topics at novotel namely breakfast and dinner hotels can be used as meeting places varied food and childfriendly hotels while the negative topics are the slow high season process food runs out not immediately refilled hotels do not match online booking information male and female pool areas are not distinguished access to childrens playgrounds drainage is not good paving is uneven urine smells deluxe rooms not good the sitting terrace bathtub is worrying the positive topics of grand savero are varied breakfasts fast service delicious nus child friendly modern indoor concepts easy booking there are various porridge and fruit good team performance complete facilities and fresh and clean rooms while the negative topics are the reserve process and access to the hotel area is difficult and extra beds are paid positive topics at aston are varied and delicious breakfast nus and childfriendly hotels while the negative topics are staff attitudes dinner nus dont match the price paid fying fox smelly balcony area annoying sound inappropriate requests damaged childrens play area noise furniture less room
Implementasi Model Formal untuk Rekonstruksi Peristiwa Forensik Digital.,"Pardede, Immanuel Maruli Tua",http://repository.its.ac.id/117622/,"Penggunaan perangkat digital yang makin meluas telah berdampak pada berbagai sektor, termasuk peningkatan kompleksitas kejahatan siber. Hal ini mendorong hadirnya penelitian tentang analisis forensik digital yang lebih variatif. Analisis forensik digital sering kali menghadapi tantangan seperti ukuran data yang besar dan sifat data yang heterogen. Sementara itu, metode konvensional memiliki keterbatasan dalam menangani data besar dan heterogen, sehingga memerlukan pendekatan alternatif. Penelitian ini mengusulkan implementasi model formal berbasis ontologi untuk mendukung rekonstruksi peristiwa forensik digital. Data digital yang dikumpulkan dianalisis menggunakan Aljabar Interval Allen, yang memungkinkan penentuan hubungan temporal antarperistiwa. Model ini tidak hanya mampu menyusun peristiwa secara kronologis, tetapi juga menganalisis hubungan semantik dan temporal antarentitas yang terlibat dalam peristiwa tersebut. Dengan menggunakan metode yang terstruktur, penelitian ini menganalisis studi kasus dugaan penyalahgunaan sumber daya perusahaan oleh seorang karyawan. Hasil penelitian menunjukkan bahwa model formal berbasis ontologi efektif untuk mendukung proses rekonstruksi peristiwa dan menghasilkan bukti digital yang kredibel. Penelitian ini membuktikan bahwa model formal berbasis ontologi dapat digunakan untuk memproses jejak digital, menerapkan model formal, dan mengukur kinerja rekonstruksi peristiwa dalam konteks forensik digital.==============================================================================================================================The increasingly widespread use of digital devices has had an impact on various sectors, including the increasing complexity of cyber crime. This has encouraged the presence of more varied research on digital forensic analysis. Digital forensic analysis often faces challenges such as large data sizes and heterogeneous data nature. Meanwhile, conventional methods have limitations in handling large and heterogeneous data, requiring alternative approaches. This study proposes the implementation of an ontology-based formal model to support digital forensic event reconstruction. The digital data collected uses Allen Interval Algebra, which allows the determination of temporal relationships between events. This model is not only able to organize events chronologically, but also analyzes the semantic and temporal relationships between entities involved in the event. Using a structured method, this study analyzes a case study of alleged corporate resource context by an employee. The results of the study show that an ontology-based formal model is effective in supporting the event reconstruction process and producing credible digital evidence. This study proves that an ontology-based formal model can be used to process digital traces, apply formal models, and measure event reconstruction performance in the context of digital forensics.",implementasi model formal rekonstruksi peristiwa forensik digital,guna perangkat digital luas dampak sektor tingkat kompleksitas jahat siber dorong hadir teliti analisis forensik digital variatif analisis forensik digital kali hadap tantang ukur data sifat data heterogen metode konvensional milik batas tangan data heterogen dekat alternatif teliti usul implementasi model formal bas ontologi dukung rekonstruksi peristiwa forensik digital data digital kumpul analis aljabar interval allen tentu hubung temporal antarperistiwa model susun peristiwa kronologis analis hubung semantik temporal antarentitas libat peristiwa metode struktur teliti analis studi duga penyalahgunaan sumber daya usaha karyawan hasil teliti model formal bas ontologi efektif dukung proses rekonstruksi peristiwa hasil bukti digital kredibel teliti bukti model formal bas ontologi proses jejak digital terap model formal ukur kerja rekonstruksi peristiwa konteks forensik digitalthe increasingly widespread use of digital devices has had an impact on various sectors including the increasing complexity of cyber crime this has encouraged the presence of more varied research on digital forensic analysis digital forensic analysis often faces challenges such as large data sizes and heterogeneous data nature meanwhile conventional methods have limitations in handling large and heterogeneous data requiring alternative approaches this study proposes the implementation of an ontologybased formal model to support digital forensic event reconstruction the digital data collected uses allen interval algebra which allows the determination of temporal relationships between events this model is not only able to organize events chronologically but also analyzes the semantic and temporal relationships between entities involved in the event using a structured method this study analyzes a case study of alleged corporate resource context by an employee the results of the study show that an ontologybased formal model is effective in supporting the event reconstruction process and producing credible digital evidence this study proves that an ontologybased formal model can be used to process digital traces apply formal models and measure event reconstruction performance in the context of digital forensics
Klasifikasi Multi-label Dangerous User Berdasarkan Fitur Struktural Twitter.,"Parwata, Anak Agung Yatestha",http://repository.its.ac.id/106584/,"Dangerous speech, atau ujaran berbahaya merupakan suatu ujaran yang dapat meningkatkan risiko seseorang atau suatu kelompok orang melakukan kejahatan terhadap orang lain atau kelompok orang lainnya. Dalam dangerous speech ini, terdapat 7 aspek, yaitu: konteks sosial, konteks historis, dehumanisasi, tuduhan, serangan terhadap wanita dan anak kecil, loyalitas suatu kelompok, dan ancaman terhadap suatu kelompok. Dangerous speech sendiri marak ditemukan di media sosial seperti Twitter. Dangerous user merupakan pengguna yang memiliki presentase tweet dangerous speech dan abusive language lebih banyak dibanding tweet neutral speech dan hate speech. Pada penelitian ini, telah dibuat suatu model yang dapat melakukan klasifikasi multi-label dangerous user berdasarkan fitur struktural yang diekstraksi dari graf pengguna yang terbentuk dari kemiripan unggahan Twitter. Fitur struktural yang digunakan adalah degree centrality, eigenvector centrality, betweenness centrality, closeness centrality, dan clustering coefficient. Tahapan yang dilalui mencakup pengolahan data tweet, ekstraksi fitur struktural pada jejaring berdasarkan kemiripan tweet, dan Klasifikasi pengguna dengan multi-label topik dangerous speech. Pengolahan data tweet dilakukan dengan cara pra-proses tweet, pemodelan topik menggunakan LDA, dan pseudo-label aspek dangerous speech menggunakan model IndoBERTweet, Naïve Bayes, dan Logistic Regresion. Tahapan selanjutnya adalah ekstraksi fitur struktural pada jejaring berdasarkan kemiripan tweet yang dilakukan dengan cara membuat graf dimana nodes nya merupakan pengguna twitter dan edgesnya merupakan nilai cosine similiarity atau kemiripan unggahan. Dilakukan pemilihan node dan edge mengunakan metode thresholding. Pengekstraksian fitur dilakukan dengan menggunakan pustaka networkx. Selanjutnya dilakukan pengklasifikasian pengguna dengan multi-label topik dangerous speech menggunakan Logistic Regression, Naïve Bayes, K-nearest Neighbors, Support Vector Classifier Decision Tree dan Random Forest. Pseudo-label aspek dangerous speech terbaik menggunakan model gabungan dari IndoBERTweet, Naïve Bayes, dan Logistic Regresion  dengan nilai akurasi diatas 80%. Dalam pemodelan topik, ditemukan jumlah topik terbaik adalah 6 berdasarkan nilai coherence score, namun masih terdapat sub-topik yang terbentuk, sehingga digunakan jumlah topik 19 berdasarkan nilai coherence scorenya dan ketiadaannya sub-topik baru. Ditemukan metode thresholding terbaik dengan minimal tiap pengguna memiliki average retweet lebih dari 1 dan nilai cosine similiarity lebih dari 0,149. Klasifikasi dangerous user terbaik terdapat pada model Naïve Bayes dengan fitur degree centrality, closeness centrality, dan eigenvecot centrality dengan nilai hamming loss sebesar 0,555.=============================================================================================================================Dangerous speech, or dangerous discourse, refers to a form of expression that can increase the risk of an individual or a group of people committing crimes against others or another group of people. In dangerous speech, there are 7 aspects, namely: social context, historical context, dehumanization, accusations, attacks against women and children, group loyalty, and threats against a group. Dangerous speech is often found on social media platforms like Twitter. A dangerous user is a user who has a higher percentage of dangerous speech and abusive language in their tweets compared to neutral speech and hate speech. In this final project, a model has been developed to perform multi-label classification of dangerous users based on structural features extracted from user graphs formed by the similarity of Twitter posts. The structural features used are degree centrality, eigenvector centrality, betweenness centrality, closeness centrality, and clustering coefficient. The steps involved include tweet data preprocessing, structural feature extraction on the network based on tweet similarity, and user classification with multi-label dangerous speech topics. Tweet data processing is done by pre-processing tweets, topic modeling using LDA, and pseudo-labeling of dangerous speech aspects using IndoBERTweet, Naïve Bayes, and Logistic Regression models. The next step is the extraction of structural features on the network based on tweet similarity, which is done by creating a graph where the nodes represent Twitter users and the edges represent cosine similarity values or post similarity. Node and edge selection is performed using thresholding methods. Feature extraction is done using the networkx library. User classification with multi-label dangerous speech topics is done using Logistic Regression, Naïve Bayes, K-nearest Neighbors, Support Vector Classifier Decision Tree, and Random Forest. The best pseudo-label for dangerous speech aspects is obtained using a combined model of IndoBERTweet, Naïve Bayes, and Logistic Regression with an accuracy above 80%. In topic modeling, it was found that the optimal number of topics is 19 based on their coherence score and the absence of new sub-topics. The best thresholding method involves each account having an average retweet count of more than 1 and a cosine similarity value of more than 0.149. The best classification of dangerous users is achieved with the Naïve Bayes model using degree centrality, closeness centrality, and eigenvector centrality features, with a hamming loss value of 0.555.",klasifikasi multilabel dangerous user dasar fitur struktural twitter,dangerous speech ujar bahaya ujar tingkat risiko kelompok orang jahat orang kelompok orang dangerous speech 7 aspek konteks sosial konteks historis dehumanisasi tuduh serang wanita anak loyalitas kelompok ancam kelompok dangerous speech marak temu media sosial twitter dangerous user guna milik presentase tweet dangerous speech abusive language banding tweet neutral speech hate speech teliti model klasifikasi multilabel dangerous user dasar fitur struktural ekstraksi graf guna bentuk mirip unggah twitter fitur struktural degree centrality eigenvector centrality betweenness centrality closeness centrality clustering coefficient tahap cakup olah data tweet ekstraksi fitur struktural jejaring dasar mirip tweet klasifikasi guna multilabel topik dangerous speech olah data tweet praproses tweet model topik lda pseudolabel aspek dangerous speech model indobertweet na ve bayes logistic regresion tahap ekstraksi fitur struktural jejaring dasar mirip tweet graf mana nodes nya guna twitter edgesnya nilai cosine similiarity mirip unggah pilih node edge mengunakan metode thresholding ekstraksi fitur pustaka networkx klasifikasi guna multilabel topik dangerous speech logistic regression na ve bayes knearest neighbors support vector classifier decision tree random forest pseudolabel aspek dangerous speech baik model gabung indobertweet na ve bayes logistic regresion nilai akurasi atas 80 model topik temu topik baik 6 dasar nilai coherence score subtopik bentuk topik 19 dasar nilai coherence scorenya tiada subtopik temu metode thresholding baik minimal guna milik average retweet 1 nilai cosine similiarity 0149 klasifikasi dangerous user baik model na ve bayes fitur degree centrality closeness centrality eigenvecot centrality nilai hamming loss 0555dangerous speech or dangerous discourse refers to a form of expression that can increase the risk of an individual or a group of people committing crimes against others or another group of people in dangerous speech there are 7 aspects namely social context historical context dehumanization accusations attacks against women and children group loyalty and threats against a group dangerous speech is often found on social media platforms like twitter a dangerous user is a user who has a higher percentage of dangerous speech and abusive language in their tweets compared to neutral speech and hate speech in this final project a model has been developed to perform multilabel classification of dangerous users based on structural features extracted from user graphs formed by the similarity of twitter posts the structural features used are degree centrality eigenvector centrality betweenness centrality closeness centrality and clustering coefficient the steps involved include tweet data preprocessing structural feature extraction on the network based on tweet similarity and user classification with multilabel dangerous speech topics tweet data processing is done by preprocessing tweets topic modeling using lda and pseudolabeling of dangerous speech aspects using indobertweet na ve bayes and logistic regression models the next step is the extraction of structural features on the network based on tweet similarity which is done by creating a graph where the nodes represent twitter users and the edges represent cosine similarity values or post similarity node and edge selection is performed using thresholding methods feature extraction is done using the networkx library user classification with multilabel dangerous speech topics is done using logistic regression na ve bayes knearest neighbors support vector classifier decision tree and random forest the best pseudolabel for dangerous speech aspects is obtained using a combined model of indobertweet na ve bayes and logistic regression with an accuracy above 80 in topic modeling it was found that the optimal number of topics is 19 based on their coherence score and the absence of new subtopics the best thresholding method involves each account having an average retweet count of more than 1 and a cosine similarity value of more than 0149 the best classification of dangerous users is achieved with the na ve bayes model using degree centrality closeness centrality and eigenvector centrality features with a hamming loss value of 0555
Identifikasi Diabetes Melitus Berdasarkan Biomarker pada Sekuens DNA Menggunakan Metode Deep Learning.,"Permatasari, Devindha",http://repository.its.ac.id/103748/,"Diabetes melitus merupakan salah satu penyakit kronis yang tidak dapat disembuhkan yang disebabkan oleh kekurangan atau tidak adanya hormon insulin. Menurut etiopatologi diabetes, ada tiga kategori klinis utama, yaitu: diabetes tipe 1 (DMT1), diabetes tipe 2 (DMT2), dan diabetes melitus gestasional (DMG), serta penyebab khusus lainnya. Diabetes merupakan salah satu penyebab utama kematian di seluruh dunia. Setiap tahunnya sekitar 2-5 juta pasien kehilangan nyawa karena diabetes. Individu dengan diabetes menghadapi risiko mengembangkan beberapa masalah kesehatan sekunder seperti penyakit jantung, kerusakan saraf dan berbagai masalah kesehatan lainnya. Dengan demikian, deteksi dini dan pengobatan diabetes dapat mencegah komplikasi dan membantu mengurangi risiko masalah kesehatan yang parah. Penelitian ini bertujuan untuk mengidentifikasi diabetes berdasarkan biomarker pada sekuens DNA dengan menggunakan metode berbasis deep learning. Pada penelitian ini digunakan data sekuens DNA yang direpresentasikan kedalam gambar spektogram. Data sekuens DNA diubah menjadi numerik menggunakan teknik mapping berbasis entropi yang merupakan turunan fraksional dari Shanon Entropi. Kemudian dibuat gambar spektogramnya menggunakan fungsi specgram yang ada pada libary matplotlib dengan menggunakan STFT untuk merangkai plot tiga dimensi dengan waktu, frekuensi, dan amplitudo yang diwakili oleh skala warna. Gambar spektogram dari sekuens DNA diekstraksi menggunakan modul ViT dan mendapatkan 100 fitur. 100 fitur tersebut diklasifikasi dengan menggunakan SVM dan mendapatkan hasil akurasi sebesar 99%================================================================================================================================Diabetes mellitus is an incurable chronic disease caused by a deficiency or absence of the hormone insulin. According to the etiopathology of diabetes, there are three main clinical categories, namely: type 1 diabetes (T1DM), type 2 diabetes (T2DM), and gestational diabetes mellitus (GDM), as well as other noteworthy causes. Diabetes is one of the leading causes of death worldwide. Every year around 2-5 million patients lose their lives due to diabetes. Individuals with diabetes risk developing secondary health problems, such as heart disease, nerve damage, and various other health problems. Thus, early detection and treatment of diabetes can prevent complications and help reduce the risk of severe health problems. This study aims to identify diabetes based on biomarkers in DNA sequences using a deep learning based method. The study utilizes DNA sequence data represented as spectrogram images. The DNA sequences are transformed into numeric values using entropy-based mapping techniques, which are fractional derivatives of Shannon Entropy. Spectrogram images are then created using the specgram function in the Matplotlib library, employing Short-Time Fourier Transform (STFT) to generate three-dimensional plots with time, frequency, and amplitude represented by color scale. Spectrogram images of DNA sequences extracted using the ViT module and obtaining 100 features. These 100 features are classified using SVM and obtain an accuracy of 99%",identifikasi diabetes melitus dasar biomarker sekuens dna metode deep learning,diabetes melitus salah sakit kronis sembuh sebab kurang hormon insulin etiopatologi diabetes kategori klinis utama diabetes tipe 1 dmt1 diabetes tipe 2 dmt2 diabetes melitus gestasional dmg sebab khusus diabetes salah sebab utama mati dunia tahun 25 juta pasien hilang nyawa diabetes individu diabetes hadap risiko kembang sehat sekunder sakit jantung rusa saraf sehat deteksi obat diabetes cegah komplikasi bantu kurang risiko sehat parah teliti tuju identifikasi diabetes dasar biomarker sekuens dna metode bas deep learning teliti data sekuens dna representasi dalam gambar spektogram data sekuens dna ubah numerik teknik mapping bas entropi turun fraksional shanon entropi gambar spektogram fungsi specgram libary matplotlib stft rangkai plot dimensi frekuensi amplitudo wakil skala warna gambar spektogram sekuens dna ekstraksi modul vit 100 fitur 100 fitur klasifikasi svm hasil akurasi 99diabetes mellitus is an incurable chronic disease caused by a deficiency or absence of the hormone insulin according to the etiopathology of diabetes there are three main clinical categories namely type 1 diabetes t1dm type 2 diabetes t2dm and gestational diabetes mellitus gdm as well as other noteworthy causes diabetes is one of the leading causes of death worldwide every year around 25 million patients lose their lives due to diabetes individuals with diabetes risk developing secondary health problems such as heart disease nerve damage and various other health problems thus early detection and treatment of diabetes can prevent complications and help reduce the risk of severe health problems this study aims to identify diabetes based on biomarkers in dna sequences using a deep learning based method the study utilizes dna sequence data represented as spectrogram images the dna sequences are transformed into numeric values using entropybased mapping techniques which are fractional derivatives of shannon entropy spectrogram images are then created using the specgram function in the matplotlib library employing shorttime fourier transform stft to generate threedimensional plots with time frequency and amplitude represented by color scale spectrogram images of dna sequences extracted using the vit module and obtaining 100 features these 100 features are classified using svm and obtain an accuracy of 99
Analisis Sentimen Masyarakat Indonesia Mengenai Vaksin COVID-19 Pada Media Sosial Twitter Menggunakan Metode Naïve Bayes Classifier dan Support Vector Machine.,"Permatasari, Rizka Widya",http://repository.its.ac.id/91280/,"World Health Organization (WHO) mendeklarasi-kan virus COVID-19 sebagai pandemi global pada 11 Maret 2020. Kondisi tersebut memberikan dampak langsung kepada seluruh masyarakat di dunia, dengan mulai diberlakukannya protokol ke-sehatan yang harus diterapkan pada seluruh aspek kegiatan, mulai dari pembatasan sosial hingga lockdown total yang menghambat seluruh kegiatan masyarakat. Salah satu cara yang dilakukan untuk mencegah penyebaran virus ini adalah dengan pemberian vaksin. Kegiatan vaksinasi mulai diberikan kepada masyarakat Indonesia pada bulan Januari 2021. Pada media sosial twitter, pro kontra vaksin COVID-19 sempat menjadi trending topic sehingga dirasa perlu untuk dilakukan penelitian tentang sentimen publik terhadap adanya kegiatan vaksinasi dalam memutus rantai penyebaran COVID-19 di Indonesia. Pada penelitian ini digunakan analisis klasifikasi teks yaitu Naïve Bayes Classifier (NBC) dan Support Vector Machine (SVM). NBC telah banyak digunakan dalam penelitian mengenai Text Mining karena memiliki algoritma yang sederhana namun dapat menghasilkan akurasi yang tinggi, sedangkan SVM memiliki kemampuan yang baik dalam mengolah data berdimensi besar dengan hasil yang efektif. Perbandingan kedua metode menggunakan 10 fold-stratified cross validation dengan kriteria kebaikan klasifikasi AUC dan akurasi menunjukkan bahwa SVM memiliki kinerja klasifikasi yang lebih baik dibanding NBC dan SVM kernel menghasilkan ketepatan klasifikasi lebih tinggi dibanding SVM kernel RBF.====================================================================================================The World Health Organization (WHO) declared the COVID-19 virus as a global pandemic on March 11, 2020. These conditions had a direct impact on all people in the world, with the introduction of health protocols that must be applied to all aspects of activities, starting from from social restrictions to total lockdowns that hinder all community activities. One way to prevent the spread of this virus is by giving vaccines. Vaccination activities began to be given to the people of Indonesia in January 2021. On social media Twitter, the pros and cons of the COVID-19 vaccine had become a trending topic, so it was deemed necessary to conduct research on public sentiment towards vaccination activities in breaking the chain of spread of COVID-19. 19 in Indonesia. This research uses text classification analysis, namely Naïve Bayes Classifier (NBC) and Support Vector Machine (SVM). NBC has been widely used in research on Text Mining because it has a simple algorithm but can produce high accuracy, while SVM has a good ability to process large-dimensional data with effective results. Comparison of the two methods using 10 fold-stratified cross validation with AUC classification goodness criteria and accuracy shows that SVM has better classification performance than NBC and SVM kernel produces higher classification accuracy than SVM kernel RBF.",analisis sentimen masyarakat indonesia vaksin covid19 media sosial twitter metode na ve bayes classifier support vector machine,world health organization who deklarasi virus covid19 pandemi global 11 maret 2020 kondisi dampak langsung masyarakat dunia laku protokol sehat terap aspek giat batas sosial lockdown total hambat giat masyarakat salah cegah sebar virus beri vaksin giat vaksinasi masyarakat indonesia januari 2021 media sosial twitter pro kontra vaksin covid19 trending topic rasa teliti sentimen publik giat vaksinasi putus rantai sebar covid19 indonesia teliti analisis klasifikasi teks na ve bayes classifier nbc support vector machine svm nbc teliti text mining milik algoritma sederhana hasil akurasi svm milik mampu olah data mens hasil efektif banding metode 10 foldstratified cross validation kriteria baik klasifikasi auc akurasi svm milik kerja klasifikasi banding nbc svm kernel hasil tepat klasifikasi banding svm kernel rbfthe world health organization who declared the covid19 virus as a global pandemic on march 11 2020 these conditions had a direct impact on all people in the world with the introduction of health protocols that must be applied to all aspects of activities starting from from social restrictions to total lockdowns that hinder all community activities one way to prevent the spread of this virus is by giving vaccines vaccination activities began to be given to the people of indonesia in january 2021 on social media twitter the pros and cons of the covid19 vaccine had become a trending topic so it was deemed necessary to conduct research on public sentiment towards vaccination activities in breaking the chain of spread of covid19 19 in indonesia this research uses text classification analysis namely na ve bayes classifier nbc and support vector machine svm nbc has been widely used in research on text mining because it has a simple algorithm but can produce high accuracy while svm has a good ability to process largedimensional data with effective results comparison of the two methods using 10 foldstratified cross validation with auc classification goodness criteria and accuracy shows that svm has better classification performance than nbc and svm kernel produces higher classification accuracy than svm kernel rbf
Pengembangan Sistem Deteksi dan Lokalisasi Kebocoran Pipa Berbasis Deep Learning Residual-Network pada Jaringan Distribusi Air di Perumda Air Minum Tugu Tirta Malang.,"Prabowo, Zhiya Ulhaq",http://repository.its.ac.id/109409/,"Berdasarkan ringkasan SDGs 6.2 tahun 2021, bahwa 46% dari populasi dunia kekurangan air yang tersanitasi. PERUMDA Air Minum Tugu Tirta merupakan salah perusahaan yang berkontribusi dalam penyediaan dan distribusi air bersih. Kehilangan air fisik merupakan tantangan dalam distribusi air bersih yang dialami perusahaan. Demi mengatasi tantangan, diperlukan metode deteksi lokasi kebocoran pada jaringan distribusi air. Penelitian kali ini akan diajukan metode berbasis deep learning residual-network (ResNet) untuk mendeteksi ukuran dan lokasi kebocoran yang terjadi. Pertama, dilakukan pemilihan DMA sebagai objek penelitian. Spesifikasi DMA diambil untuk dilakukan pemodelan dengan software WaterCAD dan kemudian divalidasi serta dilakukan pemodelan kebocoran dengan mengatur Emitter Coefficient serta lokasi kebocorannya. Ukuran kebocoran adalah rendah 0,3 l/s, sedang 0,6 l/s, dan tinggi 1,2 l/s. Ketika kebocoran disimulasikan, data tekanan diambil pada empat titik sensor yang telah ditentukan pada DMA. Kemudian, dilakukan variasi lokasi dengan variasi ukuran yang sama. Data tekanan aktual dari DMA juga diambil dengan menggunakan sensor tekanan yang dipasang pada pressure point dari jaringan. Sistem deteksi dan lokalisasi berbasis ResNet dikembangkan dengan menggunakan data simulasi dalam proses pelatihan sistem. Dari proses pelatihan tersebut didapatkan hasil performa akurasi deteksi ukuran sebesar 98.62% dan lokalisasi sebesar 98.16%, serta F1-Score deteksi ukuran sebesar 98.97% dan lokalisasi sebesar 98.17%. Akan tetapi, pada percobaan dengan data aktual, performa dapat disebut kurang baik, dimana akurasi deteksi ukuran dan lokalisasi sebesar 75%, serta F1-Score deteksi ukuran sebesar 85.71%. dan lokalisasi sebesar 85.71%. =================================================================================================================================According to the 2021 SDGs 6.2 summary, 46% of the world's population lacks access to sanitized water. PERUMDA Air Minum Tugu Tirta is one of the companies contributing to the provision and distribution of clean water. Physical water loss is a significant challenge in the distribution of clean water faced by the company. To address this challenge, a method for detecting leak locations in the water distribution network is necessary. This study proposes a deep learning residual-network (ResNet)-based method to detect the size and location of leaks. First, a District Metered Area (DMA) was selected as the research object. The DMA specifications were used for modeling with WaterCAD software. The model was validated, and leak modeling was performed by adjusting the Emitter Coefficient and the location of the leaks. The leak sizes were categorized as low (0.3 l/s), medium (0.6 l/s), and high (1.2 l/s). During the leak simulation, pressure data was collected at four predetermined sensor points within the DMA. Various locations with the same size variations were tested. Actual pressure data from the DMA was also collected using pressure sensors installed at pressure points in the network. The ResNet-based detection and localization system was developed using simulation data for the system training process. The training process yielded a detection size accuracy is 98.62% and a localization accuracy is 98.16%, with an F1-Score for detection size is 98.97% and for localization is 98.17%. However, when tested with actual data, the performance was less satisfactory, with a detection size and localization accuracy of 75%, and the F1-Score for detection size and localization is 85.71%.",kembang sistem deteksi lokalisasi bocor pipa bas deep learning residualnetwork jaring distribusi air perumda air minum tugu tirta malang,dasar ringkas sdgs 62 2021 46 populasi dunia kurang air sanitasi perumda air minum tugu tirta salah usaha kontribusi sedia distribusi air bersih hilang air fisik tantang distribusi air bersih alami usaha atas tantang metode deteksi lokasi bocor jaring distribusi air teliti kali aju metode bas deep learning residualnetwork resnet deteksi ukur lokasi bocor pilih dma objek teliti spesifikasi dma ambil model software watercad divalidasi model bocor atur emitter coefficient lokasi bocor ukur bocor rendah 03 ls 06 ls 12 ls bocor simulasi data tekan ambil titik sensor tentu dma variasi lokasi variasi ukur data tekan aktual dma ambil sensor tekan pasang pressure point jaring sistem deteksi lokalisasi bas resnet kembang data simulasi proses latih sistem proses latih dapat hasil performa akurasi deteksi ukur 9862 lokalisasi 9816 f1score deteksi ukur 9897 lokalisasi 9817 coba data aktual performa mana akurasi deteksi ukur lokalisasi 75 f1score deteksi ukur 8571 lokalisasi 8571 according to the 2021 sdgs 62 summary 46 of the worlds population lacks access to sanitized water perumda air minum tugu tirta is one of the companies contributing to the provision and distribution of clean water physical water loss is a significant challenge in the distribution of clean water faced by the company to address this challenge a method for detecting leak locations in the water distribution network is necessary this study proposes a deep learning residualnetwork resnetbased method to detect the size and location of leaks first a district metered area dma was selected as the research object the dma specifications were used for modeling with watercad software the model was validated and leak modeling was performed by adjusting the emitter coefficient and the location of the leaks the leak sizes were categorized as low 03 ls medium 06 ls and high 12 ls during the leak simulation pressure data was collected at four predetermined sensor points within the dma various locations with the same size variations were tested actual pressure data from the dma was also collected using pressure sensors installed at pressure points in the network the resnetbased detection and localization system was developed using simulation data for the system training process the training process yielded a detection size accuracy is 9862 and a localization accuracy is 9816 with an f1score for detection size is 9897 and for localization is 9817 however when tested with actual data the performance was less satisfactory with a detection size and localization accuracy of 75 and the f1score for detection size and localization is 8571
Klasterisasi Kasus Kemiskinan di Indonesia pada Hasil Peramalan Backpropagation Neural Network.,"Pradnyandari, Ni Putu Putri Marinda",http://repository.its.ac.id/99719/,"Kemiskinan merupakan permasalahan sosial yang cukup kompleks dan sulit untuk hilang. Banyak negara sudah memfokuskan tujuan kenegaraan mereka untuk menanggulangi kemiskinan. Hal ini dibuktikan dengan lahirnya Sustainable Development Goals (SDGs) yang disusun oleh Perserikatan Bangsa-Bangsa (PBB) dan mengharuskan Indonesia turut andil dalam penanggulangan kemiskinan. Namun, jika kita lihat berdasarkan data, menurut data Badan Pusat Statistik, angka kemiskinan di Indonesia masih mengalami peningkatan di bulan September 2022 dibandingkan dengan periode sebelumnya, Maret 2022. Berdasarkan permasalahan tersebut, solusi yang dapat ditawarkan untuk membantu pemerintah dan masyarakat dalam menanggulangi kemiskinan adalah dengan melakukan peramalan sebagai landasan dalam mengambil kebijakan. Peramalan ini menggunakan metode Backpropagation Neural Network dan hasil data peramalan dilakukan clustering menggunakan metode K-Means. Objek penelitian yang digunakan adalah data kemiskinan 34 provinsi di Indonesia dari tahun 2015 sampai 2022 yang terdiri dari variabel tingkat kemiskinan, PDRB harga konstan, tingkat pengangguran terbuka, dan rasio gini. Data berupa data semester dengan total jumlah data di setiap variabelnya sebanyak 544 data. Dalam pemodelan BPNN, didapatkan model terbaik dengan jaringan BPNN (4-6-1) dengan hasil MAPE dan MSE sebesar 7,14% dan 0,00000492. Hasil peramalan berdasarkan model BPNN terbaik kemudian dilakukan klasterisasi. Clustering K-Means menghasilkan 3 klaster dengan karakteristik yang berbeda. Jumlah provinsi yang masuk ke dalam klaster 1 sebanyak 8 provinsi, klaster 2 sebanyak 5 provinsi, dan klaster 3 sebanyak 21 provinsi.================================================================================================================================Poverty is a complex social problem that is difficult to eliminate. Many countries have focused their state goals on tackling poverty. This is evidenced by the birth of the Sustainable Development Goals (SDGs) compiled by the United Nations (UN) and requires Indonesia to take part in poverty reduction. However, if we look at the data, according to the Central Bureau of Statistics, the poverty rate in Indonesia still increased in September 2022 compared to the previous period, March 2022. Based on these problems, a solution that can be offered to help the government and society in reducing poverty is to conduct forecasting as a basis for making policies. This forecasting uses the Backpropagation Neural Network method and the results of the forecasting data are clustering using the K-Means method. The research object used is poverty data for 34 provinces in Indonesia from 2015 to 2022 which consists of variables of poverty rate, GRDP at constant prices, open unemployment rate, and Gini ratio. The data is in the form of semester data with a total of 544 data in each variable. In BPNN modeling, the best model is obtained with the BPNN network (4-6-1) with MAPE and MSE results of 7.14% and 0.00000492. Forecasting results based on the best BPNN model are then clusterized. K-Means clustering produces 3 clusters with different characteristics. The number of provinces included in cluster 1 is eight provinces, cluster 2 is five provinces, and cluster 3 is 21 provinces.",klasterisasi miskin indonesia hasil amal backpropagation neural network,miskin masalah sosial kompleks sulit hilang negara fokus tuju negara tanggulang miskin bukti lahir sustainable development goals sdgs susun serikat bangsabangsa pbb harus indonesia andil tanggulang miskin lihat dasar data data badan pusat statistik angka miskin indonesia alami tingkat september 2022 banding periode maret 2022 dasar masalah solusi tawar bantu perintah masyarakat tanggulang miskin amal landas ambil bijak amal metode backpropagation neural network hasil data amal clustering metode kmeans objek teliti data miskin 34 provinsi indonesia 2015 2022 variabel tingkat miskin pdrb harga konstan tingkat anggur buka rasio gin data data semester total data variabel 544 data model bpnn dapat model baik jaring bpnn 461 hasil mape mse 714 000000492 hasil amal dasar model bpnn baik klasterisasi clustering kmeans hasil 3 klaster karakteristik beda provinsi masuk klaster 1 8 provinsi klaster 2 5 provinsi klaster 3 21 provinsipoverty is a complex social problem that is difficult to eliminate many countries have focused their state goals on tackling poverty this is evidenced by the birth of the sustainable development goals sdgs compiled by the united nations un and requires indonesia to take part in poverty reduction however if we look at the data according to the central bureau of statistics the poverty rate in indonesia still increased in september 2022 compared to the previous period march 2022 based on these problems a solution that can be offered to help the government and society in reducing poverty is to conduct forecasting as a basis for making policies this forecasting uses the backpropagation neural network method and the results of the forecasting data are clustering using the kmeans method the research object used is poverty data for 34 provinces in indonesia from 2015 to 2022 which consists of variables of poverty rate grdp at constant prices open unemployment rate and gin ratio the data is in the form of semester data with a total of 544 data in each variable in bpnn modeling the best model is obtained with the bpnn network 461 with mape and mse results of 714 and 000000492 forecasting results based on the best bpnn model are then clusterized kmeans clustering produces 3 clusters with different characteristics the number of provinces included in cluster 1 is eight provinces cluster 2 is five provinces and cluster 3 is 21 provinces
Deteksi Dini Financial Distress Pada Perusahaan Sektor Teknologi di Bursa Efek Indonesia Menggunakan Artificial Neural Network dan Support Vector Machine.,"Pradnyaningsih, Ni Luh Eva",http://repository.its.ac.id/118576/,"Kondisi ekonomi dan geopolitik di Indonesia diperkirakan akan memburuk pada beberapa tahun kedepan yang disebabkan oleh beberapa faktor diantaranya inflasi dan biaya operasional yang tinggi. Hal ini berdampak pada minat investor dalam berinvestasi pada perusahaan. Salah satu perusahaan yang paling berdampak besar adalah perusahaan sektor teknologi. Industri teknologi di Indonesia menghadapi tantangan pada pangsa pasar yang relatif rendah dibandingkan pasar global dimana banyak saham teknologi di Indonesia masih tertinggal jauh dibandingkan negara-negara maju. Akibat hal tersebut investor lebih memilih berinvestasi pada emiten yang minim risiko. Penurunan ini memengaruhi kemampuan perusahaan-perusahaan teknologi untuk menarik investasi yang dibutuhkan untuk bertahan dan berkembang. Beberapa perusahaan di sektor teknologi telah mengalami perubahan signifikan dalam kinerja keuangan mereka, menunjukkan adanya potensi kesulitan keuangan. Kesulitan keuangan terjadi ketika kinerja keuangan perusahaan menurun dari waktu ke waktu, yang pada gilirannya memengaruhi stabilitas sistem keuangan dan sumber daya manusia perusahaan. Oleh karena itu, penelitian ini bertujuan untuk memprediksi apakah perusahaan-perusahaan di sektor teknologi di Indonesia akan mengalami kesulitan keuangan di masa depan atau tidak dengan menggunakan metode Artificial Neural Network dan Support Vector Machine. Hasil penelitian menunjukkan bahwa ANN lebih unggul dalam memprediksi kinerja keuangan perusahaan, dengan rasio PER memiliki pengaruh besar dalam memprediksi risiko ini. Selain itu, aplikasi berbasis web yang dikembangkan menggunakan Streamlit memungkinkan pengguna untuk mendeteksi dini kondisi keuangan perusahaan.===================================================================================================================================The economic and geopolitical conditions in Indonesia are expected to deteriorate in the coming years due to several factors, including inflation and high operational costs. This affects investor interest in investing in companies. One of the most significantly impacted sectors is technology companies. The technology industry in Indonesia faces challenges with a relatively low market share compared to the global market, where many technology stocks in Indonesia lag significantly behind those in developed countries. As a result, investors prefer to invest in issuers with minimal risk. This decline affects the ability of technology companies to attract the investment needed to survive and grow. Some companies in the technology sector have experienced significant changes in their financial performance, indicating potential financial difficulties. Financial difficulties occur when a company's financial performance declines over time, which in turn affects the stability of the financial system and the company's human resources. Therefore, this study aims to predict whether technology companies in Indonesia will experience financial distress in the future using Artificial Neural Network and Support Vector Machine methods. The results of the study indicate that ANN outperforms other models in predicting the financial performance of companies, with the PER ratio having a significant impact on forecasting this risk. Additionaly, the web-based application developed using Streamlit enables users to detect companies financial conditions early.",deteksi financial distress usaha sektor teknologi bursa efek indonesia artificial neural network support vector machine,kondisi ekonomi geopolitik indonesia buruk depan sebab faktor inflasi biaya operasional dampak minat investor investasi usaha salah usaha dampak usaha sektor teknologi industri teknologi indonesia hadap tantang pangsa pasar relatif rendah banding pasar global mana saham teknologi indonesia tinggal banding negaranegara maju akibat investor pilih investasi emiten minim risiko turun pengaruh mampu perusahaanperusahaan teknologi tarik investasi butuh tahan kembang usaha sektor teknologi alami ubah signifikan kerja uang potensi sulit uang sulit uang kerja uang usaha turun gilir pengaruh stabilitas sistem uang sumber daya manusia usaha teliti tuju prediksi perusahaanperusahaan sektor teknologi indonesia alami sulit uang metode artificial neural network support vector machine hasil teliti ann unggul prediksi kerja uang usaha rasio milik pengaruh prediksi risiko aplikasi bas web kembang streamlit guna deteksi kondisi uang perusahaanthe economic and geopolitical conditions in indonesia are expected to deteriorate in the coming years due to several factors including inflation and high operational costs this affects investor interest in investing in companies one of the most significantly impacted sectors is technology companies the technology industry in indonesia faces challenges with a relatively low market share compared to the global market where many technology stocks in indonesia lag significantly behind those in developed countries as a result investors prefer to invest in issuers with minimal risk this decline affects the ability of technology companies to attract the investment needed to survive and grow some companies in the technology sector have experienced significant changes in their financial performance indicating potential financial difficulties financial difficulties occur when a companys financial performance declines over time which in turn affects the stability of the financial system and the companys human resources therefore this study aims to predict whether technology companies in indonesia will experience financial distress in the future using artificial neural network and support vector machine methods the results of the study indicate that ann outperforms other models in predicting the financial performance of companies with the ratio having a significant impact on forecasting this risk additionaly the webbased application developed using streamlit enables users to detect companies financial conditions early
Analisis Faktor Yang Mempengaruhi Penjualan Produk B2B Dengan Menggunakan Metode Support Vector Machine Di PT XYZ.,"Pradnyawati, Ni Kadek Dewi",http://repository.its.ac.id/96203/,"Indonesia merupakan salah satu negara dengan pengguna internet terbesar di seluruh dunia yang menduduki posisi keenam pada tahun 2021 dengan menggunakan berbagai media seperti handphone, laptop, personal computer ataupun alat lainnya yang membutuhkan koneksi internet. PT XYZ adalah suatu perusahaan telekomunikasi yang menyediakan layanan internet di Indonesia dengan berbagai produk yang ditujukan untuk segmen Business to Business (B2B) dan juga Business to Consumer (B2C). Produk B2B yang dihasilkan oleh PT XYZ yaitu IaaS, CPaaS, SaaS, dan Analytics yang kemudian ditawarkan oleh salesperson ke pelanggan atau perusahaan yang membutuhkan dengan melakukan assessment awal yang bertujuan untuk melihat kebutuhannya dan kemudian melakukan mapping produk yang sesuai. PT XYZ memiliki lebih dari 50 salesperson yang ada di Indonesia dengan latar belakang dan profil yang berbeda-beda seperti umur, lokasi, jabatan, status, hingga kondisi keluarga dan juga ekonomi yang dapat mempengaruhi performa dari seorang salesperson. PT XYZ ingin meningkatkan performansi penjualan produk B2B dengan mengetahui faktor-faktor yang berpengaruh berdasarkan karakteristik dari salesperson dengan membandingkan antara status proyek win dan lose. Regresi logistic dan scoring feature digunakan untuk mengetahui korelasi antara variabel sehingga dapat mengetahui faktor-faktor yang berpengaruh terhadap penjualan. Support vector machine (SVM) merupakan salah satu metode dari data mining yang dapat digunakan untuk mengklasifikasikan dan memprediksi dari suatu data (Arifin, 2018). Berdasarkan hasil analisis, faktor yang mempengaruhi penjualan dari salesperson yaitu lama bekerja di PT XYZ, sisa waktu pelunasan KPR, jumlah training, usia pernikahan, dan pendidikan terakhir. Nilai akurasi pada hasil klasifikasi SVM sebesar 81% dengan derajat optimalnya yaitu sebesar 2. Rekomendasi bisnis yang dapat diberikan untuk meningkatkan performansi salesperson PT XYZ adalah dengan memberikan training yang sesuai dengan kebutuhan dan pekerjaan untuk salesperson.==============================================================================================================================PT XYZ is a telecommunication company that provides internet services in Indonesia with various products aimed at the Business to Business (B2B) and also Business to Consumer (B2C) segments. B2B products produced by PT XYZ namely IaaS, CPaaS, SaaS, and Analytics which are then offered by salespersons to customers or companies that need them by conducting an initial assessment which aims to see their needs and then mapping the appropriate products. PT XYZ has more than 50 salespersons in Indonesia with different backgrounds and profiles such as age, location, position, status, to family and economic conditions that can affect the performance of a salesperson. PT XYZ wants to improve the sales performance of B2B products by knowing the influencing factors based on the characteristics of the salesperson by comparing the win and lose project statuses. Logistic regression and scoring features are used to determine the correlation between variabels so that they can determine the factors that influence sales. Support vector machine (SVM) is a method of data mining that can be used to classify and predict data (Arifin, 2018). Based on the results of the analysis, The characteristics that influence sales from salespersons are time spent working, remaining KPR repayment time, number of trainings, marriage age, educational status. Advice that offered to PT XYZ by providing training tailored to the demands of the salesperson and also in accordance with the job is intended to boost salesperson performance, allowing them to win more products. The SVM classification results have an accuracy score of 81% with an ideal degree of 2.",analisis faktor pengaruh jual produk b2b metode support vector machine pt xyz,indonesia salah negara guna internet besar dunia duduk posisi enam 2021 media handphone laptop personal computer alat butuh koneksi internet pt xyz usaha telekomunikasi sedia layan internet indonesia produk segmen business to business b2b business to consumer b2c produk b2b hasil pt xyz iaas cpaas saas analytics tawar salesperson langgan usaha butuh assessment tuju butuh mapping produk sesuai pt xyz milik 50 salesperson indonesia latar profil berbedabeda umur lokasi jabat status kondisi keluarga ekonomi pengaruh performa salesperson pt xyz tingkat performansi jual produk b2b faktorfaktor pengaruh dasar karakteristik salesperson banding status proyek win lose regresi logistic scoring feature korelasi variabel faktorfaktor pengaruh jual support vector machine svm salah metode data mining klasifikasi prediksi data arifin 2018 dasar hasil analisis faktor pengaruh jual salesperson pt xyz sisa lunas kpr training usia nikah didik nilai akurasi hasil klasifikasi svm 81 derajat optimal 2 rekomendasi bisnis tingkat performansi salesperson pt xyz training sesuai butuh kerja salespersonpt xyz is a telecommunication company that provides internet services in indonesia with various products aimed at the business to business b2b and also business to consumer b2c segments b2b products produced by pt xyz namely iaas cpaas saas and analytics which are then offered by salespersons to customers or companies that need them by conducting an initial assessment which aims to see their needs and then mapping the appropriate products pt xyz has more than 50 salespersons in indonesia with different backgrounds and profiles such as age location position status to family and economic conditions that can affect the performance of a salesperson pt xyz wants to improve the sales performance of b2b products by knowing the influencing factors based on the characteristics of the salesperson by comparing the win and lose project statuses logistic regression and scoring features are used to determine the correlation between variabels so that they can determine the factors that influence sales support vector machine svm is a method of data mining that can be used to classify and predict data arifin 2018 based on the results of the analysis the characteristics that influence sales from salespersons are time spent working remaining kpr repayment time number of trainings marriage age educational status advice that offered to pt xyz by providing training tailored to the demands of the salesperson and also in accordance with the job is intended to boost salesperson performance allowing them to win more products the svm classification results have an accuracy score of 81 with an ideal degree of 2
Klasifikasi Tumor Glioma dengan Modalitas Magnetic Resonance Imaging (MRI) berbasis Convolutional Neural Network (CNN) untuk Diagnosis Tingkat Keganasan Tumor Otak.,"Prakosa, Nadhira Anindyafitri",http://repository.its.ac.id/111213/,"Glioma mendominasi 80% dari kasus tumor otak ganas pada pasien, menyebabkan tingginya tingkat mortalitas, disabilitas serta penurunan kualitas hidup yang signifikan. Tumor glioma diklasifikasikan menjadi Low-Grade Glioma (LGG) dan High-Grade Glioma (HGG) berdasarkan tingkat keganasannya. Klasifikasi ini sangat penting karena berdampak signifikan terhadap prognosis, keputusan pengobatan, dan perencanaan bedah. Diagnosis yang akurat oleh para ahli medis sangat penting untuk menentukan tindakan yang tepat. Computer Aided Diagnosis (CAD) dapat digunakan dalam mempermudah dokter menghasilkan diagnosis yang persisi. Metode CAD tradisional mengandalkan teknik machine learning (ML) yang memerlukan pemilihan fitur secara manual, seperti analisis tekstur. Namun, pendekatan ini dapat menyebabkan hilangnya fitur data yang esensial, yang berpotensi mengurangi akurasi diagnosis. Convolutional Neural Networks (CNN) telah merevolusi pencitraan medis dengan kemampuan luar biasa dalam mengenali dan mengidentifikasi tumor otak. Berbeda dengan metode tradisional, CNN mengintegrasikan ekstraksi fitur dalam arsitekturnya, menghilangkan kebutuhan pemilihan fitur manual. Kemampuan ini memungkinkan CNN mencapai akurasi tinggi dalam klasifikasi tumor. Untuk klasifikasi glioma, sangat penting untuk memanfaatkan informasi dari berbagai sequence MRI guna memungkinkan model CNN mengekstraksi fitur representatif secara efektif. Studi ini menggunakan pendekatan multi-sequence fusion, menggabungkan sequence MRI Flair, T1, T1ce, dan T2 dengan fine-tuned model VGG16 untuk mengklasifikasikan tingkat keganasan glioma. Model ini memanfaatkan data dari dataset BraTS 2017, 2018, 2019, dan 2020. Model yang diusulkan mencapai hasil yang luar biasa, meliputi akurasi 100%, presisi 99,04%, recall 100%, skor F1 99,52%, dan spesifisitas 99,03%. Evaluasi metrik yang luar biasa ini menunjukkan efektivitas model dalam mengklasifikasikan tingkat keganasan glioma dengan akurat. Studi ini menunjukkan kemajuan signifikan dalam mendiagnosis tingkat keganasan tumor otak, serta memperlihatkan potensi untuk mempermudah pembuatan prognosis pasien melalui klasifikasi yang akurat dan andal.========================================================================================================================Gliomas dominate 80% of malignant brain tumor cases in patients, presenting a significant challenge in neuro-oncology. These tumors are classified into Low-Grade Glioma (LGG) and High-Grade Glioma (HGG) based on their malignancy levels. This classification is crucial as it significantly impacts prognosis, treatment decisions, and surgical planning. Accurate diagnosis by medical experts is essential for determining the appropriate course of action. Computer-aided diagnosis (CAD) systems have emerged as valuable tools in assisting doctors with precise diagnoses. Traditional CAD methods have often relied on machine learning techniques that require manual feature selection, such as texture analysis. However, this approach can lead to the loss of essential data features, potentially compromising the accuracy of the diagnosis. Convolutional Neural Networks (CNNs) have revolutionized medical imaging by excelling in recognizing and identifying brain tumors. Unlike traditional methods, CNNs integrate feature extraction within their architecture, eliminating the need for manual feature selection. This capability allows CNNs to achieve high accuracy in tumor classification. For glioma classification, it is essential to utilize information from different MRI sequences to enable the CNN model to extract representative features effectively. This study employs a multi-sequence fusion approach, combining Flair, T1, T1ce, and T2 MRI sequences with a fine-tuned VGG16 model to classify glioma malignancy levels. The model leverages data from the BraTS 2017, 2018, 2019, and 2020 datasets. The proposed model achieves remarkable results, including 100% accuracy, 99.04% precision, 100% recall, a 99.52% F1 score, and 99.03% specificity. These exceptional performance metrics highlight the model's effectiveness in accurately classifying glioma malignancy levels. The study demonstrates significant advancements in diagnosing brain tumor malignancy levels, showcasing the potential to facilitate accurate and reliable patient prognoses through precise classification.",klasifikasi tumor glioma modalitas magnetic resonance imaging mri bas convolutional neural network cnn diagnosis tingkat ganas tumor otak,glioma dominasi 80 tumor otak ganas pasien sebab tinggi tingkat mortalitas disabilitas turun kualitas hidup signifikan tumor glioma klasifikasi lowgrade glioma lgg highgrade glioma hgg dasar tingkat ganas klasifikasi dampak signifikan prognosis putus obat rencana bedah diagnosis akurat ahli medis tentu tindak computer aided diagnosis cad mudah dokter hasil diagnosis persisi metode cad tradisional andal teknik machine learning ml pilih fitur manual analisis tekstur dekat sebab hilang fitur data esensial potensi kurang akurasi diagnosis convolutional neural networks cnn revolusi citra medis mampu nali identifikasi tumor otak beda metode tradisional cnn integrasi ekstraksi fitur arsitektur hilang butuh pilih fitur manual mampu cnn capai akurasi klasifikasi tumor klasifikasi glioma manfaat informasi sequence mri model cnn ekstraksi fitur representatif efektif studi dekat multisequence fusion gabung sequence mri flair t1 t1ce t2 finetuned model vgg16 klasifikasi tingkat ganas glioma model manfaat data dataset brats 2017 2018 2019 2020 model usul capai hasil liput akurasi 100 presisi 9904 recall 100 skor f1 9952 spesifisitas 9903 evaluasi metrik efektivitas model klasifikasi tingkat ganas glioma akurat studi maju signifikan diagnosis tingkat ganas tumor otak potensi mudah buat prognosis pasien klasifikasi akurat andalgliomas dominate 80 of malignant brain tumor cases in patients presenting a significant challenge in neurooncology these tumors are classified into lowgrade glioma lgg and highgrade glioma hgg based on their malignancy levels this classification is crucial as it significantly impacts prognosis treatment decisions and surgical planning accurate diagnosis by medical experts is essential for determining the appropriate course of action computeraided diagnosis cad systems have emerged as valuable tools in assisting doctors with precise diagnoses traditional cad methods have often relied on machine learning techniques that require manual feature selection such as texture analysis however this approach can lead to the loss of essential data features potentially compromising the accuracy of the diagnosis convolutional neural networks cnns have revolutionized medical imaging by excelling in recognizing and identifying brain tumors unlike traditional methods cnns integrate feature extraction within their architecture eliminating the need for manual feature selection this capability allows cnns to achieve high accuracy in tumor classification for glioma classification it is essential to utilize information from different mri sequences to enable the cnn model to extract representative features effectively this study employs a multisequence fusion approach combining flair t1 t1ce and t2 mri sequences with a finetuned vgg16 model to classify glioma malignancy levels the model leverages data from the brats 2017 2018 2019 and 2020 datasets the proposed model achieves remarkable results including 100 accuracy 9904 precision 100 recall a 9952 f1 score and 9903 specificity these exceptional performance metrics highlight the models effectiveness in accurately classifying glioma malignancy levels the study demonstrates significant advancements in diagnosing brain tumor malignancy levels showcasing the potential to facilitate accurate and reliable patient prognoses through precise classification
Engine Predictive Maintenance Schedule Optimization on Sumbagut-2 Gas Engine Power Plant Using Mixed Integer Nonlinear Programming.,"Pranata, Muhammad Kahari",http://repository.its.ac.id/110691/,"Engine maintenance scheduling is crucial for power plants, particularly those using multiple engines. For example, the Sumbagut-2 Gas Engine Power Plant in Lhokseumawe, Aceh, employs 13 engines to produce 240 MW of power for northern Sumatera, including North Sumatera and Aceh. This project designs an optimized maintenance schedule based on engine usability and the type of maintenance required according to each generator's accumulated operation hours. The goal is to maximize system reliability using a mixed integer nonlinear programming optimization approach. Constraints include maximum duration and maintenance status, while the objective function focuses on reliability. Engine reliability is determined by calculating the components’ respective reliability functions in series, and system reliability is assessed by placing the engines in parallel. The optimized schedule shows that the first maintenance occurs on the 27th day. Most engines are maintained in pairs, with at least one engine undergoing maintenance alone.",engine predictive maintenance schedule optimization on sumbagut2 gas engine power plant using mixed integer nonlinear programming,engine maintenance scheduling is crucial for power plants particularly those using multiple engines for example the sumbagut2 gas engine power plant in lhokseumawe aceh employs 13 engines to produce 240 mw of power for northern sumatera including north sumatera and aceh this project designs an optimized maintenance schedule based on engine usability and the type of maintenance required according to each generators accumulated operation hours the goal is to maximize system reliability using a mixed integer nonlinear programming optimization approach constraints include maximum duration and maintenance status while the objective function focuses on reliability engine reliability is determined by calculating the components  respective reliability functions in series and system reliability is assessed by placing the engines in parallel the optimized schedule shows that the first maintenance occurs on the 27th day most engines are maintained in pairs with at least one engine undergoing maintenance alone
Boosting Support Vector Machine pada Data Microarray yang Imbalance.,"Pratama, Risky Frasetio Wahyu",http://repository.its.ac.id/55389/,"Data microarray memainkan peran penting dalam pengklasifikasian hampir semua jenis jaringan kanker. Permasalahan yang seringkali dihadapi dalam klasifikasi menggunakan data microarray adalah high dimensional data dan kelas imbalance. Masalah high dimensional data dapat diatasi dengan menggunakan seleksi fitur Fast Correlated Based Filter. Metode klasifikasi yang digunakan dalam penelitian ini yaitu Support Vector Machines (SVM) karena beberapa kelebihannya, namun SVM sangat sensitif terhadap kelas imbalance. SMOTE merupakan salah satu dalam penanganan data imbalance dengan cara mereplikasi pengamatan pada kelas minoritas. Metode ini seringkali bekerja baik namun terkadang juga terjadi masalah overfitting. Salah satu alternatif lain dalam meningkatkan performansi klasifikasi pada data imbalance yaitu boosting. Metode ini membangun suatu classifier akhir yang kuat dengan menggabungkan sekumpulan SVM sebagai base classifier selama proses iterasi, sehingga dapat meningkatkan performansi klasifikasi. Penelitian ini, bertujuan untuk mengkaji performansi dari SMOTEBoost-SVM jika dibandingkan dengan AdaBoost-SVM dalam melakukan klasifikasi pada data microarray dengan beberapa tingkatan rasio imbalance yang didesain dalam studi simulasi dan penerapan pada data publik microarray. Data publik yang digunakan yaitu data kanker colon dan data myeloma. Hasil analisis yang diperoleh yaitu secara umum, pada studi simulasi, semua classifier mengalami penurunan performansi g-mean seiring bertambahnya rasio kelas imbalance, namun SMOTEBoost-SVM cenderung unggul dan mengalami penurunan performansi lebih kecil (lebih stabil) dibandingkan AdaBoost-SVM, SMOTE-SVM dan SVM. Pada Penerapan data publik, SMOTEBoost SVM juga  mengungguli ketiga metode lain berdasarkan ukuran g-mean dan sensitivity. Efek dari seleksi fitur juga dilihat dalam analisis dimana menggunakan fitur-fitur informatif hasil seleksi fitur, menghasilkan performansi yang lebih baik dibandingkan menggunakan seluruh fitur dalam klasifikasi.========================================================================================================Microarray data plays an important role in the classification of almost all types of cancer tissue. The problems that often appear in the classification using microarray data are high-dimensional data and imbalanced class. The problem of high-dimensional data can be solved by using Fast Correlated Based Filter (FCBF) feature selection. In this paper, Support Vector Machine (SVM) classifier is used because of its advantages. However, SVM are sensitive with respect to imbalanced class. SMOTE is one of the prepocessing data methods in handling imbalanced class based on sampling approach by increasing the number of samples from the minority class. This method often works well but sometimes it might suffer from over-fitting problem. One other alternative approach in improving the performance of imbalanced data classification is boosting. This method constructs a powerful final classifier by combining a set of SVMs as base classifier during the iteration process. So, it can improve the classification performance. This study aims to see the performance of SMOTEBoost-SVM compared with AdaBoost-SVM in classifying microarray data with several levels of imbalance ratio designed in the simulation study and to apply classification process on public microarray datasets. Colon cancer and myeloma data are used in this study. The result showed that in the simulation study, all classifiers get the g-mean performance deacreasing as the ratio of the imbalanced class is increased, but SMOTEBoost-SVM tend to be superior. Its performance is decrease smaller (more stable) than AdaBoost-SVM, SMOTE-SVM and SVM. In the real data classification, SMOTEBoost-SVM outperforms the others with respect to g-mean and sensitivity metrics.The effect of feature selection is also checked in the analysis. Using informative features obtained in feature selection process gave the better performance than using all feature in the classification process by SVM.",boosting support vector machine data microarray imbalance,data microarray main peran klasifikasi jenis jaring kanker masalah seringkali hadap klasifikasi data microarray high dimensional data kelas imbalance high dimensional data atas seleksi fitur fast correlated based filter metode klasifikasi teliti support vector machines svm lebih svm sensitif kelas imbalance smote salah tangan data imbalance mereplikasi amat kelas minoritas metode seringkali terkadang overfitting salah alternatif tingkat performansi klasifikasi data imbalance boosting metode bangun classifier kuat gabung kumpul svm base classifier proses iterasi tingkat performansi klasifikasi teliti tuju kaji performansi smoteboostsvm banding adaboostsvm klasifikasi data microarray tingkat rasio imbalance desain studi simulasi terap data publik microarray data publik data kanker colon data myeloma hasil analisis oleh studi simulasi classifier alami turun performansi gmean iring tambah rasio kelas imbalance smoteboostsvm cenderung unggul alami turun performansi stabil banding adaboostsvm smotesvm svm terap data publik smoteboost svm unggul tiga metode dasar ukur gmean sensitivity efek seleksi fitur analisis mana fiturfitur informatif hasil seleksi fitur hasil performansi banding fitur klasifikasimicroarray data plays an important role in the classification of almost all types of cancer tissue the problems that often appear in the classification using microarray data are highdimensional data and imbalanced class the problem of highdimensional data can be solved by using fast correlated based filter fcbf feature selection in this paper support vector machine svm classifier is used because of its advantages however svm are sensitive with respect to imbalanced class smote is one of the prepocessing data methods in handling imbalanced class based on sampling approach by increasing the number of samples from the minority class this method often works well but sometimes it might suffer from overfitting problem one other alternative approach in improving the performance of imbalanced data classification is boosting this method constructs a powerful final classifier by combining a set of svms as base classifier during the iteration process so it can improve the classification performance this study aims to see the performance of smoteboostsvm compared with adaboostsvm in classifying microarray data with several levels of imbalance ratio designed in the simulation study and to apply classification process on public microarray datasets colon cancer and myeloma data are used in this study the result showed that in the simulation study all classifiers get the gmean performance deacreasing as the ratio of the imbalanced class is increased but smoteboostsvm tend to be superior its performance is decrease smaller more stable than adaboostsvm smotesvm and svm in the real data classification smoteboostsvm outperforms the others with respect to gmean and sensitivity metricsthe effect of feature selection is also checked in the analysis using informative features obtained in feature selection process gave the better performance than using all feature in the classification process by svm
Trajectory Tracking Pada Mobil Autonomous Menggunakan Prediction Control Dengan Referensi Waktu.,"Priambudi, Renardi Adryantoro",http://repository.its.ac.id/99705/,"Pengaturan pada kendaraan self-driving khusus nya pada topic trajectory tracking sangat banyak dikembangkan oleh civitas akademisi. Pada kasus ini penulis coba menyelesaikan permasalahan trajectory tracking menggunakan pendekatan non-linear yang memiliki batasan waktu tempuh. Pada penelitan ini akan dibentuk time mission control diaman didalamnya terdapat kontrol lateral dan kontrol longitudinal. Kontrol longitudinal dibentuk menggunakan Bezier curve yang akan membentuk local path baru pada saat ingin mendahului mobil lain.Kontrol lateral dibentuk dari gabungan velocity profile dan adaptive cruise control yang akan mengatur kecepatan mobil. Mobil autonomous juga harus memenuhi time mission, dimana mobil akan bergerak dengan kecepatan dinamis dengan menyesuaikan waktu yang telah ditentukan serta kondisi lalu lintas yang ada. Kontrol trejektori menggunakan PID, Mobil akan diamati hanya terhadap jalan yang dilaluinya. Hasil yang diamati adalah visual path yang dibentuk dari mobilautonomous pada saat bergerak dengan referensi global path dan error waktu tempuhnya.======================================================================================================================================The development of self-driving vehicles, particularly in the field of trajectory tracking, has been extensively explored by academia. In this case, the author attempts to address the trajectory tracking issue using a nonlinear approach with a time constraint. This research focuses on implementing a time mission control system that incorporates both lateral and longitudinal control. The longitudinal control is established using a Bezier curve, which creates a new local path when overtaking other vehicles. The lateral control is a combination of a velocity profile and adaptive cruise control, which regulates the vehicle's speed.The autonomous vehicle must also adhere to the time mission, meaning it moves at a dynamic speed, adjusting to the predetermined time and traffic conditions. Trajectory control is achieved using a PID controller, with the vehicle's observations limited to the road it is traveling on. The observed results include the visual path formed by the autonomous vehicle in relation to the global path reference and the corresponding travel time error.",trajectory tracking mobil autonomous prediction control referensi,atur kendara selfdriving khusus nya topic trajectory tracking kembang civitas akademisi tulis coba selesai masalah trajectory tracking dekat nonlinear milik batas tempuh penelitan bentuk time mission control diam dalam kontrol lateral kontrol longitudinal kontrol longitudinal bentuk bezier curve bentuk local path dahulu mobil lainkontrol lateral bentuk gabung velocity profile adaptive cruise control atur cepat mobil mobil autonomous penuh time mission mana mobil gerak cepat dinamis sesuai tentu kondisi lintas kontrol trejektori pid mobil amat jalan lalu hasil amat visual path bentuk mobilautonomous gerak referensi global path error tempuhnyathe development of selfdriving vehicles particularly in the field of trajectory tracking has been extensively explored by academia in this case the author attempts to address the trajectory tracking issue using a nonlinear approach with a time constraint this research focuses on implementing a time mission control system that incorporates both lateral and longitudinal control the longitudinal control is established using a bezier curve which creates a new local path when overtaking other vehicles the lateral control is a combination of a velocity profile and adaptive cruise control which regulates the vehicles speedthe autonomous vehicle must also adhere to the time mission meaning it moves at a dynamic speed adjusting to the predetermined time and traffic conditions trajectory control is achieved using a pid controller with the vehicles observations limited to the road it is traveling on the observed results include the visual path formed by the autonomous vehicle in relation to the global path reference and the corresponding travel time error
Optimizing The Pricing of Egrek Merah Putih's Blade with Different Materials Qualities Using Responsive Pricing Strategy.,"Pribadi, Riski Puteri",http://repository.its.ac.id/108309/,"Indonesia's palm oil production significantly contributes to the country's GDP, with a volume of 46.50 million tons and an area of 15.380.981 ha in 2022, making it the world's top producer. However, Indonesia faces challenges in palm oil agriculture, particularly during harvesting. These challenges include difficulty determining fruit ripeness and quality material preferences, leading to a tendency to import harvesting sickle blades from abroad. To overcome these issues, innovative solution like the development of Egrek Merah Putih's blade from Institut Teknologi Sepuluh Nopember offers two quality materials: regular (Japanese Spring Steel) and premium (High-Speed Steel). To compete in the market, strategic pricing decisions based on a responsive pricing strategy are critical, balancing quality differences against market uncertainties influenced by quality valuation and reservation value. The research constructs a profit maximization model for Egrek Merah Putih's blades, considering reservation value and quality valuation in a responsive pricing strategy. The model includes demand, profitability, and constraint functions for regular and premium blades. Parameters include market demand, overall quality valuation, reservation value, customer Willingness to Pay (WTP), production costs, and percentage multiplier of customer Willingness to Pay (WTP). In the obtained data of 6245 demands, the optimal regular blade’s selling price is Rp225.000 with a profit of Rp27.231.105. The optimal premium blade’s selling price is Rp450.000 with a profit of Rp461.113.372. Quality valuation measures customer satisfaction with quality, while reservation value is the minimum price for a basic product. As quality valuation increases, premium blade demand and profit rise while regular blade demand and profit decline. As reservation value increases, regular blade demand and profit increase proportionally. With both increasing, overall demand and profit for both blades improve, with premium blade contributing more profit due to higher prices and quality preferences. The highest profit occurs at maximum quality valuation and maximum reservation value.=================================================================================================================================Produksi minyak sawit Indonesia memberikan kontribusi signifikan terhadap PDB negara, dengan volume sebesar 46,50 juta ton dan luas wilayah 15.380.981 ha pada tahun 2022, menjadikannya produsen terbesar dunia. Namun, Indonesia menghadapi tantangan dalam pertanian kelapa sawit, khususnya pada saat panen. Tantangan tersebut antara lain sulitnya menentukan kematangan buah dan preferensi kualitas bahan sehingga menimbulkan kecenderungan untuk mengimpor bilah dari luar negeri. Untuk mengatasi permasalahan tersebut, solusi inovatif seperti pengembangan bilah Egrek Merah Putih dari Institut Teknologi Sepuluh Nopember menawarkan dua material berkualitas: reguler (Japanese Spring Steel) dan premium (High-Speed Steel). Untuk bersaing di pasar, keputusan penetapan harga strategis berdasarkan strategi penetapan harga yang responsif sangat penting, menyeimbangkan perbedaan kualitas dengan ketidakpastian pasar yang dipengaruhi oleh penilaian kualitas dan nilai reservasi. Penelitian ini membangun model memaksimalkan keuntungan bilah Egrek Merah Putih dengan mempertimbangkan nilai reservasi dan penilaian kualitas dalam strategi penetapan harga yang responsif. Model ini mencakup fungsi permintaan, profitabilitas, dan kendala untuk bilah reguler dan premium. Parameternya meliputi permintaan pasar, penilaian kualitas secara keseluruhan, nilai reservasi, Willingness to Pay (WTP) pelanggan, biaya produksi, dan persentase pengali Willingness to Pay (WTP) pelanggan. Pada data permintaan 6245 yang diperoleh, harga jual bilah reguler optimal adalah Rp225.000 dengan keuntungan Rp27.231.105. Harga jual bilah premium optimal sebesar Rp450.000 dengan keuntungan sebesar Rp461.113.372. Penilaian kualitas mengukur kepuasan pelanggan terhadap kualitas, sedangkan nilai reservasi adalah harga minimum untuk suatu produk dasar. Ketika penilaian kualitas meningkat, permintaan dan keuntungan bilah premium meningkat sementara permintaan dan keuntungan bilah reguler menurun. Ketika nilai reservasi meningkat, permintaan dan keuntungan bilah reguler meningkat secara proporsional. Dengan meningkatkan keduanya, keseluruhan permintaan dan keuntungan untuk kedua bilah meningkat dengan bilah premium memberikan kontribusi keuntungan lebih besar karena harga dan preferensi kualitas yang lebih tinggi. Keuntungan tertinggi terjadi pada penilaian kualitas maksimum dan nilai reservasi maksimum.",optimizing the pricing of egrek merah putihs blade with different materials qualities using responsive pricing strategy,indonesias palm oil production significantly contributes to the countrys gdp with a volume of 4650 million tons and an area of 15380981 ha in 2022 making it the worlds top producer however indonesia faces challenges in palm oil agriculture particularly during harvesting these challenges include difficulty determining fruit ripeness and quality material preferences leading to a tendency to import harvesting sickle blades from abroad to overcome these issues innovative solution like the development of egrek merah putihs blade from institut teknologi puluh nopember offers two quality materials regular japanese spring steel and premium highspeed steel to compete in the market strategic pricing decisions based on a responsive pricing strategy are critical balancing quality differences against market uncertainties influenced by quality valuation and reservation value the research constructs a profit maximization model for egrek merah putihs blades considering reservation value and quality valuation in a responsive pricing strategy the model includes demand profitability and constraint functions for regular and premium blades parameters include market demand overall quality valuation reservation value customer willingness to pay wtp production costs and percentage multiplier of customer willingness to pay wtp in the obtained data of 6245 demands the optimal regular blade  s selling price is rp225000 with a profit of rp27231105 the optimal premium blade  s selling price is rp450000 with a profit of rp461113372 quality valuation measures customer satisfaction with quality while reservation value is the minimum price for a basic product as quality valuation increases premium blade demand and profit rise while regular blade demand and profit decline as reservation value increases regular blade demand and profit increase proportionally with both increasing overall demand and profit for both blades improve with premium blade contributing more profit due to higher prices and quality preferences the highest profit occurs at maximum quality valuation and maximum reservation valueproduksi minyak sawit indonesia kontribusi signifikan pdb negara volume 4650 juta ton luas wilayah 15380981 ha 2022 jadi produsen besar dunia indonesia hadap tantang tani kelapa sawit panen tantang sulit tentu matang buah preferensi kualitas bahan timbul cenderung impor bilah negeri atas masalah solusi inovatif kembang bilah egrek merah putih institut teknologi puluh nopember tawar material kualitas reguler japanese spring steel premium highspeed steel saing pasar putus tetap harga strategis dasar strategi tetap harga responsif imbang beda kualitas ketidakpastian pasar pengaruh nilai kualitas nilai reservasi teliti bangun model maksimal untung bilah egrek merah putih timbang nilai reservasi nilai kualitas strategi tetap harga responsif model cakup fungsi minta profitabilitas kendala bilah reguler premium parameter liput minta pasar nilai kualitas nilai reservasi willingness to pay wtp langgan biaya produksi persentase ali willingness to pay wtp langgan data minta 6245 oleh harga jual bilah reguler optimal rp225000 untung rp27231105 harga jual bilah premium optimal rp450000 untung rp461113372 nilai kualitas ukur puas langgan kualitas nilai reservasi harga minimum produk dasar nilai kualitas tingkat minta untung bilah premium tingkat minta untung bilah reguler turun nilai reservasi tingkat minta untung bilah reguler tingkat proporsional tingkat minta untung bilah tingkat bilah premium kontribusi untung harga preferensi kualitas untung tinggi nilai kualitas maksimum nilai reservasi maksimum
Reidentifikasi Orang Pada Data Visible-Infrared Yang Terkorupsi Menggunakan Klasifier Vision Transformer.,"Pusaka, Nathanael Tenno Phileo Wong",http://repository.its.ac.id/111951/,"Teknik Reidentifikasi orang, yaitu mengidentifikasi kembali individu berdasarkan data gambar atau video yang telah ada. Dalam era modern, Reidentifikasi menjadi penting di bidang keamanan dan pemantauan. Dataset RegDB-C berisi gambar tampak dan infrared dari berba gai individu. Vision Transformer (ViT) merupakan arsitektur jaringan saraf yang efektif dalam memproses data visual-infrared, terutama saat data tersebut terkorupsi.Penilitian ini berfokus untuk mengidentifikasi orang pada berbagai kondisi pencahayaan, perubahan cahaya yang ek strim, perubahan suhu, data yang terkena noise pada data Visible-infrred dengan menggunakan dataset RegDB-C yang terdiri dari 2.060 citra visible dan 2.060 cintra infrared.Meskipun terda pat permasalahan berupa dataset yang mengalami korupsi, Vision Transformer dapat mengiden tifikasi individu secara akurat.Penilitian ini menggunakan berbagai konfigurasi model Vision Transformer, dengan pengujian menggunakan batchsize 16, 32, 64, dan modifikasi hyperpa rameter seperti learning rate dan loss function.Hasil yang didapatkan tertinggi pada Vision Transformer yang telah dimodifikasi hyperparameter dengan nilai MAP (mean Average Pre cision) yang didapatkan yaitu senilai 0,436899, dengan Rank@1 senilai :0.396440 , Rank@5 senilai 0.601942,dan Rank@10 senilai 0.702265.Penilitian ini diharapkan dapat berkontribusi dalam mengembangkan sistem reidentifikasi pada data visible-infrared yang terkorupsi meng gunakan klasifer Vision Transformer.====================================================================================================Person Reidentification techniques involve re-identifying individuals based on existing image or video data. In the modern era, reidentification has become crucial in the fields of security and monitoring. The RegDB-C dataset contains visible and infrared images of various individ uals. Vision Transformer (ViT) is a neural network architecture that is effective in processing visual-infrared data, especially when the data is corrupted. This research focuses on identifying people under various lighting conditions, extreme light changes, temperature variations, and noise in the visible-infrared data using the RegDB-C dataset, which consists of 2,060 visible images and 2,060 infrared images. Despite issues such as data corruption, Vision Transformer can accurately identify individuals. This study employs various configurations of the Vision Transformer model, testing with batch sizes of 16, 32, and 64, and modifying hyperparameters such as learning rate and loss function. The highest results were obtained with the Vision Trans former model that had modified hyperparameters, achieving a mean Average Precision (MAP) of 0.436899, with Rank@1 of 0.396440, Rank@5 of 0.601942, and Rank@10 of 0.702265. This research is expected to contribute to the development of reidentification systems for corrupted visible-infrared data using Vision Transformer classifiers.",reidentifikasi orang data visibleinfrared korupsi klasifier vision transformer,teknik reidentifikasi orang identifikasi individu dasar data gambar video era modern reidentifikasi bidang aman pantau dataset regdbc isi gambar infrared berba gai individu vision transformer vit arsitektur jaring saraf efektif proses data visualinfrared data terkorupsipenilitian fokus identifikasi orang kondisi cahaya ubah cahaya ek strim ubah suhu data kena noise data visibleinfrred dataset regdbc 2060 citra visible 2060 cintra infraredmeskipun terda pat masalah dataset alami korupsi vision transformer mengiden tifikasi individu akuratpenilitian konfigurasi model vision transformer uji batchsize 16 32 64 modifikasi hyperpa rameter learning rate loss functionhasil dapat tinggi vision transformer modifikasi hyperparameter nilai map mean average pre cision dapat nila 0436899 rank1 nila 0396440 rank5 nila 0601942dan rank10 nila 0702265penilitian harap kontribusi kembang sistem reidentifikasi data visibleinfrared korupsi meng klasifer vision transformerperson reidentification techniques involve reidentifying individuals based on existing image or video data in the modern era reidentification has become crucial in the fields of security and monitoring the regdbc dataset contains visible and infrared images of various individ uals vision transformer vit is a neural network architecture that is effective in processing visualinfrared data especially when the data is corrupted this research focuses on identifying people under various lighting conditions extreme light changes temperature variations and noise in the visibleinfrared data using the regdbc dataset which consists of 2060 visible images and 2060 infrared images despite issues such as data corruption vision transformer can accurately identify individuals this study employs various configurations of the vision transformer model testing with batch sizes of 16 32 and 64 and modifying hyperparameters such as learning rate and loss function the highest results were obtained with the vision trans former model that had modified hyperparameters achieving a mean average precision map of 0436899 with rank1 of 0396440 rank5 of 0601942 and rank10 of 0702265 this research is expected to contribute to the development of reidentification systems for corrupted visibleinfrared data using vision transformer classifiers
Analisis Sentimen Pengguna Aplikasi Shopee Pada Situs Google Play Store Menggunakan Metode Support Vector Machine.,"Putra, Fahmi Maulutfi Dwi",http://repository.its.ac.id/103742/,"Marketplace adalah tempat jual beli online dimana penjual baru menerima uangnya jika barang sudah sampai ke pembeli, sedangkan E-Commerce adalah transaksi jual beli atau perdagangan secara online. Salah satu marketplace yang sangat diminati saat ini dikalangan remaja hingga dewasa adalah Shopee. Shopee resmi diperkenalkan di Indonesia pada Desember 2015 dibawah naungan PT Shopee International Indonesia. Shopee adalah sebuah aplikasi yang bergerak dibidang jual beli secara online dan dapat diakses secara mudah dengan menggunakan smartphone. Shopee merupakan aplikasi jual beli elektronik yang dapat diunduh di situs Google Play. Google Play Store memiliki berbagai macam fitur, salah satunya adalah ulasan atau opini. Ulasan atau opini ini digunakan untuk para pengguna menilai sebuah aplikasi. Pengguna aplikasi Shopee dapat memberikan opini yang berisi tanggapan, apresiasi, kritik dan masukan pada aplikasi Shopee yang tersedia di Google Play Store. Opini pada aplikasi Shopee dapat digunakan untuk mendapatkan informasi sebagai bahan perbaikan atau pengembangan aplikasi sehingga pengguna mendapatkan kepuasan. Proses pengembangan membutuhkan opini dari pengguna, hal tersebut bisa didapat dari data opini pada Google Play Store dalam bentuk data teskstual. Data tekstual tersebut bisa dianalisis menggunakan text mining. Banyak metode yang dapat digunakan untuk memudahkan proses klasifikasi sentiment data, setiap metode memiliki karakteristik berbeda sehingga tingkat keefektifan setiap metode berbeda-beda. Dalam menganalisis opini dibutuhkan metode yang cepat dan akurat yaitu analisis sentimen dengan metode Support Vector Machine (SVM). Hasil penelitian menunjukkan bahwa untuk analisis sentimen dengan kategori sentimen positif yaitu sebesar sebesar 53,13%, sedangkan untuk opini pengguna aplikasi Shopee berdasarkan kategori sentimen negatif sebesar 46,87% dengan hasil nilai accuracy sebesar 64,5%, nilai sensitivity sebesar 60,1%, dan nilai specificity sebesar 69,5%.=================================================================================================================================Marketplace is a place for buying and selling online where sellers only receive money if the goods have reached the buyer, while E-Commerce is buying and selling or trading transactions online. One of the marketplaces that is in great demand today among teenagers to adults is Shopee. Shopee was officially introduced in Indonesia in December 2015 under the auspices of PT Shopee International Indonesia. Shopee is an application engaged in buying and selling online and can be accessed easily using a smartphone. Shopee is an electronic buying and selling application that can be downloaded on the Google Play site. The Google Play Store has various features, one of which is reviews or opinions. These reviews or opinions are used for users to rate an application. Shopee application users can provide opinions that contain responses, appreciation, criticism and input on the Shopee application which is available on the Google Play Store. Opinions on the Shopee application can be used to obtain information as material for improvement or application development so that users get satisfaction. The development process requires opinions from users, this can be obtained from opinion data on the Google Play Store in the form of textual data. The textual data can be analyzed using text mining. Many methods can be used to facilitate the sentiment data classification process, each method has different characteristics so that the level of effectiveness of each method varies. In analyzing opinions, a fast and accurate method is needed, namely sentiment analysis using the Support Vector Machine (SVM) method. The results showed that for sentiment analysis the positive sentiment category was 53.13%, while for the opinion of Shopee application users based on the negative sentiment category it was 46.87% with an accuracy value of 64.5%, a sensitivity value of 60.1%, and a specificity value of 69.5%.",analisis sentimen guna aplikasi shopee situs google play store metode support vector machine,marketplace jual beli online mana jual terima uang barang beli ecommerce transaksi jual beli dagang online salah marketplace mati kalang remaja dewasa shopee shopee resmi kenal indonesia desember 2015 bawah naung pt shopee international indonesia shopee aplikasi gerak bidang jual beli online akses mudah smartphone shopee aplikasi jual beli elektronik unduh situs google play google play store milik fitur salah satu ulas opini ulas opini guna nilai aplikasi guna aplikasi shopee opini isi tanggap apresiasi kritik masuk aplikasi shopee sedia google play store opini aplikasi shopee informasi bahan baik kembang aplikasi guna puas proses kembang butuh opini guna data opini google play store bentuk data teskstual data tekstual analis text mining metode mudah proses klasifikasi sentiment data metode milik karakteristik beda tingkat efektif metode berbedabeda analis opini butuh metode cepat akurat analisis sentimen metode support vector machine svm hasil teliti analisis sentimen kategori sentimen positif 5313 opini guna aplikasi shopee dasar kategori sentimen negatif 4687 hasil nilai accuracy 645 nilai sensitivity 601 nilai specificity 695marketplace is a place for buying and selling online where sellers only receive money if the goods have reached the buyer while ecommerce is buying and selling or trading transactions online one of the marketplaces that is in great demand today among teenagers to adults is shopee shopee was officially introduced in indonesia in december 2015 under the auspices of pt shopee international indonesia shopee is an application engaged in buying and selling online and can be accessed easily using a smartphone shopee is an electronic buying and selling application that can be downloaded on the google play site the google play store has various features one of which is reviews or opinions these reviews or opinions are used for users to rate an application shopee application users can provide opinions that contain responses appreciation criticism and input on the shopee application which is available on the google play store opinions on the shopee application can be used to obtain information as material for improvement or application development so that users get satisfaction the development process requires opinions from users this can be obtained from opinion data on the google play store in the form of textual data the textual data can be analyzed using text mining many methods can be used to facilitate the sentiment data classification process each method has different characteristics so that the level of effectiveness of each method varies in analyzing opinions a fast and accurate method is needed namely sentiment analysis using the support vector machine svm method the results showed that for sentiment analysis the positive sentiment category was 5313 while for the opinion of shopee application users based on the negative sentiment category it was 4687 with an accuracy value of 645 a sensitivity value of 601 and a specificity value of 695
Implementasi IndoBERT Dalam Analisis Sentimen Berita Untuk Prediksi Harga Saham PT. Bank Rakyat Indonesia Tbk. Menggunakan Pendekatan Support Vector Regression.,"Putra, Ferdyansyah Permana",http://repository.its.ac.id/105901/,"Fluktuasi harga saham sering dipengaruhi oleh berbagai faktor, dan salah satunya adalah sentimen, yang dapat berasal dari masyarakat umum atau berita terkait saham. Harga saham PT. Bank Rakyat Indonesia Tbk. (BBRI), sebagai salah satu dari ""big four"" bank terbesar di Indonesia, juga dapat dipengaruhi oleh sentimen ini. Dalam usaha untuk meramalkan harga penutupan saham BBRI berdasarkan sentimen berita, penelitian ini mengadopsi pendekatan machine learning dengan menggunakan metode Support Vector Regression (SVR) dan mengoptimalkan fungsi dengan algoritma Fruit Fly Optimization Algorithm (FOA). Sentimen dievaluasi terlebih dahulu dengan metode IndoBERT. Penelitian ini mengusulkan beberapa model, termasuk model tanpa memperhitungkan sentimen, model dengan mempertimbangkan sentimen pada periode ke t, model dengan mempertimbangkan sentimen pada periode ke t-1, dan model dengan mempertimbangkan sentimen pada periode ke t dan periode ke t-1. Analisis hasil sentimen menggunakan IndoBERT menunjukkan tingkat akurasi sentimen secara keseluruhan di atas 90%. Selain itu, hasil pemodelan menunjukkan bahwa model terbaik menggunakan SVR adalah model yang tidak mempertimbangkan sentimen, dengan nilai error peramalan yaitu Mean Average Percentage Error (MAPE) lebih rendah dibandingkan dengan model lain. Hasil peramalan dengan dari model terbaik menunjukkan bahwa data aktual masih berada dalam interval kepercayaan 95% dari hasil ramalan, sehingga menunjukkan relevansi ramalan dengan data aktual.=================================================================================================================================Fluctuations in stock prices are often influenced by various factors, and one of them is sentiment, which can originate from the general public or stock-related news. The stock price of PT. Bank Rakyat Indonesia Tbk. (BBRI), as one of the ""big four"" largest banks in Indonesia, can also be influenced by this sentiment. In an effort to forecast the closing price of BBRI stock based on news sentiment, this research adopts a machine learning approach using the Support Vector Regression (SVR) method and optimizes the function with the Fruit Fly Optimization Algorithm (FOA). Sentiment is first evaluated using the IndoBERT method. This research proposes several models, including a model without considering sentiment, a model considering sentiment on the day of the event, a model considering sentiment on the previous day, and a model considering sentiment on both the day of the event and the previous day. Sentiment analysis results using IndoBERT show an overall accuracy rate above 90%. Furthermore, modelling results indicate that the best-performing SVR model is the one that does not consider sentiment, with a lower Mean Average Percentage Error (MAPE) compared to other models. The forecasting results from the best model show that the actual data still falls within the 95% confidence interval of the forecast, demonstrating the relevance of the forecast to the actual data.",implementasi indobert analisis sentimen berita prediksi harga saham pt bank rakyat indonesia tbk dekat support vector regression,fluktuasi harga saham pengaruh faktor salah satu sentimen asal masyarakat berita kait saham harga saham pt bank rakyat indonesia tbk bbri salah big four bank besar indonesia pengaruh sentimen usaha ramal harga tutup saham bbri dasar sentimen berita teliti adopsi dekat machine learning metode support vector regression svr optimal fungsi algoritma fruit fly optimization algorithm foa sentimen evaluasi metode indobert teliti usul model model hitung sentimen model timbang sentimen periode t model timbang sentimen periode t1 model timbang sentimen periode t periode t1 analisis hasil sentimen indobert tingkat akurasi sentimen 90 hasil model model baik svr model timbang sentimen nilai error amal mean average percentage error mape rendah banding model hasil amal model baik data aktual interval percaya 95 hasil ramal relevansi ramal data aktualfluctuations in stock prices are often influenced by various factors and one of them is sentiment which can originate from the general public or stockrelated news the stock price of pt bank rakyat indonesia tbk bbri as one of the big four largest banks in indonesia can also be influenced by this sentiment in an effort to forecast the closing price of bbri stock based on news sentiment this research adopts a machine learning approach using the support vector regression svr method and optimizes the function with the fruit fly optimization algorithm foa sentiment is first evaluated using the indobert method this research proposes several models including a model without considering sentiment a model considering sentiment on the day of the event a model considering sentiment on the previous day and a model considering sentiment on both the day of the event and the previous day sentiment analysis results using indobert show an overall accuracy rate above 90 furthermore modelling results indicate that the bestperforming svr model is the one that does not consider sentiment with a lower mean average percentage error mape compared to other models the forecasting results from the best model show that the actual data still falls within the 95 confidence interval of the forecast demonstrating the relevance of the forecast to the actual data
Optimasi Model Klasifikasi Multi-Label Berbahasa Indonesia: Penerapan dan Perbandingan Metode Bi-LSTM dan BERT pada Teks Berita Berbahasa Indonesia.,"Putra, Marsyavero Charisyah",http://repository.its.ac.id/111093/,"Pengguna internet di Indonesia terus meningkat setiap tahunnya. Pada tahun 2023, survei APJII mencatat 78,19% populasi Indonesia menggunakan internet, meningkat 2,67% dari tahun sebelumnya. Peningkatan ini mendorong pertumbuhan media online dan mengubah cara masyarakat mengakses berita dari media cetak ke online. Dengan bertambahnya pengguna internet, volume berita online juga meningkat signifikan. Diperlukan teknik efisien untuk mengelola dan mengklasifikasikan berita agar memudahkan pengguna memahami informasi yang relevan. Penelitian ini mengembangkan model multilabel classification menggunakan Bi-LSTM dan BERT serta membandingkan performanya dengan model dari penelitian sebelumnya. Dataset berasal dari scraping teks berita dari detik.com dan Petakabar, dijadikan satu dataset bernama Topic Mining. Dataset dilabeli secara manual dengan 39 label. Empat model dikembangkan: Bi-LSTM, Bi-LSTM dengan Attention, BERT, dan Hybrid (kombinasi BERT dan Bi-LSTM dengan Attention). Evaluasi kinerja model menggunakan metrik F1-Score, akurasi, recall, dan hamming loss. Model Hybrid menunjukkan performa terbaik dengan mean recall 0,864, mean F1-score 0,893, mean accuracy 0,981, dan mean Hamming Loss 0,019. Label yang berperforma terbaik adalah ""bencana"" dengan F1-score 0,973, sedangkan label yang berperforma terburuk adalah ""politik"" dengan F1-score 0,279.==============================================================================================================================The number of internet users in Indonesia continues to increase every year. In 2023, a survey by APJII recorded that 78.19% of Indonesia's population uses the internet, an increase of 2.67% from the previous year. This growth has driven the rapid expansion of online media and changed the way people access news from print to online. With more internet users, the volume of online news has also increased significantly. Efficient techniques are needed to manage and classify news to help users understand relevant information. This study developed a multi-label classification model using Bi-LSTM and BERT and compared its performance with the previous model from the previous research. The dataset, named Topic Mining, was created by scraping news texts from detik.com and Petakabar. The dataset was manually labeled with 39 labels. Four models were developed: Bi-LSTM, Bi-LSTM with Attention, BERT, and Hybrid (a combination of BERT and Bi-LSTM with Attention). Model performance was evaluated using F1-Score, accuracy, recall, and hamming loss. The Hybrid model showed the best performance with a mean recall of 0,864, a mean F1-score of 0,893, a mean accuracy of 0,981, and a mean hamming loss of 0,019. With the best-performing label is ""disaster"" with an F1-score of 0,973, while the worst performing label is ""politics"" with an F1-score of 0,279.",optimasi model klasifikasi multilabel bahasa indonesia terap banding metode bilstm bert teks berita bahasa indonesia,guna internet indonesia tingkat tahun 2023 survei apjii catat 7819 populasi indonesia internet tingkat 267 tingkat dorong tumbuh media online ubah masyarakat akses berita media cetak online tambah guna internet volume berita online tingkat signifikan teknik efisien kelola klasifikasi berita mudah guna paham informasi relevan teliti kembang model multilabel classification bilstm bert banding performa model teliti dataset asal scraping teks berita detikcom petakabar jadi dataset nama topic mining dataset label manual 39 label model kembang bilstm bilstm attention bert hybrid kombinasi bert bilstm attention evaluasi kerja model metrik f1score akurasi recall hamming loss model hybrid performa baik mean recall 0864 mean f1score 0893 mean accuracy 0981 mean hamming loss 0019 label performa baik bencana f1score 0973 label performa buruk politik f1score 0279the number of internet users in indonesia continues to increase every year in 2023 a survey by apjii recorded that 7819 of indonesias population uses the internet an increase of 267 from the previous year this growth has driven the rapid expansion of online media and changed the way people access news from print to online with more internet users the volume of online news has also increased significantly efficient techniques are needed to manage and classify news to help users understand relevant information this study developed a multilabel classification model using bilstm and bert and compared its performance with the previous model from the previous research the dataset named topic mining was created by scraping news texts from detikcom and petakabar the dataset was manually labeled with 39 labels four models were developed bilstm bilstm with attention bert and hybrid a combination of bert and bilstm with attention model performance was evaluated using f1score accuracy recall and hamming loss the hybrid model showed the best performance with a mean recall of 0864 a mean f1score of 0893 a mean accuracy of 0981 and a mean hamming loss of 0019 with the bestperforming label is disaster with an f1score of 0973 while the worst performing label is politics with an f1score of 0279
Sistem Informasi Geografis Berbasis Google Earth API Menggunakan Algoritma K-Nearest Neighbors.,"Putra, Nicky Permana",http://repository.its.ac.id/81664/,"Sistem Informasi Geografis merupakan sistem komputer yang memiliki kemampuan untuk membangun, menyimpan, mengelola dan menampilkan informasi berupa peta geografis suatu daerah. Sistem Informasi Geogafis ini akan digunakan untuk melakukan pengelompokan statistik – statistik daerah dan dikelompokkan pada kategori yang ada untuk kemudian ditampilkan dalam bentuk peta tematik atau peta digital menggunakan algoritma K-Nearest Neighbor. Data – data statistik yang nantinya akan dimasukkan dapat berupa data tingkat kemiskinan, data tingkat pengangguran dari suatu daerah, dll. Algoritma K-NN akan mengelompokkan data sesuai kategori dan saat data-data tersebut sudah terkelompokkan maka peta akan muncul dengan daerah yang sudah diberi warna dimana daerah-daerah tersebut sudah tergolongkan sesuai dengan kategorinya. Hal ini dapat diterapkan di pemerintahan guna untuk mempermudah dalam pengambilan kebijakan dalam suatu daerah",sistem informasi geografis bas google earth api algoritma knearest neighbors,sistem informasi geografis sistem komputer milik mampu bangun simpan kelola tampil informasi peta geografis daerah sistem informasi geogafis kelompok statistik  statistik daerah kelompok kategori tampil bentuk peta tematik peta digital algoritma knearest neighbor data  data statistik masuk data tingkat miskin data tingkat anggur daerah dll algoritma knn kelompok data sesuai kategori datadata kelompok peta muncul daerah warna mana daerahdaerah golong sesuai kategori terap perintah mudah ambil bijak daerah
"Analysis of Bittern Recovery Scenario Using Mixed-Integer Nonlinear Programming: Centralized, Decentralized, and Hybrid Case Study.","Putra, Furqon Sandiva Utomo",http://repository.its.ac.id/89066/,"In the desalination process to produce salts, it left a wastewater with a high concentration of salts, magnesium, and other kinds of mineral called bittern. For some salt producer, these bitterns are considered as waste that are dumped and never be used again. This can be problematic because although bittern water contains similar compounds as seawater, it is much more concentrated. When bittern is directly dumped into the ecosystem, the increase in salinity can pollute and harm the life around the area. Furthermore, it is also a waste in potential since bittern still contains mineral that can be extracted and have selling value. To combat this, bittern recovery has become an increasingly used practice in the salt industry. This is done not only to reduce the environmental impact of salt production, but also create a circular economy. However, there is a strong requirement in determining how the process is carried out. In that, one needs to know the optimal type and number of recovery stations that can meets the supply and demand constrains, cost effective, and beneficial for the environment and economy. This research proposes a mixed-integer nonlinear programming (MINLP) model for analyzing the supply and demand of the bittern recovery to achieve circular economy and environmental sustainability. The research considers the supply and demand structure of bittern and the constrains from the recovery process. The MINLP model is used to optimize the trade-off between the cost of waste transportation, recovery, and station installation, with the benefit from the selling value of the recovered minerals and the environmental sustainability. The objective of the research is to create a model that can determine the best bittern recovery scenario between a centralized, decentralized, or hybrid types of recovery stations based on profit optimization. The proposed system optimizations are tested and analyzed upon its sensitivity.=================================================Dalam proses desalinasi untuk menghasilkan garam, akan meninggalkan limbah cair dengan garam, magnesium, dan jenis mineral lain dengan konsentrasi tinggi yang disebut air tua atau bittern. Bagi produsen garam pada umumnya, bittern ini dianggap sebagai limbah yang dibuang dan tidak akan pernah digunakan lagi. Ini bisa menjadi masalah karena meskipun air bittern mengandung senyawa yang mirip dengan air laut, air tua memiliki kandungan yang jauh lebih pekat sehingga dapat menjadi polusi untuk lingkungan sekitar. Ketika bittern langsung dibuang ke ekosistem, peningkatan salinitas dalam air dapat membahayakan kehidupan di sekitar area tersebut. Selain itu, hal ini juga merupakan penyia-nyiaan potensi, karena bittern masih mengandung mineral yang dapat diekstraksi dan memiliki nilai jual. Untuk mengatasi hal ini, pengolahan bittern telah menjadi praktik yang semakin sering digunakan di industri garam. Hal ini dilakukan tidak hanya untuk mengurangi dampak lingkungan dari produksi garam, tetapi juga menciptakan ekonomi sirkuler. Namun, ada beberapa pertimbangan penting yang menentukan bagaimana proses tersebut dilakukan. Hal ini penting untuk menentukan jenis dan jumlah stasiun pemulihan yang optimal yang dapat memenuhi faktor supply dan demand, kehematan biaya, dan manfaatnya bagi lingkungan serta perekonomian. Penelitian ini mengusulkan model Mixed-Integer Nonlinear programming (MINLP) untuk menganalisis pasok dan permintaan pengolahan bittern untuk mencapai ekonomi sirkuler dan kelestarian lingkungan. Penelitian ini mempertimbangkan struktur supply dan demand bittern dan kendala dan batasan dari proses pemulihan. Model MINLP digunakan untuk mengoptimalkan trade-off antara biaya pengangkutan limbah, pengolahan, dan instalasi stasiun pengolahan, dengan pertimbangan keuntungan yakni nilai jual mineral yang dipulihkan dan kelestarian lingkungan. Tujuan dari penelitian ini adalah untuk memilih skenario pemulihan bittern terbaik antara tipe stasiun pengolahan terpusat, terdesentralisasi, atau hibrid berdasarkan pengoptimalan keuntungan. Optimasi sistem yang diusulkan kemudian diuji dan dianalisis berdasarkan sensitivitasnya======================================================================================================Dalam proses desalinasi untuk menghasilkan garam, akan meninggalkan limbah cair dengan garam, magnesium, dan jenis mineral lain dengan konsentrasi tinggi yang disebut air tua atau bittern. Bagi produsen garam pada umumnya, bittern ini dianggap sebagai limbah yang dibuang dan tidak akan pernah digunakan lagi. Ini bisa menjadi masalah karena meskipun air bittern mengandung senyawa yang mirip dengan air laut, air tua memiliki kandungan yang jauh lebih pekat sehingga dapat menjadi polusi untuk lingkungan sekitar. Ketika bittern langsung dibuang ke ekosistem, peningkatan salinitas dalam air dapat membahayakan kehidupan di sekitar area tersebut. Selain itu, hal ini juga merupakan penyia-nyiaan potensi, karena bittern masih mengandung mineral yang dapat diekstraksi dan memiliki nilai jual. Untuk mengatasi hal ini, pengolahan bittern telah menjadi praktik yang semakin sering digunakan di industri garam. Hal ini dilakukan tidak hanya untuk mengurangi dampak lingkungan dari produksi garam, tetapi juga menciptakan ekonomi sirkuler. Namun, ada beberapa pertimbangan penting yang menentukan bagaimana proses tersebut dilakukan. Hal ini penting untuk menentukan jenis dan jumlah stasiun pemulihan yang optimal yang dapat memenuhi faktor supply dan demand, kehematan biaya, dan manfaatnya bagi lingkungan serta perekonomian. Penelitian ini mengusulkan model Mixed-Integer Nonlinear programming (MINLP) untuk menganalisis pasok dan permintaan pengolahan bittern untuk mencapai ekonomi sirkuler dan kelestarian lingkungan. Penelitian ini mempertimbangkan struktur supply dan demand bittern dan kendala dan batasan dari proses pemulihan. Model MINLP digunakan untuk mengoptimalkan trade-off antara biaya pengangkutan limbah, pengolahan, dan instalasi stasiun pengolahan, dengan pertimbangan keuntungan yakni nilai jual mineral yang dipulihkan dan kelestarian lingkungan. Tujuan dari penelitian ini adalah untuk memilih skenario pemulihan bittern terbaik antara tipe stasiun pengolahan terpusat, terdesentralisasi, atau hibrid berdasarkan pengoptimalan keuntungan. Optimasi sistem yang diusulkan kemudian diuji dan dianalisis berdasarkan sensitivitasnya.",analysis of bittern recovery scenario using mixedinteger nonlinear programming centralized decentralized and hybrid case study,in the desalination process to produce salts it left a wastewater with a high concentration of salts magnesium and other kinds of mineral called bittern for some salt producer these bitterns are considered as waste that are dumped and never be used again this can be problematic because although bittern water contains similar compounds as seawater it is much more concentrated when bittern is directly dumped into the ecosystem the increase in salinity can pollute and harm the life around the area furthermore it is also a waste in potential since bittern still contains mineral that can be extracted and have selling value to combat this bittern recovery has become an increasingly used practice in the salt industry this is done not only to reduce the environmental impact of salt production but also create a circular economy however there is a strong requirement in determining how the process is carried out in that one needs to know the optimal type and number of recovery stations that can meets the supply and demand constrains cost effective and beneficial for the environment and economy this research proposes a mixedinteger nonlinear programming minlp model for analyzing the supply and demand of the bittern recovery to achieve circular economy and environmental sustainability the research considers the supply and demand structure of bittern and the constrains from the recovery process the minlp model is used to optimize the tradeoff between the cost of waste transportation recovery and station installation with the benefit from the selling value of the recovered minerals and the environmental sustainability the objective of the research is to create a model that can determine the best bittern recovery scenario between a centralized decentralized or hybrid types of recovery stations based on profit optimization the proposed system optimizations are tested and analyzed upon its sensitivitydalam proses desalinasi hasil garam tinggal limbah cair garam magnesium jenis mineral konsentrasi air tua bittern produsen garam bittern anggap limbah buang air bittern kandung senyawa air laut air tua milik kandung pekat polusi lingkung bittern langsung buang ekosistem tingkat salinitas air bahaya hidup area penyianyiaan potensi bittern kandung mineral ekstraksi milik nilai jual atas olah bittern praktik industri garam kurang dampak lingkung produksi garam cipta ekonomi sirkuler timbang tentu proses tentu jenis stasiun pulih optimal penuh faktor supply demand hemat biaya manfaat lingkung ekonomi teliti usul model mixedinteger nonlinear programming minlp analis pasok minta olah bittern capai ekonomi sirkuler lestari lingkung teliti timbang struktur supply demand bittern kendala batas proses pulih model minlp optimal tradeoff biaya angkut limbah olah instalasi stasiun olah timbang untung nilai jual mineral pulih lestari lingkung tuju teliti pilih skenario pulih bittern baik tipe stasiun olah pusat desentralisasi hibrid dasar optimal untung optimasi sistem usul uji analis dasar sensitivitasnyadalam proses desalinasi hasil garam tinggal limbah cair garam magnesium jenis mineral konsentrasi air tua bittern produsen garam bittern anggap limbah buang air bittern kandung senyawa air laut air tua milik kandung pekat polusi lingkung bittern langsung buang ekosistem tingkat salinitas air bahaya hidup area penyianyiaan potensi bittern kandung mineral ekstraksi milik nilai jual atas olah bittern praktik industri garam kurang dampak lingkung produksi garam cipta ekonomi sirkuler timbang tentu proses tentu jenis stasiun pulih optimal penuh faktor supply demand hemat biaya manfaat lingkung ekonomi teliti usul model mixedinteger nonlinear programming minlp analis pasok minta olah bittern capai ekonomi sirkuler lestari lingkung teliti timbang struktur supply demand bittern kendala batas proses pulih model minlp optimal tradeoff biaya angkut limbah olah instalasi stasiun olah timbang untung nilai jual mineral pulih lestari lingkung tuju teliti pilih skenario pulih bittern baik tipe stasiun olah pusat desentralisasi hibrid dasar optimal untung optimasi sistem usul uji analis dasar sensitivitas
Klasifikasi Electroencephalogram (EEG) Motor Imagery Dengan Fitur Differential Asymmetry Pada Support Vector Machine (SVM).,"Putranto, Yulianto Tejo",http://repository.its.ac.id/97190/,"Selama bertahun-tahun penelitian bidang Brain-Computer Interface (BCI) telah difokuskan pada keinginan untuk menyediakan para penyandang disabilitas kemudahan dan kemampuan untuk berinteraksi dengan lingkungannya. Dalam beberapa tahun terakhir, penelitian BCI telah merambah ke aplikasi yang diperuntukkan bagi orang normal untuk meningkatkan kualitas hidup atau mendapatkan keuntungan komersial bagi suatu komunitas atau target group. Pada penelitian ini dirancang sistem BCI berbasis EEG, khususnya untuk mengenali aktivitas motor imagery untuk diterapkan dalam perangkat keras atau perangkat lunak yang bersifat interaktif. Sistem BCI menuntut akurasi dan kecepatan respon yang tinggi. Permasalahan ini dicoba dipecahkan dengan mengembangkan ekstraksi fitur yaitu differential asymmetry berdasarkan nilai selisih antara hasil pengukuran sinyal otak belahan kiri dan kanan. Fitur-fitur statistik dari hasil dekomposisi sinyal EEG motor imagery menggunakan transformasi wavelet diskrit dan dekomposisi mode empiris dimodifikasi dengan mengambil nilai selisihnya untuk dijadikan fitur baru. Sebagai pengklasifikasi digunakan Support Vector Machine (SVM).Hasil penelitian menunjukkan peningkatan nilai akurasi dari pengklasifikasi dengan menerapkan fitur differential asymmetry dibandingkan tanpa menerapkan fitur differential asymmetri. Dari tiga dataset yang diteliti, dataset I mengalami kenaikan nilai akurasi rata-rata sebesar 30,33%, dataset II sebesar 6,54% dan dataset III sebesar 23,17%. Hasil akurasi dengan menggunakan SVM untuk dataset I, dataset II dan dataset III berturut-turut: 91,70%, 66,91% dan 93,16%.=================================================================================================================================Through the years, research in Brain-Computer Interface (BCI) has focused on providing convenience and ability for disabilities people to interact with the environment. In recent years, BCI research has been enlarge into applications intended for normal people to improve life quality or obtain commercial advantage for a community or group target. In this study, an EEG-based BCI system was designed, especially for recognizing motor imagery activity to be applied in games.The BCI system demands accuracy and response speed. This problem will be solved by developing a feature extraction, namely differential asymmetry based on the value of the difference between the measurement results of the left and right brain hemisphere signals. Statistical features from the decomposition of motor imagery EEG signals using discrete wavelet transform (DWT) and empirical mode decomposition (EMD) are modified by taking those difference values was as a new feature. As a classifier, Support Vector Machine (SVM) is used.The results showed an increase in the accuracy value of the classifier by applying the differential asymmetry feature compared to without applying the differential asymmetry feature. Of the three datasets studied, dataset I experienced an average increase in accuracy by 30.33%, dataset II by 6.54% and dataset III by 23.17%. Accuracy results using SVM for dataset I, dataset II and dataset III are respectively: 91.70%, 66.91% and 93.16%.",klasifikasi electroencephalogram eeg motor imagery fitur differential asymmetry support vector machine svm,bertahuntahun teliti bidang braincomputer interface bci fokus sedia sandang disabilitas mudah mampu interaksi lingkung teliti bci rambah aplikasi untuk orang normal tingkat kualitas hidup untung komersial komunitas target group teliti rancang sistem bci bas eeg nali aktivitas motor imagery terap perangkat keras perangkat lunak sifat interaktif sistem bci tuntut akurasi cepat respon masalah coba pecah kembang ekstraksi fitur differential asymmetry dasar nilai selisih hasil ukur sinyal otak bahan kiri kanan fiturfitur statistik hasil dekomposisi sinyal eeg motor imagery transformasi wavelet diskrit dekomposisi mode empiris modifikasi ambil nilai selisih jadi fitur klasifikasi support vector machine svmhasil teliti tingkat nilai akurasi klasifikasi terap fitur differential asymmetry banding terap fitur differential asymmetri dataset teliti dataset i alami naik nilai akurasi ratarata 3033 dataset ii 654 dataset iii 2317 hasil akurasi svm dataset i dataset ii dataset iii berturutturut 9170 6691 9316through the years research in braincomputer interface bci has focused on providing convenience and ability for disabilities people to interact with the environment in recent years bci research has been enlarge into applications intended for normal people to improve life quality or obtain commercial advantage for a community or group target in this study an eegbased bci system was designed especially for recognizing motor imagery activity to be applied in gamesthe bci system demands accuracy and response speed this problem will be solved by developing a feature extraction namely differential asymmetry based on the value of the difference between the measurement results of the left and right brain hemisphere signals statistical features from the decomposition of motor imagery eeg signals using discrete wavelet transform dwt and empirical mode decomposition emd are modified by taking those difference values was as a new feature as a classifier support vector machine svm is usedthe results showed an increase in the accuracy value of the classifier by applying the differential asymmetry feature compared to without applying the differential asymmetry feature of the three datasets studied dataset i experienced an average increase in accuracy by 3033 dataset ii by 654 and dataset iii by 2317 accuracy results using svm for dataset i dataset ii and dataset iii are respectively 9170 6691 and 9316
Optimization Model for Vehicle Parking Space Unit Proportion And Zoning On Conventional And Digital Parking System Using Mixed Integer Non-Linear Programming And Response Surface Methodology.,"Qisthauzan, Avenzoar Zufar",http://repository.its.ac.id/87645/,"Pemerintah setempat menemukan bahwa pungutan liar masih terjadi pada area parkir di bahu jalan. Tindakan ini mengurangi pendapatan dari retribusi parkir daerah sebesar 72,5% pada tahun 2018. Untuk mengatasi masalah tersebut, pemerintah bekerjasama dengan pihak ketiga untuk mengembangkan aplikasi parkir digital. Studi sebelumnya menyimpulkan bahwa program parkir digital layak secara finansial untuk diterapkan di beberapa lokasi di Indonesia. Namun, studi tersebut berdasar pada asumsi bahwa 100% masyarakat siap menerima perubahan sistem parkir dari konvensional ke digital. Studi lebih lanjut menemukan bahwa hanya 59,3% masyarakat lokal yang siap dengan perubahan sistem; dengan demikian, perlu dilakukan proses transisi sistem secara bertahap. Penelitian ini akan menentukan proporsi optimal satuan ruang parkir (SRP) antara mobil dan sepeda motor yang dikombinasikan dengan proporsi optimal sistem digital dan konvensional yang diterapkan pada suatu area parkir. Tujuan sistem ini untuk memaksimalkan manfaat yang diterima oleh penyedia tempat parkir dan pengguna parkir. Model optimasi dilakukan dengan software LINGO. Response Surface Methodology (RSM) juga digunakan untuk pengambilan keputusan. Dari hasil keputusan optimasi, SRP yang optimum untuk Jalan Gajah Mada di Kabupaten Sidoarjo adalah 188 SRP mobil untuk area parkir digital, 323 SRP sepeda motor untuk area parkir digital, 133 SRP mobil untuk area parkir konvensional, dan 251 SRP sepeda motor untuk area parkir konvensional. Komposisi tersebut diharapkan akan memberikan retribusi yang kepada penyedia jasa parkir sebesar Rp75.798.856 dengan tingkat kepadatan tempat parkir sebesar 68,07%. Dari sisi pengguna parkir, total biaya pengguna parkir sebesar Rp57.358.168.====================================================================================================The Indonesian government imposed a subscription parking policy to improve the on-street parking system, but the execution did not go well. The local government found that illegal levies were still happening. This action negatively impacted the local government by reducing revenue from parking fees by 72.5% in 2018. To overcome this problem, the government collaborates with third parties to develop a digital parking application. A previous study has concluded that the digital parking program is financially feasible to be implemented in several locations in Indonesia. However, the study assumes that 100% of the people are ready to accept the change in the parking system from conventional to digital. A further study found that only 59.3% of the local community is ready for the system changes; thus, a gradual transition is needed. This research will determine the optimal proportion of parking space units between cars and motorcycles combined with the optimal proportion of digital and conventional system proportion applied to the parking area. The objective is to maximize benefits from parking space providers and parking users. The optimization model were carried out with a model built on the LINGO software. Response Surface Methodology will be performed for final decision making. The model found that the optimum SRP arrangement for Gajah Mada Street is 188 car SRP for digital parking area, 323 motorcycle SRP for digital parking area, 133 car SRP for conventional parking area, and 251 motorcycle SRP for conventional parking area. The arrangement will give parking service providers expected retribution of Rp75,798,856 with a parking area utilization rate of 68.07%. From the parking user perspective, the total parking user cost is Rp57,358,168.",optimization model for vehicle parking space unit proportion and zoning on conventional and digital parking system using mixed integer nonlinear programming and response surface methodology,perintah temu pungut liar area parkir bahu jalan tindak kurang dapat retribusi parkir daerah 725 2018 atas perintah bekerjasama tiga kembang aplikasi parkir digital studi simpul program parkir digital layak finansial terap lokasi indonesia studi dasar asumsi 100 masyarakat terima ubah sistem parkir konvensional digital studi temu 593 masyarakat lokal ubah sistem proses transisi sistem tahap teliti tentu proporsi optimal satu ruang parkir srp mobil sepeda motor kombinasi proporsi optimal sistem digital konvensional terap area parkir tuju sistem maksimal manfaat terima sedia parkir guna parkir model optimasi software lingo response surface methodology rsm ambil putus hasil putus optimasi srp optimum jalan gajah mada kabupaten sidoarjo 188 srp mobil area parkir digital 323 srp sepeda motor area parkir digital 133 srp mobil area parkir konvensional 251 srp sepeda motor area parkir konvensional komposisi harap retribusi sedia jasa parkir rp75798856 tingkat padat parkir 6807 sisi guna parkir total biaya guna parkir rp57358168the indonesian government imposed a subscription parking policy to improve the onstreet parking system but the execution did not go well the local government found that illegal levies were still happening this action negatively impacted the local government by reducing revenue from parking fees by 725 in 2018 to overcome this problem the government collaborates with third parties to develop a digital parking application a previous study has concluded that the digital parking program is financially feasible to be implemented in several locations in indonesia however the study assumes that 100 of the people are ready to accept the change in the parking system from conventional to digital a further study found that only 593 of the local community is ready for the system changes thus a gradual transition is needed this research will determine the optimal proportion of parking space units between cars and motorcycles combined with the optimal proportion of digital and conventional system proportion applied to the parking area the objective is to maximize benefits from parking space providers and parking users the optimization model were carried out with a model built on the lingo software response surface methodology will be performed for final decision making the model found that the optimum srp arrangement for gajah mada street is 188 car srp for digital parking area 323 motorcycle srp for digital parking area 133 car srp for conventional parking area and 251 motorcycle srp for conventional parking area the arrangement will give parking service providers expected retribution of rp75798856 with a parking area utilization rate of 6807 from the parking user perspective the total parking user cost is rp57358168
"STUDI KINERJA METODE SELEKSI FITUR BERBASIS 
UNCERTAINTY PADA DETEKSI CHRONIC KIDNEY DISEASE
DENGAN KLASIFIKASI SVM.","Qolby, Lailly Syifa`ul",http://repository.its.ac.id/88100/,"Chronic Kidney Disease (CKD) merupakan sebuah kelainan yang merusak fungsi ginjal. Tanda awal penderita CKD sangat sulit untuk diketahui hingga penderita kehilangan 25% dari fungsi ginjalnya. Oleh karena itu dibutuhkan pendeteksian dini dan treatment yang efektif untuk mengurangi tingkat kematian penderita CKD.Dalam penelitian ini penulis melakukan diagnosa pada dataset CKD menggunakan metode klasifikasi Support Vector Machine (SVM) untuk mendapatkan hasil diagnosa yang akurat. Untuk memperoleh hasil klasifikasi yang terbaik, maka penulis mengusulkan perbandingan hasil pada penerapan metodeseleksi fitur agar mendapatkan kandidat fitur terbaik dalam meningkatkan hasil klasifikasi.Proses pengujian dilakukan dengan membandingkan metode seleksi fiturSymmetrical Uncertainty (SU) dan Multivariate Symmetrical Uncertainty (MSU)serta metode SVM sebagai metode klasifikasi. Dengan menggunakan dataset CKD, dilakukan beberapa skenario percobaan baik dengan menggunakan metode seleksi fitur SU maupun MSU. Dari hasil ujicoba yang dilakukan menunjukkan bahwa dengan menggunakan metode seleksi fitur MSU dengan split data 80% : 20% menghasilkan jumlah fitur penting sebanyak 9 fitur dengan nilai akurasi 0.9, sensitivy 0.8400, dan specification 1 serta jika dilihat pada grafik ROC grafik metode MSU menunjukkan nilai true positive lebih tinggi daripada nilai false positive. Sehingga klasifikasi dengan menggunakan metode seleksi fitur MSU lebih baik daripada metode seleksi fitur SU.=====================================================================================================Chronic Kidney Disease (CKD) is a disorder that impairs kidney function. Early signs of CKD patients are very difficult to know until the patient loses 25% of their kidney function. Therefore, early detection and effective treatment are needed to reduce the mortality rate of CKD sufferers.In this study, the authors diagnose the CKD dataset using the Support Vector Machine (SVM) classification method to obtain accurate diagnostic results. The authors propose a comparison of the result on the application of the feature selection method in order to get the best feature candidates in improving the classification result.Testing process is carried out by comparing the Symmetrical Uncertainty (SU) and Multivariate Symmetrical Uncertainty (MSU) feature selection method as well as the SVM method as a classification method. By using the CKD dataset, several experimental scenarios were carried out using both the SU and MSU feature selection methods. From the results of the tests carried out, it shows that using the MSU feature selection method with 80% : 20% data split produces 9 important features with an accuracy value of 0.9, sensitivity 0.8400, specification 1 and when viewed on the ROC graph, the MSU method graph shows the true positive value is higher than the false positive value. So the classification using the MSU feature selection method is better than the SU feature selection method.",studi kerja metode seleksi fitur bas uncertainty deteksi chronic kidney disease klasifikasi svm,chronic kidney disease ckd lain rusak fungsi ginjal tanda derita ckd sulit derita hilang 25 fungsi ginjal butuh deteksi treatment efektif kurang tingkat mati derita ckddalam teliti tulis diagnosa dataset ckd metode klasifikasi support vector machine svm hasil diagnosa akurat oleh hasil klasifikasi baik tulis usul banding hasil terap metodeseleksi fitur kandidat fitur baik tingkat hasil klasifikasiproses uji banding metode seleksi fitursymmetrical uncertainty su multivariate symmetrical uncertainty msuserta metode svm metode klasifikasi dataset ckd skenario coba metode seleksi fitur su msu hasil ujicoba metode seleksi fitur msu split data 80 20 hasil fitur 9 fitur nilai akurasi 09 sensitivy 08400 specification 1 grafik roc grafik metode msu nilai true positive nilai false positive klasifikasi metode seleksi fitur msu metode seleksi fitur suchronic kidney disease ckd is a disorder that impairs kidney function early signs of ckd patients are very difficult to know until the patient loses 25 of their kidney function therefore early detection and effective treatment are needed to reduce the mortality rate of ckd sufferersin this study the authors diagnose the ckd dataset using the support vector machine svm classification method to obtain accurate diagnostic results the authors propose a comparison of the result on the application of the feature selection method in order to get the best feature candidates in improving the classification resulttesting process is carried out by comparing the symmetrical uncertainty su and multivariate symmetrical uncertainty msu feature selection method as well as the svm method as a classification method by using the ckd dataset several experimental scenarios were carried out using both the su and msu feature selection methods from the results of the tests carried out it shows that using the msu feature selection method with 80 20 data split produces 9 important features with an accuracy value of 09 sensitivity 08400 specification 1 and when viewed on the roc graph the msu method graph shows the true positive value is higher than the false positive value so the classification using the msu feature selection method is better than the su feature selection method
Sistem Deteksi Gangguan Spektrum Autisme pada Anak Melalui Metode Facial Landmarks dan Machine Learning pada Citra Respons Emosional.,"Rachmah, Indah Nabila",http://repository.its.ac.id/113008/,"Meskipun prevalensi Autism Spectrum Disorder (ASD) terus meningkat secara global, metode skrining saat ini untuk deteksi dini tetap memakan waktu dan mahal, yang menyoroti kesenjangan penelitian yang kritis. Penelitian ini bertujuan untuk mengembangkan sistem deteksi baru untuk ASD pada anak-anak, memanfaatkan landmark wajah dan metode pembelajaran mesin untuk menganalisis gambar respons emosional. Pendekatan kami melibatkan penangkapan ekspresi wajah spontan menggunakan sensor pencitraan non-invasif, diikuti dengan ekstraksi landmark wajah kunci. Dua model klasifikasi, Support Vector Machine (SVM) dan Convolutional Neural Network (CNN), diimplementasikan untuk menganalisis dan mengklasifikasikan landmark wajah ini. Model SVM mencapai akurasi 92.54%, presisi 93.43%, recall 92.56%, dan skor F1 92.42%, sementara model CNN mencapai akurasi 84.16%, presisi 83.06%, recall 85.83%, dan skor F1 84.42%. Studi ini menunjukkan potensi integrasi teknik pembelajaran mesin lanjutan dengan ekstraksi landmark wajah untuk deteksi dini ASD yang andal dan non-invasi. Kinerja menjanjikan dari model SVM dan CNN menunjukkan bahwa pendekatan kami dapat secara signifikan meningkatkan strategi diagnosis dan intervensi dini untuk anak-anak dengan ASD. Selain itu, penggunaan dataset yang beragam dan real-time serta langkah-langkah pra-pemrosesan yang efektif memastikan akurasi, keandalan, dan generalisasi sistem deteksi ini. Potensi sistem yang diusulkan untuk aplikasi praktis dalam diagnosis dini ASD ditingkatkan oleh integrasi teknik pencitraan non-invasi yang berhasil dan pengembangan GUI yang ramah pengguna, membuka jalan untuk deteksi real-time dan pelaporan otomatis, yang pada akhirnya berkontribusi pada hasil perkembangan yang lebih baik dan kualitas hidup anak-anak yang terkena ASD.",sistem deteksi ganggu spektrum autisme anak metode facial landmarks machine learning citra respons emosional,prevalensi autism spectrum disorder asd tingkat global metode skrining deteksi makan mahal sorot senjang teliti kritis teliti tuju kembang sistem deteksi asd anakanak manfaat landmark wajah metode ajar mesin analis gambar respons emosional dekat libat tangkap ekspresi wajah spontan sensor citra noninvasif ikut ekstraksi landmark wajah kunci model klasifikasi support vector machine svm convolutional neural network cnn implementasi analis klasifikasi landmark wajah model svm capai akurasi 9254 presisi 9343 recall 9256 skor f1 9242 model cnn capai akurasi 8416 presisi 8306 recall 8583 skor f1 8442 studi potensi integrasi teknik ajar mesin lanjut ekstraksi landmark wajah deteksi asd andal noninvasi kerja janji model svm cnn dekat signifikan tingkat strategi diagnosis intervensi anakanak asd guna dataset agam realtime langkahlangkah prapemrosesan efektif akurasi andal generalisasi sistem deteksi potensi sistem usul aplikasi praktis diagnosis asd tingkat integrasi teknik citra noninvasi hasil kembang gui ramah guna buka jalan deteksi realtime lapor otomatis kontribusi hasil kembang kualitas hidup anakanak kena asd
Analisis Hubungan Sentimen Publik di Media Sosial X dan SPI Terhadap Pemerintah Provinsi di Indonesia Menggunakan Algoritma GRU dan LSTM.,"Rafli, Andi Muhammad",http://repository.its.ac.id/111297/,"Media sosial, khususnya Twitter, telah menjadi platform utama bagi masyarakat untuk mengekspresikan pandangan dan opini mereka terhadap berbagai isu, termasuk kinerja pemerintah provinsi di Indonesia. Penelitian ini bertujuan untuk menganalisis sentimen publik di media sosial X (Twitter) terkait pemerintah provinsi dengan menggunakan algoritma Gated Recurrent Unit (GRU) dan Long Short-Term Memory   (LSTM). Tahap pertama penelitian melibatkan pengumpulan dan pra-pemrosesan data teks, termasuk case folding, penghapusan tautan, dan lainnya. Setelah itu, data dilabeli secara manual dan dengan model pra-terlatih IndoBERT untuk klasifikasi ke dalam label positif, negatif, dan netral. Metode oversampling dan parameter tuning diterapkan untuk menghasilkan model LSTM dengan akurasi 0,9313, F1-Score 0,9352, dan loss 0,3269.Analisis topik dengan metode LDA menunjukkan dominasi sentimen negatif pada topik seperti ""Persepsi Publik tentang Program dan Kebijakan Anies Baswedan,"" ""Proyek Infrastruktur dan Pengelolaan Lahan,"" dan ""Kinerja Pemerintah Provinsi dalam Sektor Transportasi."" Ini menunjukkan kecenderungan negatif masyarakat terhadap isu-isu pemerintah provinsi.Penelitian ini juga membandingkan analisis sentimen di lima provinsi dengan hasil Survei Penilaian Integritas (SPI). Perhitungan korelasi Pearson menunjukkan nilai sentimen negatif dan positif terhadap SPI masing-masing sebesar 0,53 dan -0,53. Hasil ini mengindikasikan bahwa tingginya nilai SPI tidak selalu berhubungan langsung dengan tingginya atau rendahnya sentimen positif dan negatif, menunjukkan bahwa faktor lain mungkin mempengaruhi bagaimana masyarakat memandang kinerja pemerintah provinsi.============================================================Social media, especially Twitter, has become a major platform for people to express their views and opinions on various issues, including the performance of provincial governments in Indonesia. This study aims to analyze public sentiment on social media X (Twitter) regarding provincial governments using Gated Recurrent Unit (GRU) and Long Short-Term Memory   (LSTM) algorithms. The first stage of the research involved collecting and preprocessing text data, including case folding, removing links, usernames, punctuation, stopwords, double spaces, duplicate data, emoticons, and tweets with fewer than four words. After that, the data was manually labeled and classified using a pre-trained IndoBERT model into positive, negative, and neutral labels. Data imbalance was addressed using oversampling and parameter tuning methods, resulting in an LSTM model with an accuracy of 0.9313, an F1-Score of 0.9352, and a loss of 0.3269.Topic analysis using the Latent Dirichlet Allocation (LDA) method shows a dominance of negative sentiment on topics such as ""Public Perception of Anies Baswedan's Programs and Policies,"" ""Infrastructure Projects and Land Management by the Provincial Government,"" and ""Public Perception of the Provincial Government's Performance in the Transportation Sector."" This indicates a negative tendency in public sentiment towards provincial government issues.The study also compares sentiment analysis across five provinces with the Integrity Assessment Survey (SPI). Pearson correlation calculations show that the correlations between negative and positive sentiment scores and SPI are 0.53 and -0.53, respectively. This suggests that a high SPI value does not necessarily correlate with high or low positive and negative sentiment, indicating that other factors may influence public perceptions of provincial government performance.",analisis hubung sentimen publik media sosial x spi perintah provinsi indonesia algoritma gru lstm,media sosial twitter platform utama masyarakat ekspresi pandang opini isu kerja perintah provinsi indonesia teliti tuju analis sentimen publik media sosial x twitter kait perintah provinsi algoritma gated recurrent unit gru long shortterm memory lstm tahap teliti libat kumpul prapemrosesan data teks case folding hapus taut data label manual model praterlatih indobert klasifikasi label positif negatif netral metode oversampling parameter tuning terap hasil model lstm akurasi 09313 f1score 09352 loss 03269analisis topik metode lda dominasi sentimen negatif topik persepsi publik program bijak anies baswedan proyek infrastruktur kelola lahan kerja perintah provinsi sektor transportasi cenderung negatif masyarakat isuisu perintah provinsipenelitian banding analisis sentimen provinsi hasil survei nilai integritas spi hitung korelasi pearson nilai sentimen negatif positif spi masingmasing 053 053 hasil indikasi tinggi nilai spi hubung langsung tinggi rendah sentimen positif negatif faktor pengaruh masyarakat pandang kerja perintah provinsisocial media especially twitter has become a major platform for people to express their views and opinions on various issues including the performance of provincial governments in indonesia this study aims to analyze public sentiment on social media x twitter regarding provincial governments using gated recurrent unit gru and long shortterm memory lstm algorithms the first stage of the research involved collecting and preprocessing text data including case folding removing links usernames punctuation stopwords double spaces duplicate data emoticons and tweets with fewer than four words after that the data was manually labeled and classified using a pretrained indobert model into positive negative and neutral labels data imbalance was addressed using oversampling and parameter tuning methods resulting in an lstm model with an accuracy of 09313 an f1score of 09352 and a loss of 03269topic analysis using the latent dirichlet allocation lda method shows a dominance of negative sentiment on topics such as public perception of anies baswedans programs and policies infrastructure projects and land management by the provincial government and public perception of the provincial governments performance in the transportation sector this indicates a negative tendency in public sentiment towards provincial government issuesthe study also compares sentiment analysis across five provinces with the integrity assessment survey spi pearson correlation calculations show that the correlations between negative and positive sentiment scores and spi are 053 and 053 respectively this suggests that a high spi value does not necessarily correlate with high or low positive and negative sentiment indicating that other factors may influence public perceptions of provincial government performance
"Tutorial Pemodelan, Perhitungan Volume, dan Biaya Menggunakan Revit 2018.","Rahaditya, Verdi Arya",http://repository.its.ac.id/82609/,"Autodesk Revit adalah software Building Information Modeling (BIM) oleh Autodesk untuk desain arsitektur, struktur serta mekanikal, elektrikal dan plumbing (MEP). Dengan software ini pengguna dapat merancang bangunan dan struktur dengan pemodelan komponen dalam 3D dan sekaligus menyajikan gambar kerja dalam 2D. Data yang digunakan dalam tutorial pemodelan ini adalah data sekunder berupa gambar CAD dengan sumber yang telah dilampirkan. Tugas KP ini memberikan tutorial permodelan untuk komponen struktur sekaligus menghitung Rencana Anggaran Biaya (RAB) secara otomatis. Tujuan dari tugas pengganti KP ini adalah untuk: 1) Memberikan cara pemodelan rumah dua lantai menggunakan Autodesk Revit 2018. 2) Memberikan cara perhitungan volume, dan biaya menggunakan Autodesk Revit 2018. 3) Untuk mengetahui hasil perhitungan biaya total perencanaan rumah dua lantai sederhana yang dihitung menggunakan Autodesk Revit 2018. Tugas pengganti KP diharapkan dapat memberi tutorial mengenai pemodelan dalam Autodesk Revit yang jelas dan mudah dipahami untuk pembaca.=====================================================================================================Autodesk Revit is Autodesk's Building Information Modeling (BIM) software, for architectural, structural, mechanical, electrical and plumbing (MEP) design. With this software users can design buildings and structures with component modeling in 3D and simultaneously present work drawings in 2D. The data used in this modeling tutorial is secondary data in the form of CAD drawings with the attached source. This internship report provides modeling tutorials for structural components as well as calculating the Budget Plan (RAB) automatically. The objectives of this internship report replacement task are to: 1) Provide a two-story house modeling method using Autodesk Revit 2018. 2) Provide a method of calculating volume and costs using Autodesk Revit 2018.3) To find out the results of calculating the total cost of planning a simple two-story house calculated using Autodesk Revit 2018. The task of replacing the internship program is expected to provide a tutorial on modeling in Autodesk Revit that is clear and easy to understand for readers.",tutorial model hitung volume biaya revit 2018,autodesk revit software building information modeling bim autodesk desain arsitektur struktur mekanikal elektrikal plumbing mep software guna rancang bangun struktur model komponen 3d saji gambar kerja 2d data tutorial model data sekunder gambar cad sumber lampir tugas kp tutorial model komponen struktur hitung rencana anggar biaya rab otomatis tuju tugas ganti kp 1 model rumah lantai autodesk revit 2018 2 hitung volume biaya autodesk revit 2018 3 hasil hitung biaya total rencana rumah lantai sederhana hitung autodesk revit 2018 tugas ganti kp harap tutorial model autodesk revit mudah paham pembacaautodesk revit is autodesks building information modeling bim software for architectural structural mechanical electrical and plumbing mep design with this software users can design buildings and structures with component modeling in 3d and simultaneously present work drawings in 2d the data used in this modeling tutorial is secondary data in the form of cad drawings with the attached source this internship report provides modeling tutorials for structural components as well as calculating the budget plan rab automatically the objectives of this internship report replacement task are to 1 provide a twostory house modeling method using autodesk revit 2018 2 provide a method of calculating volume and costs using autodesk revit 20183 to find out the results of calculating the total cost of planning a simple twostory house calculated using autodesk revit 2018 the task of replacing the internship program is expected to provide a tutorial on modeling in autodesk revit that is clear and easy to understand for readers
Desain Trajektori Kapal Patrol Menggunakan  Deep Reinforcement Learning dalam Operasi  Pengejaran Kapal dengan Losses Data AIS.,"Rahmania, Amanda Caesa",http://repository.its.ac.id/109525/,"Indonesia, sebagai negara kepulauan terbesar, menghadapi tantangan dalam menjaga keamanan maritimnya yang luas. Kehilangan data AIS (Automatic Identification System) pada kapal, seperti yang terjadi di Selat Malaka dan Laut Natuna Utara, mengindikasikan adanya aktivitas ilegal di perairan Indonesia. Penelitian ini bertujuan merancang rute patroli kapal yang optimal menggunakan deep reinforcement learning untuk mengatasi masalah kehilangan data AIS dengan mempertimbangkan faktor lingkungan kapal. Data kapal yang diteliti berada di Selat Malaka terutama Pulau Bengkalis, dengan spesifikasi kapal patrol yaitu KN Ular Laut 406. Penelitian ini dimulai dengan mendeteksi kapal yang mengalami kehilangan data selama lebih dari 1 jam, kemudian dilajutkan dengan deteksi tindakan illegal, setelah mendapatkan data kapal yang mengalami losses data kemudian dilakukan pembuatan trajektori dengan diakhiri dengan pembuatan trajektori dengan berbagai variasi. Hasil dari model yang telah dibuat didapatkan metrik performansi MAE untuk subsistem identifikasi losses data sebesar 0.01312 dan untuk subsistem selektor sebesar 0.12. Pada Deep Reinforcement Learning didapatkan grafik loss dibandingkan dengan 8000episode menunjukkan tren turun dan grafik reward dibandingkan dengan 8000episode menunjukkan tren naik. RMSE juga digunakan untuk perhitungan error dari model visualisasi trajektori dengan nilai terkecil yaitu 0.8104575756222229. Kesimpulan dari penelitian ini antara lain, metode DRL dapat dijadikan sebagai metode dalam pembuatan trajektori kapal patrol, dan model yang digunakan memunculkan grafik loss function dengan tren naik dan reward dengan tren turun maka dapat dikatakan bahwa model bagus.============================================================================================================================================Indonesia, as the largest archipelagic country, faces challenges in maintaining the security of its vast maritime territory. The loss of AIS (Automatic Identification System) data on ships, as observed in the Malacca Strait and the North Natuna Sea, indicates illegal activities in Indonesian waters. This research aims to design an optimal patrol route for ships using deep reinforcement learning to address the problem of AIS data loss and accelerate the capture of illegal vessels by considering the ship's environmental factors. The studied ship data is from the Malacca Strait, particularly around Bengkalis Island, with the patrol vessel specifications being KN Ular Laut 406. The research begins by detecting ships that have experienced data loss for more than 1 hour, followed by the detection of illegal activities. After obtaining data on ships experiencing data loss, trajectory planning is carried out, concluding with the creation of various trajectory variations. The performance metrics of the developed model showed a Mean Absolute Error (MAE) of 0.04 for the data loss identification subsystem and 0.12 for the selector subsystem. In the Deep Reinforcement Learning model, the loss graph over 8000 episodes showed a downward trend, and the reward graph over 8000 episodes showed an upward trend, indicating that the deep reinforcement learning model developed is effective. RMSE was also used to calculate the error of the trajectory visualization model, with the smallest value being 0.8104575756222229.",desain trajektori kapal patrol deep reinforcement learning operasi kejar kapal losses data ais,indonesia negara pulau besar hadap tantang jaga aman maritim luas hilang data ais automatic identification system kapal selat malaka laut natuna utara indikasi aktivitas ilegal air indonesia teliti tuju rancang rute patroli kapal optimal deep reinforcement learning atas hilang data ais timbang faktor lingkung kapal data kapal teliti selat malaka pulau bengkal spesifikasi kapal patrol kn ular laut 406 teliti deteksi kapal alami hilang data 1 jam dilajutkan deteksi tindak illegal data kapal alami losses data buat trajektori buat trajektori variasi hasil model dapat metrik performansi mae subsistem identifikasi losses data 001312 subsistem lektor 012 deep reinforcement learning dapat grafik loss banding 8000episode tren turun grafik reward banding 8000episode tren rmse hitung error model visualisasi trajektori nilai kecil 08104575756222229 simpul teliti metode drl jadi metode buat trajektori kapal patrol model muncul grafik loss function tren reward tren turun model bagusindonesia as the largest archipelagic country faces challenges in maintaining the security of its vast maritime territory the loss of ais automatic identification system data on ships as observed in the malacca strait and the north natuna sea indicates illegal activities in indonesian waters this research aims to design an optimal patrol route for ships using deep reinforcement learning to address the problem of ais data loss and accelerate the capture of illegal vessels by considering the ships environmental factors the studied ship data is from the malacca strait particularly around bengkal island with the patrol vessel specifications being kn ular laut 406 the research begins by detecting ships that have experienced data loss for more than 1 hour followed by the detection of illegal activities after obtaining data on ships experiencing data loss trajectory planning is carried out concluding with the creation of various trajectory variations the performance metrics of the developed model showed a mean absolute error mae of 004 for the data loss identification subsystem and 012 for the selector subsystem in the deep reinforcement learning model the loss graph over 8000 episodes showed a downward trend and the reward graph over 8000 episodes showed an upward trend indicating that the deep reinforcement learning model developed is effective rmse was also used to calculate the error of the trajectory visualization model with the smallest value being 08104575756222229
Klasifikasi Gerakan Pencak Silat Menggunakan Convolutional Neural Network Berbasis Body Pose.,"Rahmawati, Vira Nur",http://repository.its.ac.id/99417/,"Pencak silat selain bermanfaat untuk perlindungan diri, juga memiliki banyak manfaat lainnya, seperti meningkatkan kekuatan fisik, menjaga postur tubuh, dan menjaga kesehatan jantung. Karena pandemi yang belakangan terjadi ini, latihan pencak silat sulit dilakukan secara bersama-sama. Selain itu, jika ada materi pelajaran pencak silat di sekolah, guru olahraga kesulitan untuk mengajarkan gerak secara langsung. Tetapi latihan pencak silat yang dilakukan sendiri tanpa pelatih dapat menyebabkan cedera jika gerakannya tidak benar. Oleh karena itu, penelitian ini membangun sistem pengenalan gerakan pencak silat. Sistem dibangun menggunakan metode CNN berbasis bodypose. Bodypose extraction digunakan untuk mendeteksi keypoint tubuh manusia, kemudian keypoint tersebut digunakan sebagai fitur input ke CNN untuk mengenali gerakan pada setiap frame. Sistem ini menggunakan CNN karena membutuhkan parameter yang lebih sedikit dan daya komputasi yang lebih sedikit sehingga dapat lebih mudah diterapkan untuk studi selanjutnya. Akurasi yang diperoleh mencapai 77% saat diuji pada data yang belum pernah digunakan. Model ini dapat digunakan sebagai titik awal untuk membuat sistem yang mudah digunakan untuk membantu orang berlatih pencak silat dengan gerakan yang lebih banyak.================================================================================================================================Pencak silat, besides from being useful for self-protection, also has many other benefits, such as increasing physical strength, maintaining posture, and maintaining heart health. Due to the recent pandemic, practicing pencak silat is difficult to do together. Even when there is study material on pencak silat at school, it is difficult for the sports teacher to teach the movements directly. Pencak silat exercises that are practiced alone without a coach can cause injury if the movements are not correct. Therefore, this study builds a system to recognize pencak silat movements. The system was built using the bodypose-based CNN method. Bodypose estimation is used to detect human body keypoints, then these keypoints are used as a feature for input to CNN to recognize movement in each frame. This system uses CNN because it requires fewer parameters and less computing power so that it can be more easily applied for further studies. The accuracy obtained reaches 77% when tested on data that has never been used. This model can be used as a starting point for creating an easy-to-use system to help people practice pencak silat with more recognizable moves.",klasifikasi gera pencak silat convolutional neural network bas body pose,pencak silat manfaat lindung milik manfaat tingkat kuat fisik jaga postur tubuh jaga sehat jantung pandemi latih pencak silat sulit bersamasama materi ajar pencak silat sekolah guru olahraga sulit ajar gerak langsung latih pencak silat latih sebab cedera gera teliti bangun sistem kenal gera pencak silat sistem bangun metode cnn bas bodypose bodypose extraction deteksi keypoint tubuh manusia keypoint fitur input cnn nali gera frame sistem cnn butuh parameter daya komputasi mudah terap studi akurasi oleh capai 77 uji data model titik sistem mudah bantu orang latih pencak silat gera banyakpencak silat besides from being useful for selfprotection also has many other benefits such as increasing physical strength maintaining posture and maintaining heart health due to the recent pandemic practicing pencak silat is difficult to do together even when there is study material on pencak silat at school it is difficult for the sports teacher to teach the movements directly pencak silat exercises that are practiced alone without a coach can cause injury if the movements are not correct therefore this study builds a system to recognize pencak silat movements the system was built using the bodyposebased cnn method bodypose estimation is used to detect human body keypoints then these keypoints are used as a feature for input to cnn to recognize movement in each frame this system uses cnn because it requires fewer parameters and less computing power so that it can be more easily applied for further studies the accuracy obtained reaches 77 when tested on data that has never been used this model can be used as a starting point for creating an easytouse system to help people practice pencak silat with more recognizable moves
Integrasi Data Multisensor Untuk Peningkatan Lokalisasi Pada Navigasi Mobile Robot Menggunakan Extended Kalman Filter.,"Ramadhan, Fadhly",http://repository.its.ac.id/117061/,"Sistem navigasi robot tidak terlepas dari penggunaan sensor yang digunakan sebagai masukan untuk menentukan persepsi robot baik secara internal maupun eksternal. Setiap sensor memiliki kelebihan dan kekurangannya masing – masing, seperti penggunaan sensor INS menawarkan keunggulan dalam menyediakan data posisi dan orientasi dengan laju tinggi, sementara rotary encoder menyediakan data posisi yang lebih akurat namun rotary encoder yangsensitif terhadap slip. Mengandalkan satu jenis sensor sering kali tidak cukup untuk mencapai estimasi posisi yang akurat dan andal, terutama dalam lingkungan yang kompleks dan dinamis. Kombinasi kedua sistem ini melalui EKF memungkinkan pemanfaatan keunggulan masing-masing sistem, menghasilkan data navigasi yang lebih stabil dan akurat. Dalam penelitian ini, Sensor yang digunakan meliputi Inertial Measurement Unit (IMU) untuk memperoleh orientasi, Rotary Encoder untuk posisi translasi, dan RPLidar A1 untuk deteksi lingkungan. Proses integrasi data melibatkan mekanisasi IMU, filtering menggunakan Kalman Filter, dan pemetaan lingkungan SLAM. Mobile robot yang digunakan memiliki konfigurasi roda omni-directional 4WD yang memungkinkan gerakan bebas dalam ruang dua dimensi. Hasil pengujian menunjukkan bahwa integrasi multisensor dengan EKF signifikan meningkatkan akurasi estimasi posisi dan orientasi dibandingkan metode sensor tunggal.====================================================================================================================================The robot navigation system cannot be separated from the use of sensors which are used as input to determine the robot's perception both internally and externally. Each sensor has its own advantages and disadvantages, such as the use of the INS sensor offers the advantage of providing position and orientation data at a high rate, while the rotary encoder provides more accurate position data but the rotary encoder is sensitive to slip. Relying on one type of sensor is often insufficient to achieve accurate and reliable position estimation, especially in complex and dynamic environments. The combination of these two systems via EKF allows exploiting the advantages of each system, producing more stable and accurate navigation data. In this research, the sensors used include the Inertial Measurement Unit (IMU) to obtain orientation, the Rotary Encoder for translation position, and the RPLidar A1 for environmental detection. The data integration process involves IMU mechanization, filtering using the Kalman Filter, and SLAM environment mapping. The mobile robot used has a 4WD omni-directional wheel configuration which allows free movement in two-dimensional space. Test results show that multisensor integration with EKF significantly increases the accuracy of position and orientation estimation compared to single sensor methods.",integrasi data multisensor tingkat lokalisasi navigasi mobile robot extended kalman filter,sistem navigasi robot lepas guna sensor masuk tentu persepsi robot internal eksternal sensor milik lebih kurang  guna sensor ins tawar unggul sedia data posisi orientasi laju rotary encoder sedia data posisi akurat rotary encoder yangsensitif slip andal jenis sensor kali capai estimasi posisi akurat andal lingkung kompleks dinamis kombinasi sistem ekf manfaat unggul masingmasing sistem hasil data navigasi stabil akurat teliti sensor liput inertial measurement unit imu oleh orientasi rotary encoder posisi translasi rplidar a1 deteksi lingkung proses integrasi data libat mekanisasi imu filtering kalman filter meta lingkung slam mobile robot milik konfigurasi roda omnidirectional 4wd gera bebas ruang dimensi hasil uji integrasi multisensor ekf signifikan tingkat akurasi estimasi posisi orientasi banding metode sensor tunggalthe robot navigation system can not be separated from the use of sensors which are used as input to determine the robots perception both internally and externally each sensor has its own advantages and disadvantages such as the use of the ins sensor offers the advantage of providing position and orientation data at a high rate while the rotary encoder provides more accurate position data but the rotary encoder is sensitive to slip relying on one type of sensor is often insufficient to achieve accurate and reliable position estimation especially in complex and dynamic environments the combination of these two systems via ekf allows exploiting the advantages of each system producing more stable and accurate navigation data in this research the sensors used include the inertial measurement unit imu to obtain orientation the rotary encoder for translation position and the rplidar a1 for environmental detection the data integration process involves imu mechanization filtering using the kalman filter and slam environment mapping the mobile robot used has a 4wd omnidirectional wheel configuration which allows free movement in twodimensional space test results show that multisensor integration with ekf significantly increases the accuracy of position and orientation estimation compared to single sensor methods
Prototipe Sistem Deteksi Maling Menggunakan Wi-Fi Based Secure Indoor Positioning System.,"Ramadhan, Naufal",http://repository.its.ac.id/106170/,"Sistem pemosisian dalam ruangan sudah mulai berkembang dalam beberapa tahun belakangan ini. Berbeda dengan sistem pemosisian yang sudah sangat dikenal oleh masyarakat yakni Global Positioning System (GPS), pada penelitian kali ini akan berfokus melakukan pemosisian di dalam ruangan atau biasa disebut dengan Indoor Positioning System (IPS). Indoor Positiong System (IPS) pada era digitalisasi sangat berpengaruh mengingat seluruh perkembangan infrastruktur sangat maju serta dengan sektor digitalisasi. Pada perkembangan di banyak sektor ini pula maka akan menimbulkan banyak masalah baru seperti contohnya apabila terdapat gedung pencakar langit maka terdapat banyak halangan atau masalah untuk memastikan lokasi dari orang atau pun benda. Masalah tidak berhenti sampai disitu, dimana ancaman juga dapat datang dari manusia baik masuk melalui sistem maupun secara fisik. Pada penelitian kali ini akan digunakan untuk mencari tau perbandingan model terbaik berdasarkan dataset yang sudah ada dengan dataset yang diambil secara langsung dalam salah satu ruangan yang dianggap steril. Kemudian dibandingkan menggunakan beberapa algoritma machine learning sebagai bahan perbandingan algoritma mana yang memiliki akurasi terbaik. Serta dibuat salah satu ujicoba metode serangan yang kemudian dibuat model yang robust. Kemudian dari perbandingan tersebut akan dipilih salah satu model dari dataset yang memiliki akurasi terbaik untuk dibuat prototipe sistem deteksi dimana apabila terdeteksi sebuah anomali di dalam model maka akan mengirimkan pesan warning melalui email dengan harapan sistem ini dapat berguna di ruang atau tempat restricted. Penelitian ini memanfaatkan dataset berbentuk Channel State Information (CSI). Dari beberapa model yang diuji diperoleh akurasi senilai 74,02% menggunakan algoritma random forest. Dimana implementasi serangan menggunakan Decision Tree Attack berhasil dilakukan hingga akurasi turun di angka 52%. Uji coba penerapan metode pertahanan menggunakan featuresqueezing berhasil membuat model lebig tahan dibuktikan dengan akurasi menjadi 68%. Serta implementasi Anomaly Detector dapat mengirimkan pesan bahaya melalui email.=================================================================================================================================Indoor positioning systems have begun to develop in recent years. Different from the positioning system that is well known to the public, namely the Global Positioning System (GPS), this research will focus on indoor positioning or what is usually called the Indoor Positioning System (IPS). The Indoor Positioning System (IPS) in the digitalization era is very influential considering that all infrastructure developments are very advanced as well as the digitalization sector. Development in many of these sectors will also give rise to many new problems, for example if there are skyscrapers then there will be many obstacles or problems in determining the location of people or objects. The problem doesn't stop there, where threats can also come from humans, either through the system or physically. In this research, it will be used to find out the comparison of the best model based on an existing dataset with a dataset taken directly in a room that is considered sterile. Then it is compared using several machine learning algorithms as a comparison which algorithm has the best accuracy. And a test method of attack was made which was then made into a sturdy model. Then, from this comparison, one of the models from the dataset that has the best accuracy will be selected to create a detection system prototype, where if an anomaly is detected in the model, it will send a warning message via email in the hope that this system can be useful in limited spaces or places. This research utilizes a dataset in the form of Channel State Information (CSI). Several models tested obtained an accuracy of 74.02% using the random forest algorithm. Where the implementation of the attack using Decision Tree Attack was successfully carried out until the accuracy fell to 52%. The trial application of the maintenance method using featurequeezing succeeded in making the model more durable, proven by an accuracy of 68%. And the Anomaly Detector implementation can send danger messages via email.",prototipe sistem deteksi maling wifi based secure indoor positioning system,sistem posisi ruang kembang beda sistem posisi kenal masyarakat global positioning system gps teliti kali fokus posisi ruang indoor positioning system ips indoor positiong system ips era digitalisasi pengaruh kembang infrastruktur maju sektor digitalisasi kembang sektor timbul contoh gedung cakar langit halang lokasi orang benda henti situ mana ancam manusia masuk sistem fisik teliti kali cari tau banding model baik dasar dataset dataset ambil langsung salah ruang anggap steril banding algoritma machine learning bahan banding algoritma milik akurasi baik salah ujicoba metode serang model robust banding pilih salah model dataset milik akurasi baik prototipe sistem deteksi mana deteksi anomali model kirim pesan warning email harap sistem guna ruang restricted teliti manfaat dataset bentuk channel state information csi model uji oleh akurasi nila 7402 algoritma random forest mana implementasi serang decision tree attack hasil akurasi turun angka 52 uji coba terap metode tahan featuresqueezing hasil model lebig tahan bukti akurasi 68 implementasi anomaly detector kirim pesan bahaya emailindoor positioning systems have begun to develop in recent years different from the positioning system that is well known to the public namely the global positioning system gps this research will focus on indoor positioning or what is usually called the indoor positioning system ips the indoor positioning system ips in the digitalization era is very influential considering that all infrastructure developments are very advanced as well as the digitalization sector development in many of these sectors will also give rise to many new problems for example if there are skyscrapers then there will be many obstacles or problems in determining the location of people or objects the problem doesnt stop there where threats can also come from humans either through the system or physically in this research it will be used to find out the comparison of the best model based on an existing dataset with a dataset taken directly in a room that is considered sterile then it is compared using several machine learning algorithms as a comparison which algorithm has the best accuracy and a test method of attack was made which was then made into a sturdy model then from this comparison one of the models from the dataset that has the best accuracy will be selected to create a detection system prototype where if an anomaly is detected in the model it will send a warning message via email in the hope that this system can be useful in limited spaces or places this research utilizes a dataset in the form of channel state information csi several models tested obtained an accuracy of 7402 using the random forest algorithm where the implementation of the attack using decision tree attack was successfully carried out until the accuracy fell to 52 the trial application of the maintenance method using featurequeezing succeeded in making the model more durable proven by an accuracy of 68 and the anomaly detector implementation can send danger messages via email
Analisis Gangguan (Noise) Heart Rate Sensor Pada Wearable Device Berdasarkan Artefak Tangan Menggunakan Polar Oh1.,"Ramadhan, Rizqi",http://repository.its.ac.id/110335/,"Penelitian ini bertujuan untuk mengidentifikasi dan menganalisis tingkat noise yang dihasilkan oleh perangkat wearable OH1 selama berbagai gerakan tangan, yang dapat mempengaruhi keakuratan pengukuran detak jantung (HR). Masalah umum yang dihadapi adalah ketidakakuratan data HR yang disebabkan oleh noise saat perangkat digunakan selama aktivitas fisik. Masalah khususnya adalah menentukan gerakan tangan mana yang menghasilkan noise tertinggi dan terendah, serta bagaimana variabilitas data BPM dalam kondisi gerakan tangan yang berbeda-beda. Untuk mengatasi masalah ini, penelitian ini mengumpulkan data HR dari 10 jenis gerakan tangan, yaitu Menekan Tangan Lurus, Horizontal Shoulder Extension, Siku ke Hidung, Menyentuh Bahu, Mengangkat Bahu 90°, Supinate, Pronate, Melenturkan Bahu 180°, Tangan ke Dahi, dan Siku Menekuk 90°. Data tersebut kemudian dianalisis menggunakan metode Support Vector Machine (SVM) untuk mengklasifikasikan tingkat noise yang dihasilkan oleh setiap gerakan.Dengan meenggunakan 11 partisipan yang dalam kondisi sehat. Hasil analisis menunjukkan bahwa gerakan Melenturkan Bahu 180° menghasilkan tingkat noise tertinggi, sementara gerakan Siku Menekuk 90° menghasilkan noise terendah. Variabilitas data BPM menunjukkan perbedaan signifikan dalam stabilitas pengukuran HR yang dipengaruhi oleh jenis gerakan tangan. Dengan menggunakan metode SVM, akurasi klasifikasi mencapai 67%, yang menunjukkan efektivitas metode ini dalam mengidentifikasi dan mengklasifikasikan noise dari berbagai gerakan tangan. Kesimpulannya, penelitian ini memberikan wawasan penting tentang pengaruh gerakan tangan terhadap akurasi pengukuran HR oleh perangkat wearable OH1. Dengan mengetahui gerakan yang menghasilkan noise tinggi, pengguna dapat menghindari gerakan tersebut untuk memperoleh data HR yang lebih akurat dan andal.=================================================================================================================================This study aims to identify and analyze the level of noise produced by the OH1 wearable device during various hand movements, which can affect the accuracy of heart rate (HR) measurements. The general issue addressed is the inaccuracy of HR data caused by noise when the device is used during physical activities. The specific issues include determining which hand movements produce the highest and lowest noise levels and understanding the variability of BPM data under different hand movement conditions. To address these issues, HR data was collected from 10 types of hand movements, including Pressing Straight Hand, Horizontal Shoulder Extension, Elbow to Nose, Touching Shoulder, Lifting Shoulder 90°, Supinate, Pronate, Shoulder Flexion 180°, Hand to Forehead, and Elbow Bent 90°. The data was analyzed using the Support Vector Machine (SVM) method to classify the noise levels generated by each movement. The study involved 11 healthy participants. The analysis results show that the Shoulder Flexion 180° movement produces the highest noise level, while the Elbow Bent 90° movement produces the lowest noise. The variability in BPM data indicates significant differences in the stability of HR measurements influenced by the type of hand movement. Using the SVM method, the classification accuracy reached 67%, demonstrating the effectiveness of this method in identifying and classifying noise from various hand movements. In conclusion, this study provides important insights into the impact of hand movements on the accuracy of HR measurements by the OH1 wearable device. By identifying movements that generate high noise levels, users can avoid these movements to obtain more accurate and reliable HR data.",analisis ganggu noise heart rate sensor wearable device dasar artefak tangan polar oh1,teliti tuju identifikasi analis tingkat noise hasil perangkat wearable oh1 gera tangan pengaruh akurat ukur detak jantung hr hadap ketidakakuratan data hr sebab noise perangkat aktivitas fisik tentu gera tangan hasil noise tinggi rendah variabilitas data bpm kondisi gera tangan berbedabeda atas teliti kumpul data hr 10 jenis gera tangan tekan tangan lurus horizontal shoulder extension siku hidung sentuh bahu angkat bahu 90 supinate pronate lentur bahu 180 tangan dahi siku tekuk 90 data analis metode support vector machine svm klasifikasi tingkat noise hasil gerakandengan meenggunakan 11 partisipan kondisi sehat hasil analisis gera lentur bahu 180 hasil tingkat noise tinggi gera siku tekuk 90 hasil noise rendah variabilitas data bpm beda signifikan stabilitas ukur hr pengaruh jenis gera tangan metode svm akurasi klasifikasi capai 67 efektivitas metode identifikasi klasifikasi noise gera tangan simpul teliti wawas pengaruh gera tangan akurasi ukur hr perangkat wearable oh1 gera hasil noise guna hindar gera oleh data hr akurat andalthis study aims to identify and analyze the level of noise produced by the oh1 wearable device during various hand movements which can affect the accuracy of heart rate hr measurements the general issue addressed is the inaccuracy of hr data caused by noise when the device is used during physical activities the specific issues include determining which hand movements produce the highest and lowest noise levels and understanding the variability of bpm data under different hand movement conditions to address these issues hr data was collected from 10 types of hand movements including pressing straight hand horizontal shoulder extension elbow to nose touching shoulder lifting shoulder 90 supinate pronate shoulder flexion 180 hand to forehead and elbow bent 90 the data was analyzed using the support vector machine svm method to classify the noise levels generated by each movement the study involved 11 healthy participants the analysis results show that the shoulder flexion 180 movement produces the highest noise level while the elbow bent 90 movement produces the lowest noise the variability in bpm data indicates significant differences in the stability of hr measurements influenced by the type of hand movement using the svm method the classification accuracy reached 67 demonstrating the effectiveness of this method in identifying and classifying noise from various hand movements in conclusion this study provides important insights into the impact of hand movements on the accuracy of hr measurements by the oh1 wearable device by identifying movements that generate high noise levels users can avoid these movements to obtain more accurate and reliable hr data
Peringkasan Pertanyaan Stack Overflow Pada Atribut Kualitas Perangkat Lunak Menggunakan Teknik Penggalian Informasi Dan Klasifikasi Support Vector Machine (SVM).,"Rausanfita, Alqis",http://repository.its.ac.id/92791/,"Stack Overflow merupakan forum diskusi informal yang dapat menjadi bahan untuk evaluasi kualitas suatu perangkat lunak dengan cara penambangan teks. Evaluasi dapat dilakukan dengan menggunakan hasil peringkasan pertanyaan pada Stack Overflow, peringkasan tersebut dapat mengandung persyaratan kebutuhan pelanggan yang dapat dilakukan pemrosesan lebih lanjut. Selain itu, developer juga dapat mengelompokkan kendala yang dialami pengguna berdasarkan kualitas perangkat lunak sehingga dapat memudahkan dalam melakukan maintenance. Metode peringkasan sebelumnya menggunakan 2 jenis bobot, yang mana antara frasa pada sub aspek dengan frasa pada extend domain memiliki bobot yang sama, seharusnya bobot  sub domain lebih besar daripada frasa hasil extend.  Oleh karena itu penelitian ini bertujuan untuk meringkas kebutuhan pengguna pada atribut kualitas perangkat lunak dengan menggunakan informasi retrieval dan klasifikasi kualitas perangkat lunak sehingga diharapkan dapat membantu developer dalam mengevaluasi kualitas perangkat lunak secara otomatis. Ada beberapa tahapan yang dilakukan, yaitu: melakukan klasifikasi. Kemudian hasil klasifikasi tiap atribut kualitas dilakukan peringkasan. Pada penelitian ini, didapatkan hasil akurasi terbaikk dengan menggunakan metode SVM dengan nilai akurasi sebesar 86,63 persen. Hasil akurasi terbaik ini didapatkan dengan membandingkan 5 metode lainnya, yaitu Random Forest, Decision Tree, Logistic Regression, Naïve Bayes, dan Neural Network. Setelah didapatkan hasil klasifikasi kemudian dilakukan proses peringkasan dan mendapatkan nilai akurasi sebesar 73,08 persen. Hal tersebut mengindikasikan bahwa penelitian ini cukup baik dalam menghasilkan ringkasan kebutuhan pengguna pada atribut kualitas perangkat lunak dengan menggunakan information retrieval dan klasifikasi kualitas perangkat lunak. ================================================================================================Stack Overflow is an informal discussion platform that can be used as source for quality evaluation of a software through text mining. Evaluation can be done using the results of the questions summary on the Stack Overflow, the summary can contain the requirements of customer needs that can be processed further. Besides, developer can also group the constraints experienced by users based on the quality of the software so that it can be easier to carry out maintenance. The previous summary method used 2 types of weights with the phrases in the sub-aspects and the phrases in the extend domain had the same weight, in which sub domain should be larger than the extended result phrase. Therefore, this study aims to summarize the user needs on software quality by using retrieval information and software quality classification so that it can help developers in evaluating the software quality automatically. There are several stages that carried out, the first one is classifying. Then the results of the classification of each quality attribute are summarized. In this study, the best accuracy result was obtained using the SVM method with the accuracy value of 86.63 percent. The best accuracy results is obtained by comparing 5 other methods, that are Random Forest, Decision Tree, Logistic Regression, Naïve Bayes, and Neural Network. After obtaining the classification, a summary process was carried out and obtained the accuracy value of 73.08 percent. This indicates that this research is quite good at producing a summary of user needs on software quality attributes using information retrieval and classification of software quality.",ringkas stack overflow atribut kualitas perangkat lunak teknik gali informasi klasifikasi support vector machine svm,stack overflow forum diskusi informal bahan evaluasi kualitas perangkat lunak tambang teks evaluasi hasil ringkas stack overflow ringkas kandung syarat butuh langgan pemrosesan developer kelompok kendala alami guna dasar kualitas perangkat lunak mudah maintenance metode ringkas 2 jenis bobot frasa sub aspek frasa extend domain milik bobot bobot sub domain frasa hasil extend teliti tuju ringkas butuh guna atribut kualitas perangkat lunak informasi retrieval klasifikasi kualitas perangkat lunak harap bantu developer evaluasi kualitas perangkat lunak otomatis tahap klasifikasi hasil klasifikasi atribut kualitas ringkas teliti dapat hasil akurasi terbaikk metode svm nilai akurasi 8663 persen hasil akurasi baik dapat banding 5 metode random forest decision tree logistic regression na ve bayes neural network dapat hasil klasifikasi proses ringkas nilai akurasi 7308 persen indikasi teliti hasil ringkas butuh guna atribut kualitas perangkat lunak information retrieval klasifikasi kualitas perangkat lunak stack overflow is an informal discussion platform that can be used as source for quality evaluation of a software through text mining evaluation can be done using the results of the questions summary on the stack overflow the summary can contain the requirements of customer needs that can be processed further besides developer can also group the constraints experienced by users based on the quality of the software so that it can be easier to carry out maintenance the previous summary method used 2 types of weights with the phrases in the subaspects and the phrases in the extend domain had the same weight in which sub domain should be larger than the extended result phrase therefore this study aims to summarize the user needs on software quality by using retrieval information and software quality classification so that it can help developers in evaluating the software quality automatically there are several stages that carried out the first one is classifying then the results of the classification of each quality attribute are summarized in this study the best accuracy result was obtained using the svm method with the accuracy value of 8663 percent the best accuracy results is obtained by comparing 5 other methods that are random forest decision tree logistic regression na ve bayes and neural network after obtaining the classification a summary process was carried out and obtained the accuracy value of 7308 percent this indicates that this research is quite good at producing a summary of user needs on software quality attributes using information retrieval and classification of software quality
Prediksi Curah Hujan Memanfaatkan Statistical Downscaling Data Global Forecast System Menggunakan Support Vector Regression dan Long Short-Term Memory Sebagai Penunjang Keputusan Top Management.,"Rohman, Priya Setiawan A.",http://repository.its.ac.id/116288/,"Wilayah Sungai (WS) Brantas sering mengalami kejadian banjir akibat dari curah hujan yang tinggi, sehingga diperlukan prediksi cuaca yang akurat untuk mendukung keputusan manajemen dalam mitigasi banjir. Data Global Forecast System (GFS) digunakan dalam memprediksi cuaca khususnya prediksi curah hujan, namun resolusinya yang rendah tidak cukup memadai untuk skala lokal di WS Brantas. Masalah yang dihadapi adalah bagaimana cara untuk meningkatkan ketepatan prediksi curah hujan dengan mengintegrasikan data GFS yang memiliki resolusi rendah dengan data curah hujan lokal. Penelitian ini bertujuan untuk meningkatkan akurasi prediksi curah hujan di WS Brantas dengan teknik Statistical downscaling menggunakan metode Support Vector Regression (SVR) yang baik dalam menangani data non-linear dan Long Short-Term Memory (LSTM), sebuah jenis jaringan saraf tiruan yang dapat menangkap hubungan temporal dalam data deret waktu. Data yang diperlukan adalah prediksi curah hujan dari GFS dan data curah hujan lokal hasil pengukuran di WS Brantas. Hasil penelitian menunjukkan bahwa tingkat akurasi prediksi dengan SVR dan LSTM lebih tinggi daripada akurasi data prediksi GFS, sehingga dapat diusulkan untuk diimplementasikan sebagai data penunjang top management.==================================================================================================================================The Brantas River Basin (Brantas RB) often experiences flooding events due to high rainfall, so accurate weather predictions are needed to support management decisions in flood mitigation. Global Forecast System (GFS) data is used in predicting weather, especially rainfall prediction, but its low resolution is not sufficient for the local scale in the Brantas RB. The problem faced is how to improve the accuracy of rainfall prediction by integrating low-resolution GFS data with local rainfall data. This study aims to improve the accuracy of rainfall prediction in Brantas RB with statistical downscaling technique using Support Vector Regression (SVR) method which is good in handling non-linear data and Long Short-Term Memory (LSTM), a type of artificial neural network that can capture temporal relationships in time series data. The data required are rainfall predictions from GFS and local rainfall data measured in Brantas RB. The results show that the accuracy of prediction with SVR and LSTM is higher than the accuracy of GFS prediction data, so it can be proposed to be implemented as top management support data.",prediksi curah hujan manfaat statistical downscaling data global forecast system support vector regression long shortterm memory tunjang putus top management,wilayah sungai ws brantas alami jadi banjir akibat curah hujan prediksi cuaca akurat dukung putus manajemen mitigasi banjir data global forecast system gfs prediksi cuaca prediksi curah hujan resolusi rendah pada skala lokal ws brantas hadap tingkat tepat prediksi curah hujan integrasi data gfs milik resolusi rendah data curah hujan lokal teliti tuju tingkat akurasi prediksi curah hujan ws brantas teknik statistical downscaling metode support vector regression svr tangan data nonlinear long shortterm memory lstm jenis jaring saraf tiru tangkap hubung temporal data deret data prediksi curah hujan gfs data curah hujan lokal hasil ukur ws brantas hasil teliti tingkat akurasi prediksi svr lstm akurasi data prediksi gfs usul implementasi data tunjang top managementthe brantas river basin brantas rb often experiences flooding events due to high rainfall so accurate weather predictions are needed to support management decisions in flood mitigation global forecast system gfs data is used in predicting weather especially rainfall prediction but its low resolution is not sufficient for the local scale in the brantas rb the problem faced is how to improve the accuracy of rainfall prediction by integrating lowresolution gfs data with local rainfall data this study aims to improve the accuracy of rainfall prediction in brantas rb with statistical downscaling technique using support vector regression svr method which is good in handling nonlinear data and long shortterm memory lstm a type of artificial neural network that can capture temporal relationships in time series data the data required are rainfall predictions from gfs and local rainfall data measured in brantas rb the results show that the accuracy of prediction with svr and lstm is higher than the accuracy of gfs prediction data so it can be proposed to be implemented as top management support data
Perencanaan Model Distribusi Bahan Baku Baterai Kendaraan Listrik.,"Roihan, Imam Farhannabil",http://repository.its.ac.id/106836/,"Pemerintah Republik Indonesia telah melarang ekspor bijih nikel agar bijih nikel diolah lebih  lanjut di dalam negeri. Kebijakan ini guna meningkatkan nilai tambah dari ekspor nikel  Indonesia. Nikel merupakan salah satu mineral yang melimpah di Indonesia dan merupakan  salah satu bahan baku utama dalam memproduksi baterai kendaraan listrik di samping bahan  baku lainnya seperti mangan, kobalt, dan litium. Indonesia memiliki peluang untuk menjadi  lokasi produksi baterai kendaraan listrik. Untuk menjadi produsen baterai kendaraan listrik,  Indonesia harus membangun industri produksi baterai kendaraan listrik di dalam negeri serta  ngimpor bahan baku lainnya yang tidak melimpah di Indonesia. Industri baterai kendaraan  listrik merupakan industri yang masih tergolong baru di Indonesi sehingga penelitian ini adalah  untuk mencari model distribusi bahan baku baterai kendaraan listrik yang optimum  menggunakan metode optimisasi. Optimisasi dilakukan dengan membagi model distribusi  menjadi beberapa skenario berdasarkan model transportasi laut yang digunakan. Transportasi  laut yang terpilih akan mempengaruhi model distribusi secara keseluruhan. Model distribusi  yang terpilih didapatkan unit cost distribusi bijih nikel Rp22.205/ton, nikel sulfat  Rp2.751.791/ton, kobalt sulfat Rp2.751.791/ton, litium hidroksida Rp1.253.788/ton, mangan  sulfat Rp1.253.788/ton, dan katoda Rp878.723/ton==================================================================================================================================The Government of the Republic of Indonesia has banned the export of nickel ore so that nickel ore can be further processed domestically. This policy is to increase the added value of Indonesian nickel exports. Nickel is one of the minerals that is abundant in Indonesia and is one of the main raw materials for producing electric vehicle batteries alongside other raw materials such as manganese, cobalt and lithium. Indonesia has the opportunity to become a production location for electric vehicle batteries. To become an electric vehicle battery producer, Indonesia must build a domestic electric vehicle battery production industry and import other raw materials that are not abundant in Indonesia. The electric vehicle battery industry is an industry that is still relatively new in Indonesia, so this research is to find an optimum distribution model for electric vehicle battery raw materials using optimization methods. Optimization is carried out by dividing the distribution model into several scenarios based on the sea transportation model used. The selected sea transportation will influence the overall distribution model. The selected distribution model obtained unit distribution costs for nickel ore IDR 22,205/ton, nickel sulfate IDR 2,751,791/ton, cobalt sulfate IDR 2,751,791/ton, lithium hydroxide IDR 1,253,788/ton, manganese sulfate IDR 1,253,788/ton, and cathode IDR 878,723/ton",rencana model distribusi bahan baku baterai kendara listrik,perintah republik indonesia larang ekspor bijih nikel bijih nikel olah negeri bijak tingkat nilai ekspor nikel indonesia nikel salah mineral limpah indonesia salah bahan baku utama produksi baterai kendara listrik samping bahan baku mangan kobalt litium indonesia milik peluang lokasi produksi baterai kendara listrik produsen baterai kendara listrik indonesia bangun industri produksi baterai kendara listrik negeri ngimpor bahan baku limpah indonesia industri baterai kendara listrik industri golong indonesi teliti cari model distribusi bahan baku baterai kendara listrik optimum metode optimisasi optimisasi bagi model distribusi skenario dasar model transportasi laut transportasi laut pilih pengaruh model distribusi model distribusi pilih dapat unit cost distribusi bijih nikel rp22205ton nikel sulfat rp2751791ton kobalt sulfat rp2751791ton litium hidroksida rp1253788ton mangan sulfat rp1253788ton katoda rp878723tonthe government of the republic of indonesia has banned the export of nickel ore so that nickel ore can be further processed domestically this policy is to increase the added value of indonesian nickel exports nickel is one of the minerals that is abundant in indonesia and is one of the main raw materials for producing electric vehicle batteries alongside other raw materials such as manganese cobalt and lithium indonesia has the opportunity to become a production location for electric vehicle batteries to become an electric vehicle battery producer indonesia must build a domestic electric vehicle battery production industry and import other raw materials that are not abundant in indonesia the electric vehicle battery industry is an industry that is still relatively new in indonesia so this research is to find an optimum distribution model for electric vehicle battery raw materials using optimization methods optimization is carried out by dividing the distribution model into several scenarios based on the sea transportation model used the selected sea transportation will influence the overall distribution model the selected distribution model obtained unit distribution costs for nickel ore idr 22205ton nickel sulfate idr 2751791ton cobalt sulfate idr 2751791ton lithium hydroxide idr 1253788ton manganese sulfate idr 1253788ton and cathode idr 878723ton
DETEKSI PENYAKIT CABAI MERAH BESAR BERDASARKAN CITRA DAUN MENGGUNAKAN METODE SUPPORT VECTOR MACHINE (SVM) DAN LEARNING VECTOR QUANTIZATION (LVQ).,"Rossa, Shevia",http://repository.its.ac.id/114982/,"Salah satu tantangan utama yang menyebabkan rendahnya produksi cabai merah besar adalah gangguan penyakit yang dapat menyerang tanaman mulai dari tahap persemian hingga hasil panen. Gejala visual kunci suatu penyakit menjadi petunjuk kritis dalam menentukan patogen penyebabnya. Beberapa penyakit yang secara signifikan mempengaruhi produksi cabai merah besar di Indonesia meliputi penyakit kuning, embun tepung, mosaik keriting, dan kuning keriting. Penyebaran cepat penyakit ini terjadi karena kurangnya perhatian khusus dari petani, yang mengakibatkan kurangnya pemahaman mereka tentang karakteristik dan penanganan penyakit ini. Oleh karena itu, sangat penting untuk mengembangkan sistem deteksi yang akurat, cepat, dan efisien dalam mengidentifikasi penyakit pada tanaman cabai. Salah satu cara pendeteksian adalah dengan mengklasifikasikan citra daun. Data penelitian bersumber dari pertanian di Kabupaten Bener Meriah Provinsi Aceh pada 21 September hingga 1 Oktober tahun 2023. Teknologi rekognisi citra dilakukan untuk mengenali jenis hama dan penyakit pada tanaman cabai merah besar. Langkah pertama dalam penelitian adalah mengumpulkan citra daun, kemudilan melakukan preprocessing dan dilanjutkan tahap proses ekstraksi fitur warna, fitur tekstur dan fitur bentuk, hasil ekstraksi citra digunakan sebagai input dalam proses klasifikasi menggunakan algoritma Support Vector Machine (SVM) dan Learning Vector Quantization (LVQ). Accuracy hasil prediksi data training dan testing dengan metode SVM kernel polynolial adalah 95% dan 97%, sedangkan accuracy data training dan testing menggunakan metode LVQ adalah 53% dan 57%. Model terbaik dalam memprediksi penyakit cabai adalah model SVM dengan kernel polynomial.========================================================================================================================One of the primary challenges contributing to the low production of large red chili peppers is the prevalence of diseases that can affect plants from the seedling stage to the harvest. Key visual symptoms of a disease serve as critical indicators in determining the causative pathogen. Several diseases significantly impact the production of large red chili peppers in Indonesia, including yellowing disease, powdery mildew, mosaic curl, and yellow curl. The rapid spread of these diseases is attributed to the insufficient specific attention from farmers, resulting in a lack of understanding regarding the characteristics and management of these diseases. Therefore, it is crucial to develop an accurate, rapid, and efficient detection system to identify diseases in chili plants. One method of detection involves classifying leaf images. The research data is sourced from agricultural activities in the Bener Meriah Regency, Aceh Province, from September 21 to October 1, 2023. Image recognition technology is employed to identify types of pests and diseases affecting large red chili plants. The first step in the research involves collecting leaf images, followed by preprocessing and subsequent stages of color feature extraction, texture feature extraction, and shape feature extraction. The extracted image features serve as parameters in the classification process using the Support Vector Machine (SVM) and Learning Vector Quantization (LVQ) algorithms. The accuracy of the prediction results for the training and testing data using the SVM with a polynomial kernel method is 95% and 97%, respectively. In contrast, the accuracy of the training and testing data using the LVQ method is 53% and 57%, respectively. Therefore, the best model for predicting chili plant diseases is the SVM model with a polynomial kernel.",deteksi sakit cabai merah dasar citra daun metode support vector machine svm learning vector quantization lvq,salah tantang utama sebab rendah produksi cabai merah ganggu sakit serang tanam tahap semi hasil panen gejala visual kunci sakit tunjuk kritis tentu patogen sebab sakit signifikan pengaruh produksi cabai merah indonesia liput sakit kuning embun tepung mosaik keriting kuning keriting sebar cepat sakit kurang perhati khusus tani akibat kurang paham karakteristik tangan sakit kembang sistem deteksi akurat cepat efisien identifikasi sakit tanam cabai salah deteksi klasifikasi citra daun data teliti sumber tani kabupaten bener riah provinsi aceh 21 september 1 oktober 2023 teknologi rekognisi citra nali jenis hama sakit tanam cabai merah langkah teliti kumpul citra daun kemudilan preprocessing lanjut tahap proses ekstraksi fitur warna fitur tekstur fitur bentuk hasil ekstraksi citra input proses klasifikasi algoritma support vector machine svm learning vector quantization lvq accuracy hasil prediksi data training testing metode svm kernel polynolial 95 97 accuracy data training testing metode lvq 53 57 model baik prediksi sakit cabai model svm kernel polynomialone of the primary challenges contributing to the low production of large red chili peppers is the prevalence of diseases that can affect plants from the seedling stage to the harvest key visual symptoms of a disease serve as critical indicators in determining the causative pathogen several diseases significantly impact the production of large red chili peppers in indonesia including yellowing disease powdery mildew mosaic curl and yellow curl the rapid spread of these diseases is attributed to the insufficient specific attention from farmers resulting in a lack of understanding regarding the characteristics and management of these diseases therefore it is crucial to develop an accurate rapid and efficient detection system to identify diseases in chili plants one method of detection involves classifying leaf images the research data is sourced from agricultural activities in the bener riah regency aceh province from september 21 to october 1 2023 image recognition technology is employed to identify types of pests and diseases affecting large red chili plants the first step in the research involves collecting leaf images followed by preprocessing and subsequent stages of color feature extraction texture feature extraction and shape feature extraction the extracted image features serve as parameters in the classification process using the support vector machine svm and learning vector quantization lvq algorithms the accuracy of the prediction results for the training and testing data using the svm with a polynomial kernel method is 95 and 97 respectively in contrast the accuracy of the training and testing data using the lvq method is 53 and 57 respectively therefore the best model for predicting chili plant diseases is the svm model with a polynomial kernel
PREDIKSI PENGELUARAN PERKAPITA YANG DISESUAIKAN BERDASARKAN CITRA DIGITAL GOOGLE EARTH MENGGUNAKAN KOMBINASI CONVOLUTIONAL NEURAL NETWORK (CNN) DAN SUPPORT VECTOR REGRESSION(SVR).,"Rouhan, Asva Abadila",http://repository.its.ac.id/81193/,"Kemiskinan dapat didefinisikan sebagai ketidakmampuan seseorang atau rumah tangga dalam memenuhi kebutuhan pokoknya. Kebanyakan negara menggunakan pendapatan atau konsumsi rumah tangga sebagai standar pengukuran kesejahteraan penduduk. Namun, pengumpulan data secara mendetail dari pintu ke pintu merupakan hal banyak memakan waktu dan biaya. Belakangan ini muncul sumber data alternatif pengganti survei, yaitu citra digital satelit. Citra digital umumnya diolah menggunakan Convolutional Neural Network (CNN). Salah satu arsitektur CNN yang dianggap paling baik adalah VGG16. VGG16 dalam tugas akhir ini digunakan sebagai fixed feature extraction sedangkan pemodelan estimasi kemiskinan di Pulau Jawa menggunakan Support Vector Regression (SVR). Kombinasi kedua metode menghasilkan model dengan performa 0,703 pada tahap testing. Terdapat hampir 80% kesesuaian pada 25% golongan pengeluaran perkapita terendah antara hasil estimasi dan data aktual.",prediksi keluar kapita sesuai dasar citra digital google earth kombinasi convolutional neural network cnn support vector regressionsvr,miskin definisi ketidakmampuan rumah tangga penuh butuh pokok banyak negara dapat konsumsi rumah tangga standar ukur sejahtera duduk kumpul data detail pintu pintu makan biaya muncul sumber data alternatif ganti survei citra digital satelit citra digital olah convolutional neural network cnn salah arsitektur cnn anggap vgg16 vgg16 tugas fixed feature extraction model estimasi miskin pulau jawa support vector regression svr kombinasi metode hasil model performa 0703 tahap testing 80 sesuai 25 golong keluar kapita rendah hasil estimasi data aktual
Bayisehatkita: Aplikasi Berbasis Web Untuk Klasifikasi Stunting Pada Aud.,"Ruslan, Bima Triadi",http://repository.its.ac.id/88038/,"Malnutrisi merupakan permasalahan umum yang masih banyak terjadi di seluruh dunia, salah satu bentuk dari malnutrisi yang paling banyak diderita oleh anak dibawah 5 tahun adalah stunting. Indonesia masuk ke dalam region Asia Selatan dengan nilai persentase stunting yang masih berada di kategori sangat tinggi. Pada tahun 2019 stunting masih dianggap sebagai permasalahan utama dalam kesehatan masyarakat Indonesia dengan angka prevalensi sebesar 27,67%. Stunting dapat mengakibatkan penurunan kemampuan kognitif dan akademik dari anak, penurunan produktivitas, peningkatan risiko naik berat badan yang eksesif dan penyakit kronis terkait nutrisi pada saat kehidupan dewasa. Dengan angka prevalensi yang masih tinggi dan dampak yang memiliki pengaruh besar pada kehidupan anak, maka perlu diteliti lebih lanjut langkah atau cara apa yang perlu dilakukan untuk menurunkan angka prevalensi stunting di Indonesia.Dalam tugas akhir ini metode yang akan digunakan adalah Binary Logistic Regression. Metode tersebut digunakan karena dapat membandingkan beberapa independent variabel berjenis continuous dan categorical dengan variabel dependent yang terdiri dari dua kemungkinan atau dichotomous. Selain itu dengan menggunakan metode ini maka dapat diperhitungkan probabilitas dari suatu kejadian yang akan terjadi, dalam kasus ini proabilitias anak akan stunting atau probabilitas anak tidak akan stunting. Lalu untuk mengukur kinerja dari metode tersebut akan digunakan confusion matrix untuk memperhitungkan tingkat accuracy, precision, dan recall. Dataset yang akan digunakan dalam tugas akhir ini merupakan dataset Indonesian Family Life Surveys 4 (IFLS 4) dari tahun 2007 dan Indonesian Family Life Survey 5 (IFLS 5) dari tahun 2014-2015 yang diselenggarakan oleh RAND Corporation dan Surveymeter.Hasil analisis dari tugas akhir ini telah diketahui bahwa faktor yang memiliki pengaruh signifikan terhadap perubahan status stunting anak terdiri dari tinggi ayah, tinggi ibu, berat badan ibu, pendidikan ibu, area rumah, dan gender anak. Lalu dalam pengembangan model telah didapatkan bahwa model menggunakan binary logistic regression dengan parameter C bernilai 1, penalty L2 dan solver newton-cg dapat melakukan prediksi status stunting anak dengan cukup baik dengan nilai accuracy sebesar 75,05% dan f1-score sebesar 74,89%.==================================================================================================Malnutrition is a common problem that still occurs throughout the world, one of the most common forms of malnutrition that is suffered by children under years old is stunting. Indonesia is part of the Sout Asia region with a stunting percentage value that is still in the very high category. In 2019 stunting was still considered a major problem in the Indonesian public healthwith a prevalence rate of 27.67%. Stunting can lead to decreased cognitive and academic abilities of children, decreased productivity, increased risk of excessive weight gain and chronic nutrition-related disease when they grow older. With a prevalence rate that is still considered as high and the impact that has a big influence on children’s lives, it is necessary to further investigate what steps or ways that needs to be done to reduce the prevalence of stunting in Indonesia.In this final project the method that is used is binary logistic regression. This method is used based on it’s capabilities to compare several independent variable of continuous and categorical type with a dependent variable which consists of two possibilities or is dichotomous. In addition, by using this method, the probability of an event that will occur can be calculated. In this case the probability of the child being stunted or the probability that the child will not be stunted. To calculate the performance of the model, a confusion matrix will be used to calculate the level of accuracy, precision, and recall. The dataset that is used in this final project is the Indonesian Family Life Surveys 4 (IFLS 4) dataset from 2007 and the Indonesian Family Life Survey 5 (IFLS 5) from 2014-2015 organized by RAND Corporation and Surveymeter. The results of the analysis that is conducted in this final project have shown that the factors that have a significant influence on changes in a child stunting status consist of father’s height, mother’s height, mother’s weight, mother’s education, house area, and child’s gender. Then in the development of the model, it was found that the model using binary logistic regression with a parameter C with a value of 1, penalty of L2, and with the newton-cg solver can predict the stunting status quite well with an accuracy value of 75.05% and f1-score of 74.89%.",bayisehatkita aplikasi bas web klasifikasi stunting aud,malnutrisi masalah dunia salah bentuk malnutrisi derita anak bawah 5 stunting indonesia masuk region asia selatan nilai persentase stunting kategori 2019 stunting anggap masalah utama sehat masyarakat indonesia angka prevalensi 2767 stunting akibat turun mampu kognitif akademik anak turun produktivitas tingkat risiko berat badan eksesif sakit kronis kait nutrisi hidup dewasa angka prevalensi dampak milik pengaruh hidup anak teliti langkah turun angka prevalensi stunting indonesiadalam tugas metode binary logistic regression metode banding independent variabel jenis continuous categorical variabel dependent dichotomous metode hitung probabilitas jadi proabilitias anak stunting probabilitas anak stunting ukur kerja metode confusion matrix hitung tingkat accuracy precision recall dataset tugas dataset indonesian family life surveys 4 ifls 4 2007 indonesian family life survey 5 ifls 5 20142015 selenggara rand corporation surveymeterhasil analisis tugas faktor milik pengaruh signifikan ubah status stunting anak ayah berat badan didik area rumah gender anak kembang model dapat model binary logistic regression parameter c nila 1 penalty l2 solver newtoncg prediksi status stunting anak nilai accuracy 7505 f1score 7489malnutrition is a common problem that still occurs throughout the world one of the most common forms of malnutrition that is suffered by children under years old is stunting indonesia is part of the sout asia region with a stunting percentage value that is still in the very high category in 2019 stunting was still considered a major problem in the indonesian public healthwith a prevalence rate of 2767 stunting can lead to decreased cognitive and academic abilities of children decreased productivity increased risk of excessive weight gain and chronic nutritionrelated disease when they grow older with a prevalence rate that is still considered as high and the impact that has a big influence on children  s lives it is necessary to further investigate what steps or ways that needs to be done to reduce the prevalence of stunting in indonesiain this final project the method that is used is binary logistic regression this method is used based on it  s capabilities to compare several independent variable of continuous and categorical type with a dependent variable which consists of two possibilities or is dichotomous in addition by using this method the probability of an event that will occur can be calculated in this case the probability of the child being stunted or the probability that the child will not be stunted to calculate the performance of the model a confusion matrix will be used to calculate the level of accuracy precision and recall the dataset that is used in this final project is the indonesian family life surveys 4 ifls 4 dataset from 2007 and the indonesian family life survey 5 ifls 5 from 20142015 organized by rand corporation and surveymeter the results of the analysis that is conducted in this final project have shown that the factors that have a significant influence on changes in a child stunting status consist of father  s height mother  s height mother  s weight mother  s education house area and child  s gender then in the development of the model it was found that the model using binary logistic regression with a parameter c with a value of 1 penalty of l2 and with the newtoncg solver can predict the stunting status quite well with an accuracy value of 7505 and f1score of 7489
Model Optimasi (Mixed Integer Nonlinear Programming) Untuk Menentukan Struktur Rantai Pasok Pengolahan Bittern Dengan Konsolidasi.,"Ryanto, Zido Fairuz",http://repository.its.ac.id/89061/,"Garam merupakan salah satu komoditas dengan tingkat permintaan yang tinggi di Indonesia. Produksi garam terdiri dari beberapa tahap, salah satunya adalah pemisahan air dari garam. Selama proses pemisahan air dari garam, terdapat air sisa yang menjadi limbah. Air tersebut disebut sebagai air tua atau bittern. Bittern merupakan cairan pekat sebagai limbah hasil dari proses produksi garam. Bittern dibuang ke lingkungan sekitar sehingga dapat mencemari lingkungan, terutama sungai dan laut. Namun, bittern dapat diolah dan dijual kembali karena memiliki beberapa kandungan mineral yang dapat dimanfaatkan. Pengolahan bittern membutuhkan fasilitas pengolahan untuk mengolah bittern berupa bahan mentah menjadi bittern yang siap digunakan dan sebagai perantara antara produsen dan konsumen dengan fungsi sebagai fasilitas pengolahan atau gudang. Skenario yang dapat diimplementasikan adalah sentralisasi, desentralisasi dengan konsolidasi, dan campuran dengan konsolidasi. Permasalahan digambarkan melalui model mixed integer nonlinear programming (MINLP) dan penyelesaian dilakukan dengan metode GRG Nonlinear. Berdasarkan penelitian yang telah dilakukan, skenario desentralisasi dengan konsolidasi lebih layak untuk digunakan pada rantai pasok pengolahan bittern. Perubahan keputusan penggunaan skenario dipengaruhi oleh tingkat permintaan konsumen, biaya pengolahan bittern, dan biaya pembangunan fasilitas pengolahan atau gudang sebagai parameter yang paling berpengaruh.=========================================================================================================Salt is one of the commodities with a high level of demand in Indonesia. Salt production consists of several stages, one of them is the separation of water from salt. During the process, there is residual water that becomes waste. This water is known as old water or bittern. Bittern is a concentrated liquid come from the salt production process. Bitterns are thrown into the environment so it can pollute the environment, especially rivers and seas. However, bittern can be processed and resold because it has some mineral that can be used. Bittern processing requires processing facilities to process bittern in the form of raw materials to be ready to use and as intermediaries between producers and consumers with the function as processing facilities or warehouses. The scenarios that can be implemented are centralized, decentralized with consolidation, and mixed with consolidation. Problems in the bittern processing supply chain are described through a mixed integer nonlinear programming (MINLP) model and the solution is solved with GRG Nonlinear method. Based on the research that has been done, decentralized with consolidation scenario is more suitable to use in the bittern processing supply chain. Changes in decision to use scenarios are influenced by the level of consumer demand, bittern processing cost, and the cost to build processing facilities or warehouses as the most influential parameter.",model optimasi mixed integer nonlinear programming tentu struktur rantai pasok olah bittern konsolidasi,garam salah komoditas tingkat minta indonesia produksi garam tahap salah satu pisah air garam proses pisah air garam air sisa limbah air air tua bittern bittern cair pekat limbah hasil proses produksi garam bittern buang lingkung cari lingkung sungai laut bittern olah jual milik kandung mineral manfaat olah bittern butuh fasilitas olah olah bittern bahan mentah bittern antara produsen konsumen fungsi fasilitas olah gudang skenario implementasi sentralisasi desentralisasi konsolidasi campur konsolidasi masalah gambar model mixed integer nonlinear programming minlp selesai metode grg nonlinear dasar teliti skenario desentralisasi konsolidasi layak rantai pasok olah bittern ubah putus guna skenario pengaruh tingkat minta konsumen biaya olah bittern biaya bangun fasilitas olah gudang parameter berpengaruhsalt is one of the commodities with a high level of demand in indonesia salt production consists of several stages one of them is the separation of water from salt during the process there is residual water that becomes waste this water is known as old water or bittern bittern is a concentrated liquid come from the salt production process bitterns are thrown into the environment so it can pollute the environment especially rivers and seas however bittern can be processed and resold because it has some mineral that can be used bittern processing requires processing facilities to process bittern in the form of raw materials to be ready to use and as intermediaries between producers and consumers with the function as processing facilities or warehouses the scenarios that can be implemented are centralized decentralized with consolidation and mixed with consolidation problems in the bittern processing supply chain are described through a mixed integer nonlinear programming minlp model and the solution is solved with grg nonlinear method based on the research that has been done decentralized with consolidation scenario is more suitable to use in the bittern processing supply chain changes in decision to use scenarios are influenced by the level of consumer demand bittern processing cost and the cost to build processing facilities or warehouses as the most influential parameter
Semi-Kuantifikasi Electronic Nose Berdasarkan HS-SPME/GC-MS Untuk Klasifikasi Jenis Daging.,"Sabilla, Shoffi Izza",http://repository.its.ac.id/91759/,"Masyarakat membedakan jenis daging secara tradisional dengan cara melihat warna, tekstur, dan mencium aromanya. Namun, untuk membedakan potongan jenis daging menggunakan cara tradisional kurang akurat jika dilakukan oleh manusia karena warna, tekstur, dan aroma memiliki beberapa kesamaan antara jenis daging satu dengan jenis daging yang lainnya sehingga butuh keahlian khusus dan pengalaman. Selain itu, hasil yang didapat berbeda antara satu orang dengan orang yang lainnya.Saat ini, electronic nose (e-nose) telah banyak dikembangkan untuk mengidentifikasi berbagai jenis daging dengan cepat dan akurat dengan biaya produksi yang terjangkau. Namun, hasil dari e-nose tidak dapat digunakan sebagai analisis kuantitatif karena tidak dapat memberikan informasi gas atau volatile organic compound (VOC) dan jumlah kadar dari setiap VOC yang dapat membedakan antara jenis daging. Beberapa penelitian sebelumnya telah mengusulkan semi-kuantifikasi e-nose berdasarkan HS-SPME/GC-MS. Namun, hasil dari semi-kuantifikasi pada penelitian tersebut memiliki nilai eror yang tinggi dan tidak dilakukan klasifikasi kembali dari hasil semi-kuantifikasi.Penelitian ini mengusulkan untuk mengembangkan semi-kuantifikasi e- nose berdasarkan Headspace Solid-Phase Microextraction/Gas Chromatography- Mass Spectrometer (HS-SPME/GC-MS) untuk klasifikasi jenis daging. Metode optimasi hyperparameter klasifikasi berbasis Single-Objective Modified Grey Wolf Optimization Deep Neural Network (SOM-GWO-DNN) dan Multi-Objective M- GWO-DNN (MOM-GWO-DNN) yang diusulkan dapat menemukan hyperparameter klasifikasi yang optimal dan dapat digunakan untuk analisis kualitatif jenis daging pada e-nose dengan akurasi 94,03% dan 95,52%. Metode Ensemble MOM-GWO-DNN strategi one versus one (OVO) berhasil meningkatkan akurasi analisis kualitatif pada e-nose sebesar 97,02%.E-nose yang dikembangkan dapat melakukan semi-kuantifikasi dengan mengestimasi kadar %TIC dari VOC berdasarkan hasil HS-SPME/GC-MS menggunakan metode yang diusulkan yaitu Stacking MOM-GWO-DNNR dengan R2 mendekati sempurna yaitu 0,9845. Hasil estimasi kadar %TIC dari metode Stacking MOM-GWO-DNNR digunakan untuk klasifikasi jenis daging menggunakan metode MOM-GWO-DNN dengan akurasi 100% sehingga masyarakat dapat menggunakan aplikasi semi-kuantifikasi e-nose untuk klasifikasi empat jenis daging dengan efektif, efisien, portabel dan murah.",semikuantifikasi electronic nose dasar hsspmegcms klasifikasi jenis daging,masyarakat beda jenis daging tradisional warna tekstur cium aroma beda potong jenis daging tradisional akurat manusia warna tekstur aroma milik sama jenis daging jenis daging butuh ahli khusus alam hasil beda orang orang lainnyasaat electronic nose enose kembang identifikasi jenis daging cepat akurat biaya produksi jangkau hasil enose analisis kuantitatif informasi gas volatile organic compound voc kadar voc beda jenis daging teliti usul semikuantifikasi enose dasar hsspmegcms hasil semikuantifikasi teliti milik nilai eror klasifikasi hasil semikuantifikasipenelitian usul kembang semikuantifikasi e nose dasar headspace solidphase microextractiongas chromatography mass spectrometer hsspmegcms klasifikasi jenis daging metode optimasi hyperparameter klasifikasi bas singleobjective modified grey wolf optimization deep neural network somgwodnn multiobjective m gwodnn momgwodnn usul temu hyperparameter klasifikasi optimal analisis kualitatif jenis daging enose akurasi 9403 9552 metode ensemble momgwodnn strategi one versus one ovo hasil tingkat akurasi analisis kualitatif enose 9702enose kembang semikuantifikasi estimasi kadar tic voc dasar hasil hsspmegcms metode usul stacking momgwodnnr r2 dekat sempurna 09845 hasil estimasi kadar tic metode stacking momgwodnnr klasifikasi jenis daging metode momgwodnn akurasi 100 masyarakat aplikasi semikuantifikasi enose klasifikasi jenis daging efektif efisien portabel murah
Perencanaan Jalur Quadcopter dan Penghindaran Rintangan Menggunakan Algoritma Fuzzy RRT.,"Sadida, Tiara Asa",http://repository.its.ac.id/110426/,"Sistem kontrol UAV (Unmanned Aerial Vehicle) merupakan topik penelitian yang sering dikembangkan di bidang penerbangan terutama mengenai perencanaan jalur dan penghindaran rintangan di berbagai sektor, sehingga berbagai metode sering diuji untuk memperoleh hasil optimal. Berdasarkan hal tersebut, diperlukan algoritma yang efektif dan efisien untuk eksplorasi ruang pada UAV. Pada tugas akhir ini, dikembangkan dua metode Rapidly exploring Random Tree (RRT) untuk global path planning dan Fuzzy Control Logic untuk local planning refinement. Kedua metode ini dipilih karena keefektifannya dalam optimalisasi jalur pada ruang tiga dimensi dan kemampuan menyesuaikan jalur dengan keadaan sekitar. Pada tugas akhir ini dirancang simulasi dalam MATLAB yang memungkinkan quadcopter merencanakan jalur, menghindari rintangan, dan mencapai tujuan. Dengan mengombinasikan RRT dan Fuzzy Control Logic, proses eksplorasi ruang tiga dimensi dapat ditingkatkan serta menghasilkan jalur yang lebih baik, sehingga lebih efisien dan mudah diikuti oleh quadcopter. Hasil simulasi menunjukkan bahwa kombinasi RRT dan Fuzzy Control Logic mampu memperbaiki perencanaan jalur untuk quadcopter dengan pengurangan panjang jalur total sebesar 9.73% hingga 14.74% setelah fuzzy refinement, pengurangan nilai kesalahan RMSE sebesar 24.44%, MedAE sebesar 20.81%, dan pengurangan curvature serta deviasi jalurnya. ======================================================================================================================================The UAV (Unmanned Aerial Vehicle) control system is a frequently developed research topic in aviation, especially regarding path planning and obstacle avoidance in various sectors. Effective and efficient algorithms are needed for UAV space exploration. In this final project, two methods are developed: Rapidly exploring Random Tree (RRT) for global path planning and Fuzzy Control for local planning refinement. These methods were chosen for their effectiveness in optimizing paths in three dimensional space and adapting to surroundings. Therefore, a MATLAB simulation will be designed, enabling the quadcopter to plan paths, avoid obstacles, and reach destinations. Combining RRT and Fuzzy Control Logic aims to enhance three-dimensional space exploration and produce a better path, making it more efficient and easier for the quadcopter to follow. Simulation results show that the combination of RRT and Fuzzy Control Logic improves path planning for the quadcopter, with a reduction in total path length of 9.73% to 14.74% after fuzzy refinement, a reduction in RMSE error value by 24.44%, MedAE of 20.81%, and a reduction in curvature and path deviation.",rencana jalur quadcopter hindar rintang algoritma fuzzy rrt,sistem kontrol uav unmanned aerial vehicle topik teliti kembang bidang terbang rencana jalur hindar rintang sektor metode uji oleh hasil optimal dasar algoritma efektif efisien eksplorasi ruang uav tugas kembang metode rapidly exploring random tree rrt global path planning fuzzy control logic local planning refinement metode pilih efektif optimalisasi jalur ruang dimensi mampu sesuai jalur tugas rancang simulasi matlab quadcopter rencana jalur hindar rintang capai tuju kombinasi rrt fuzzy control logic proses eksplorasi ruang dimensi tingkat hasil jalur efisien mudah ikut quadcopter hasil simulasi kombinasi rrt fuzzy control logic baik rencana jalur quadcopter kurang jalur total 973 1474 fuzzy refinement kurang nilai salah rmse 2444 medae 2081 kurang curvature deviasi jalur the uav unmanned aerial vehicle control system is a frequently developed research topic in aviation especially regarding path planning and obstacle avoidance in various sectors effective and efficient algorithms are needed for uav space exploration in this final project two methods are developed rapidly exploring random tree rrt for global path planning and fuzzy control for local planning refinement these methods were chosen for their effectiveness in optimizing paths in three dimensional space and adapting to surroundings therefore a matlab simulation will be designed enabling the quadcopter to plan paths avoid obstacles and reach destinations combining rrt and fuzzy control logic aims to enhance threedimensional space exploration and produce a better path making it more efficient and easier for the quadcopter to follow simulation results show that the combination of rrt and fuzzy control logic improves path planning for the quadcopter with a reduction in total path length of 973 to 1474 after fuzzy refinement a reduction in rmse error value by 2444 medae of 2081 and a reduction in curvature and path deviation
Pelabelan dan Pembuatan Model Image Captioning Menggunakan Deep Learning.,"Safitri, Wardatul Amalia",http://repository.its.ac.id/118175/,"Kerja praktik ini dilakukan di Laboratorium Komputasi Cerdas dan Visi (KCV) Departemen Teknik Informatika Institut Teknologi Sepuluh Nopember (ITS). Kegiatan yang dilakukan memiliki tujuan untuk menghasilkan model image captioning dengan memanfaatkan deep learning. Kegiatan kerja praktik dimulai dengan membuat dataset citra trotoar dan lingkungan ITS beserta pelabelan atau pemberian deskripsi di setiap citra. Selanjutnya, dataset citra yang sudah diberi label akan diolah menjadi model image captioning dengan beberapa skenario implementasi deep learning. Metode deep learning yang diimplementasikan dalam kerja praktik ini meliputi LSTM, CNN, dan GRU. Hasil pengembangan model akan dibandingkan performanya menggunakan parameter BLEU Score dan ROUGE. Hasil evaluasi menunjukkan bahwa Dataset 1 menghasilkan performa terbaik dengan BLEU-1 51.49% dan ROUGE-1 40.05%. Metode CNN memberikan hasil terbaik dengan BLEU-1 25.56% dan ROUGE-1 23.44%. Sementara itu, fungsi aktivasi Relu memberikan performa terbaik pada hyperparameter tuning dengan BLEU-1 23.61% dan ROUGE-1 22.37%.============================================================================================================================This project was carried out at the Komputasi Cerdas dan Visi (KCV) Laboratory, Department of Informatics Engineering, Institut Teknologi Sepuluh Nopember (ITS). The activities carried out have the aim of producing an image captioning model by utilizing deep learning. This project begin with creating a dataset of images of ITS pavements and environments along with labeling or giving descriptions in each image. Furthermore, the labeled image dataset will be processed into an image captioning model with several deep learning implementation scenarios. The deep learning methods implemented in this practical work include LSTM, CNN, and GRU. The results of the model development will be compared using the BLEU Score and ROUGE parameters. The evaluation results show that Dataset 1 produces the best performance with BLEU-1 51.49% and ROUGE-1 40.05%. CNN method gives the best result with BLEU-1 25.56% and ROUGE-1 23.44%. Meanwhile, the Relu activation function gives the best performance in hyperparameter tuning with BLEU-1 23.61% and ROUGE-1 22.37%.",label buat model image captioning deep learning,kerja praktik laboratorium komputasi cerdas visi kcv departemen teknik informatika institut teknologi puluh nopember its giat milik tuju hasil model image captioning manfaat deep learning giat kerja praktik dataset citra trotoar lingkung its serta label beri deskripsi citra dataset citra label olah model image captioning skenario implementasi deep learning metode deep learning implementasi kerja praktik liput lstm cnn gru hasil kembang model banding performa parameter bleu score rouge hasil evaluasi dataset 1 hasil performa baik bleu1 5149 rouge1 4005 metode cnn hasil baik bleu1 2556 rouge1 2344 fungsi aktivasi relu performa baik hyperparameter tuning bleu1 2361 rouge1 2237this project was carried out at the komputasi cerdas visi kcv laboratory department of informatics engineering institut teknologi puluh nopember its the activities carried out have the aim of producing an image captioning model by utilizing deep learning this project begin with creating a dataset of images of its pavements and environments along with labeling or giving descriptions in each image furthermore the labeled image dataset will be processed into an image captioning model with several deep learning implementation scenarios the deep learning methods implemented in this practical work include lstm cnn and gru the results of the model development will be compared using the bleu score and rouge parameters the evaluation results show that dataset 1 produces the best performance with bleu1 5149 and rouge1 4005 cnn method gives the best result with bleu1 2556 and rouge1 2344 meanwhile the relu activation function gives the best performance in hyperparameter tuning with bleu1 2361 and rouge1 2237
Penerapan Artificial Neural Network Untuk Prediksi Energi Listrik Jangka Menengah Menggunakan Backpropagation.,"Sakhis, Badri Ainur",http://repository.its.ac.id/119006/,"Peningkatan kebutuhan energi listrik yang terus berkembang menuntut adanya sistem prediksi untuk mendukung perencanaan dan pengelolaan sumber daya energi. Penelitian ini bertujuan untuk menerapkan metode Artificial Neural Network (ANN) dengan algoritma backpropagation dalam memprediksi konsumsi energi listrik jangka menengah. Metode ini dipilih karena kemampuannya dalam menangkap pola kompleks dan hubungan non-linear dalam data historis konsumsi listrik. Oleh karena itu, penting untuk memilih metode yang tepat untuk melakukan prediksi. Untuk menguji tingkat akurasi hasil peramalan konsumsi energi listrik menggunakan perhitungan nilai Mean Absolute Error (MAE). Tujuan penelitian ini adalah menganalisis akurasi hasil peramalan dengan algoritma backpropagation. Arsitektur ANN pada penelitian ini menggunakan 36 input layer, 2 hidden layer dimana masing masing hidden layer sebanyak 10 neuron, dan 1 output layer yang merupakan total energi yang dikonsumsi. Pada penelitian ini, melakukan beberapa pengujian model dan mengatur parameter-parameter ANN setiap pengujian. Parameter tersebut meliputi banyaknya hidden layer yang digunakan, learning rate, dan epoch. Optimizer yang digunakan untuk membangun model yaitu Adaptive Moment Estimation (Adam). Hasil penelitian menyatakan bahwa dari beberapa pengujian model terdapat nilai persentase error terendah dan persentase akurasi atau valid tertinggi. Pengujian terbaik menghasilkan error sebesar 5,6%, dengan tingkat akurasi atau validasi sebesar 94,4%. Percobaan prediksi kedepannya berdasarkan input tanggal yang ditentukan menghasilkan persentase error sebesar 43% dan persentase valid sebesar 57%.=================================================================================================================================The growing demand for electrical energy requires a prediction system to support the planning and management of energy resources. This research aims to apply the Artificial Neural Network (ANN) method with the backpropagation algorithm in predicting medium-term electrical energy consumption. This method was chosen due to its ability to capture complex patterns and non-linear relationships in historical electricity consumption data. Therefore, it is important to choose the right method for prediction. To test the accuracy of electric energy consumption forecasting results using the calculation of the Mean Absolute Error (MAE) value. The purpose of this research is to analyze the accuracy of forecasting results with the backpropagation algorithm. The ANN architecture in this study uses 36 input layers, 2 hidden layers where each hidden layer is 10 neurons, and 1 output layer which is the total energy consumed. In this research, several model tests were conducted and ANN parameters were set for each test. These parameters include the number of hidden layers used, learning rate, and epoch. The optimizer used to build the model is Adaptive Moment Estimation (Adam). The results state that from several model tests there is the lowest percentage error value and the highest percentage of accuracy or validity. The best test produces an error of 5,6%, with an accuracy or validation rate of 94,4%. Future prediction experiments based on the specified date input resulted in an error percentage of 43% and a valid percentage of 57%.",terap artificial neural network prediksi energi listrik jangka tengah backpropagation,tingkat butuh energi listrik kembang tuntut sistem prediksi dukung rencana kelola sumber daya energi teliti tuju terap metode artificial neural network ann algoritma backpropagation prediksi konsumsi energi listrik jangka tengah metode pilih mampu tangkap pola kompleks hubung nonlinear data historis konsumsi listrik pilih metode prediksi uji tingkat akurasi hasil amal konsumsi energi listrik hitung nilai mean absolute error mae tuju teliti analis akurasi hasil amal algoritma backpropagation arsitektur ann teliti 36 input layer 2 hidden layer mana hidden layer 10 neuron 1 output layer total energi konsumsi teliti uji model atur parameterparameter ann uji parameter liput banyak hidden layer learning rate epoch optimizer bangun model adaptive moment estimation adam hasil teliti uji model nilai persentase error rendah persentase akurasi valid tinggi uji baik hasil error 56 tingkat akurasi validasi 944 coba prediksi depan dasar input tanggal tentu hasil persentase error 43 persentase valid 57the growing demand for electrical energy requires a prediction system to support the planning and management of energy resources this research aims to apply the artificial neural network ann method with the backpropagation algorithm in predicting mediumterm electrical energy consumption this method was chosen due to its ability to capture complex patterns and nonlinear relationships in historical electricity consumption data therefore it is important to choose the right method for prediction to test the accuracy of electric energy consumption forecasting results using the calculation of the mean absolute error mae value the purpose of this research is to analyze the accuracy of forecasting results with the backpropagation algorithm the ann architecture in this study uses 36 input layers 2 hidden layers where each hidden layer is 10 neurons and 1 output layer which is the total energy consumed in this research several model tests were conducted and ann parameters were set for each test these parameters include the number of hidden layers used learning rate and epoch the optimizer used to build the model is adaptive moment estimation adam the results state that from several model tests there is the lowest percentage error value and the highest percentage of accuracy or validity the best test produces an error of 56 with an accuracy or validation rate of 944 future prediction experiments based on the specified date input resulted in an error percentage of 43 and a valid percentage of 57
Model Optimasi Gabungan Pada Manajemen Persediaan Suku Cadang Dan Perencanaan Perawatan Dengan Mempertimbangkan Ketidakpastian Kegagalan.,"Salsabila, Nabila Yuraisyah",http://repository.its.ac.id/79796/,"Suku cadang pada umumnya termasuk dalam kelompok barang kelas C, hal ini disebabkan karena biaya dan permintaan yang rendah dibandingkan dengan barang-barang lainnya. Tetapi, ketersediaan suku cadang sangat penting untukmendukung perawatan. Salah satu masalah utama dalam manajemen persediaan suku cadang adalah meminimalkan jumlah barang yang tersimpan dalam gudang dengan mengoptimalkan parameter persediaan. Teknik optimasi pada umumnya digunakan untuk menyeimbangkan biaya persediaan dan ketersediaan suku cadang. Penelitian ini mengusulkan model optimasi gabungan dari manajemen persediaan suku cadang multi-periode multi-item dan perencanaan perawatan dengan mempertimbangkan ketidakpastian kegagalan. Pertama, model Mixed Integer Nonlinear Programing (MINLP) persediaan suku cadang diformulasikan dengan kebijakan (s, S) dengan tinjauan berkala setiap T periode. Kedua, model persediaan suku cadang ini kemudian digabungkan dengan model perencanaan pemeliharaan berkala. Ketidakpastian kegagalan dimodelkan berdasarkan distribusi probabilitas normal. Pendekatan optimasi eksak akan membutuhkan waktu komputasi yang lama untuk menyelesaikan model gabungan ini dalam skala besar. Sehingga, pendekatan metaheuristik dengan Genetic Algorithm (GA) dikembangkan untuk menyelesaikan permasalahan ini dalam skala besar. Ketiga, analisis komputasi dilakukan pada beberapa contoh dan studi kasus untuk mengevaluasi efektivitas dan efisiensi pendekatan GA yang diusulkan. Berdasarkan hasil simulasi, GA dapat menyelesaikan permasalahan berskala besar. Total biaya pada contoh studi kasus dapat menurun hingga 17,9% dibandingkan dengan kebijakan awal.============================================================================================Spare parts are often considered as Class C items, because of their low cost and low demand among the stocked items, but the availability of spare parts is essential to support maintenance requirements. Optimizing inventory parameters is the main problem of spare parts management to maintain a small number of SKUs kept in a store, and optimization techniques are commonly used to balance inventory cost and spare parts availability. Thus, this research proposes a joint optimization model of single-item multi-period spare parts inventory management and planned maintenance under uncertain failures. We present a Mixed Integer Nonlinear Programming (MINLP) formulation of the inventory optimization model under (s, S) policy with T periods of the order interval. Second, we combine this formulation with the predictive maintenance interval, representing the uncertain failures under predefined distribution. Since the model is nonlinear and stochastic, it is difficult to use exact methods to tackle it. Therefore, we combine the previously introduced MINLP formulation with a metaheuristic approach to solve the problem. Lastly, we perform a computational study on some instances and a real case study to demonstrate the proposed approach’s effectiveness and efficiency. Based on the numerical experiment results, the proposed GA performs efficiently in large scale problem and the total cost of the real case study decreased by 17.9% compared to the current policy.",model optimasi gabung manajemen sedia suku cadang rencana awat timbang ketidakpastian gagal,suku cadang kelompok barang kelas c sebab biaya minta rendah banding barangbarang sedia suku cadang untukmendukung awat salah utama manajemen sedia suku cadang minimal barang simpan gudang optimal parameter sedia teknik optimasi imbang biaya sedia sedia suku cadang teliti usul model optimasi gabung manajemen sedia suku cadang multiperiode multiitem rencana awat timbang ketidakpastian gagal model mixed integer nonlinear programing minlp sedia suku cadang formulasi bijak s s tinjau kala t periode model sedia suku cadang gabung model rencana pelihara kala ketidakpastian gagal model dasar distribusi probabilitas normal dekat optimasi eksak butuh komputasi selesai model gabung skala dekat metaheuristik genetic algorithm ga kembang selesai masalah skala tiga analisis komputasi contoh studi evaluasi efektivitas efisiensi dekat ga usul dasar hasil simulasi ga selesai masalah skala total biaya contoh studi turun 179 banding bijak awalspare parts are often considered as class c items because of their low cost and low demand among the stocked items but the availability of spare parts is essential to support maintenance requirements optimizing inventory parameters is the main problem of spare parts management to maintain a small number of skus kept in a store and optimization techniques are commonly used to balance inventory cost and spare parts availability thus this research proposes a joint optimization model of singleitem multiperiod spare parts inventory management and planned maintenance under uncertain failures we present a mixed integer nonlinear programming minlp formulation of the inventory optimization model under s s policy with t periods of the order interval second we combine this formulation with the predictive maintenance interval representing the uncertain failures under predefined distribution since the model is nonlinear and stochastic it is difficult to use exact methods to tackle it therefore we combine the previously introduced minlp formulation with a metaheuristic approach to solve the problem lastly we perform a computational study on some instances and a real case study to demonstrate the proposed approach  s effectiveness and efficiency based on the numerical experiment results the proposed ga performs efficiently in large scale problem and the total cost of the real case study decreased by 179 compared to the current policy
Sistem Deteksi Ekspresi Toileting Pada Anak Penyandang Multidisabilitas Berdasarkan Ekstraksi Fitur Menggunakan Support Vector Machine.,"Siregar, Salsabiela Khairunnisa",http://repository.its.ac.id/113488/,"Anak-anak dengan disabilitas sering menghadapi kesulitan dalam mengekspresikan keinginan mereka, termasuk saat ingin menggunakan fasilitas toilet. Hambatan ini dapat menyebabkan terjadinya masalah kesehatan ataupun masalah lainnya pada anak, seperti perilaku buang air tidak pada tempatnya. Melalui toilet training, anak akan belajar bagaimana mereka mengendalikan keinginan untuk buang air. Keberhasilan toilet training tergantung pada cara pengajaran bertahap sesuai dengan kemampuan anak. Oleh karena itu, penelitian ini bertujuan untuk menemukan parameter toileting berdasarkan ekspresi wajah anak disabilitas dengan menggunakan kamera. Kamera diposisikan di depan subjek selama kegiatan sekolah berlangsung untuk merekam perubahan ekspresi. Hasil citra akuisisi akan dipilih untuk dibuat dataset berdasarkan perubahan ekspresi yang muncul pada saat kondisi toileting. Ekstraksi fitur dilakukan dari 51 titik landmark wajah untuk mendapatkan nilai sudut, jarak, kemiringan antar titik landmark elemen wajah. Dataset TOP5 dan TOP10 dibuat menggunakan fitur-fitur dengan nilai korelasi pearson tertinggi. Proses klasifikasi menggunakan Support Vector Machine (SVM) menunjukkan bahwa model dengan dataset TOP5 mencapai akurasi tertinggi sebesar 96% dengan kombinasi parameter C=25 dan γ=0.001, menggunakan cross validation 5-folds. Model ini menunjukkan kinerja yang baik dengan nilai precision, recall, dan F1-score yang tinggi. Sistem deteksi ekspresi toileting ini memiliki beberapa kendala pada proses pengambilan data yang membutuhkan banyak pengondisian subjek. Selain itu, terdapat beberapa kesalahan klasifikasi yang perlu diatasi untuk mendapatkan hasil yang lebih baik. Untuk meningkatkan kemampuan dan generalisasi sistem dalam mendeteksi ekspresi toileting, diperlukan dilakukan penambahan jumlah dan variasi dataset dengan melibatkan subjek dari berbagai jenis disabilitas.=========================================================================================Children with disabilities often face challenges in expressing their needs, including when they wish to use toilet facilities. These barriers can lead to health issues or other problems, such as inappropriate toileting behaviors. Toilet training helps children learn to control their urges to urinate or defecate, and its success relies on gradual teaching methods tailored to the child`s abilities. Therefore, this study aims to identify toileting parameters based on the facial expressions of children with disabilities using a camera system. The camera is positioned in front of the subjects during school activities to capture expression changes. The acquired images are selected to create a dataset based on the expression changes observed during toileting events. Feature extraction is performed using 51 facial landmark points to obtain angles, distances, and inclinations between these points. TOP5 and TOP10 datasets are generated using features with the highest Pearson correlation values. The classification process using Support Vector Machine (SVM) demonstrated that the model with the TOP5 dataset achieved the highest accuracy of 96%, with parameter settings of C=25 and γ=0.001, utilizing 5-fold cross validation. This model exhibits robust performance with high precision, recall, and F1-score metrics. Despite this, the toileting expression detection system faces challenges in data collection, such as the extensive conditioning required for data collection and some misclassification errors that need to be addressed for improved results. To enhance the system`s capability and generalization in detecting toileting expressions, it is essential to increase the number and diversity of datasets by involving subjects with various types of disabilities.",sistem deteksi ekspresi toileting anak sandang multidisabilitas dasar ekstraksi fitur support vector machine,anakanak disabilitas hadap sulit ekspresi fasilitas toilet hambat sebab sehat anak perilaku buang air tempat toilet training anak ajar kendali buang air hasil toilet training gantung ajar tahap sesuai mampu anak teliti tuju temu parameter toileting dasar ekspresi wajah anak disabilitas kamera kamera posisi subjek giat sekolah rekam ubah ekspresi hasil citra akuisisi pilih dataset dasar ubah ekspresi muncul kondisi toileting ekstraksi fitur 51 titik landmark wajah nilai sudut jarak miring titik landmark elemen wajah dataset top5 top10 fiturfitur nilai korelasi pearson tinggi proses klasifikasi support vector machine svm model dataset top5 capai akurasi tinggi 96 kombinasi parameter c25 0001 cross validation 5folds model kerja nilai precision recall f1score sistem deteksi ekspresi toileting milik kendala proses ambil data butuh kondisi subjek salah klasifikasi atas hasil tingkat mampu generalisasi sistem deteksi ekspresi toileting tambah variasi dataset libat subjek jenis disabilitaschildren with disabilities often face challenges in expressing their needs including when they wish to use toilet facilities these barriers can lead to health issues or other problems such as inappropriate toileting behaviors toilet training helps children learn to control their urges to urinate or defecate and its success relies on gradual teaching methods tailored to the childs abilities therefore this study aims to identify toileting parameters based on the facial expressions of children with disabilities using a camera system the camera is positioned in front of the subjects during school activities to capture expression changes the acquired images are selected to create a dataset based on the expression changes observed during toileting events feature extraction is performed using 51 facial landmark points to obtain angles distances and inclinations between these points top5 and top10 datasets are generated using features with the highest pearson correlation values the classification process using support vector machine svm demonstrated that the model with the top5 dataset achieved the highest accuracy of 96 with parameter settings of c25 and 0001 utilizing 5fold cross validation this model exhibits robust performance with high precision recall and f1score metrics despite this the toileting expression detection system faces challenges in data collection such as the extensive conditioning required for data collection and some misclassification errors that need to be addressed for improved results to enhance the systems capability and generalization in detecting toileting expressions it is essential to increase the number and diversity of datasets by involving subjects with various types of disabilities
Deteksi Kecacatan Perangkat Lunak Menggunakan Support Vector Machine Teroptimasi Berbasis Grey Wolf Optimizer dan Random Walk.,"Siswantoro, Muhammad Zain Fawwaz Nuruddin",http://repository.its.ac.id/118354/,"Deteksi kecacatan perangkat lunak merupakan proses penting dalam pengembangan perangkat lunak untuk mengidentifikasi sebagai bug sehingga aplikasi dapat berfungsi tanpa kesalahan. Namun, proses ini sering memakan biaya dan waktu. Penelitian ini mengusulkan penggunaan Support Vector Machine (SVM) yang hyperparameter-nya dioptimasi menggunakan Grey Wolf Optimizer (GWO) yang dipadukan dengan Random Walk (RW). Selain itu penelitian ini juga menggunakan Principal Component Analysis (PCA) sebagai pengurangan dimensi fitur dan juga oversampling dengan Synthetic Minority Over-sampling Technique (SMOTE) untuk menyeimbangkan dataset. Hasil dari penelitian ini menunjukan bahwa GWO yang dipadukan dengan RW mampu meningkatkan akurasi SVM dalam mengklasifikasi deteksi kecacatan perangkat lunak dibandingkan dengan optimasi lain, dengan akurasi berkisar antara 76,26% - 98,21% dan rata-rata akurasi 87,03% pada berbagai dataset, sehingga membuktikan efektivitasnya dalam deteksi kecacatan perangkat lunak.=================================================================================================================================Software defect detection is an important process in software development to identify as a bug so that the application can function without errors. However, this process is often costly and time consuming. This study proposes the use of Support Vector Machine (SVM) whose hyperparameters are optimized using Grey Wolf Optimizer (GWO) combined with Random Walk (RW). In addition, this study also uses Principal Component Analysis (PCA) as a feature dimension reduction and also oversampling with Synthetic Minority Over-sampling Technique (SMOTE) to balance the dataset. The results of this study show that GWO combined with RW is able to increase the accuracy of SVM in classifying software defect detection compared to other optimizations, with an accuracy ranging from 76.26% - 98.21% and an average accuracy of 87.03% on various datasets, thus proving its effectiveness in software defect detection.",deteksi cacat perangkat lunak support vector machine teroptimasi bas grey wolf optimizer random walk,deteksi cacat perangkat lunak proses kembang perangkat lunak identifikasi bug aplikasi fungsi salah proses makan biaya teliti usul guna support vector machine svm hyperparameternya dioptimasi grey wolf optimizer gwo padu random walk rw teliti principal component analysis pca kurang dimensi fitur oversampling synthetic minority oversampling technique smote imbang dataset hasil teliti tunjuk gwo padu rw tingkat akurasi svm klasifikasi deteksi cacat perangkat lunak banding optimasi akurasi kisar 7626 9821 ratarata akurasi 8703 dataset bukti efektivitas deteksi cacat perangkat lunaksoftware defect detection is an important process in software development to identify as a bug so that the application can function without errors however this process is often costly and time consuming this study proposes the use of support vector machine svm whose hyperparameters are optimized using grey wolf optimizer gwo combined with random walk rw in addition this study also uses principal component analysis pca as a feature dimension reduction and also oversampling with synthetic minority oversampling technique smote to balance the dataset the results of this study show that gwo combined with rw is able to increase the accuracy of svm in classifying software defect detection compared to other optimizations with an accuracy ranging from 7626 9821 and an average accuracy of 8703 on various datasets thus proving its effectiveness in software defect detection
SEGMENTASI DAN EKSTRAKSI CIRI CITRA SEL DARAH PUTIH UNTUK KLASIFIKASI LEUKEMIA AKUT.,"Siti Fatonah, Nenden",http://repository.its.ac.id/77972/,"Penyakit leukemia adalah penyakit yang sangat berbahaya dan mematikan. Penyakit leukemia disebabkan oleh gagalnya kematangan sel-sel yang dihasilkan oleh sumsum tulang dan menyebar keseluruh tubuh. Perhitungan dan analisa sel darah putih saat ini hanya bisa dilakukan oleh ahli hematologi atau dokter di laboratorium dan hasil diagnosa bersifat subyektif berdasarkan pengalaman dokter. Perhitungan dan analisa sel darah putih secara otomatis sangat diperlukan agar lebih mudah dalam membantu dokter melakukan diagnosa penyakit misalnya leukemia. Leukemia akut merupakan penyakit leukemia yang paling banyak diderita pasien. Pengembangan sistem deteksi jenis leukemia akut secara otomatis berdasarkan citra mikroskopis dibagi menjadi tiga tahapan yaitu segmentasi sel darah putih, ekstraksi ciri sel darah putih, dan klasifikasi. Kendala pertama pada segmentasi sel darah putih adalah variasi staining (pewarnaan) pada citra mikroskopis sel darah sehingga perlu metode segmentasi yang bisa menangani permasalahan tersebut. Kendala kedua adalah segmentasi multi sel darah putih yaitu adanya sel-sel yang bersentuhan sehingga perlu dikembangkan metode pemisahan sel yang lebih baik agar perhitungan jumlah sel serta hasil ekstraksi ciri lebih akurat untuk proses klasifikasi. Metode pemisahan sel-sel bersentuhan yang sudah dilakukan penelitian-penelitian sebelumnya masih terkendala adanya oversegmen, undersegmen, dan estimasi kontur sel darah putih yang kurang akurat.Penelitian ini mengusulkan perbaikan metode segmentasi sel darah putih dan melakukan ekstraksi ciri pada citra mikroskopik sel darah untuk klasifikasi jenis leukemia akut. Untuk mendapatkan hasil klasifikasi yang akurat, metode segmentasi sel darah putih yang dikembangkan harus mendapatkan area sel darah putih dengan baik khususnya sel-sel yang bersentuhan sehingga pada tahapan ekstraksi ciri dapat menghasilkan ciri yang merepresentasikan karakteristik sel darah putih dengan baik. Tahapan segmentasi sel darah putih meliputi segmentasi area sel darah putih yaitu area nukleus dan sitoplasma, deteksi sel bersentuhan dan perhitungan jumlah sel, serta estimasi kontur hasil pemisahan sel yang bersentuhan. Sedangkan tahapan ekstraksi ciri adalah ekstraksi ciri warna, bentuk, dan tekstur pada area nukleus dan sitoplasma sel darah putih. Tahapan terakhir melakukan klasifikasi untuk mendapatkan jenis leukemia akut Acute Lymphocytic Leukemia (ALL) yang mempunyai tiga tipe yaitu L1, L2, dan L3. Dataset yang digunakan adalah data pada citra mikroskopis apusan darah tepi ALL yang disediakan oleh Labati, dkk dan dikumpulkan oleh pakar di Pusat Penelitian Tettamanti, Tettamanti Research. Serta menggunakan data citra bone marrow jenis Acute Lymphocytic Leukemia (ALL) dan Acute Myelotic Leukemia (AML) dari RSUD Dr. Soetomo Surabaya. Dari hasil ujicoba yang sudah dilakukan menunjukkan metode segmentasi sel darah putih yang diusulkan meliputi deteksi sel bersentuhan dan estimasi kontur single sel lebih baik dibandingkan metode sebelumnya. Metode segmentasi sel darah putih yang diusulkan kemudian digunakan untuk klasifikasi jenis ALL menghasilkan sensitivitas yang lebih tinggi dibandingkan metode lainnya.",segmentasi ekstraksi ciri citra sel darah putih klasifikasi leukemia akut,sakit leukemia sakit bahaya mati sakit leukemia sebab gagal matang selsel hasil sumsum tulang sebar seluruh tubuh hitung analisa sel darah putih ahli hematologi dokter laboratorium hasil diagnosa sifat subyektif dasar alam dokter hitung analisa sel darah putih otomatis mudah bantu dokter diagnosa sakit leukemia leukemia akut sakit leukemia derita pasien kembang sistem deteksi jenis leukemia akut otomatis dasar citra mikroskopis bagi tahap segmentasi sel darah putih ekstraksi ciri sel darah putih klasifikasi kendala segmentasi sel darah putih variasi staining warna citra mikroskopis sel darah metode segmentasi tangan masalah kendala segmentasi multi sel darah putih selsel sentuh kembang metode pisah sel hitung sel hasil ekstraksi ciri akurat proses klasifikasi metode pisah selsel sentuh penelitianpenelitian kendala oversegmen undersegmen estimasi kontur sel darah putih akuratpenelitian usul baik metode segmentasi sel darah putih ekstraksi ciri citra mikroskopik sel darah klasifikasi jenis leukemia akut hasil klasifikasi akurat metode segmentasi sel darah putih kembang area sel darah putih selsel sentuh tahap ekstraksi ciri hasil ciri representasi karakteristik sel darah putih tahap segmentasi sel darah putih liput segmentasi area sel darah putih area nukleus sitoplasma deteksi sel sentuh hitung sel estimasi kontur hasil pisah sel sentuh tahap ekstraksi ciri ekstraksi ciri warna bentuk tekstur area nukleus sitoplasma sel darah putih tahap klasifikasi jenis leukemia akut acute lymphocytic leukemia all tipe l1 l2 l3 dataset data citra mikroskopis apusan darah tepi all sedia labati dkk kumpul pakar pusat teliti tettamanti tettamanti research data citra bone marrow jenis acute lymphocytic leukemia all acute myelotic leukemia aml rsud dr soetomo surabaya hasil ujicoba metode segmentasi sel darah putih usul liput deteksi sel sentuh estimasi kontur single sel banding metode metode segmentasi sel darah putih usul klasifikasi jenis all hasil sensitivitas banding metode
Prediksi Drop Pressure Dan Over Pressure Pada Jaringan Pipa Distribusi Gas Bumi Menggunakan Machine Learning.,"Supriatna, Reza Yudistira",http://repository.its.ac.id/117602/,"Menjaga stabilitas distribusi gas bumi sangat penting untuk memastikan pasokan energi yang dapat diandalkan dan mendukung tujuan energi yang berkelanjutan. Pemantauan dan simulasi secara real time sangat penting untuk mengelola gangguan pasokan sehingga menyebabkan fluktuasi tekanan yang dapat membahayakan jika tidak segera ditangani, serta dapat menyebabkan penurunan produksi sehingga berdampak kepada revenue perusahaan dan risiko keselamatan pada peralatan. Kondisi tekanan over pressure dapat mendorong sistem untuk melampaui batas operasional yang aman, sehingga mengancam infrastruktur dan personel yang berada di sekitar peralatan. Menstabilkan jaringan distribusi tidak hanya mengatasi masalah keselamatan tetapi juga meningkatkan efisiensi energi, mengurangi limbah, dan mendukung upaya keberlanjutan. Studi ini mengevaluasi empat model prediktif ARIMAX, SARIMAX, random forest regression, dan linear regression untuk mengurangi risiko dan meningkatkan pengambilan keputusan operasional dalam distribusi gas alam. Model-model tersebut dinilai dengan menggunakan metrik kinerja utama, termasuk Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), dan Mean Absolute Percentage Error (MAPE), untuk mengidentifikasi metode yang paling akurat dan dapat diandalkan untuk prediksi waktu nyata. Mengingat risiko operasional dan keuangan yang terkait dengan ketidakseimbangan pasokan, memilih model prediksi yang tepat sangat penting untuk menjaga stabilitas jaringan dan meminimalkan potensi kerugian. Temuan ini menunjukkan bahwa random forest regression memberikan akurasi tertinggi dalam pengujian di dunia nyata dimana memiliki nilai MAPE 2.264, menjadikannya model yang paling cocok untuk memprediksi fluktuasi tekanan yang kompleks. Sebaliknya, linear regression kurang efektif karena variabilitasnya yang lebih tinggi ketika menangani kompleksitas manajemen tekanan memiliki nilai MAPE sebesar 31.714. Pada akhirnya, memilih model prediktif yang tepat adalah kunci untuk memastikan stabilitas jaringan, mengurangi risiko, dan mempromosikan praktik energi yang berkelanjutan.",prediksi drop pressure over pressure jaring pipa distribusi gas bumi machine learning,jaga stabilitas distribusi gas bumi pasok energi andal dukung tuju energi lanjut pantau simulasi real time kelola ganggu pasok sebab fluktuasi tekan bahaya tangan sebab turun produksi dampak revenue usaha risiko selamat alat kondisi tekan over pressure dorong sistem lampau batas operasional aman ancam infrastruktur personel alat stabil jaring distribusi atas selamat tingkat efisiensi energi kurang limbah dukung upaya lanjut studi evaluasi model prediktif arimax sarimax random forest regression linear regression kurang risiko tingkat ambil putus operasional distribusi gas alam modelmodel nilai metrik kerja utama mean squared error mse root mean squared error rmse mean absolute error mae mean absolute percentage error mape identifikasi metode akurat andal prediksi nyata risiko operasional uang kait ketidakseimbangan pasok pilih model prediksi jaga stabilitas jaring minimal potensi rugi temu random forest regression akurasi tinggi uji dunia nyata mana milik nilai mape 2264 jadi model cocok prediksi fluktuasi tekan kompleks linear regression efektif variabilitas tangan kompleksitas manajemen tekan milik nilai mape 31714 pilih model prediktif kunci stabilitas jaring kurang risiko promosi praktik energi lanjut
Entity Matching Menggunakan Large Language Model dan Knowledge Graph untuk Mencari Redundansi Fitur dalam Software Specification.,"Syaifudin, Mohamad Fahmi",http://repository.its.ac.id/117535/,"Dalam Software Development Lifecycle (SDLC), berbagai dokumentasi software pendukung dihasilkan, salah satunya adalah dokumen software specification, yang berisi deskripsi fitur yang dibangun. Permasalahan umum dalam pengembangan software adalah munculnya requirement baru yang mirip dengan fungsionalitas modul yang sudah ada. Masalah ini dapat diatasi dengan memanfaatkan entity matching (EM) untuk mendeteksi redundansi antar fitur dalam software atau modul yang berbeda. EM bertujuan untuk menentukan apakah dua entitas yang berbeda mengacu pada entitas yang sama. Pendekatan EM tradisional umumnya menggunakan rule-based, deep learning, atau machine learning. Penelitian ini mengusulkan pendekatan entity matching menggunakan Large Language Model (LLM) dan Knowledge Graph (KG). Dataset yang digunakan dalam penelitian ini antara lain dari dokumen panduan user Odoo, dokumen panduan Zoho Commerce, dan dokumen public user requirement. Entitas dan relasi diekstrak dan dirubah kedalam dimensi vector melalui proses knowledge embedding. Neo4j digunakan untuk menyimpan KG dan memanfaatkan vektor index mencari entitas atau relasi yang relevan untuk EM. Penelitian ini menggunakan metode sentence-based dan graph-based dalam EM. Sentence-based matching memiliki F1-score 0.762, lebih tinggi dibandingkan metode graph-based dengan F1-score maksimum 0.471. Namun, graph-based matching unggul pada Mean Reciprocal Rank dengan nilai 0.660 dibandingkan sentence-based yang hanya 0.477. Keunggulan lain dari graph-based adalah ketidakbergantungannya pada jenis word embedding, yang ditunjukkan oleh konsistensi F1-score dalam rentang 0.4 sampai 0.5 untuk berbagai variasi model embedding.==============================================================================================================================In the Software Development Lifecycle (SDLC), various supporting software documentation is produced, one of which is the software specification document that contains a description of the features being developed. A common issue in software development is the emergence of new requirements that are similar to the functionalities of existing modules. This can be addressed by leveraging entity matching (EM) to identify redundancies between features in different software or modules. EM aims to determine whether two different entities refer to the same entity. Traditional EM approaches generally use rule-based, deep learning, or machine learning methods. This study proposes an entity matching approach using a Large Language Model (LLM) and a Knowledge Graph (KG). The datasets used in this research include user guide documents from Odoo, Zoho Commerce user guide documents, and public user requirement documents. Entities and relationships are extracted and transformed into vector dimensions through a knowledge embedding process. Neo4j is used to store the KG and to utilize vector indexing for finding relevant entities or relationships for EM. This research employs both sentence-based and graph-based methods in EM. Sentence-based matching achieved an F1-score of 0.762, which is higher than the graph-based method with a maximum F1-score of 0.471. However, graph-based matching outperformed in Mean Reciprocal Rank (MRR) with a score of 0.660 compared to 0.477 for the sentence-based approach. Another advantage of the graph-based method is its independence from the type of word embedding, as indicated by the consistent F1-score range of 0.4 to 0.5 across various embedding model variations.",entity matching large language model knowledge graph cari redundansi fitur software specification,software development lifecycle sdlc dokumentasi software dukung hasil salah satu dokumen software specification isi deskripsi fitur bangun masalah kembang software muncul requirement fungsionalitas modul atas manfaat entity matching em deteksi redundansi fitur software modul beda em tuju tentu entitas beda acu entitas dekat em tradisional rulebased deep learning machine learning teliti usul dekat entity matching large language model llm knowledge graph kg dataset teliti dokumen pandu user odoo dokumen pandu zoho commerce dokumen public user requirement entitas relasi ekstrak rubah dalam dimensi vector proses knowledge embedding neo4j simpan kg manfaat vektor index cari entitas relasi relevan em teliti metode sentencebased graphbased em sentencebased matching milik f1score 0762 banding metode graphbased f1score maksimum 0471 graphbased matching unggul mean reciprocal rank nilai 0660 banding sentencebased 0477 unggul graphbased ketidakbergantungannya jenis word embedding konsistensi f1score rentang 04 05 variasi model embeddingin the software development lifecycle sdlc various supporting software documentation is produced one of which is the software specification document that contains a description of the features being developed a common issue in software development is the emergence of new requirements that are similar to the functionalities of existing modules this can be addressed by leveraging entity matching em to identify redundancies between features in different software or modules em aims to determine whether two different entities refer to the same entity traditional em approaches generally use rulebased deep learning or machine learning methods this study proposes an entity matching approach using a large language model llm and a knowledge graph kg the datasets used in this research include user guide documents from odoo zoho commerce user guide documents and public user requirement documents entities and relationships are extracted and transformed into vector dimensions through a knowledge embedding process neo4j is used to store the kg and to utilize vector indexing for finding relevant entities or relationships for em this research employs both sentencebased and graphbased methods in em sentencebased matching achieved an f1score of 0762 which is higher than the graphbased method with a maximum f1score of 0471 however graphbased matching outperformed in mean reciprocal rank mrr with a score of 0660 compared to 0477 for the sentencebased approach another advantage of the graphbased method is its independence from the type of word embedding as indicated by the consistent f1score range of 04 to 05 across various embedding model variations
Prediksi Tipe Kepribadian Berdasaran Myers-Briggs Type Indicator Menggunakan Metode Klasifikasi Kolmogorov-Arnold Networks.,"Syamsudin, Afifah Nur Sabrina",http://repository.its.ac.id/117237/,"Pembahasan mengenai prediksi tipe kepribadian di media sosial telah meningkat pesat dalam beberapa tahun terakhir. Salah satu tes kepribadian yang ramai diperbincangkan adalah Myers-Briggs Type Indicator (MBTI). MBTI merupakan sebuah metode penilaian kepribadian yang mengklasifikasikan individu ke dalam salah satu dari 16 tipe kepribadian berdasarkan empat dimensi utama: Ekstroversi-Introversi, Sensing-Intuition, Thinking-Feeling, dan Judging-Perceiving. Terdapat banyak cara dalam memprediksi kepribadian seseorang salah satunya melalui analisis tipe kepribadian berdasarkan tulisan di media sosial, metode yang umum digunakan melibatkan beberapa tahapan analisis teks dan pemrosesan bahasa. Pada penelitian ini akan dipelajari proses dan kinerja dari model klasifikasi KAN. Metode klasifikasi baru ini diharapkan dapat digunakan sebagai cara untuk mengkategorikan teks ke dalam tipe kepribadian yang sesuai. Hasil dari penelitian ini nantinya diharapkan dapat mengetahui penggunaan kata pada unggahan media sosial terhadap tipe kepribadian seseorang serta kinerja model klasifikasi dalam mengenali tipe kepribadian berdasarkan aktivitas media sosial. Hasil dari uji coba pada implementasi metode KAN mendapatkan akurasi data uji senilai 0,2545.===================================================================================================================================Discussions about personality type prediction on social media have increased rapidly in recent years. One of the most discussed personality tests is the Myers-Briggs Type Indicator (MBTI). MBTI is a personality assessment method that classifies individuals into one of 16 personality types based on four main dimensions: Extroversion-Introversion, Sensing-Intuition, Thinking-Feeling, and Judging-Perceiving. There are many ways to predict a person's personality, one of which is through analyzing personality types based on social media posts, a commonly used method involving several stages of text analysis and language processing. In this research, the process and performance of the KAN classification model will be explained. This new classification method is expected to be used to categorize text into the appropriate personality type. The results of this research are expected to determine the use of words in social media posts on a person's personality type and the performance of the classification model in recognizing personality types based on social media activities. The results of the trial on the KAN method show that the implementation gets a test data metric accuracy of 0.2545.",prediksi tipe pribadi dasar myersbriggs type indicator metode klasifikasi kolmogorovarnold networks,bahas prediksi tipe pribadi media sosial tingkat pesat salah tes pribadi ramai bincang myersbriggs type indicator mbti mbti metode nilai pribadi klasifikasi individu salah 16 tipe pribadi dasar dimensi utama ekstroversiintroversi sensingintuition thinkingfeeling judgingperceiving prediksi pribadi salah satu analisis tipe pribadi dasar tulis media sosial metode libat tahap analisis teks pemrosesan bahasa teliti ajar proses kerja model klasifikasi metode klasifikasi harap kategori teks tipe pribadi sesuai hasil teliti harap guna unggah media sosial tipe pribadi kerja model klasifikasi nali tipe pribadi dasar aktivitas media sosial hasil uji coba implementasi metode akurasi data uji nila 02545discussions about personality type prediction on social media have increased rapidly in recent years one of the most discussed personality tests is the myersbriggs type indicator mbti mbti is a personality assessment method that classifies individuals into one of 16 personality types based on four main dimensions extroversionintroversion sensingintuition thinkingfeeling and judgingperceiving there are many ways to predict a persons personality one of which is through analyzing personality types based on social media posts a commonly used method involving several stages of text analysis and language processing in this research the process and performance of the classification model will be explained this new classification method is expected to be used to categorize text into the appropriate personality type the results of this research are expected to determine the use of words in social media posts on a persons personality type and the performance of the classification model in recognizing personality types based on social media activities the results of the trial on the method show that the implementation gets a test data metric accuracy of 02545
Perancangan Penyelesaian Kinematika Balik Pada Posisi Dan Orientasi End Effector Robot Open Manipulator-X Dengan Metode Neural Network.,"Syauqi, Muhammad Yavi Marsa",http://repository.its.ac.id/98932/,"Robot manipulator merupakan bukti dari perkembangan teknologi otomasi di era 4.0 saat ini, Robot yang memiliki 4 degree of freedom (DoF) dalam pergerakannya merupakan salah satu sistem yang biasa digunakan untuk mengefisiensi dan mengurangi resiko kecelakaan pada dunia Industri. Namun, pada penyelesaian kinematika balik robot manipulator terdapat permasalahan dimana terdapat multi solution dalam mendapatkan nilai sudut keluaran pada setiap joint. Oleh sebab itu, Penelitian ini bertujuan untuk menyelesaikan permasalahan kinematika balik tersebut menggunakan metode neural network menggunakan Robot Open Manipulator-X. Penelitian ini dilakukan dengan pengambilan dataset dengan kinematika maju, perancangan model neural network dengan melakukan pengujian pada jumlah neuron, hidden layer, dan learning rate, serta pembuktian dengan pengujian titik dari hasil neural network pada robot melalui simulasi pada gazebo dan real plant. Hasil dari peneletian ini yaitu metode neural network dapat menemukan single solution sebagai penyelesaian kinematika balik untuk Robot Open Manipulator-X dengan rata-rata error posisi dan orientasi sebesar (0.36 ± 0.06) cm dan (3.224±2.942)° pada simulasi, serta (0.37 ± 0.06) cm dan (3.224±2.942)° pada real plant.====================================================================================================================================Manipulator robot is evidence of the technological advancement in automation in the current era of Industry 4.0. A robot with 4 degrees of freedom (DoF) in its movement is commonly used to improve efficiency and reduce the risk of accidents in the industrial world. However, there is a problem in solving the inverse kinematics of robot manipulators where multiple solutions exist in obtaining the angle values for each joint. Therefore, this research aims to solve the inverse kinematics problem using a neural network method with the Robot Open Manipulator-X. The research involves collecting a dataset with forward kinematics, designing a neural network model by testing various configurations such as the number of neurons, hidden layers, and learning rate, and validating the results through point testing of the neural network's output on the robot using simulations in Gazebo and real plant environments. The result of this research is that the neural network method can find a single solution as the inverse kinematics solution for the Robot Open Manipulator-X with an average position error of (0.36 ± 0.06) cm and orientation error of (3.224±2.942)° in simulation, as well as (0.37 ± 0.06) cm and (3.224±2.942)° in the real plant.",ancang selesai kinematika posisi orientasi end effector robot open manipulatorx metode neural network,robot manipulator bukti kembang teknologi otomasi era 40 robot milik 4 degree of freedom dof gera salah sistem efisiensi kurang resiko celaka dunia industri selesai kinematika robot manipulator masalah mana multi solution nilai sudut keluar joint teliti tuju selesai masalah kinematika metode neural network robot open manipulatorx teliti ambil dataset kinematika maju ancang model neural network uji neuron hidden layer learning rate bukti uji titik hasil neural network robot simulasi gazebo real plant hasil peneletian metode neural network temu single solution selesai kinematika robot open manipulatorx ratarata error posisi orientasi 036  006 cm 3224 2942 simulasi 037  006 cm 3224 2942 real plantmanipulator robot is evidence of the technological advancement in automation in the current era of industry 40 a robot with 4 degrees of freedom dof in its movement is commonly used to improve efficiency and reduce the risk of accidents in the industrial world however there is a problem in solving the inverse kinematics of robot manipulators where multiple solutions exist in obtaining the angle values for each joint therefore this research aims to solve the inverse kinematics problem using a neural network method with the robot open manipulatorx the research involves collecting a dataset with forward kinematics designing a neural network model by testing various configurations such as the number of neurons hidden layers and learning rate and validating the results through point testing of the neural networks output on the robot using simulations in gazebo and real plant environments the result of this research is that the neural network method can find a single solution as the inverse kinematics solution for the robot open manipulatorx with an average position error of 036  006 cm and orientation error of 3224 2942 in simulation as well as 037  006 cm and 3224 2942 in the real plant
Identifikasi Normality Shift dalam Deteksi Anomali dengan Pendekatan Uji Distribusi.,"Talasari, Resky Ayu Dewi",http://repository.its.ac.id/116720/,"Seiring dengan pesatnya perkembangan teknologi jaringan dan internet, serta meningkatnya ancaman yang beragam dan sulit dideteksi, deteksi anomali menjadi sangat penting, event logs dapat digunakan untuk mencatat setiap aktivitas yang terjadi dan digunakan untuk mendeteksi anomali. Salah satu pendekatan untuk mendeteksi anomali pada event logs adalah berbasis rekonstruksi menggunakan deep learning dengan mempelajari pola normal data, namun tantangannya terletak pada normality shift, yaitu perubahan pola normal data yang dipelajari model. Penelitian ini berfokus pada deteksi normality shift dalam data Windows Event Logs dan Sysmon, menggunakan uji distribusi Jensen Shannon Divergence (JSD) dan Hellinger Distance (HD), hasil penelitian menunjukkan bahwa HD mampu mendeteksi distribution shift dengan baik pada skenario distribution shift kecil dan besar. Proses filtering data dapat mempengaruhi kinerja model deteksi anomali pada skenario distribution shift kecil dengan peningkatan 66% pada precision, 63% pada recall, 40% pada f1-Score dan AUC Score. Namun, model deteksi anomali tidak mampu menghadapi skenario distribution shift besar dengan penurunan performa pada precision, recall, f1-score, dan AUC score. Karena proses filtering data yaitu proses mengidentifikasi data treatment yang berada dalam rentang batas atas dan bawah data control sebagai normal sehingga membuat model deteksi anomali bergantung pada pola normalitas awal pada data control (data training).=================================================================================================================================Along with the rapid development of network and internet technology, as well as the increase in diverse and difficult-to-detect threats, anomaly detection is very important, event logs can be used to record every activity that occurs and used to detect anomalies. One approach to detect anomalies in event logs is reconstruction-based using deep learning by learning the normal pattern of the data, but the challenge lies in normality shift, which is the change in the normal pattern of the data that the model learns. This research focuses on normality shift detection in Windows Event Logs and Sysmon data, using Jensen Shannon Divergence (JSD) and Hellinger Distance (HD) distribution tests, the results show that HD is able to detect distribution shifts well in small and large distribution shift scenarios. The data filtering process can affect the performance of the anomaly detection model in the small distribution shift scenario with an increase of 66% in precision, 63% in recall, 40% in f1-Score and AUC Score.However, the anomaly detection model is not able to deal with large distribution shift scenarios with decreased performance in precision, recall, f1-score, and AUC score. Due to the data filtering process, which is the process of identifying treatment data that is within the upper and lower limits of the control data as normal, the anomaly detection model depends on the initial normality pattern in the control data (training data).",identifikasi normality shift deteksi anomali dekat uji distribusi,iring pesat kembang teknologi jaring internet tingkat ancam agam sulit deteksi deteksi anomali event logs catat aktivitas deteksi anomali salah dekat deteksi anomali event logs bas rekonstruksi deep learning ajar pola normal data tantang letak normality shift ubah pola normal data ajar model teliti fokus deteksi normality shift data windows event logs sysmon uji distribusi jensen shannon divergence jsd hellinger distance hd hasil teliti hd deteksi distribution shift skenario distribution shift proses filtering data pengaruh kerja model deteksi anomali skenario distribution shift tingkat 66 precision 63 recall 40 f1score auc score model deteksi anomali hadap skenario distribution shift turun performa precision recall f1score auc score proses filtering data proses identifikasi data treatment rentang batas data control normal model deteksi anomali gantung pola normalitas data control data trainingalong with the rapid development of network and internet technology as well as the increase in diverse and difficulttodetect threats anomaly detection is very important event logs can be used to record every activity that occurs and used to detect anomalies one approach to detect anomalies in event logs is reconstructionbased using deep learning by learning the normal pattern of the data but the challenge lies in normality shift which is the change in the normal pattern of the data that the model learns this research focuses on normality shift detection in windows event logs and sysmon data using jensen shannon divergence jsd and hellinger distance hd distribution tests the results show that hd is able to detect distribution shifts well in small and large distribution shift scenarios the data filtering process can affect the performance of the anomaly detection model in the small distribution shift scenario with an increase of 66 in precision 63 in recall 40 in f1score and auc scorehowever the anomaly detection model is not able to deal with large distribution shift scenarios with decreased performance in precision recall f1score and auc score due to the data filtering process which is the process of identifying treatment data that is within the upper and lower limits of the control data as normal the anomaly detection model depends on the initial normality pattern in the control data training data
Klasifikasi Citra Hasil Endoskopi Pada Sistem Gastrointestinal Bagian Bawah Menggunakan Metode Transfer Learning dengan Convolutional Neural Network.,"Tambunan, Rivaldo Panangian",http://repository.its.ac.id/117621/,"Sistem gastrointestinal sering menjadi perhatian utama dalam penelitian medis karena berbagai gangguan, seperti polip dan kolitis ulseratif, yang jika tidak segera ditangani dapat berkembang menjadi kondisi yang serius. Endoskopi merupakan metode utama yang digunakan untuk mendeteksi penyakit ini, meskipun prosesnya sering memakan waktu dan membutuhkan tenaga ahli yang signifikan. Penelitian ini bertujuan untuk klasifikasi citra hasil endoskopi dengan memanfaatkan metode Transfer Learning berbasis Convolutional Neural Network (CNN). Dataset HyperKvasir dan GastroVision digunakan sebagai dataset citra, terdapat tiga kelas : polip, kolitis ulseratif, dan mukosa normal. Model pre-trained seperti VGG19, ResNet101V2, dan InceptionV3 akan digunakan sebagai ekstraksi fitur dan menambahkan fully connected layer untuk melakukan klasifikasi kelas polip, kolitis ulseratif, dan mukosa normal. Dalam penggunaan model pre-trained tersebut akan menggunakan teknik finetuning pada layer awal setiap model pre-trained. Hasil eksperimen menunjukkan bahwa model pre-trained ResNet101V2 memberikan hasil terbaik dengan tingkat akurasi, recall, dan F1-score yang tinggi. Dengan Hasil akurasi sebesar 0.9881, loss 0.0687, Recall 0.9881, Presicion 0.9882, dan F1-Score 0.9881. Penelitian ini diharapkan dapat berkontribusi dalam mendukung deteksi dini penyakit gastrointestinal secara lebih cepat dan efisien, sekaligus mempermudah proses diagnosis di bidang medis.==============================================================================================================================The gastrointestinal system is a major focus in medical research due to various disorders, such as polyps and ulcerative colitis, which, if left untreated, can develop into severe conditions. Endoscopy is the primary method used to detect these diseases, although the process often requires significant time and specialized expertise. This study aims to classify endoscopic images using a Transfer Learning approach based on Convolutional Neural Networks (CNN). The HyperKvasir and GastroVision datasets were utilized, consisting of three main classes: polyps, ulcerative colitis, and normal mucosa. Pre-trained models such as VGG19, ResNet101V2, and InceptionV3 were employed for feature extraction, with the addition of fully connected layers for classifying the three aforementioned categories. Fine-tuning techniques were applied to the initial layers of each pre-trained model to optimize performance. Experimental results demonstrated that the ResNet101V2 pre-trained model achieved the best performance, with high accuracy, recall, and F1-score. The final results include an accuracy of 0.9881, loss of 0.0687, recall of 0.9881, precision of 0.9882, and F1-score of 0.9881.This research is expected to contribute to the early detection of gastrointestinal diseases more efficiently and effectively, thereby facilitating the diagnostic process in the medical field.",klasifikasi citra hasil endoskopi sistem gastrointestinal metode transfer learning convolutional neural network,sistem gastrointestinal perhati utama teliti medis ganggu polip kolitis ulseratif tangan kembang kondisi serius endoskopi metode utama deteksi sakit proses makan butuh tenaga ahli signifikan teliti tuju klasifikasi citra hasil endoskopi manfaat metode transfer learning bas convolutional neural network cnn dataset hyperkvasir gastrovision dataset citra kelas polip kolitis ulseratif mukosa normal model pretrained vgg19 resnet101v2 inceptionv3 ekstraksi fitur fully connected layer klasifikasi kelas polip kolitis ulseratif mukosa normal guna model pretrained teknik finetuning layer model pretrained hasil eksperimen model pretrained resnet101v2 hasil baik tingkat akurasi recall f1score hasil akurasi 09881 loss 00687 recall 09881 presicion 09882 f1score 09881 teliti harap kontribusi dukung deteksi sakit gastrointestinal cepat efisien mudah proses diagnosis bidang medisthe gastrointestinal system is a major focus in medical research due to various disorders such as polyps and ulcerative colitis which if left untreated can develop into severe conditions endoscopy is the primary method used to detect these diseases although the process often requires significant time and specialized expertise this study aims to classify endoscopic images using a transfer learning approach based on convolutional neural networks cnn the hyperkvasir and gastrovision datasets were utilized consisting of three main classes polyps ulcerative colitis and normal mucosa pretrained models such as vgg19 resnet101v2 and inceptionv3 were employed for feature extraction with the addition of fully connected layers for classifying the three aforementioned categories finetuning techniques were applied to the initial layers of each pretrained model to optimize performance experimental results demonstrated that the resnet101v2 pretrained model achieved the best performance with high accuracy recall and f1score the final results include an accuracy of 09881 loss of 00687 recall of 09881 precision of 09882 and f1score of 09881this research is expected to contribute to the early detection of gastrointestinal diseases more efficiently and effectively thereby facilitating the diagnostic process in the medical field
Prediksi Kejadian Luar Biasa Pada Kasus Demam Berdarah Dengue Di Kabupaten Malang Menggunakan Support Vector Machines - Flower Pollination Algorithm.,"Tendio, Yusnardo",http://repository.its.ac.id/78859/,"Penyakit demam berdarah dengue (DBD) merupakan salah satu penyakit berbahaya yang menjadi sumber masalah kesehatan bagi masyarakat Indonesia. Jumlah penderita DBD mengalami peningkatan seiring berjalannya waktu. KLB pada kasus DBD dapat diprediksi dengan membuat model prediksi menggunakan keterkaitan antar variabel. Beberapa variabel yang mempengaruhi hasil prediksi antara lain adalah curah hujan, suhu, kecepatan angin, dan kelembaban. Dalam tugas akhir ini, data jumlah kasus DBD per kecamatan diperoleh dari Dinas Kesehatan Kabupaten Malang, sedangkan data curah hujan, suhu, kecepatan angin, dan kelembaban diperoleh dari Badan Meteorologi, Klimatologi, dan Geofisika (BMKG). Dalam Tugas Akhir ini, sebuah model prediksi KLB untuk kasus DBD dibangun menggunakan gabungan metode Support Vector Machine dan Flower Pollination Algorithm (SVM-FPA). Metode SVM digunakan untuk memisahkan kasus yang termasuk dalam kelas KLB dan kelas non-KLB, sedang FPA digunakan untuk memperoleh nilai parameter yang optimal dalam SVM. Hasil uji coba menunjukkan bahwa nilai parameter opti-mal yang dihasilkan oleh FPA berupa kombinasi nilai cost dan gamma berturut-turut sebesar 2.829,0587 dan 0,002801. Kombinasi kedua nilai paremeter ini mem-berikan hasil prediksi SVM terbaik untuk data validasi, di mana berturut-turut diperoleh nilai akurasi, recall, dan presisi sebesar 90,34%, 89,11%, dan 91,32%. Dengan menggunakan nilai parameter yang sama, hasil prediksi untuk data tes berturut-turut diperoleh nilai akurasi, recall, dan presisi sebesar 59,65%, 88,37%, dan 36,53%. Kata Kunci: demam berdarah, prediksi kejadian luar biasa, support vector machines, algoritma penyerbukan bunga.======================================================================================================Dengue fever (DF) is a dangerous disease that causes health problems for the people. The number of DF cases increases as time goes by. DF Outbreak can be predicted by making prediction models using interrelationships among variables. Some relevant variables that influence the results of predictions are rainfall, temperature, wind speed, and humidity. In this final project, the number of dengue cases per district data are obtained from the Public Health Office of Malang Region, while rainfall, temperature, wind speed, and humidity data are obtained from the Meteorology, Climatology and Geophysics Agency. In this Final Project, an outbreak prediction model for DF cases is built using a combination of Support Vector Machine and Flower Pollination Algorithm (SVM-FPA). The SVM method is used to classify cases that are included in the outbreak class or not outbreak class, while the FPA is used to obtain optimal parameter values in the SVM.. The experimental results show that the optimal parameter values produced by the FPA consists of a combination of cost and gamma values respectively of 2,829.0587 and 0.002801. The combination of these two parameter values gives the best SVM prediction results for validation data, where successively obtained values of accuracy, recall, and precision of 90.34%, 89.11%, and 91.32%. By using the same parameter values, the prediction results for test data in terms of accuracy, recall, and precision values of 59.65%, 88.37%, and 36.53% are obtained, respectively. Keywords: dengue fever, outbreak prediction, support vector machines, flower pollination algorithm.",prediksi jadi demam darah dengue kabupaten malang support vector machines flower pollination algorithm,sakit demam darah dengue dbd salah sakit bahaya sumber sehat masyarakat indonesia derita dbd alami tingkat iring jalan klb dbd prediksi model prediksi kait variabel variabel pengaruh hasil prediksi curah hujan suhu cepat angin kelembaban tugas data dbd camat oleh dinas sehat kabupaten malang data curah hujan suhu cepat angin kelembaban oleh badan meteorologi klimatologi geofisika bmkg tugas model prediksi klb dbd bangun gabung metode support vector machine flower pollination algorithm svmfpa metode svm pisah kelas klb kelas nonklb fpa oleh nilai parameter optimal svm hasil uji coba nilai parameter optimal hasil fpa kombinasi nilai cost gamma berturutturut 28290587 0002801 kombinasi nilai paremeter hasil prediksi svm baik data validasi berturutturut oleh nilai akurasi recall presisi 9034 8911 9132 nilai parameter hasil prediksi data tes berturutturut oleh nilai akurasi recall presisi 5965 8837 3653 kunci demam darah prediksi jadi support vector machines algoritma serbu bungadengue fever df is a dangerous disease that causes health problems for the people the number of df cases increases as time goes by df outbreak can be predicted by making prediction models using interrelationships among variables some relevant variables that influence the results of predictions are rainfall temperature wind speed and humidity in this final project the number of dengue cases district data are obtained from the public health office of malang region while rainfall temperature wind speed and humidity data are obtained from the meteorology climatology and geophysics agency in this final project an outbreak prediction model for df cases is built using a combination of support vector machine and flower pollination algorithm svmfpa the svm method is used to classify cases that are included in the outbreak class or not outbreak class while the fpa is used to obtain optimal parameter values in the svm the experimental results show that the optimal parameter values produced by the fpa consists of a combination of cost and gamma values respectively of 28290587 and 0002801 the combination of these two parameter values gives the best svm prediction results for validation data where successively obtained values of accuracy recall and precision of 9034 8911 and 9132 by using the same parameter values the prediction results for test data in terms of accuracy recall and precision values of 5965 8837 and 3653 are obtained respectively keywords dengue fever outbreak prediction support vector machines flower pollination algorithm
Klasifikasi Tumor Otak Pada Citra MRI Menggunakan en-CNN.,"Tjahyaningtijas, Hapsari Peni Agustin",http://repository.its.ac.id/87168/,"Tumor otak adalah salah satu penyakit yang paling umum terjadi pada sistem saraf pusat dan sifatnya berbahaya. Diagnosis dini sangat penting untuk perawatan pasien yang tepat. Klasifikasi biner tumor otak yang sering dicirikan dengan tumor otak ganas dan jinak yang melibatkan multi-sekuen MRI (T1, T2, T1CE, dan FLAIR), membuat pekerjaan ahli radiologi membosankan dan rawan terjadinya kesalahan. Pada penelitian ini, dikembangkan metode klasifikasi melalui tahap segmentasi dan metode klasifikasi langsung tanpa mealui tahap segmentasi untuk membantu proses klasifikasi tumor otak oleh ahli. Untuk metode klasifikasi melalui segmentasi, fokus penelitian terdapat pada pengembangan metode segmentasi otomatis untuk segmentasi tumor otak ganas yaitu Glioblastoma (GBM) dan tumor otak jinak yaitu Low Grade Glioma (LGG). Metode segmentasi dikembangkan menggunakan modifikasi U-Net. Arsitektur U-Net dievaluasi berdasarkan jumlah epoch dan nilai drop-out untuk mencapai arsitektur yang paling sesuai. Dari hasil eksperimen, model arsitektur yang paling sesuai untuk segmentasi tumor otak  adalah arsitektur modifikasi U-Net atau mU-Net dengan jumlah epoch 90 dan nilai lapisan drop out 0,5. Hasil kinerja segmentasi ditunjukkan dengan nilai dice score sebesar 0,909 yang lebih besar dari penelitian sebelumnya. Metode segmentasi yang diusulkan mampu meningkatkan akurasi klasifikasi tumor otak sebesar 95,65% menggunakan DNN. Nilai akurasi tersebut 2,7% lebih tinggi dari pada jika menggunakan metode SVM yaitu sebesar 92,9%. Dilain pihak, beberapa metode klasifikasi berdasarkan deep learning  digunakan untuk mengklasifikasikan tumor otak. Performa masing-masing model sangat bergantung pada arsitektur CNN yang digunakan. Karena kompleksitas arsitektur CNN yang ada, penyetelan hyperparameter menjadi masalah dalam penerapannya. Pada penelitian ini diusulkan metode CNN yang disebut dengan en-CNN untuk mengatasi masalah ini. Metode ini didasarkan pada VGG-16 yang terdiri dari tujuh jaringan konvolusi, empat ReLU, dan empat max-pooling. Metode yang diusulkan digunakan untuk memfasilitasi penyetelan hyperparameter. Metode ini merupakan pendekatan dimana klasifikasi tumor otak dilakukan secara langsung tanpa terlebih dahulu melakukan proses segmentasi. Pendekatan baru terdiri dari tahapan berikut: preproses, augmentasi citra, dan penerapan metode en-CNN. Klasifikasi tumor otak dilakukan  menggunakan empat sekuen MRI T1, T1CE, T2, dan FLAIR. Metode yang diusulkan memberikan akurasi pada dataset MRI multi-sekuen BraTS 2018 dengan akurasi 95,5% untuk T1, 95,5% untuk T1CE, 94% untuk T2, dan 97% untuk FLAIR dengan ukuran mini-batch 128 dan epoch 200 menggunakan fungsi optimasi ADAM. Akurasinya 4% lebih tinggi dari penelitian sebelumnya dalam dataset yang sama.=====================================================================================================Brain tumors are one of the most common diseases of the central nervous system and are dangerous in nature. Early diagnosis is essential for proper patient care. Radiologists need an automated system to identify brain tumor images. The tumor identification process is a tedious and error-prone task. In addition, the binary classification of brain tumors which are often characterized by malignant and benign brain tumors involving multi-sequence MRI (T1, T2, T1CE, and FLAIR), makes the work of radiologists quite challenging. In this study, a classification method was developed through the segmentation stage. and the direct classification method without going through the segmentation stage. For the classification method through segmentation, the research focus is on the development of automatic segmentation methods using U-Net modifications. The U-Net architecture was evaluated based on the number of epochs and drop-out values to achieve the most suitable architecture for automatic segmentation of glioblastoma brain tumors. From the experimental results, the most suitable architectural model for brain tumor segmentation is the mU-Net architecture with 90 epochs and a dropout layer value of 0.5. The results of segmentation performance are indicated by a dice score of 0.909, which is greater than the previous study. Using DNN, the proposed segmentation method can improve the accuracy of brain tumor classification by 95.65%. The accuracy value is 2.7 % higher than 92.9 % when using the SVM method.On the other hand, several classification methods based on deep learning are used to classify brain tumors. The performance of each model is highly dependent on the CNN architecture used. Due to the complexity of the existing CNN architecture, hyperparameter tuning is a problem in its implementation. In this study, a CNN method called en-CNN is proposed to overcome this problem. This method is based on VGG-16 which consists of seven convolution networks, four ReLUs, and four max-poolings. The proposed method is used to facilitate hyperparameter tuning. This method is an approach where the classification of brain tumors is done directly without first doing the segmentation process. The new approach consists of the following stages: preprocessing, image augmentation, and application of the en-CNN method. Brain tumor classification was performed using four MRI sequences T1, T1CE, T2, and FLAIR. The proposed method provides an accuracy of the 2018 BraTS multi-sequence MRI dataset with an accuracy of 95.5% for T1, 95.5% for T1CE, 94% for T2, and 97% for FLAIR with mini-batch sizes of 128 and epoch 200 using the function ADAM optimization. The accuracy is 4% higher than previous studies in the same dataset",klasifikasi tumor otak citra mri encnn,tumor otak salah sakit sistem saraf pusat sifat bahaya diagnosis awat pasien klasifikasi biner tumor otak ciri tumor otak ganas jinak libat multisekuen mri t1 t2 t1ce flair kerja ahli radiologi bosan rawan salah teliti kembang metode klasifikasi tahap segmentasi metode klasifikasi langsung mealui tahap segmentasi bantu proses klasifikasi tumor otak ahli metode klasifikasi segmentasi fokus teliti kembang metode segmentasi otomatis segmentasi tumor otak ganas glioblastoma gbm tumor otak jinak low grade glioma lgg metode segmentasi kembang modifikasi unet arsitektur unet evaluasi dasar epoch nilai dropout capai arsitektur sesuai hasil eksperimen model arsitektur sesuai segmentasi tumor otak arsitektur modifikasi unet munet epoch 90 nilai lapis drop out 05 hasil kerja segmentasi nilai dice score 0909 teliti metode segmentasi usul tingkat akurasi klasifikasi tumor otak 9565 dnn nilai akurasi 27 metode svm 929 lain metode klasifikasi dasar deep learning klasifikasi tumor otak performa masingmasing model gantung arsitektur cnn kompleksitas arsitektur cnn setel hyperparameter terap teliti usul metode cnn encnn atas metode dasar vgg16 tujuh jaring konvolusi relu maxpooling metode usul fasilitas setel hyperparameter metode dekat mana klasifikasi tumor otak langsung proses segmentasi dekat tahap preproses augmentasi citra terap metode encnn klasifikasi tumor otak sekuen mri t1 t1ce t2 flair metode usul akurasi dataset mri multisekuen brats 2018 akurasi 955 t1 955 t1ce 94 t2 97 flair ukur minibatch 128 epoch 200 fungsi optimasi adam akurasi 4 teliti dataset samabrain tumors are one of the most common diseases of the central nervous system and are dangerous in nature early diagnosis is essential for proper patient care radiologists need an automated system to identify brain tumor images the tumor identification process is a tedious and errorprone task in addition the binary classification of brain tumors which are often characterized by malignant and benign brain tumors involving multisequence mri t1 t2 t1ce and flair makes the work of radiologists quite challenging in this study a classification method was developed through the segmentation stage and the direct classification method without going through the segmentation stage for the classification method through segmentation the research focus is on the development of automatic segmentation methods using unet modifications the unet architecture was evaluated based on the number of epochs and dropout values to achieve the most suitable architecture for automatic segmentation of glioblastoma brain tumors from the experimental results the most suitable architectural model for brain tumor segmentation is the munet architecture with 90 epochs and a dropout layer value of 05 the results of segmentation performance are indicated by a dice score of 0909 which is greater than the previous study using dnn the proposed segmentation method can improve the accuracy of brain tumor classification by 9565 the accuracy value is 27 higher than 929 when using the svm methodon the other hand several classification methods based on deep learning are used to classify brain tumors the performance of each model is highly dependent on the cnn architecture used due to the complexity of the existing cnn architecture hyperparameter tuning is a problem in its implementation in this study a cnn method called encnn is proposed to overcome this problem this method is based on vgg16 which consists of seven convolution networks four relus and four maxpoolings the proposed method is used to facilitate hyperparameter tuning this method is an approach where the classification of brain tumors is done directly without first doing the segmentation process the new approach consists of the following stages preprocessing image augmentation and application of the encnn method brain tumor classification was performed using four mri sequences t1 t1ce t2 and flair the proposed method provides an accuracy of the 2018 brats multisequence mri dataset with an accuracy of 955 for t1 955 for t1ce 94 for t2 and 97 for flair with minibatch sizes of 128 and epoch 200 using the function adam optimization the accuracy is 4 higher than previous studies in the same dataset
Analisis Sentimen Terhadap Tweets Samsung Indonesia Menggunakan Metode Support Vector Machine.,"Triantoro, Aris Rendyansyah",http://repository.its.ac.id/90797/,"Samsung as the world's leading smartphone company is a company that produces various types of technological devices. Technology as the driving force of human civilization is very important. However, in the course of time it is necessary to improve and evaluate gradually in order to satisfy needs properly and avoid undesirable things.Social media Twitter is an application that allows users to write about various topics and discuss current issues. Services are available to send tweets or re-tweets messages that have been shared. With the existence of Twitter this makes it easier for people to have an opinion. The opinion expressed by the public is a very valuable input and can be an instrument for evaluating. These opinions can be analyzed so that information can be obtained, but in practice, processing a text data requires an appropriate method so that the information generated can help many parties to support a decision or choice.Sentiment analysis is the classification of text documents into sentiment classes, such as positive and negative. This study aims to classify the community's tweets against the Samsung Indonesia company on Twitter social media using the Support Vector Machine method by using the data source from crawling tweets with samsungidas the reference keyword using the Twitter API. This research results that the number of tweets with negative sentiment is 13.37%, positive sentiment is 26.01%, and neutral sentiment is 60.60% tweets and the best model for classifying tweet data with SVM is to use data sharing by sharing training data by 80% and testing data by 20% and using value C = 1.",analisis sentimen tweets samsung indonesia metode support vector machine,samsung as the worlds leading smartphone company is a company that produces various types of technological devices technology as the driving force of human civilization is very important however in the course of time it is necessary to improve and evaluate gradually in order to satisfy needs properly and avoid undesirable thingssocial media twitter is an application that allows users to write about various topics and discuss current issues services are available to send tweets or retweets messages that have been shared with the existence of twitter this makes it easier for people to have an opinion the opinion expressed by the public is a very valuable input and can be an instrument for evaluating these opinions can be analyzed so that information can be obtained but in practice processing a text data requires an appropriate method so that the information generated can help many parties to support a decision or choicesentiment analysis is the classification of text documents into sentiment classes such as positive and negative this study aims to classify the communitys tweets against the samsung indonesia company on twitter social media using the support vector machine method by using the data source from crawling tweets with samsungidas the reference keyword using the twitter api this research results that the number of tweets with negative sentiment is 1337 positive sentiment is 2601 and neutral sentiment is 6060 tweets and the best model for classifying tweet data with svm is to use data sharing by sharing training data by 80 and testing data by 20 and using value c 1
Sentiment Analysis of Public Figure News using Sentiment Lexicon and Machine Learning.,"Tsabit, Fitriana Zahirah",http://repository.its.ac.id/100969/,"Dalam dunia politik maupun dunia bisnis penilaian yang dibentuk media dapat menjadi sebuah citra dari seseorang. Citra seseorang merupakan komponen penting bagi seorang publik figur untuk mendapatkan popularitas dan keuntungan secara finansial. Saat ini dunia informasi berkembang dengan cepat sehingga lebih mudah mendapatkan informasi melalui situs berita online. Di Indonesia salah satu situs beritaonline terbesar yaitu Detik.com. Situs berita online menyediakan informasi dalam berbagai bentuk (teks, video atau gambar) dengan membaginya sesuai dengan topik-topik tertentu. Sehingga, dapat dilakukan sentimen analisis untuk mengetahui citra publik figur dari situs berita online melalui penerapan metode machine learning yaitu klasifikasi. Data yang digunakan berasal dari situs berita online yang diambil dengan cara scraping. Tahapan yang dilakukan preprocessing, gabungan score feature extraction menggunakan kamus lexicon, InSet, SentIl, Emolex dan juga terhadap gabungan kamus EmoTil (Emolex dan SentIl), EmoSet (Emotil dan InSet) dan SenSet (InSet dan SentIl) dengan TFIDF. Hasil dari penggabungan ini digunakan untuk klasifikasi machine learning dengan algoritma SVM dan Logistic Regression. Model yang telah dibangun akan dievaluasi dengan membandingkan nilai akurasi dari cross validation. Hasil akurasi terbesar dan terkecil akan dilakukan penembahan parameter untuk meningkatkan hasil dari rata-rata cross validation. Hasil dari akurasi terbesar adalah SVM dengan selisih 1.2% dengan Logistic Regression=================================================================================================================================In the world of politics and business, the judgment formed by the media can become an image of a person. A person's image is essential for a public figure to gain popularity and financial benefits. The world of information is developing rapidly, making it easier to get information through online news sites. In Indonesia, one of the largest online news sites is Detik.com. Online news sites provide information in various forms (text, video, or images) by dividing it according to specific topics. Thus, an analysis of sentiment can be carried out to determine the image of public figures from online news sites through machine learning methods, namely classification. The data used comes from online news sites taken by scraping. The stages carried out are preprocessing, combined score feature extraction using lexicon dictionaries, InSet, SentIl, and Emolex and also against the combined dictionaries EmoTil (Emolex and SentIl), EmoSet (Emotil and InSet) and SenSet (InSet and SentIl) with TFIDF. The result of this combination is used for machine learning classification with SVM and Logistic Regression algorithms. The model that has been built will be evaluated by comparing the accuracy value of cross validation. The largest and smallest accuracy results will be parameterised to improve the results of the average cross validation. The result of the greatest accuracy is SVM with a difference of 1.2% with Logistic Regression.",sentiment analysis of public figure news using sentiment lexicon and machine learning,dunia politik dunia bisnis nilai bentuk media citra citra komponen publik figur popularitas untung finansial dunia informasi kembang cepat mudah informasi situs berita online indonesia salah situs beritaonline besar detikcom situs berita online sedia informasi bentuk teks video gambar bagi sesuai topiktopik sentimen analisis citra publik figur situs berita online terap metode machine learning klasifikasi data asal situs berita online ambil scraping tahap preprocessing gabung score feature extraction kamus lexicon inset sentil emolex gabung kamus emotil emolex sentil emoset emotil inset senset inset sentil tfidf hasil gabung klasifikasi machine learning algoritma svm logistic regression model bangun evaluasi banding nilai akurasi cross validation hasil akurasi besar kecil penembahan parameter tingkat hasil ratarata cross validation hasil akurasi besar svm selisih 12 logistic regressionin the world of politics and business the judgment formed by the media can become an image of a person a persons image is essential for a public figure to gain popularity and financial benefits the world of information is developing rapidly making it easier to get information through online news sites in indonesia one of the largest online news sites is detikcom online news sites provide information in various forms text video or images by dividing it according to specific topics thus an analysis of sentiment can be carried out to determine the image of public figures from online news sites through machine learning methods namely classification the data used comes from online news sites taken by scraping the stages carried out are preprocessing combined score feature extraction using lexicon dictionaries inset sentil and emolex and also against the combined dictionaries emotil emolex and sentil emoset emotil and inset and senset inset and sentil with tfidf the result of this combination is used for machine learning classification with svm and logistic regression algorithms the model that has been built will be evaluated by comparing the accuracy value of cross validation the largest and smallest accuracy results will be parameterised to improve the results of the average cross validation the result of the greatest accuracy is svm with a difference of 12 with logistic regression
Penerapan Algoritma Blocplan Sebagai Metode Desain Terminal Regasifikasi Gas Alam Cair (LNG).,"Ulfauzi, Zaki",http://repository.its.ac.id/80801/,"Dalam perancangan tata letak fasilitas yang menggunakan aplikasi, seperti dalam bidang teknik sipil, perkapalan, arsitektur, banyak sistem algoritma perancangan yang telah dikembangkan. Algoritma perancangan merupakan salah satu metode pendekatan dalam perancangan dimana sistem komputer telah diolah dengan beberapa rumus untuk menghasilkan rancangan secara otomatis dan efisien. Peneliti mencoba menggunakan salah satu algoritma perancangan untuk mendesain layout terminal LNG yang disebut algoritma BLOCPLAN. Algoritma BLOCPLAN digunakan untuk meningkatkan efisiensi pemanfaatan ruang dan penempatan fasilitas. BLOCPLAN bekerja dengan menghasilkan beberapa tata letak terminal dengan sistem penilaian langsung. Desain yang paling efisien akan dipilih dari desain yang dihasilkan setelah proses analisis ulang. Dalam menentukan fasilitas terminal utama, Excel Solver juga digunakan untuk memilih skenario terbaik dengan parameter modal investasi yang rendah. Dalam penelitian ini, 15 layout dihasilkan oleh algoritma. Untuk proses perankingan, metode AHP digunakan untuk mengubah karakter skor dari cost criteria menjadi benefit criteria. Nilai bobot untuk masing-masing skor adalah 0.1 untuk Adj.Score, 0.3 untuk R.Score, dan 0.6 untuk Rel-Dist Score. Dari hasil pemeringkatan, layout nomor 14 menjadi rekomendasi terbaik dengan total skor 0.14987.======================================================================================================================================================================In the layout design of buildings using applications, such as in the fields of civil engineering, shipping, architecture, many design algorithm systems have been developed. Design algorithm is an approaching method in design where the computer system has been processed with several formulas to produce designs automatically and efficiently. The researcher tries to use one of the design algorithms for designing the LNG terminal layout, called the BLOCPLAN algorithm. The BLOCPLAN algorithm is used to improve the efficiency of space utilization and facility placement. BLOCPLAN works by generating several terminal layouts with a direct appraisal system. A most efficient design will be selected from generated designs after the re-analysis process. In determining the main terminal facilities, Excel Solver is also used to choose the best scenario with low investment capital. In this research, 15 layouts are generated by the algorithm. For the ranking process, the AHP method is used to change the character of the score from the cost criteria to the benefit criteria. The weighted value of each score is 0.1 for Adj.Score, 0.3 for R.Score, and 0.6 for the Rel-Dist Score. From the ranking results, layout number 14 is the best recommendation with a total score of 0.14987.",terap algoritma blocplan metode desain terminal regasifikasi gas alam cair lng,ancang tata letak fasilitas aplikasi bidang teknik sipil kapal arsitektur sistem algoritma ancang kembang algoritma ancang salah metode dekat ancang mana sistem komputer olah rumus hasil rancang otomatis efisien teliti coba salah algoritma ancang desain layout terminal lng algoritma blocplan algoritma blocplan tingkat efisiensi manfaat ruang tempat fasilitas blocplan hasil tata letak terminal sistem nilai langsung desain efisien pilih desain hasil proses analisis ulang tentu fasilitas terminal utama excel solver pilih skenario baik parameter modal investasi rendah teliti 15 layout hasil algoritma proses perankingan metode ahp ubah karakter skor cost criteria benefit criteria nilai bobot masingmasing skor 01 adjscore 03 rscore 06 reldist score hasil peringkat layout nomor 14 rekomendasi baik total skor 014987in the layout design of buildings using applications such as in the fields of civil engineering shipping architecture many design algorithm systems have been developed design algorithm is an approaching method in design where the computer system has been processed with several formulas to produce designs automatically and efficiently the researcher tries to use one of the design algorithms for designing the lng terminal layout called the blocplan algorithm the blocplan algorithm is used to improve the efficiency of space utilization and facility placement blocplan works by generating several terminal layouts with a direct appraisal system a most efficient design will be selected from generated designs after the reanalysis process in determining the main terminal facilities excel solver is also used to choose the best scenario with low investment capital in this research 15 layouts are generated by the algorithm for the ranking process the ahp method is used to change the character of the score from the cost criteria to the benefit criteria the weighted value of each score is 01 for adjscore 03 for rscore and 06 for the reldist score from the ranking results layout number 14 is the best recommendation with a total score of 014987
Model Traffic Forecasting dengan RNN-Based Deep Learning dan Explainable Artificial Intelligence.,"Ulhaq, Naufal Dhiya",http://repository.its.ac.id/106242/,"Peningkatan konsep smart city yang didorong oleh kemajuan Internet of Things (IoT), telah mengubah lanskap perkotaan modern. Salah satu pilar utama dari hal ini adalah Intelligent Transportation System (ITS), di mana model traffic forecasting menjadi perangkat kunci dari sistem ini. Penelitian ini bertujuan untuk mengembangkan model forecasting yang tidak hanya akurat tetapi juga mudah dipahami, dengan menggunakan pendekatan Recurrent Neural Network (RNN) dan menerapkan Explainable Artificial Intelligence (XAI). Hasil pengujian menunjukkan bahwa model dengan algoritma Bidirectional Long Short-Term Memory (BiLSTM) yang merupakan pengembangan RNN, mencapai kinerja terbaik. Model tersebut berhasil mencapai nilai Mean Absolute Error (MAE) sebesar 163,13, Root Mean Square Error (RMSE) sebesar 241,62, dan Mean Absolute Percentage Error (MAPE) sebesar 8,03%. Penggunaan XAI, khususnya metode Shapley Additive Explanations (SHAP), mengungkapkan bahwa fitur ""traffic_volume"" dan timestep pada 1 jam terakhir memberikan kontribusi terbesar dalam pengambilan keputusan model. Lebih lanjut, penelitian ini berhasil mengintegrasikan model dan XAI ke dalam aplikasi website berbasis Flask. Integrasi ini memberikan akses untuk melihat riwayat forecasting, nilai shap value, feature importance, dan dataset. Aplikasi tersebut juga menyertakan formulir untuk input data baru dan tabel dataset.====================================================================================================================================The rise of the smart city concept, driven by the advancement of the Internet of Things (IoT), has changed the modern urban landscape. One of its main pillars is the Intelligent Transportation System (ITS), where traffic forecasting models are a key tool of this system. This research aims to develop a forecasting model that is not only accurate but also easy to understand, by using a Recurrent Neural Network (RNN) approach and applying Explainable Artificial Intelligence (XAI). The results showed that the model with the Bidirectional Long Short-Term Memory (BiLSTM) algorithm, which is a development of RNN, achieved the best performance. The model managed to achieve a Mean Absolute Error (MAE) value of 163.13, Root Mean Square Error (RMSE) of 241.62, and Mean Absolute Percentage Error (MAPE) of 8,03%. The use of XAI, specifically the Shapley Additive Explanations (SHAP) method, revealed that the ""traffic_volume"" feature and the timestep of the last 1 hour contributed the most to the model's decision making. Furthermore, this research successfully integrated the model and XAI into a Flask-based website application. This integration provides access to view forecasting history, shap value, feature importance, and datasets. The application also includes a form for new data input and a dataset table.",model traffic forecasting rnnbased deep learning explainable artificial intelligence,tingkat konsep smart city dorong maju internet of things iot ubah lanskap kota modern salah pilar utama intelligent transportation system its model traffic forecasting perangkat kunci sistem teliti tuju kembang model forecasting akurat mudah paham dekat recurrent neural network rnn terap explainable artificial intelligence xai hasil uji model algoritma bidirectional long shortterm memory bilstm kembang rnn capai kerja baik model hasil capai nilai mean absolute error mae 16313 root mean square error rmse 24162 mean absolute percentage error mape 803 guna xai metode shapley additive explanations shap fitur trafficvolume timestep 1 jam kontribusi besar ambil putus model teliti hasil integrasi model xai aplikasi website bas flask integrasi akses riwayat forecasting nilai shap value feature importance dataset aplikasi serta formulir input data tabel datasetthe rise of the smart city concept driven by the advancement of the internet of things iot has changed the modern urban landscape one of its main pillars is the intelligent transportation system its where traffic forecasting models are a key tool of this system this research aims to develop a forecasting model that is not only accurate but also easy to understand by using a recurrent neural network rnn approach and applying explainable artificial intelligence xai the results showed that the model with the bidirectional long shortterm memory bilstm algorithm which is a development of rnn achieved the best performance the model managed to achieve a mean absolute error mae value of 16313 root mean square error rmse of 24162 and mean absolute percentage error mape of 803 the use of xai specifically the shapley additive explanations shap method revealed that the trafficvolume feature and the timestep of the last 1 hour contributed the most to the models decision making furthermore this research successfully integrated the model and xai into a flaskbased website application this integration provides access to view forecasting history shap value feature importance and datasets the application also includes a form for new data input and a dataset table
Peningkatan Akurasi Klasifikasi Kemurnian Daging Sapi Berbasis Electronic Nose Dengan Menggunakan Ensemble Method.,"Ulhaq, Azzam Jihad",http://repository.its.ac.id/84701/,"Daging sapi merupakan salah satu jenis daging yang sering dikonsumsi oleh manusia. Namun, pencampuran jenis daging sapi dengan daging lainnya seperti daging babi dilakukan dalam praktik jual beli dalam rangka mendapatkan keuntungan yang lebih. Hal ini tidak hanya mengurangi kepercayaan publik tentang keaslian daging juga membahayakan kesehatan dan melanggar aturan-aturan agam tertentu. Dalam penelitian ini, kami merancang dan mengusulkan sistem yang lebih akurat dalam melakukan klasifikasi kemurnian daging sapi berdasarkan data sampel aroma yang ditangkap oleh electronic nose.Sistem ini dibangun melalui tujuh tahap: pengambilan sampel data menggunakan electronic nose yang dibuat dari sensor gas dan Arduino; praproses data sensor; ekstraksi fitur statistik; hyperparameter tunning; seleksi fitur menggunakan ANOVA; klasifikasi menggunakan metode SVM, LDA dan MLP; dan peningkatan akurasi menggunakan ensemble method.Hasil penelitian menunjukkan bahwa sistem ini dapat membedakan daging sapi yang dicampur dengan daging babi dengan perbandingan 0%, 10%, 25%, 50%, 75%, 90%, dan 100% dengan akurasi 89,71% menggunakan Bagging MLP.======================================================================================================Beef is a type of meat that is often consumed by humans. However, mixing types of beef with other meats such as pork is carried out in buying and selling to get more profit. The adulteration undermines public belief in meat's authenticity and harms health, and violates specific religious rules. In this study, we designed and proposed a more accurate system for classifying beef purity based on the aroma sample data captured by the electronic nose.This system has seven stages: data sampling using an electronic nose made from the gas sensor and Arduino; preprocessing sensor data; statistical feature extraction; hyperparameter tunning; feature selection using ANOVA; classification using the SVM, LDA, and MLP methods; and improved accuracy using the ensemble method.The results showed that this system could distinguish beef mixed with pork with a ratio of 0%, 10%, 25%, 50%, 75%, 90%, and 100% with an accuracy of 89.71% using Bagging MLP.",tingkat akurasi klasifikasi murni daging sapi bas electronic nose ensemble method,daging sapi salah jenis daging konsumsi manusia campur jenis daging sapi daging daging babi praktik jual beli rangka untung kurang percaya publik asli daging bahaya sehat langgar aturanaturan agam teliti rancang usul sistem akurat klasifikasi murni daging sapi dasar data sampel aroma tangkap electronic nosesistem bangun tujuh tahap ambil sampel data electronic nose sensor gas arduino praproses data sensor ekstraksi fitur statistik hyperparameter tunning seleksi fitur anova klasifikasi metode svm lda mlp tingkat akurasi ensemble methodhasil teliti sistem beda daging sapi campur daging babi banding 0 10 25 50 75 90 100 akurasi 8971 bagging mlpbeef is a type of meat that is often consumed by humans however mixing types of beef with other meats such as pork is carried out in buying and selling to get more profit the adulteration undermines public belief in meats authenticity and harms health and violates specific religious rules in this study we designed and proposed a more accurate system for classifying beef purity based on the aroma sample data captured by the electronic nosethis system has seven stages data sampling using an electronic nose made from the gas sensor and arduino preprocessing sensor data statistical feature extraction hyperparameter tunning feature selection using anova classification using the svm lda and mlp methods and improved accuracy using the ensemble methodthe results showed that this system could distinguish beef mixed with pork with a ratio of 0 10 25 50 75 90 and 100 with an accuracy of 8971 using bagging mlp
News Classification Using Ensemble Learning Approach.,"Utomo, Erlangga Wahyu",http://repository.its.ac.id/117829/,"The amount of information published online every day can be overwhelming, making it difficult to effectively manage and categorize. This research addresses this problem by combining multiple machine learning and deep learning models in a method known as ensemble learning. Using a set of Huffpost News from Kaggle, the study integrates traditional models, such as logistics regression, random forests and Support for Vector Machines (SVM) with advanced approaches deep learning, such as Long Short Term Memory (LSTM), Bidirectional Long Short Term Memory (BiLSTM) with a mechanism for attention, and the introduction of layers. The data preparation process included cleaning the text, removing unnecessary characters and the conversion of text into numerical forms using Word2Vec embedding field These features were then fed into an ensemble model that combined predictions from different classifiers using a method called soft voting, improving the overall accuracy and reliability of the classification process. To confirm the results, the model was tested using various departments of learning data and test data (80-20 reports). The results indicate that the ensemble model achieved an overall accuracy of 60.19%, outperforming individual models. Among the individual models, BiLSTM with Attention achieved the highest accuracy of 63.9%, followed by LSTM at 54.7%, Random Forest at 48.3%, Logistic Regression at 58.2%, and SVM at 57.5%. Among the individual models, BiLSTM with Attention achieved the best performance, demonstrating its effectiveness in understanding sentence structure and capturing complex patterns in news content. Even though it differs not so much from the individual model, the ensemble still has the best accuracy because it combines all the individual models and combines preprocessing data between machine learning and deep learning, However, the training process for the ensemble model required significant computational resources, taking 10 days to complete.",news classification using ensemble learning approach,the amount of information published online every day can be overwhelming making it difficult to effectively manage and categorize this research addresses this problem by combining multiple machine learning and deep learning models in a method known as ensemble learning using a set of huffpost news from kaggle the study integrates traditional models such as logistics regression random forests and support for vector machines svm with advanced approaches deep learning such as long short term memory lstm bidirectional long short term memory bilstm with a mechanism for attention and the introduction of layers the data preparation process included cleaning the text removing unnecessary characters and the conversion of text into numerical forms using word2vec embedding field these features were then fed into an ensemble model that combined predictions from different classifiers using a method called soft voting improving the overall accuracy and reliability of the classification process to confirm the results the model was tested using various departments of learning data and test data 8020 reports the results indicate that the ensemble model achieved an overall accuracy of 6019 outperforming individual models among the individual models bilstm with attention achieved the highest accuracy of 639 followed by lstm at 547 random forest at 483 logistic regression at 582 and svm at 575 among the individual models bilstm with attention achieved the best performance demonstrating its effectiveness in understanding sentence structure and capturing complex patterns in news content even though it differs not so much from the individual model the ensemble still has the best accuracy because it combines all the individual models and combines preprocessing data between machine learning and deep learning however the training process for the ensemble model required significant computational resources taking 10 days to complete
Nowcasting Jumlah Penduduk dengan Metode Support Vector Regression (SVR) dan Multi-Output Support Vector Regression (M-SVR).,"Vinahari, Riyan Zulmaniar",http://repository.its.ac.id/104274/,"Data dan informasi statistik beserta proyeksinya merupakan dasar penting untuk perencanaan dan evaluasi pembangunan nasional di masa mendatang khususnya jangka menengah maupun jangka panjang. Data tersebut tidak dapat dipenuhi melalui sistem registrasi sehingga data-data diperoleh dari sensus dan survei yang dilakukan Badan Pusat Statistik (BPS) untuk digunakan sebagai dasar proyeksi. Metode proyeksi penduduk yang umum digunakan di berbagai negara dan masih menjadi metode proyeksi penduduk Indonesia adalah Cohort Component Model (CCM). Akan tetapi, metode ini mempunyai beberapa kelemahan sehingga diperlukan metode baru yang lebih akurat salah satunya melalui metode nowcasting. Analisis time series tidak hanya dilakukan menggunakan statistika klasik, tetapi juga machine learning (ML). Metode ML mempunyai performa lebih unggul dibandingkan dengan metode statistika klasik. Algoritma ML yang umum digunakan untuk nowcasting adalah Support Vector Regression (SVR) dan Multi-output SVR (M-SVR). SVR juga mampu menghasilkan performa bagus dalam proyeksi di berbagai macam bidang. Akan tetapi SVR hanya mampu menangani single output. Sedangkan M-SVR mampu menangani permasalahan regresi multi-output seperti jumlah penduduk di beberapa provinsi di Pulau Jawa yang saling berkorelasi. Data yang digunakan bersumber dari BPS dengan variabel output jumlah penduduk di Provinsi DKI Jakarta, Jawa Barat, Jawa Tengah, dan Jawa Timur. Variabel input yang digunakan yaitu jumlah pelanggan listrik kelompok rumah tangga, jumlah angkatan kerja, jumlah rumah tangga, kepadatan penduduk (jiwa/km2), PDRB komponen PKRT ADHK (miliar Rp). Periode data yang digunakan merupakan data tahunan dari tahun 1985 sampai 2022. Pemilihan model terbaik dilakukan dengan membandingkan nilai RMSE dan MAPE out sample nowcasting model SVR dan M-SVR. Hasil penelitian menunjukkan bahwa berdasarkan nilai kebaikan model, nowcasting model SVR mempunyai performa yang lebih baik dibandingkan model M-SVR yang ditunjukkan dari nilai MAPE out sample nowcasting model SVR yang lebih kecil dibanding model M-SVR untuk seluruh variabel output. Selain itu, proyeksi penduduk hasil dari metode nowcasting memberikan performa yang lebih baik dibandingkan dengan metode CCM.===================================================================================================================================Statistical data and information, as well as their projections are an important basis for planning and evaluation of future national development, especially in the medium and long term development. These data cannot be provided through the population registration system. Hence, the data obtained from censuses and surveys conducted by Badan Pusat Statistik (BPS- Statistics Indonesia). The common method is Cohort Component Method (CCM). CCM is widely used in many countries including Indonesia, which still be utilized by BPS. Unfortunately, this method has several drawbacks, and therefore, more accurate method is required to outperform CCM. One of these methods is nowcasting. Time series analysis can now be conducted not only using classical statistical but also machine learning (ML). Machine learning is a new method in statistical forecasting that shows an excellent performance compared to classical statistical methods. Machine learning algorithms that are commonly used in sequential analysis are Support Vector Regression (SVR) and Multioutput SVR (MSVR) where both of these algorithms can perform nowcasting. SVR is also capable of producing excellent projections in a variety of disciplines. However, SVR is only able to handle single output. Meanwhile, M-SVR is capable of handling multi-output regression problems such as the number of populations in several provinces in Java Island which are correlated with each other. The data used was obtained from the BPS, and the output variable is the population of DKI Jakarta, West Java, Central Java, and East Java Provinces.  The variables used as inputs are the number of electricity consumers for the household group, the number of workers, the number of households, the population density (people/km2), and the GRDP of the PKRT ADHK component (billion Rp). The data period used spans from 1985 to 2022 with annual data. Comparing the SVR and MSVR models' RMSE and MAPE values enables the selection of the optimal model. The results showed that based on the quality of the model, the SVR nowcasting model outperformed the M-SVR model, as shown by the SVR nowcasting model's out sample MAPE value, which was lower for all output variables than MAPE value from M-SVR. In addition, the efficacy of the population projections derived from the nowcasting method is outperform than CCM method.",nowcasting duduk metode support vector regression svr multioutput support vector regression msvr,data informasi statistik serta proyeksi dasar rencana evaluasi bangun nasional jangka tengah jangka data penuh sistem registrasi datadata oleh sensus survei badan pusat statistik bps dasar proyeksi metode proyeksi duduk negara metode proyeksi duduk indonesia cohort component model ccm metode lemah metode akurat salah satu metode nowcasting analisis time series statistika klasik machine learning ml metode ml performa unggul banding metode statistika klasik algoritma ml nowcasting support vector regression svr multioutput svr msvr svr hasil performa bagus proyeksi bidang svr tangan single output msvr tangan masalah regresi multioutput duduk provinsi pulau jawa korelasi data sumber bps variabel output duduk provinsi dki jakarta jawa barat jawa jawa timur variabel input langgan listrik kelompok rumah tangga angkat kerja rumah tangga padat duduk jiwakm2 pdrb komponen pkrt adhk miliar rp periode data data tahun 1985 2022 pilih model baik banding nilai rmse mape out sample nowcasting model svr msvr hasil teliti dasar nilai baik model nowcasting model svr performa banding model msvr nilai mape out sample nowcasting model svr banding model msvr variabel output proyeksi duduk hasil metode nowcasting performa banding metode ccmstatistical data and information as well as their projections are an important basis for planning and evaluation of future national development especially in the medium and long term development these data can not be provided through the population registration system hence the data obtained from censuses and surveys conducted by badan pusat statistik bps statistics indonesia the common method is cohort component method ccm ccm is widely used in many countries including indonesia which still be utilized by bps unfortunately this method has several drawbacks and therefore more accurate method is required to outperform ccm one of these methods is nowcasting time series analysis can now be conducted not only using classical statistical but also machine learning ml machine learning is a new method in statistical forecasting that shows an excellent performance compared to classical statistical methods machine learning algorithms that are commonly used in sequential analysis are support vector regression svr and multioutput svr msvr where both of these algorithms can perform nowcasting svr is also capable of producing excellent projections in a variety of disciplines however svr is only able to handle single output meanwhile msvr is capable of handling multioutput regression problems such as the number of populations in several provinces in java island which are correlated with each other the data used was obtained from the bps and the output variable is the population of dki jakarta west java central java and east java provinces the variables used as inputs are the number of electricity consumers for the household group the number of workers the number of households the population density peoplekm2 and the grdp of the pkrt adhk component billion rp the data period used spans from 1985 to 2022 with annual data comparing the svr and msvr models rmse and mape values enables the selection of the optimal model the results showed that based on the quality of the model the svr nowcasting model outperformed the msvr model as shown by the svr nowcasting models out sample mape value which was lower for all output variables than mape value from msvr in addition the efficacy of the population projections derived from the nowcasting method is outperform than ccm method
Pengembangan Sistem Deteksi Kebocoran Air Berbasis Support Vector Machine Pada Jaringan Distribusi Air Di Perumda Air Minum Tugu Tirta Malang.,"Wicaksana, Farhan Arief",http://repository.its.ac.id/109411/,"Di Indonesia, PDAM (Perusahaan Daerah Air Minum) mendistribusikan air minum kepada masyarakat melalui jaringan pipa. Pada penggunaan jaringan pipa, seringkali pipa ditempatkan di bawah tanah di area luas, menyulitkan operator untuk memantau aliran air dan kondisi pipa karena keterbatasan peralatan dan tenaga. Oleh karena itu, penelitian ini menggunakan Artificial Intelligence sebagai opsi metode deteksi kebocoran air dengan memprediksi tekanan yang tercatat pada datalogger DMA(District Meter Area). Algoritma SVM (Support Vector Machine)  yang digunakan sendiri untuk memprediksi hasil tekanan pada DMA yang dianalisis. Dalam penelitian tugas akhir ini, setelah melalui studi literatur dan lapangan, kemudian hasil dari software tersebut akan dimasukkan kedalam algoritma SVM. Hasil menunjukkan untuk perfomansi algoritma pada ukuran kebocoran pada DMA TL 2.2I memiliki nilai akurasi sebesar 93.5% dan F1 score sebesar 93.25% dan untuk perfomansi algoritma pada lokalisasi area kebocoran memiliki nilai akurasi sebesar 93.30% dan F1 score sebesar 93.80%. Kemudian untuk perbedaan perfomansi menggunakan data lapangan memiliki perbedaan nilai, untuk nilai akurasi dari pemodelan ukuran kebocoran menggunakan data lapangan yaitu sebesar 82.10% dan F1 score 90% serta untuk pemodelan lokalisasi area kebocoran yaitu memiliki nilai akurasi sebesar 85.71% dan F1 score 92 %. Dengan nilai perfomansi seperti yang ditunjukan pada pemodelan, maka dapat disimpulkan algoritma SVM dapat digunakan untuk mendeteksi adanya kebocoran air pada jaringan distribusi air.====================================================================================================================================In Indonesia, PDAMs (Regional Water Supply Companies) distribute drinking water to the public through pipelines. In the use of pipelines, pipes are often placed underground in large areas, making it difficult for operators to monitor water flow and pipe conditions due to limited equipment and manpower. Therefore, this research uses Artificial Intelligence as an option for water leak detection methods by predicting the pressure recorded in the DMA (District Meter Area) datalogger. The SVM (Support Vector Machine) algorithm is used alone to predict the pressure results on the analyzed DMA. In this final project research, after going through literature and field studies, then the results of the software will be entered into the SVM algorithm. The results show that the algorithm performance on leakage size in DMA TL 2.2I has an accuracy value of 93.5% and F1 score of 93.25% and for the algorithm performance on leakage area localization has an accuracy value of 93.30% and F1 score of 93.80%. Then for the difference in performance using acquisition data has a difference in value, for the accuracy value of the leak size modeling using acquisition data is 82.10% and F1 score 90% and for modeling the leak area localization which has an accuracy value of 85.71% and F1 score 92%. With the performance value as shown in the modeling, it can be concluded that the SVM algorithm can be used to detect water leaks in the water distribution network.",kembang sistem deteksi bocor air bas support vector machine jaring distribusi air perumda air minum tugu tirta malang,indonesia pdam usaha daerah air minum distribusi air minum masyarakat jaring pipa guna jaring pipa seringkali pipa tempat tanah area luas sulit operator pantau alir air kondisi pipa batas alat tenaga teliti artificial intelligence opsi metode deteksi bocor air prediksi tekan catat datalogger dmadistrict meter area algoritma svm support vector machine prediksi hasil tekan dma analis teliti tugas studi literatur lapang hasil software masuk dalam algoritma svm hasil perfomansi algoritma ukur bocor dma tl 22i milik nilai akurasi 935 f1 score 9325 perfomansi algoritma lokalisasi area bocor milik nilai akurasi 9330 f1 score 9380 beda perfomansi data lapang milik beda nilai nilai akurasi model ukur bocor data lapang 8210 f1 score 90 model lokalisasi area bocor milik nilai akurasi 8571 f1 score 92 nilai perfomansi tunjuk model simpul algoritma svm deteksi bocor air jaring distribusi airin indonesia pdams regional water supply companies distribute drinking water to the public through pipelines in the use of pipelines pipes are often placed underground in large areas making it difficult for operators to monitor water flow and pipe conditions due to limited equipment and manpower therefore this research uses artificial intelligence as an option for water leak detection methods by predicting the pressure recorded in the dma district meter area datalogger the svm support vector machine algorithm is used alone to predict the pressure results on the analyzed dma in this final project research after going through literature and field studies then the results of the software will be entered into the svm algorithm the results show that the algorithm performance on leakage size in dma tl 22i has an accuracy value of 935 and f1 score of 9325 and for the algorithm performance on leakage area localization has an accuracy value of 9330 and f1 score of 9380 then for the difference in performance using acquisition data has a difference in value for the accuracy value of the leak size modeling using acquisition data is 8210 and f1 score 90 and for modeling the leak area localization which has an accuracy value of 8571 and f1 score 92 with the performance value as shown in the modeling it can be concluded that the svm algorithm can be used to detect water leaks in the water distribution network
Pemanfaatan Komputasi Awan untuk Pengenalan Ekspresi Wajah menggunakan AWS DeepLens.,"Widojoko, Gregorius Rafael",http://repository.its.ac.id/81986/,"Komunikasi tatap-muka merupakan suatu bentuk interaksi yang sering dilakukan oleh semua orang. Akan tetapi, hal tersebut sulit untuk diimplementasikan bagi penyandang tuna netra, terutama bagi mereka untuk mengenali ekspresi wajah dari lawan bicaranya dan ekspresi wajah dipercayai mempunyai kaitan erat dalam emosi seseorang dan memberikan informasi yang lebih lengkap saat berkomunikasi.  Oleh karena itu, diperlukanlah suatu alat yang bisa membaca ataupun mengenali ekspresi wajah, sehingga para penyandang tuna netra dapat mengenali ekspresi wajah dari lawan bicaranya dengan jelas dan ekspresi itu dikonversikan menjadi informasi non-verbal berupa suara yang mengindikasikan ekspresi dari lawan bicara penyandang tuna netra.Penelitian tentang pengenalan ekspresi wajah kepada penyandang tunanetra telah banyak dilakukan. Akan tetapi, salah satu skenario kendala yang dihadapi dari beberapa penelitian sebelumnya adalah biaya pembuatan dan performa yang kurang sesuai dengan pengguna. Pada penelitian ini akan digunakan perangkat untuk komputasi awan dan pembelajaran mesin AWS DeepLens yang bertujuan untuk mencari performa dari perangkat yang menggunakan layanan komputasi awan AWS dan membandingkannya dengan performa dari alat yang menggunakan pemrograman deep learning tanpa komputasi awan. Semua bentuk keluaran dari perangkat akan menyampaikan informasi pengenalan ekspresi ke pengguna melalui media suara. Keberhasilan algoritma deep learning akan diukur dalam confusion matrix dengan rerata keberhasilan sebesar 73,43 % . Alat yang dikembangkan dari divais AWS DeepLens ini menggunakan sistem komputasi awan dari AWS, dengan harapan alat ini robust secara sistem dan real-time dalam penggunaannya.",manfaat komputasi awan kenal ekspresi wajah aws deeplens,komunikasi tatapmuka bentuk interaksi orang sulit implementasi sandang tuna netra nali ekspresi wajah lawan bicara ekspresi wajah percaya kait erat emosi informasi lengkap komunikasi perlu alat baca nali ekspresi wajah sandang tuna netra nali ekspresi wajah lawan bicara ekspresi konversi informasi nonverbal suara indikasi ekspresi lawan bicara sandang tuna netrapenelitian kenal ekspresi wajah sandang tunanetra salah skenario kendala hadap teliti biaya buat performa sesuai guna teliti perangkat komputasi awan ajar mesin aws deeplens tuju cari performa perangkat layan komputasi awan aws banding performa alat pemrograman deep learning komputasi awan bentuk keluar perangkat informasi kenal ekspresi guna media suara hasil algoritma deep learning ukur confusion matrix rerata hasil 7343 alat kembang divais aws deeplens sistem komputasi awan aws harap alat robust sistem realtime guna
Analisis Sentimen Twitter Pada Initial Public  Offering Saham GOTO Tahun 2022 Dengan  Menggunakan Support Vector Machine.,"Wijaya, Ikhlasul Ikhwan",http://repository.its.ac.id/99758/,"Initial Public Offering atau biasa disingkat IPO merupakan sebuah penarawaran saham kepada  publik dengan penjualan pertama dari suatu perusahaan kepada masyarakat sehingga perusahaan yang  bersangkutan status perusahaanya berubah yang semula berupa perusahaan swasta menjadi perusahaan  publik. Initial Public Offering sendiri biasanya dikelola oleh bank yang membantu investasi yang  fungsinya mencatat saham di bursa efek, tujuan dari IPO sebuah perusahaan sendiri adalah untuk  meningkatkan modal ekuitas baru bagi perusahaan. Kinerja dari perusahaan sendiri sangat berpengaruh  pada penawaran kepada publik, apabila dari masyarakat memiliki banyak sentimen buruk maka akan  sangat berpengaruh terhadap minat beli dan harga saham pada pembukaan saham. Oleh karena itu,  penting untuk mengetahui seberapa besar sentimen dan minat pada saham yang akan IPO. Tujuan  penelitian kali ini adalah untuk mengklasifikasi seberapa besar sentimen masyarakat melalui twitter  terhadap beberapa perusahaan pada kuartal 2 tahun 2022 yang rilis ke publik atau IPO. Metode yang  digunakan pada peneliain kali ini adalah support vector machine dengan menggunakan sumber data dari  crawling tweet dengan menggunakan package scrapping dari Python. Dari penelitian kali ini  didapatkan hasil tweets sebanyak 4873 tweets dengan presentase 22,8% sentimen positif dan  77,2% sentimen negatif dengan menggunakan tiga kali percobaan dengan data testing sebesar  20%, 30%, dan 40% dengan tiga kernel yang dicoba yaitu linear, radial basis function, dan  Sigmoid. Berdasarkan ketiga percobaan dengan menggunakan tiga kernel yang berbeda, dapat  didapatkan skor akurasi yang terbesar yaitu dengan menggunakan kernel linear dengan skor  akurasi sebesar 80% pada data testing 30% dan memiliki nilai sensitivity, precission dan recall sebesar 91%, 38%, 85% dan 89% pada nilai cost 50% dengan akurasi cost sebesar 80%===================================================================================================================================Initial Public Offering or commonly abbreviated as IPO is an offering of shares to the public with  the first sale of a company to the public so that the company concerned changes its company status from  a private company to a public company. Initial Public Offering itself is usually managed by an  investment bank whose function is to list shares on the stock exchange, the purpose of a company's own  IPO is to raise new equity capital for the company. The performance of the company itself is very  influential on the offer to the public, if the public has a lot of bad sentiment, it will greatly affect the  buying interest and share price at the opening of the stock. Therefore, it is important to know how much  sentiment and interest in stocks that will IPO. The purpose of this research is to classify how much  public sentiment through twitter towards several companies in the 2nd quarter of 2022 that are released  to the public or IPO. The method used in this research is support vector machine by using data sources  from crawling tweets using the scrapping package from Python. From this research, 4873 tweets were  obtained with a percentage of 22.8% positive sentiment and 77.2% negative sentiment using three  experiments with testing data of 20%, 30%, and 40% with three kernels tried, namely linear, radial basis  function, and Sigmoid. Based on the three experiments using three different kernels, the largest accuracy  score can be obtained by using a linear kernel with an accuracy score of 80% on 30% testing data and  has sensitivity, precission and recall values of 91%, 38%, 85% and 89% at a cost value of 50% with a  cost accuracy of 80%",analisis sentimen twitter initial public offering saham goto 2022 support vector machine,initial public offering singkat ipo penarawaran saham publik jual usaha masyarakat usaha sangkut status perusahaanya ubah usaha swasta usaha publik initial public offering kelola bank bantu investasi fungsi catat saham bursa efek tuju ipo usaha tingkat modal ekuitas usaha kerja usaha pengaruh tawar publik masyarakat milik sentimen buruk pengaruh minat beli harga saham buka saham sentimen minat saham ipo tuju teliti kali klasifikasi sentimen masyarakat twitter usaha kuartal 2 2022 rilis publik ipo metode peneliain kali support vector machine sumber data crawling tweet package scrapping python teliti kali dapat hasil tweets 4873 tweets presentase 228 sentimen positif 772 sentimen negatif kali coba data testing 20 30 40 kernel coba linear radial basis function sigmoid dasar tiga coba kernel beda dapat skor akurasi besar kernel linear skor akurasi 80 data testing 30 milik nilai sensitivity precission recall 91 38 85 89 nilai cost 50 akurasi cost 80initial public offering or commonly abbreviated as ipo is an offering of shares to the public with the first sale of a company to the public so that the company concerned changes its company status from a private company to a public company initial public offering itself is usually managed by an investment bank whose function is to list shares on the stock exchange the purpose of a companys own ipo is to raise new equity capital for the company the performance of the company itself is very influential on the offer to the public if the public has a lot of bad sentiment it will greatly affect the buying interest and share price at the opening of the stock therefore it is important to know how much sentiment and interest in stocks that will ipo the purpose of this research is to classify how much public sentiment through twitter towards several companies in the 2nd quarter of 2022 that are released to the public or ipo the method used in this research is support vector machine by using data sources from crawling tweets using the scrapping package from python from this research 4873 tweets were obtained with a percentage of 228 positive sentiment and 772 negative sentiment using three experiments with testing data of 20 30 and 40 with three kernels tried namely linear radial basis function and sigmoid based on the three experiments using three different kernels the largest accuracy score can be obtained by using a linear kernel with an accuracy score of 80 on 30 testing data and has sensitivity precission and recall values of 91 38 85 and 89 at a cost value of 50 with a cost accuracy of 80
Prototipe Sistem Rekomendasi Konten Hiburan Anak-Anak Dan Klasifikasi Kelompok Usia Berbasis Suara Pada Perangkat Tinyml (Tiny Machine Learning).,"Wijaya, Rayhan Kurnia Alunantara",http://repository.its.ac.id/106099/,"Era digital menuntut solusi inovatif untuk memastikan anak-anak mengakses konten hiburan yang sesuai usia. Sistem rekomendasi yang digunakan pada berbagai platform konten hiburan tidak dapat mengklasifikasikan usia anak-anak secara akurat dan memberikan konten yang sesuai untuk mereka. Oleh karena itu, penelitian ini bertujuan untuk mengembangkan prototipe sistem rekomendasi dan klasifikasi usia anak-anak berbasis suara menggunakan perangkat Tiny Machine Learning yang dapat menentukan kelompok usia anak-anak secara akurat. Model kunci dalam penelitian ini adalah Hybrid MLP (Hybrid Multilayer Perceptron), dimana digunakan teknik ekstraksi fitur MFCC (Mel-Frequency Cepstral Coefficients) untuk mengolah data suara. Dalam penelitian ini, dataset utama berasal dari Mozilla Common Voice dan dataset suara anak-anak Indonesia yang dikumpulkan secara mandiri. Dilakukan juga perbandingan dengan model-model yang telah dikembangkan sebelumnya pada dataset yang sama dimana model Hybrid MLP berhasil melebihi akurasi model pembanding tersebut. Pengembangan model klasifikasi usia dilakukan pada platform Edge Impulse dengan menggunakan Arduino Nano BLE 33 Sense Lite. Pengujian model dilakukan dengan memanfaatkan kata kunci 'oke' yang bertujuan untuk mengaktivasi dan mengevaluasi respons sistem. Dalam uji coba untuk mengklasifikasikan kelompok usia anak SD dan SMP dengan skenario optimasi paling optimal, Hybrid MLP berhasil menunjukkan tingkat akurasi pelatihan sebesar 97.6% serta akurasi validasi 87.72%. Hasil ini mengindikasikan efektivitas model dalam proses klasifikasi usia dalam kondisi sumber daya komputasi yang terbatas.==================================================================================================================================The digital age demands innovative solutions to ensure children access age-appropriate entertainment content. Recommendation systems used on various entertainment content platforms are unable to accurately classify children's age and provide appropriate content for them. Therefore, this research aims to develop a prototype of a voice-based children's age classification and recommendation system using Tiny Machine Learning tools that can accurately determine children's age groups. The key model in this research is Hybrid MLP (Hybrid Multilayer Perceptron), where MFCC (Mel-Frequency Cepstral Coefficients) feature extraction technique is used to process voice data. In this research, the main dataset comes from Mozilla Common Voice and Indonesian children's voice dataset collected independently. Comparisons were also made with previously developed models on the same dataset where the Hybrid MLP model successfully exceeded the accuracy of the comparison model. The age classification model development was conducted on the Edge Impulse platform using Arduino Nano BLE 33 Sense Lite. Model testing was conducted by utilizing the keyword 'oke' which aims to activate and evaluate the system response. In the test to classify the age groups of elementary and junior high school children with the most optimal optimization scenario, Hybrid MLP successfully showed a training accuracy rate of 97.6% and a validation accuracy of 87.72%. These results indicate the effectiveness of the model in the age classification process under conditions of limited computational resources.",prototipe sistem rekomendasi konten hibur anakanak klasifikasi kelompok usia bas suara perangkat tinyml tiny machine learning,era digital tuntut solusi inovatif anakanak akses konten hibur sesuai usia sistem rekomendasi platform konten hibur klasifikasi usia anakanak akurat konten sesuai teliti tuju kembang prototipe sistem rekomendasi klasifikasi usia anakanak bas suara perangkat tiny machine learning tentu kelompok usia anakanak akurat model kunci teliti hybrid mlp hybrid multilayer perceptron mana teknik ekstraksi fitur mfcc melfrequency cepstral coefficients olah data suara teliti dataset utama asal mozilla common voice dataset suara anakanak indonesia kumpul mandiri banding modelmodel kembang dataset mana model hybrid mlp hasil lebih akurasi model banding kembang model klasifikasi usia platform edge impulse arduino nano ble 33 sense lite uji model manfaat kunci oke tuju mengaktivasi evaluasi respons sistem uji coba klasifikasi kelompok usia anak sd smp skenario optimasi optimal hybrid mlp hasil tingkat akurasi latih 976 akurasi validasi 8772 hasil indikasi efektivitas model proses klasifikasi usia kondisi sumber daya komputasi terbatasthe digital age demands innovative solutions to ensure children access ageappropriate entertainment content recommendation systems used on various entertainment content platforms are unable to accurately classify childrens age and provide appropriate content for them therefore this research aims to develop a prototype of a voicebased childrens age classification and recommendation system using tiny machine learning tools that can accurately determine childrens age groups the key model in this research is hybrid mlp hybrid multilayer perceptron where mfcc melfrequency cepstral coefficients feature extraction technique is used to process voice data in this research the main dataset comes from mozilla common voice and indonesian childrens voice dataset collected independently comparisons were also made with previously developed models on the same dataset where the hybrid mlp model successfully exceeded the accuracy of the comparison model the age classification model development was conducted on the edge impulse platform using arduino nano ble 33 sense lite model testing was conducted by utilizing the keyword oke which aims to activate and evaluate the system response in the test to classify the age groups of elementary and junior high school children with the most optimal optimization scenario hybrid mlp successfully showed a training accuracy rate of 976 and a validation accuracy of 8772 these results indicate the effectiveness of the model in the age classification process under conditions of limited computational resources
Inversi Data Magnetotellurik (MT) 1-D Menggunakan Algoritma Ensemble Kalman Inversion (EKI).,"Wijdannysa, Jasinda",http://repository.its.ac.id/115180/,"Metode magnetotellurik (MT) merupakan metode eksplorasi geofisika pasif yang dapat menjangkau kedalaman lapisan batuan yang sangat dalam, sehingga cocok digunakan untuk penentuan kedalaman basemen. Untuk menentukan kedalaman basemen, data MT diinversikan agar mendapatkan estimasi parameter model (resistivitas dan ketebalan lapisan batuan). Pada penelitian ini, algoritma Ensemble Kalman Inversion (EKI) digunakan untuk melakukan inversi data MT 1-D. Algoritma EKI dilakukan uji coba pada data sintetik tipe kurva sounding (A, K, H, Q, D, Q) serta data sintetik kasus cekungan sedimen. Setelahnya, hasil inversi pada setiap data sintetik tersebut dianalisis posterior distribution model (PDM) dan principal component analysis (PCA). Analisis PDM dilakukan untuk mengestimasi ketidakpastian parameter model terbaik hasil inversi, sedangkan analisis PCA digunakan untuk mengkorelasikan parameter model sebenarnya pada data sintetik dengan parameter model hasil inversi. Hasil analisis PDM pada data sintetik A, K, H, Q, D, dan Q menunjukkan estimasi model parameter yang sesuai dengan model sebenarnya, sedangkan hasil analisis PCA menunjukkan model sebenarnya dan model terbaik yang berhimpit untuk setiap tipe kurva dan berada pada nilai fungsi objektif yang minimum. Hal ini mengindikasikan bahwa algoritma EKI terbukti robust dalam uji coba data sintetik tipe kurva sounding. Analisis yang sama juga dilakukan pada data MT sintetik untuk kasus cekungan sedimen. Namun, untuk data ini model terbaik pada analisis PDM menunjukkan hasil yang berbeda dari model sebenarnya, serta jarak model sebenarnya dengan model terbaik hasil inversi yang berjauhan pada ruang PCA. Hal ini menunjukkan bahwa algoritma EKI belum akurat dalam menentukan estimasi model parameter pada kasus cekungan sedimen sintetik, khususnya dalam penentuan parameter model resistivitas lapisan basemen.=================================================================================================================================The magnetotelluric (MT) method is a passive geophysical exploration technique that can probe deep rock layers, making it ideal for determining basement depths. To achieve this, inversion modeling of MT data is performed to estimate model parameters such as resistivity and rock layer thickness. This research utilizes the Ensemble Kalman Inversion (EKI) algorithm for 1-D MT data inversion. The EKI algorithm was tested on synthetic sounding curve data types (A, K, H, Q, D, Q) and synthetic data in the case of sedimentary basins. The inversion results for each synthetic dataset were analyzed using posterior distribution model (PDM) and principal component analysis (PCA). PDM analysis estimates the uncertainty of the best model parameters from the inversion, while PCA correlates the actual model parameters of synthetic data with the inversion results. For synthetic sounding curve data, PDM analysis indicated that the estimated model parameters matched the actual model, and PCA analysis showed the actual and best models coinciding at the minimum objective function value. This demonstrates the robustness of the EKI algorithm for synthetic sounding curve data. For synthetic MT data representing sedimentary basins, the PDM analysis showed discrepancies between the best model and the actual model, with a significant distance between them in PCA space. This suggests that the EKI algorithm is less accurate in estimating model parameters for synthetic sedimentary basin cases, particularly in determining basement layer resistivity model.",inversi data magnetotellurik mt 1d algoritma ensemble kalman inversion eki,metode magnetotellurik mt metode eksplorasi geofisika pasif jangkau dalam lapis batu cocok tentu dalam basemen tentu dalam basemen data mt inversi estimasi parameter model resistivitas tebal lapis batu teliti algoritma ensemble kalman inversion eki inversi data mt 1d algoritma eki uji coba data sintetik tipe kurva sounding a k h q d q data sintetik cekung sedimen telah hasil inversi data sintetik analis posterior distribution model pdm principal component analysis pca analisis pdm estimasi ketidakpastian parameter model baik hasil inversi analisis pca korelasi parameter model data sintetik parameter model hasil inversi hasil analisis pdm data sintetik a k h q d q estimasi model parameter sesuai model hasil analisis pca model model baik berhimpit tipe kurva nilai fungsi objektif minimum indikasi algoritma eki bukti robust uji coba data sintetik tipe kurva sounding analisis data mt sintetik cekung sedimen data model baik analisis pdm hasil beda model jarak model model baik hasil inversi jauh ruang pca algoritma eki akurat tentu estimasi model parameter cekung sedimen sintetik tentu parameter model resistivitas lapis basementhe magnetotelluric mt method is a passive geophysical exploration technique that can probe deep rock layers making it ideal for determining basement depths to achieve this inversion modeling of mt data is performed to estimate model parameters such as resistivity and rock layer thickness this research utilizes the ensemble kalman inversion eki algorithm for 1d mt data inversion the eki algorithm was tested on synthetic sounding curve data types a k h q d q and synthetic data in the case of sedimentary basins the inversion results for each synthetic dataset were analyzed using posterior distribution model pdm and principal component analysis pca pdm analysis estimates the uncertainty of the best model parameters from the inversion while pca correlates the actual model parameters of synthetic data with the inversion results for synthetic sounding curve data pdm analysis indicated that the estimated model parameters matched the actual model and pca analysis showed the actual and best models coinciding at the minimum objective function value this demonstrates the robustness of the eki algorithm for synthetic sounding curve data for synthetic mt data representing sedimentary basins the pdm analysis showed discrepancies between the best model and the actual model with a significant distance between them in pca space this suggests that the eki algorithm is less accurate in estimating model parameters for synthetic sedimentary basin cases particularly in determining basement layer resistivity model
Prediksi Mahasiswa Drop Out Institut Teknologi Sepuluh Nopember Menggunakan XGBoost dan SHAP Values Berbasis Dashboard Interaktif.,"Winarso, Raihan Adam Handoyo",http://repository.its.ac.id/105897/,"Peran mahasiswa menjadi aspek penting dalam menentukan keberhasilan penyelenggaraan pendidikan. Namun, tidak semua mahasiswa dapat menyelesaikan studi tepat waktu sesuai dengan yang direncanakan, hingga terancam drop out. Drop out atau pemberhentian status mahasiswa adalah proses pencabutan status kemahasiswaan, yang disebabkan oleh hal-hal tertentu atau sudah ditentukan oleh perguruan tinggi yang bersangkutan. Fenomena ini menjadi tantangan bagi institusi, yang harus ditemukan solusinya, karena drop out menimbulkan kerugian signifikan baik pada mahasiswa maupun institusi. Langkah preventif untuk memprediksi mahasiswa yang berpotensi drop out dilakukan dengan menggunakan teknik klasifikasi menggunakan XGBoost dan SHAP Values. XGBoost adalah algoritma klasifikasi yang menggunakan teknik boosting, yaitu langkah berulang untuk memperkuat performa model klasifikasi lemah hingga akhirnya menjadi model yang lebih kuat. Setelah model XGBoost terbentuk, interpretasi dilakukan dengan melihat rata-rata kontribusi setiap variabel menggunakan SHAP Values. Hasil penelitian ini menunjukkan bahwa semester yang sudah dijalani, IPK persiapan, dan IPK mahasiswa memiliki kontribusi besar dalam menentukan status mahasiswa sebagai drop out atau tidak drop out. Model XGBoost yang terbentuk memberikan kebaikan model dengan akurasi sebesar 100%, sensitivitas sebesar 100%, dan spesifisitas sebesar 100%. Dashboard prediksi mahasiswa drop out atau tidak drop out memiliki 4 menu yaitu menu dashboard untuk melihat karakteristik dari mahasiswa ketika data imbalance dan balance, menu kedua yaitu data mahasiswa untuk menampilkan data mahasiswa secara keseluruhan, menu ketiga yaitu prediksi untuk melakukan prediksi dengan cara input variabel yang diduga memengaruhi status mahasiswa, dan yang terakhir adalah kontribusi variabel untuk melihat besar kontribusi variabel yang digunakan dalam memprediksi status mahasiswa.=================================================================================================================================The role of students is an important aspect in determining the success of educational provision. However, not all students can complete their studies on time as planned, so they are threatened with dropping out. Drop out or termination of student status is the process of revoking student status, which is caused by certain reasons or has been determined by the university concerned. This phenomenon is a challenge for institutions, which must find a solution, because dropping out causes significant losses to both students and institutions. Preventive steps to predict students who have the potential to drop out are carried out using classification techniques using XGBoost and SHAP Values. XGBoost is a classification algorithm that uses a boosting technique, namely repeated steps to strengthen the performance of a weak classification model until it finally becomes a stronger model. After the XGBoost model is formed, interpretation is carried out by looking at the average contribution of each variable using SHAP Values. The results of this research show that the semester that has been completed, the preparatory GPA, and the student's GPA have a major contribution in determining a student's status as a dropout or not. The XGBoost model formed provides a good model with an accuracy of 100%, sensitivity of 100%, and specificity of 100%. The dashboard predicting whether students will drop out or not drop out has 4 menus, namely the dashboard menu to see the characteristics of students when the data is imbalanced and balanced, the second menu is student data to display overall student data, the third menu is prediction to make predictions by inputting the specified variables. is thought to influence student status, and the last is variable contribution to see the contribution of the variables used in predicting student status.",prediksi mahasiswa drop out institut teknologi puluh nopember xgboost shap values bas dashboard interaktif,peran mahasiswa aspek tentu hasil selenggara didik mahasiswa selesai studi sesuai rencana ancam drop out drop out henti status mahasiswa proses cabut status mahasiswa sebab halhal tentu guru sangkut fenomena tantang institusi temu solusi drop out timbul rugi signifikan mahasiswa institusi langkah preventif prediksi mahasiswa potensi drop out teknik klasifikasi xgboost shap values xgboost algoritma klasifikasi teknik boosting langkah ulang kuat performa model klasifikasi lemah model kuat model xgboost bentuk interpretasi ratarata kontribusi variabel shap values hasil teliti semester jalan ipk siap ipk mahasiswa milik kontribusi tentu status mahasiswa drop out drop out model xgboost bentuk baik model akurasi 100 sensitivitas 100 spesifisitas 100 dashboard prediksi mahasiswa drop out drop out milik 4 menu menu dashboard karakteristik mahasiswa data imbalance balance menu data mahasiswa tampil data mahasiswa menu tiga prediksi prediksi input variabel duga pengaruh status mahasiswa kontribusi variabel kontribusi variabel prediksi status mahasiswathe role of students is an important aspect in determining the success of educational provision however not all students can complete their studies on time as planned so they are threatened with dropping out drop out or termination of student status is the process of revoking student status which is caused by certain reasons or has been determined by the university concerned this phenomenon is a challenge for institutions which must find a solution because dropping out causes significant losses to both students and institutions preventive steps to predict students who have the potential to drop out are carried out using classification techniques using xgboost and shap values xgboost is a classification algorithm that uses a boosting technique namely repeated steps to strengthen the performance of a weak classification model until it finally becomes a stronger model after the xgboost model is formed interpretation is carried out by looking at the average contribution of each variable using shap values the results of this research show that the semester that has been completed the preparatory gpa and the students gpa have a major contribution in determining a students status as a dropout or not the xgboost model formed provides a good model with an accuracy of 100 sensitivity of 100 and specificity of 100 the dashboard predicting whether students will drop out or not drop out has 4 nus namely the dashboard menu to see the characteristics of students when the data is imbalanced and balanced the second menu is student data to display overall student data the third menu is prediction to make predictions by inputting the specified variables is thought to influence student status and the last is variable contribution to see the contribution of the variables used in predicting student status
Sistem Klasifikasi Kondisi Motor Dust Collector Menggunakan Model Support Vector Machine (SVM) Guna Menunjang Condition-Based Maintenance.,"Winata, Nurdiwansyah Bagus",http://repository.its.ac.id/115583/,"Perusahaan Pestisida MSI merupakan salah satu perusahaan yang bergerak di bidang formulasi pestisida. Pada proses produksi, terdapat satu mesin penting yang menggunakan motor induksi 3 fasa sebagai penggerak utama, yaitu mesin dust collector. Namun, dalam dua tahun terakhir, terjadi sembilan kali kasus kerusakan pada mesin dust collector di MSI. Kerusakan tersebut terbagi menjadi beberapa jenis kerusakan, seperti kerusakan bearing, shaft misalignment, dan motor terbakar. Untuk mencegah kerusakan pada motor diperlukan penerapan metode maintenance yang efektif. Dengan data historis yang terbatas, metode Condition-Based Maintenance (CBM) adalah metode yang efektif. Dengan melakukan pemeliharaan hanya saat diperlukan berdasarkan kondisi aktual peralatan, CBM dapat mengurangi biaya yang tidak perlu dan mengurangi downtime yang tidak direncanakan. Dibantu dengan model Support Vector Machine (SVM), CBM pada proyek ini bertujuan untuk mengklasifikasikan kondisi motor secara aktual. Motor dengan kondisi normal, shaft miasalignment, dan bearing damage menjadi target klasifikasi pada proyek ini. Klasifikasi kondisi motor tersebut mengacu kepada data historis getaran dan suhu permukaan motor secara aktual. Dari penelitian yang telah dilakukan, pembacaan sensor HVT100 pada nilai getaran memiliki error sebesar 2,16% dan nilai suhu permukaan motor memiliki galat sebesar 3,89% dari 20 kali percobaan. Metode Support Vector Machine (SVM) menggunakan multiclass strategy OneVsOne (OVO) dan OneVsRest (OVR) dapat mengklasifikasikan kondisi motor normal, shaft misalignment, dan bearing damage secara aktual dengan akurasi dari 66% hingga 100%.==================================================================================================================================Pesticide company MSI is one of the companies active in the field of pesticide formulation. In the production process, there's one important engine that uses a three-phase induction motor as its primary driver, a dust collector. However, in the last two years, there have been nine cases of damage to the dust collection machine at MSI. Such damage is divided into several types of damage, such as bearing damage, shaft misalignment, and motorcycle burning. To prevent damage to the motorcycle, effective maintenance methods are required. With limited historical data, the Condition-Based Maintenance (CBM) method is an effective method. By performing maintenance only when necessary based on the actual condition of the equipment, CBM can reduce unnecessary costs and reduce unplanned downtime. Assisted by the Support Vector Machine (SVM) model, the CBM in this project aims to classify the motor condition in actual terms. Motorcycles in normal condition, shaft misalignment, and bearing damage are classified targets on this project. The classification of the condition of the motor refers to the historical data of the vibration and surface temperature of the actual motor. From the research that has been carried out the HVT100 sensor readings on the vibration value had an error of 2.16% and the surface temperature value of the motor had a error of 3.89% of 20 trials. Support Vector Machine (SVM) methods using multiclass strategies OneVsOne (OVO) and OneVsRest (OVR) can classify normal motor conditions, shaft misalignment, and bearing damage effectively with accuracy from 66% up to 100%.",sistem klasifikasi kondisi motor dust collector model support vector machine svm tunjang conditionbased maintenance,usaha pestisida msi salah usaha gerak bidang formulasi pestisida proses produksi mesin motor induksi 3 fasa gerak utama mesin dust collector sembilan kali rusa mesin dust collector msi rusa bagi jenis rusa rusa bearing shaft misalignment motor bakar cegah rusa motor terap metode maintenance efektif data historis batas metode conditionbased maintenance cbm metode efektif pelihara dasar kondisi aktual alat cbm kurang biaya kurang downtime rencana bantu model support vector machine svm cbm proyek tuju klasifikasi kondisi motor aktual motor kondisi normal shaft miasalignment bearing damage target klasifikasi proyek klasifikasi kondisi motor acu data historis getar suhu muka motor aktual teliti baca sensor hvt100 nilai getar milik error 216 nilai suhu muka motor milik galat 389 20 kali coba metode support vector machine svm multiclass strategy onevsone ovo onevsrest ovr klasifikasi kondisi motor normal shaft misalignment bearing damage aktual akurasi 66 100pesticide company msi is one of the companies active in the field of pesticide formulation in the production process theres one important engine that uses a threephase induction motor as its primary driver a dust collector however in the last two years there have been nine cases of damage to the dust collection machine at msi such damage is divided into several types of damage such as bearing damage shaft misalignment and motorcycle burning to prevent damage to the motorcycle effective maintenance methods are required with limited historical data the conditionbased maintenance cbm method is an effective method by performing maintenance only when necessary based on the actual condition of the equipment cbm can reduce unnecessary costs and reduce unplanned downtime assisted by the support vector machine svm model the cbm in this project aims to classify the motor condition in actual terms motorcycles in normal condition shaft misalignment and bearing damage are classified targets on this project the classification of the condition of the motor refers to the historical data of the vibration and surface temperature of the actual motor from the research that has been carried out the hvt100 sensor readings on the vibration value had an error of 216 and the surface temperature value of the motor had a error of 389 of 20 trials support vector machine svm methods using multiclass strategies onevsone ovo and onevsrest ovr can classify normal motor conditions shaft misalignment and bearing damage effectively with accuracy from 66 up to 100
Simulasi Performa Sistem Suspensi Semi Aktif Dengan Kendali PID Pada Kendaraan Roda Dua.,"Yahya, Nur Muhammad Adi",http://repository.its.ac.id/107805/,"Seiring dengan perkembangan sepeda motor dalam masyarakat, spesifikasi kendaraan roda dua masih terbatas pada suspensi standar yang menggunakan sistem pasif. Dimana sistem suspensi ini belum mampu secara optimal mengatasi getaran yang timbul akibat berbagai kondisi jalan. Ketidakmampuan mengisolasi getaran mengakibatkan ketidaknyamanan bagi pengendara. Pada proyek akhir ini, dilakukan perancangan simulasi sistem suspensi semi aktif yang dapat menghasilkan respon keseluruhan dari model kendaraan roda dua yang sesuai dengan standar kenyamanan ISO 2631 dengan menggunakan kendali PID. Metode autotuning digunakan untuk menentukan nilai parameter pengendali PID. Hasil autotuning menghasilkan nilai Kp = 36836, Ki = 212093, dan Kd = 17587. Perancangan simulasi dilakukan dengan variasi kecepatan yang berbeda yaitu 15 km/jam, 30 km/jam, dan 45 km/jam. Terdapat tiga jenis lintasan pengganggu jalan yang digunakan, yaitu step, impulse, dan sinusoidal. Perancangan ini bertujuan untuk mendapatkan hasil respon percepatan dan simpangan yang dialami  bodi kendaraan dari sistem suspensi semi aktif yang dibantu oleh gaya aktuator, dan membandingkannya dengan sistem suspensi pasif. Dari hasil simulasi yang dilakukan, sistem suspensi semi aktif yang dirancang dapat menghasilkan respon percepatan pada bodi kendaraan yang sesuai dengan ISO 2631. Seluruh parameter dari sistem suspensi semi aktif yang dirancang menghasilkan rentang nilai displacement 0.0005 – 0.006 m, nilai settling time selama 0.5 – 2s ,serta nilai a_{rms} sebesar 0.050 – 0.28 {m/s}^2,dimana nilai ini sudah sesuai dengan standar kenyamanan yang sudah ditetapkan ISO 2631 yaitu a_{rms}< 0.315 {m/s}^2.=================================================================================================================================Along with the development of motorbikes in society, the specifications of two-wheeled vehicles are still limited to standard suspensions that use passive systems. Where this suspension system has not been able to optimally overcome vibrations arising from various road conditions. The inability to isolate vibrations results in discomfort for the rider. In this final project, a semi-active suspension system simulation design is carried out that can produce an overall response from a two-wheeled vehicle model that complies with ISO 2631 comfort standards using PID control. The autotuning method is used to determine the value of the PID controller parameters. The autotuning results produce values of Kp = 36836, Ki = 212093, and Kd = 17587. The simulation design is carried out with different speed variations of 15 km/h, 30 km/h, and 45 km/h. There are three types of road disturbance trajectories used, namely step, impulse, and sinusoidal. This design aims to get the results of the acceleration and deviation response experienced by the vehicle body of the semi-active suspension system assisted by the actuator force, and compare it with the passive suspension system. From the simulation results, the designed semi-active suspension system can produce an acceleration response on the vehicle body in accordance with ISO 2631. All parameters of the designed semi-active suspension system produce a displacement value range of 0.0005 - 0.006 m, a settling time value of 0.5 - 2s, and a_{rms} value of 0.050 - 0.28 {m/s}^2., where this value is in accordance with the comfort standards set by ISO 2631, namely a_{rms} < 0.315 {m/s}^2.",simulasi performa sistem suspensi semi aktif kendali pid kendara roda,iring kembang sepeda motor masyarakat spesifikasi kendara roda batas suspensi standar sistem pasif mana sistem suspensi optimal atas getar timbul akibat kondisi jalan ketidakmampuan isolasi getar akibat ketidaknyamanan kendara proyek ancang simulasi sistem suspensi semi aktif hasil respon model kendara roda sesuai standar nyaman iso 2631 kendali pid metode autotuning tentu nilai parameter kendali pid hasil autotuning hasil nilai kp 36836 ki 212093 kd 17587 ancang simulasi variasi cepat beda 15 kmjam 30 kmjam 45 kmjam jenis lintas ganggu jalan step impulse sinusoidal ancang tuju hasil respon cepat simpang alami bodi kendara sistem suspensi semi aktif bantu gaya aktuator banding sistem suspensi pasif hasil simulasi sistem suspensi semi aktif rancang hasil respon cepat bodi kendara sesuai iso 2631 parameter sistem suspensi semi aktif rancang hasil rentang nilai displacement 00005  0006 m nilai settling time 05  2s nilai arms 0050  028 ms2dimana nilai sesuai standar nyaman tetap iso 2631 arms 0315 ms2along with the development of motorbikes in society the specifications of twowheeled vehicles are still limited to standard suspensions that use passive systems where this suspension system has not been able to optimally overcome vibrations arising from various road conditions the inability to isolate vibrations results in discomfort for the rider in this final project a semiactive suspension system simulation design is carried out that can produce an overall response from a twowheeled vehicle model that complies with iso 2631 comfort standards using pid control the autotuning method is used to determine the value of the pid controller parameters the autotuning results produce values of kp 36836 ki 212093 and kd 17587 the simulation design is carried out with different speed variations of 15 kmh 30 kmh and 45 kmh there are three types of road disturbance trajectories used namely step impulse and sinusoidal this design aims to get the results of the acceleration and deviation response experienced by the vehicle body of the semiactive suspension system assisted by the actuator force and compare it with the passive suspension system from the simulation results the designed semiactive suspension system can produce an acceleration response on the vehicle body in accordance with iso 2631 all parameters of the designed semiactive suspension system produce a displacement value range of 00005 0006 m a settling time value of 05 2s and arms value of 0050 028 ms2 where this value is in accordance with the comfort standards set by iso 2631 namely arms 0315 ms2
Sistem Rejector Label Kemasan Susu Menggunakan Image processing Dengan Metode Support Vector Machine Pada Industri Pengolahan Susu.,"Yuliyanto, Jefrin",http://repository.its.ac.id/89605/,"Pada pabrik pengolahan susu, terdapat beberapa permasalahan saat pemasangan label kemasan botol susu. Permasalahan tersebut adalah terjadinya gagal pemasangan atau sobeknya label pada saat dilakukan pemasangan label botol. Problem tersebut menjadi jobdesk tersendiri pada suatu pabrik, yang menyebabkan produk belum layak jual. Sehingga memerlukan perbaikan pada label dan produk harus di reject terlebih dahulu. Maka dari itu dirancang sebuah alat yang dapat mendeteksi kerusakan atau gagal pemasangan pada label kemasan susu menggunakan image processing dengan metode Gray Level Co-occurance Matrix (GLCM) sebagai pendeteksi texture dari objek dengan mengeluarkan nilai energy, entropy, homogeneity, dan contrast. Kemudian hasil pembacaan GLCM akan dilakukan klasifikasi menggunakan support vector machine (SVM) untuk memilah kondisi label botol. Jika salah label botol cacat maka botol akan di reject dan jika sempurna atau normal akan lanjut ke proses pengemasan. Hasil dari alat rejector label kemasan susu ini, Ketika mendeteksi label kemasan botol susu secara random menghasilkan nilai accuracy sebesar 85%, precission 90%, dan False Positive Rate 20%, Ketika dilakukan pengujian keseluruhan didapat hasil %error sebesar 20%.=====================================================================================================In milk processing plants, there are several problems when installing milk bottle packaging labels. The problem is the occurrence of failed installation or tearing of the label when the bottle label is installed. The problem becomes a separate job desk in a factory, which causes the product to be unfit for sale. So it requires improvement on the label and the product must be rejected first. Therefore, a tool is designed that can detect damage or failure of installation on milk packaging labels using image processing with the Gray Level Co-occurance Matrix (GLCM) method as a texture detector of objects by issuing energy, entropy, homogeneity, and contrast values. Then the results of the GLCM reading will be classified using a support vector machine (SVM) to sort out the condition of the bottle label. If the wrong bottle label is defective, the bottle will be rejected and if it is perfect or normal, it will continue to the packaging process. The results of this milk packaging label rejector tool, when detecting milk bottle packaging labels randomly produce an accuracy value of 85%, precision 90%, and a False Positive Rate of 20%. When the overall test is carried out, the result is an error of 20%.",sistem rejector label kemas susu image processing metode support vector machine industri olah susu,pabrik olah susu masalah pasang label kemas botol susu masalah gagal pasang sobek label pasang label botol problem jobdesk sendiri pabrik sebab produk layak jual baik label produk reject rancang alat deteksi rusa gagal pasang label kemas susu image processing metode gray level cooccurance matrix glcm deteksi texture objek keluar nilai energy entropy homogeneity contrast hasil baca glcm klasifikasi support vector machine svm mem kondisi label botol salah label botol cacat botol reject sempurna normal proses emas hasil alat rejector label kemas susu deteksi label kemas botol susu random hasil nilai accuracy 85 precission 90 false positive rate 20 uji hasil error 20in milk processing plants there are several problems when installing milk bottle packaging labels the problem is the occurrence of failed installation or tearing of the label when the bottle label is installed the problem becomes a separate job desk in a factory which causes the product to be unfit for sale so it requires improvement on the label and the product must be rejected first therefore a tool is designed that can detect damage or failure of installation on milk packaging labels using image processing with the gray level cooccurance matrix glcm method as a texture detector of objects by issuing energy entropy homogeneity and contrast values then the results of the glcm reading will be classified using a support vector machine svm to sort out the condition of the bottle label if the wrong bottle label is defective the bottle will be rejected and if it is perfect or normal it will continue to the packaging process the results of this milk packaging label rejector tool when detecting milk bottle packaging labels randomly produce an accuracy value of 85 precision 90 and a false positive rate of 20 when the overall test is carried out the result is an error of 20
Analisis Sentimen Dan Clustering Pada Pengguna Tiket.Com Menggunakan Metode Naïve Bayes Classifier Dan Support Vector Machine.,"Yuniar, Iga Amalia",http://repository.its.ac.id/100403/,"Tiket.com adalah perusahaan agen untuk pelayanan perjalanan daring yang berbasis website dan aplikasi untuk mobile phone atau perangkat desktop. Aplikasi tiket.com juga disebut sebagai pionir online travel agent (OTA) terbesar di Indonesia yang selalu memberikan inovasi handal untuk mempermudah pengguna ketika memesan tiket pesawat online, selain itu aplikasi ini melayani pesanan untuk penginapan, sewa mobil maupun menawarkan berbagai macam aktifitas hiburan dan menjadi satu-satunya mitra resmi PT Kereta Api Indonesia. Penelitian ini melakukan penelitian dengan topik analisis sentimen terhadap pengguna tiket.com. Dengan bantuan analisis sentimen, informasi yang sebelumnya tidak terstruktur dapat dirubah menjadi data yang lebih terstruktur. Selain itu sistem analisis sentimen ini dapat membantu perusahaan dalam memahami keinginan pelanggan berdasarkan review atau umpan balik pelanggan yang tulus dan spesifik untuk meningkatkan kualitas produk dan layanan perusahaan. Penelitian ini melakukan perbandingan hasil analisis sentimen pengguna tiket.com dengan menggunakan metode Naïve Bayes Classifier dan Support Vector Machine untuk membandingkan tingkat akurasi yang lebih akurat. dan mengelompokkan review pengguna yang mana memberikan respon positif atau negatif. Akurasi terbaik diperoleh dari klasifikasi dengan menggunakan algoritma Support Vector Machine Kernel RBF dengan indikator kinerja dengan menggunakan akurasi sebesar 93,1%, AUC sebesar 64,3% dan GMean sebesar 53,5%. dan dengan berdasarkan analisis Cluster K-means terdapat 2 kelompok opini yang terbentuk yaitu opini bersentimen positif, negatif.=================================================================================================================================Tiket.com is an online travel agent company which is website based and an application for mobile phone or desktop. Tiket.com is also known as the pioneer of the biggest online travel agent (OTA) in Indonesia which always provides reliable innovation to make users easier when they order a plane online, this application also provides accommodation, rent car or any other entertainment and became the only official partner for PT. Kereta Api Indonesia. This study conducts research on sentiment analysis towards users of tiket.com users. By using sentiment analysis, the unstructured information can be transformed to well-structured data. Besides, this sentiment analysis system can help the company to figure out what users want based on honest and specific reviews to approve quality of the product and company services. Researchers want to compare the result of sentiment analysis of tiket.com users by using the methods of Naive Bayes Classifier and Support Vector Machine. This research is done by comparing the accuracy level of the methods so can get the method with the most accurate analysis result. And cluster user reviews based on their positive, and negative responses using K-Means clustering analysis. The best accuracy is obtained from classification by using Support Vector Machine kernel RBF algorithm with performance indicator by using accuracy as 93,1%, AUC as 64,3% and G-mean as 53,5%. Based on the K-means clustering analysis, two opinion clusters have been formed, namely positive sentiment, negative sentiment.",analisis sentimen clustering guna tiketcom metode na ve bayes classifier support vector machine,tiketcom usaha agen layan jalan daring bas website aplikasi mobile phone perangkat desktop aplikasi tiketcom pionir online travel agent ota besar indonesia inovasi handal mudah guna mes tiket pesawat online aplikasi layan pesan inap sewa mobil tawar aktifitas hibur satusatunya mitra resmi pt kereta api indonesia teliti teliti topik analisis sentimen guna tiketcom bantu analisis sentimen informasi struktur rubah data struktur sistem analisis sentimen bantu usaha paham langgan dasar review umpan langgan tulus spesifik tingkat kualitas produk layan usaha teliti banding hasil analisis sentimen guna tiketcom metode na ve bayes classifier support vector machine banding tingkat akurasi akurat kelompok review guna respon positif negatif akurasi baik oleh klasifikasi algoritma support vector machine kernel rbf indikator kerja akurasi 931 auc 643 gmean 535 dasar analisis cluster kmeans 2 kelompok opini bentuk opini sentimen positif negatiftiketcom is an online travel agent company which is website based and an application for mobile phone or desktop tiketcom is also known as the pioneer of the biggest online travel agent ota in indonesia which always provides reliable innovation to make users easier when they order a plane online this application also provides accommodation rent car or any other entertainment and became the only official partner for pt kereta api indonesia this study conducts research on sentiment analysis towards users of tiketcom users by using sentiment analysis the unstructured information can be transformed to wellstructured data besides this sentiment analysis system can help the company to figure out what users want based on honest and specific reviews to approve quality of the product and company services researchers want to compare the result of sentiment analysis of tiketcom users by using the methods of naive bayes classifier and support vector machine this research is done by comparing the accuracy level of the methods so can get the method with the most accurate analysis result and cluster user reviews based on their positive and negative responses using kmeans clustering analysis the best accuracy is obtained from classification by using support vector machine kernel rbf algorithm with performance indicator by using accuracy as 931 auc as 643 and gmean as 535 based on the kmeans clustering analysis two opinion clusters have been formed namely positive sentiment negative sentiment
Pengembangan Algoritma Support Vector Machine (SVM) Multiclass untuk Prediktor Kategorik dengan Proportional Class Constraint.,"Yustanti, Wiyli",http://repository.its.ac.id/107355/,"Terdapat  tiga prinsip penting dalam pengelompokan Uang Kuliah Tunggal (UKT). Pertama, pengelompokan UKT harus berdasarkan pada tingkat kemampuan sosial ekonomi orang tua mahasiswa. Kedua, perguruan tinggi harus mencapai pendapatan negara bukan pajak (PNBP) melalui penerimaan pembayaran UKT berdasarkan target yang ditetapkan, dan yang ketiga adalah bahwa PTN sebagai lembaga pemerintah memiliki tanggung jawab sosial untuk menerima minimal 20% mahasiswa dari keluarga kurang mampu. Ketiga prinsip ini menjadi latar belakang utama dalam penelitian ini, sehingga dibutuhkan sebuah pengembangan metode klasifikasi UKT dengan memperhitungkan target penerimaan (revenue) PTN dan persyaratan proporsi minimal pada kelompok UKT rendah. Untuk penyelesaian masalah tersebut, perlu dikembangkan algoritma klasifikasi yang dapat mengakomodasi faktor kendala (constraint). Faktor kendala yang wajib ada adalah proporsi  kelas tertentu dari hasil klasifikasi (Proportional Class Constraint) dan jumlah minimal penerimaan UKT (revenue). Tipe variabel prediktor dari studi kasus penelitian ini adalah kategorik. Hasil kajian pustaka mendapatkan bahwa metode klasifikasi untuk prediktor kategorik yang secara langsung dapat digunakan adalah metode berbasis Kernel Density Classification (KDC). Akan tetapi, metode KDC memiliki keterbatasan dalam penambahan constraint pada model klasi-fikasinya, selain itu banyak penelitian yang menunjukkan bahwa kinerjanya masih dapat diungguli oleh metode Support Vector Machine (SVM). Pada metode SVM terdapat keterbatasan yaitu bahwa input algoritma harus bertipe numerik. Dengan demikian penelitian ini memberikan kontribusi, yaitu (1) pemilihan metode encoding prediktor kategorik yang mampu meningkatkan kinerja SVM multiclass pada tahap pre-processing, dan (2) pengembangan algoritma SVM multiclass dengan Proportional Class Constraint (SVM-ProClass). Penelitian ini meng-gunakan ordinal encoding dan menghasilkan algoritma SVM-ProClass dengan dua tahapan utama yaitu fase prediksi kelas dan fase pergeseran kelas (Birth-Death Process). Selanjutnya, algoritma SVM-ProClass diterapkan pada dataset UKT untuk menghasilkan dataset yang besifat separable dan imbalanced berbasis proporsi kelas, dimana kinerja dari dataset hasil SVM-ProClass memiliki nilai akurasi F1-Score rata-rata 99,22% dan berbeda secara signifikan dengan α=5% terhadap kinerja dataset tanpa  SVM-ProClass.===================================================================================================================================There are three important principles in grouping single tuition fees (UKT). First, the UKT grouping must be based on the socio-economic ability level of the student's parents. Second, universities must achieve non-tax state income (PNBP) through receipt of UKT payments based on set targets, and third, the public university as government institutions have a social responsibility to accept a minimum of 20% of students from underprivileged families. These three principles are the main background for this research, so it is necessary to develop a UKT classification method that takes into account university revenue targets and minimum proportion requirements in the low UKT group. To solve this problem, it is necessary to develop a classification algorithm that can accommodate constraint factors. The constraint factors that must be present are the proportion of a certain class from the classification results (proportional class constraint) and the minimum amount of UKT receipts (revenue). The type of predictor variable used in the case study is categorical. The results of the literature review found that the classification method for categorical predictors that can be directly used is the Kernel Density Classification (KDC) based method. However, the KDC method has limitations in adding constraints to the classification model; apart from that, many studies show that its performance can still be superior to the Support Vector Machine (SVM) method. There is a limitation to the SVM method, namely that the algorithm input cannot be of the categorical type. Thus, this research provides contributions, namely (1) selecting a categorical predictor encoding method that is able to improve multiclass SVM performance at the pre-processing stage and (2) developing a multiclass SVM algorithm with proportional class constraints (SVM-ProClass). This research uses ordinal encoding and produces the SVM-ProClass algorithm with two main stages, namely the class prediction phase and the class shift phase (Birth-Death Process). Next, the SVM-ProClass algorithm is applied to the UKT dataset to produce a separable and imbalanced dataset based on class proportions, where the performance of the SVM-ProClass dataset has an average F1-Score accuracy value of 99.22% and it is significantly different from the performance of the dataset without SVM-ProClass with α=5%.",kembang algoritma support vector machine svm multiclass prediktor kategorik proportional class constraint,prinsip kelompok uang kuliah tunggal ukt kelompok ukt dasar tingkat mampu sosial ekonomi orang tua mahasiswa guru capai dapat negara pajak pnbp terima bayar ukt dasar target tetap tiga ptn lembaga perintah milik tanggung sosial terima minimal 20 mahasiswa keluarga tiga prinsip latar utama teliti butuh kembang metode klasifikasi ukt hitung target terima revenue ptn syarat proporsi minimal kelompok ukt rendah selesai kembang algoritma klasifikasi akomodasi faktor kendala constraint faktor kendala wajib proporsi kelas hasil klasifikasi proportional class constraint minimal terima ukt revenue tipe variabel prediktor studi teliti kategorik hasil kaji pustaka metode klasifikasi prediktor kategorik langsung metode bas kernel density classification kdc metode kdc milik batas tambah constraint model klasifikasi teliti kerja unggul metode support vector machine svm metode svm batas input algoritma tipe numerik teliti kontribusi 1 pilih metode encoding prediktor kategorik tingkat kerja svm multiclass tahap preprocessing 2 kembang algoritma svm multiclass proportional class constraint svmproclass teliti ordinal encoding hasil algoritma svmproclass tahap utama fase prediksi kelas fase geser kelas birthdeath process algoritma svmproclass terap dataset ukt hasil dataset besifat separable imbalanced bas proporsi kelas mana kerja dataset hasil svmproclass milik nilai akurasi f1score ratarata 9922 beda signifikan 5 kerja dataset svmproclassthere are three important principles in grouping single tuition fees ukt first the ukt grouping must be based on the socioeconomic ability level of the students parents second universities must achieve nontax state income pnbp through receipt of ukt payments based on set targets and third the public university as government institutions have a social responsibility to accept a minimum of 20 of students from underprivileged families these three principles are the main background for this research so it is necessary to develop a ukt classification method that takes into account university revenue targets and minimum proportion requirements in the low ukt group to solve this problem it is necessary to develop a classification algorithm that can accommodate constraint factors the constraint factors that must be present are the proportion of a certain class from the classification results proportional class constraint and the minimum amount of ukt receipts revenue the type of predictor variable used in the case study is categorical the results of the literature review found that the classification method for categorical predictors that can be directly used is the kernel density classification kdc based method however the kdc method has limitations in adding constraints to the classification model apart from that many studies show that its performance can still be superior to the support vector machine svm method there is a limitation to the svm method namely that the algorithm input can not be of the categorical type thus this research provides contributions namely 1 selecting a categorical predictor encoding method that is able to improve multiclass svm performance at the preprocessing stage and 2 developing a multiclass svm algorithm with proportional class constraints svmproclass this research uses ordinal encoding and produces the svmproclass algorithm with two main stages namely the class prediction phase and the class shift phase birthdeath process next the svmproclass algorithm is applied to the ukt dataset to produce a separable and imbalanced dataset based on class proportions where the performance of the svmproclass dataset has an average f1score accuracy value of 9922 and it is significantly different from the performance of the dataset without svmproclass with 5
Optimisasi Rate of Penetration (ROP) pada Operasi Drilling menggunakan Predictive Modelling dan Particle Swarm Optimization (PSO) untuk Meminimalkan Waktu dan Biaya (Studi Kasus : Sumur X Lapangan Mudi).,"Zahra, Haya Aqilah",http://repository.its.ac.id/109285/,"Operasi pemboran diketahui merepresentasikan 30% dari total biaya produksi pada sumur minyak dan gas. Biaya pemboran memiliki hubungan yang erat dengan waktu pemboran, yang mana semakin singkat waktu pemboran, maka biaya pemboran akan semakin murah, dan begitu juga sebaliknya. Parameter utama yang mempengaruhi secara langsung waktu pemboran adalah Rate of Penetration (ROP). Untuk itu, dalam memecahkan masalah biaya dan waktu pemboran, dilakukan penelitian untuk mengoptimasi ROP dengan mempertimbangan tiga parameter utama, yaitu Weight on Bit (WOB), Rotation per Minute(RPM),dan Flowrate. Metode Predictive Modelling dan Particle Swarm Optimization (PSO) diterapkan untuk mengoptimisasi ROP. Metode Predictive Modelling merupakan metode data-driven based yang menggantikan persamaan tradisional. Penelitian ini menggunakan empat model regresi, memungkinkan model untuk dapat mengidentifikasi hubungan kompleks antara parameter pemboran dengan membaca datahistoris yang diberikan. Empat algoritma predictive modelling yang disimulasikan lalu dievaluasi menggunakan nilai RMSE,R², MAE, dan MAPE. Random Forest Regressor dipilih sebagai model yang paling akurat dengan nilai R² mencapai 0.92. Optimisasi ROP memberikan hasil yang signifikan, yaitu pengurangan waktu pemboran sampai 6.2 hari dan biaya hingga Rp1,812,531.93 atau 16% lebih murah dari biaya aktual.=====================================================================================================================================Drilling operations are known to represent 30% of the total production cost in oil and gas wells. Drilling costs are closely related to drilling time; the shorter the drilling time, the cheaper the drilling costs, and vice versa. The primary parameter that directly influences drilling time is the Rate of Penetration (ROP). Therefore, to address the issues of drilling costs and time, a study was conducted to optimize ROP by considering three main parameters: Weight on Bit (WOB), Revolutions per Minute (RPM), and Flowrate. Predictive Modeling and Particle Swarm Optimization (PSO) methods were applied to optimize ROP. Predictive Modeling is a data-driven method that replaces traditional equations. This study utilized four regression models, allowing the model to identify complex relationships between drilling parameters by reading the provided historical data. Four predictive modeling algorithms were simulated and then evaluated using RMSE, R², MAE, and MAPE values. Random Forest Regressor was selected as the most accurate model with an R² value of 0.92. The ROP optimization yielded significant results, reducing drilling time by up to 6.2 days and costs by Rp1,812,531.93 or 16% cheaper than actual costs.",optimisasi rate of penetration rop operasi drilling predictive modelling particle swarm optimization pso minimal biaya studi sumur x lapang mud,operasi bor representasi 30 total biaya produksi sumur minyak gas biaya bor milik hubung erat bor singkat bor biaya bor murah parameter utama pengaruh langsung bor rate of penetration rop pecah biaya bor teliti mengoptimasi rop timbang parameter utama weight on bit wob rotation minuterpmdan flowrate metode predictive modelling particle swarm optimization pso terap mengoptimisasi rop metode predictive modelling metode datadriven based ganti sama tradisional teliti model regresi model identifikasi hubung kompleks parameter bor baca datahistoris algoritma predictive modelling simulasi evaluasi nilai rmser mae mape random forest regressor pilih model akurat nilai r capai 092 optimisasi rop hasil signifikan kurang bor 62 biaya rp181253193 16 murah biaya aktualdrilling operations are known to represent 30 of the total production cost in oil and gas wells drilling costs are closely related to drilling time the shorter the drilling time the cheaper the drilling costs and vice versa the primary parameter that directly influences drilling time is the rate of penetration rop therefore to address the issues of drilling costs and time a study was conducted to optimize rop by considering three main parameters weight on bit wob revolutions mute rpm and flowrate predictive modeling and particle swarm optimization pso methods were applied to optimize rop predictive modeling is a datadriven method that replaces traditional equations this study utilized four regression models allowing the model to identify complex relationships between drilling parameters by reading the provided historical data four predictive modeling algorithms were simulated and then evaluated using rmse r mae and mape values random forest regressor was selected as the most accurate model with an r value of 092 the rop optimization yielded significant results reducing drilling time by up to 62 days and costs by rp181253193 or 16 cheaper than actual costs
Deteksi Nodul Paru Pada Citra Ct Scan Berbasis Fitur Glcm Dan Rlm Menggunakan Metode Support Vector Machine (SVM).,"Zai'mah, Permatasari",http://repository.its.ac.id/87680/,"Kanker paru-paru merupakan salah satu jenis kanker yang memiliki  tingkat kematian yang tinggi di dunia. Untuk mengurangi angka kematian  tersebut, maka perlu dilakukan pendeteksian secara dini sehingga pasien dapat  diobati secepat mungkin. Salah satu proses pendeteksian yang dilakukan adalah  dengan cara screening yaitu menggunakan Computed Tomography (CT) scan.  Penelitian ini bertujuan untuk mengembangkan metode yang dapat membedakan karakteristik densitas nodul paru normal dan tidak. Tahap ekstraksi fitur tekstur  berbasis histogram dan Gray Level Co-occurrence Matrix (GLCM) dan (Run Length Matrix) RLM. Nilai fitur tekstur kemudian digunakan sebagai masukan  tahap klasifikasi menggunakan metode Support Vector Machine (SVM) dan  Neural Network Backpropagation. Berdasarkan pada hasil eksperimen,didapatkan bahwa metode SVM dapat mengenali nodul paru lebih baik dibandingkan aNN Backpropagation dengan nilai akurasi terbaik 85,3% sedangan nilai akursi aNN Backpropagation 77.7 % .Hasil ini menyediakan informasi bahwa deteksi nodul paru berdasarkan fitur glcm dan rlm yang dapat dideteksi lebih baik. Lebih jauh, memilih parameter C dan γ pada SVM dan nilai learning dan hidden layer pada aNN Backpropagation untuk mendapatkan hasil klasifikasi yang optimal dapat diemplementasikan untuk mendapatkan hasil yang lebih baik. Kata kunci : Kanker paru-paru, glcm, rlm, Klasifikasi fitur, aNN Backpropagation",deteksi nodul paru citra ct scan bas fitur glcm rlm metode support vector machine svm,kanker paruparu salah jenis kanker milik tingkat mati dunia kurang angka mati deteksi pasien obat cepat salah proses deteksi screening computed tomography ct scan teliti tuju kembang metode beda karakteristik densitas nodul paru normal tahap ekstraksi fitur tekstur bas histogram gray level cooccurrence matrix glcm run length matrix rlm nilai fitur tekstur masuk tahap klasifikasi metode support vector machine svm neural network backpropagation dasar hasil eksperimendidapatkan metode svm nali nodul paru banding ann backpropagation nilai akurasi baik 853 sedang nilai akursi ann backpropagation 777 hasil sedia informasi deteksi nodul paru dasar fitur glcm rlm deteksi pilih parameter c  svm nilai learning hidden layer ann backpropagation hasil klasifikasi optimal diemplementasikan hasil kunci kanker paruparu glcm rlm klasifikasi fitur ann backpropagation
